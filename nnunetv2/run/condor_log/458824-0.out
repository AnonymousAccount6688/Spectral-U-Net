OrderedDict([('self', <Parameter "self">), ('plans', <Parameter "plans: dict">), ('configuration', <Parameter "configuration: str">), ('fold', <Parameter "fold: int">), ('dataset_json', <Parameter "dataset_json: dict">), ('unpack_dataset', <Parameter "unpack_dataset: bool = True">), ('device', <Parameter "device: torch.device = device(type='cuda')">), ('debug', <Parameter "debug=True">), ('job_id', <Parameter "job_id=None">)])
Using device: cuda:0
==========================initial_lr: 0.005===========================
2023-09-03 13:43:23.040735: I am training on qa-rtx6k-022.crc.nd.edu
2023-09-03 13:43:23.042617: output folder: /afs/crc.nd.edu/user/y/ypeng4/data/trained_models/Dataset124_ISIC2018/ISICTrainer__nnUNetPlans__2d/458821_my_unet_FusedMBConv_16/fold_0

#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################

===============use SpatialAtt + ChannelAtt and My attention layer===============
model: PVTNetwork_4(
  (backbone): pvt_v2_b2(
    (patch_embed1): OverlapPatchEmbed(
      (proj): Conv2d(3, 64, kernel_size=(7, 7), stride=(4, 4), padding=(3, 3))
      (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
    )
    (patch_embed2): OverlapPatchEmbed(
      (proj): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
    )
    (patch_embed3): OverlapPatchEmbed(
      (proj): Conv2d(128, 320, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
    )
    (patch_embed4): OverlapPatchEmbed(
      (proj): Conv2d(320, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    )
    (block1): ModuleList(
      (0): Block(
        (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=64, out_features=64, bias=True)
          (kv): Linear(in_features=64, out_features=128, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=64, out_features=64, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (sr): Conv2d(64, 64, kernel_size=(8, 8), stride=(8, 8))
          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (drop_path): Identity()
        (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=64, out_features=512, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
          )
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=512, out_features=64, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (1): Block(
        (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=64, out_features=64, bias=True)
          (kv): Linear(in_features=64, out_features=128, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=64, out_features=64, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (sr): Conv2d(64, 64, kernel_size=(8, 8), stride=(8, 8))
          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (drop_path): DropPath(drop_prob=0.007)
        (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=64, out_features=512, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
          )
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=512, out_features=64, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (2): Block(
        (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=64, out_features=64, bias=True)
          (kv): Linear(in_features=64, out_features=128, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=64, out_features=64, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (sr): Conv2d(64, 64, kernel_size=(8, 8), stride=(8, 8))
          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (drop_path): DropPath(drop_prob=0.013)
        (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=64, out_features=512, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
          )
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=512, out_features=64, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
    )
    (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
    (block2): ModuleList(
      (0): Block(
        (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=128, out_features=128, bias=True)
          (kv): Linear(in_features=128, out_features=256, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=128, out_features=128, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (sr): Conv2d(128, 128, kernel_size=(4, 4), stride=(4, 4))
          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (drop_path): DropPath(drop_prob=0.020)
        (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=128, out_features=1024, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
          )
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=1024, out_features=128, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (1): Block(
        (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=128, out_features=128, bias=True)
          (kv): Linear(in_features=128, out_features=256, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=128, out_features=128, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (sr): Conv2d(128, 128, kernel_size=(4, 4), stride=(4, 4))
          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (drop_path): DropPath(drop_prob=0.027)
        (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=128, out_features=1024, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
          )
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=1024, out_features=128, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (2): Block(
        (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=128, out_features=128, bias=True)
          (kv): Linear(in_features=128, out_features=256, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=128, out_features=128, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (sr): Conv2d(128, 128, kernel_size=(4, 4), stride=(4, 4))
          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (drop_path): DropPath(drop_prob=0.033)
        (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=128, out_features=1024, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
          )
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=1024, out_features=128, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (3): Block(
        (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=128, out_features=128, bias=True)
          (kv): Linear(in_features=128, out_features=256, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=128, out_features=128, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (sr): Conv2d(128, 128, kernel_size=(4, 4), stride=(4, 4))
          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (drop_path): DropPath(drop_prob=0.040)
        (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=128, out_features=1024, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
          )
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=1024, out_features=128, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
    )
    (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
    (block3): ModuleList(
      (0): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
        )
        (drop_path): DropPath(drop_prob=0.047)
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (1): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
        )
        (drop_path): DropPath(drop_prob=0.053)
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (2): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
        )
        (drop_path): DropPath(drop_prob=0.060)
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (3): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
        )
        (drop_path): DropPath(drop_prob=0.067)
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (4): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
        )
        (drop_path): DropPath(drop_prob=0.073)
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (5): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
        )
        (drop_path): DropPath(drop_prob=0.080)
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
    )
    (norm3): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
    (block4): ModuleList(
      (0): Block(
        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=512, out_features=512, bias=True)
          (kv): Linear(in_features=512, out_features=1024, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (drop_path): DropPath(drop_prob=0.087)
        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)
          )
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (1): Block(
        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=512, out_features=512, bias=True)
          (kv): Linear(in_features=512, out_features=1024, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (drop_path): DropPath(drop_prob=0.093)
        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)
          )
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (2): Block(
        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=512, out_features=512, bias=True)
          (kv): Linear(in_features=512, out_features=1024, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (drop_path): DropPath(drop_prob=0.100)
        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)
          )
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
    )
    (norm4): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
  )
  (ca_1): ChannelAttention(
    (avg_pool): AdaptiveAvgPool2d(output_size=1)
    (max_pool): AdaptiveMaxPool2d(output_size=1)
    (fc1): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (relu1): ReLU()
    (fc2): Conv2d(4, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (sigmoid): Sigmoid()
  )
  (sa_1): SpatialAttention(
    (conv1): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
    (sigmoid): Sigmoid()
  )
  (ca_2): ChannelAttention(
    (avg_pool): AdaptiveAvgPool2d(output_size=1)
    (max_pool): AdaptiveMaxPool2d(output_size=1)
    (fc1): Conv2d(128, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (relu1): ReLU()
    (fc2): Conv2d(8, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (sigmoid): Sigmoid()
  )
  (sa_2): SpatialAttention(
    (conv1): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
    (sigmoid): Sigmoid()
  )
  (ca_3): ChannelAttention(
    (avg_pool): AdaptiveAvgPool2d(output_size=1)
    (max_pool): AdaptiveMaxPool2d(output_size=1)
    (fc1): Conv2d(320, 20, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (relu1): ReLU()
    (fc2): Conv2d(20, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (sigmoid): Sigmoid()
  )
  (sa_3): SpatialAttention(
    (conv1): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
    (sigmoid): Sigmoid()
  )
  (ca_4): ChannelAttention(
    (avg_pool): AdaptiveAvgPool2d(output_size=1)
    (max_pool): AdaptiveMaxPool2d(output_size=1)
    (fc1): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (relu1): ReLU()
    (fc2): Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (sigmoid): Sigmoid()
  )
  (sa_4): SpatialAttention(
    (conv1): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
    (sigmoid): Sigmoid()
  )
  (Translayer_1): BasicConv2d(
    (conv): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (Translayer_2): BasicConv2d(
    (conv): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (Translayer_3): BasicConv2d(
    (conv): Conv2d(320, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (Translayer_4): BasicConv2d(
    (conv): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (attention_1): AttentionLayer(
    (convs): ModuleList(
      (0-3): 4 x Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
  )
  (attention_2): AttentionLayer(
    (convs): ModuleList(
      (0-3): 4 x Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
  )
  (attention_3): AttentionLayer(
    (convs): ModuleList(
      (0-3): 4 x Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
  )
  (attention_4): AttentionLayer(
    (convs): ModuleList(
      (0-3): 4 x Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
  )
  (seg_outs): ModuleList(
    (0-3): 4 x Conv2d(32, 2, kernel_size=(1, 1), stride=(1, 1))
  )
  (deconv2): ConvTranspose2d(32, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
  (deconv2_conv): BasicConv2d(
    (conv): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (deconv3): ConvTranspose2d(32, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
  (deconv3_conv): BasicConv2d(
    (conv): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (deconv4): ConvTranspose2d(32, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
  (deconv4_conv): BasicConv2d(
    (conv): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
)
===============<class 'nnunetv2.training.network.model.dim2.pvt.pvt_4.PVTNetwork_4'>================
ds wegihts: [0.53333333 0.26666667 0.13333333 0.06666667]
loading from : /afs/crc.nd.edu/user/y/ypeng4/data/trained_models/Dataset124_ISIC2018/ISICTrainer__nnUNetPlans__2d/458821_my_unet_FusedMBConv_16/fold_0/checkpoint_latest.pth

This is the configuration used by this training:
Configuration name: 2d
 {'data_identifier': 'nnUNetPlans_2d', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 49, 'patch_size': [256, 256], 'median_image_size_in_voxels': [256.0, 256.0], 'spacing': [1.0, 1.0], 'normalization_schemes': ['ZScoreNormalization', 'ZScoreNormalization', 'ZScoreNormalization'], 'use_mask_for_norm': [False, False, False], 'UNet_class_name': 'PlainConvUNet', 'nnUNet_UNet': False, 'my_net_class': 'pvt_4', 'UNet_base_num_features': 32, 'n_conv_per_stage_encoder': [2, 2, 2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2, 2, 2], 'num_pool_per_axis': [6, 6], 'pool_op_kernel_sizes': [[1, 1], [2, 2], [2, 2], [2, 2], [2, 2], [2, 2], [2, 2]], 'conv_kernel_sizes': [[3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3]], 'unet_max_num_features': 512, 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'batch_dice': True} 

These are the global plan.json settings:
 {'dataset_name': 'Dataset124_ISIC2018', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [999.0, 1.0, 1.0], 'original_median_shape_after_transp': [1, 256, 256], 'image_reader_writer': 'NaturalImage2DIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 255.0, 'mean': 160.57754516601562, 'median': 164.0, 'min': 0.0, 'percentile_00_5': 29.0, 'percentile_99_5': 253.0, 'std': 42.08180618286133}, '1': {'max': 255.0, 'mean': 111.1130142211914, 'median': 113.0, 'min': 0.0, 'percentile_00_5': 8.0, 'percentile_99_5': 222.0, 'std': 43.864933013916016}, '2': {'max': 255.0, 'mean': 91.45153045654297, 'median': 91.0, 'min': 0.0, 'percentile_00_5': 4.0, 'percentile_99_5': 209.0, 'std': 43.73163604736328}}} 

2023-09-03 13:43:29.791101: unpacking dataset...
2023-09-03 13:43:45.573075: unpacking done...
2023-09-03 13:43:45.574542: do_dummy_2d_data_aug: False
2023-09-03 13:43:45.594770: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 13:43:45.595892: The split file contains 1 splits.
2023-09-03 13:43:45.596445: Desired fold for training: 0
2023-09-03 13:43:45.596836: This split has 1886 training and 808 validation cases.
==================batch size: 49==================
2023-09-03 13:43:45.632095: Unable to plot network architecture:
2023-09-03 13:43:45.632456: No module named 'hiddenlayer'
PVTNetwork_4
===================debug: False===================
2023-09-03 13:43:47.351690: 
2023-09-03 13:43:47.352485: Epoch 10
2023-09-03 13:43:47.353101: Current learning rate: backbone 0.00096995, others 0.00096995
2023-09-03 13:43:47.353609: start training, 250
==========num_iterations_per_epoch: 250===========
using pin_memory on device 0
2023-09-03 13:45:01.050536: finished training epoch 10
2023-09-03 13:45:01.117023: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 13:45:01.118500: The split file contains 1 splits.
2023-09-03 13:45:01.119117: Desired fold for training: 0
2023-09-03 13:45:01.119575: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 13:50:10.647329: dsc: 90.28%
2023-09-03 13:50:10.648286: miou: 82.28%
2023-09-03 13:50:10.648890: acc: 94.96%, sen: 93.03%, spe: 95.61%
2023-09-03 13:50:10.649886: current best miou: 0.8227859298297809 at epoch: 10, (10, 0.8227859298297809, 0.9027784517808034)
2023-09-03 13:50:10.650656: current best dsc: 0.9027784517808034 at epoch: 10, (10, 0.8227859298297809, 0.9027784517808034)
2023-09-03 13:50:12.140163: finished real validation
using pin_memory on device 0
2023-09-03 13:50:17.380487: train_loss -1.3032
2023-09-03 13:50:17.381930: val_loss -1.134
2023-09-03 13:50:17.383578: Pseudo dice [0.8989]
2023-09-03 13:50:17.384341: Epoch time: 390.03 s
2023-09-03 13:50:17.384882: Yayy! New best EMA pseudo Dice: 0.8901
2023-09-03 13:50:20.145605: 
2023-09-03 13:50:20.147104: Epoch 11
2023-09-03 13:50:20.148094: Current learning rate: backbone 0.00096694, others 0.00096694
2023-09-03 13:50:20.149901: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 13:51:22.997340: finished training epoch 11
2023-09-03 13:51:23.026225: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 13:51:23.027692: The split file contains 1 splits.
2023-09-03 13:51:23.028471: Desired fold for training: 0
2023-09-03 13:51:23.029181: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 13:56:54.944057: dsc: 91.12%
2023-09-03 13:56:54.945154: miou: 83.68%
2023-09-03 13:56:54.945789: acc: 95.47%, sen: 92.36%, spe: 96.52%
2023-09-03 13:56:54.946695: current best miou: 0.8368015308606969 at epoch: 11, (11, 0.8368015308606969, 0.9111507332733816)
2023-09-03 13:56:54.947349: current best dsc: 0.9111507332733816 at epoch: 11, (11, 0.8368015308606969, 0.9111507332733816)
2023-09-03 13:56:56.545812: finished real validation
2023-09-03 13:57:00.915430: train_loss -1.3161
2023-09-03 13:57:00.916718: val_loss -1.1795
2023-09-03 13:57:00.917808: Pseudo dice [0.9112]
2023-09-03 13:57:00.918506: Epoch time: 400.77 s
2023-09-03 13:57:00.919079: Yayy! New best EMA pseudo Dice: 0.8922
2023-09-03 13:57:03.567955: 
2023-09-03 13:57:03.569616: Epoch 12
2023-09-03 13:57:03.570720: Current learning rate: backbone 0.00096393, others 0.00096393
2023-09-03 13:57:03.572546: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 13:58:06.154069: finished training epoch 12
2023-09-03 13:58:06.198035: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 13:58:06.200777: The split file contains 1 splits.
2023-09-03 13:58:06.201817: Desired fold for training: 0
2023-09-03 13:58:06.202732: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 14:03:44.693364: dsc: 90.55%
2023-09-03 14:03:44.695319: miou: 82.73%
2023-09-03 14:03:44.696046: acc: 95.29%, sen: 89.76%, spe: 97.14%
2023-09-03 14:03:44.697999: current best miou: 0.8368015308606969 at epoch: 11, (11, 0.8368015308606969, 0.9111507332733816)
2023-09-03 14:03:44.699496: current best dsc: 0.9111507332733816 at epoch: 11, (11, 0.8368015308606969, 0.9111507332733816)
2023-09-03 14:03:44.700206: finished real validation
2023-09-03 14:03:49.155439: train_loss -1.3177
2023-09-03 14:03:49.156635: val_loss -1.1869
2023-09-03 14:03:49.157783: Pseudo dice [0.9096]
2023-09-03 14:03:49.158664: Epoch time: 405.59 s
2023-09-03 14:03:49.159307: Yayy! New best EMA pseudo Dice: 0.894
2023-09-03 14:03:51.879114: 
2023-09-03 14:03:51.880146: Epoch 13
2023-09-03 14:03:51.880803: Current learning rate: backbone 0.00096091, others 0.00096091
2023-09-03 14:03:51.882305: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 14:04:54.146282: finished training epoch 13
2023-09-03 14:04:54.175797: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 14:04:54.178123: The split file contains 1 splits.
2023-09-03 14:04:54.178787: Desired fold for training: 0
2023-09-03 14:04:54.179376: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 14:10:27.671673: dsc: 91.12%
2023-09-03 14:10:27.672708: miou: 83.69%
2023-09-03 14:10:27.673307: acc: 95.54%, sen: 91.11%, spe: 97.02%
2023-09-03 14:10:27.674374: current best miou: 0.8369482446326413 at epoch: 13, (13, 0.8369482446326413, 0.9112376977175172)
2023-09-03 14:10:27.674932: current best dsc: 0.9112376977175172 at epoch: 13, (13, 0.8369482446326413, 0.9112376977175172)
2023-09-03 14:10:29.364123: finished real validation
2023-09-03 14:10:33.773524: train_loss -1.3292
2023-09-03 14:10:33.775267: val_loss -1.1676
2023-09-03 14:10:33.777283: Pseudo dice [0.9106]
2023-09-03 14:10:33.779226: Epoch time: 401.9 s
2023-09-03 14:10:33.780245: Yayy! New best EMA pseudo Dice: 0.8956
2023-09-03 14:10:36.551653: 
2023-09-03 14:10:36.552823: Epoch 14
2023-09-03 14:10:36.553542: Current learning rate: backbone 0.0009579, others 0.0009579
2023-09-03 14:10:36.554637: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 14:11:38.808686: finished training epoch 14
2023-09-03 14:11:38.837336: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 14:11:38.838754: The split file contains 1 splits.
2023-09-03 14:11:38.839373: Desired fold for training: 0
2023-09-03 14:11:38.839872: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 14:17:24.870694: dsc: 90.91%
2023-09-03 14:17:24.871989: miou: 83.34%
2023-09-03 14:17:24.872716: acc: 95.50%, sen: 89.53%, spe: 97.50%
2023-09-03 14:17:24.873785: current best miou: 0.8369482446326413 at epoch: 13, (13, 0.8369482446326413, 0.9112376977175172)
2023-09-03 14:17:24.874396: current best dsc: 0.9112376977175172 at epoch: 13, (13, 0.8369482446326413, 0.9112376977175172)
2023-09-03 14:17:24.874912: finished real validation
2023-09-03 14:17:29.311657: train_loss -1.3376
2023-09-03 14:17:29.313143: val_loss -1.1732
2023-09-03 14:17:29.314406: Pseudo dice [0.909]
2023-09-03 14:17:29.315094: Epoch time: 412.76 s
2023-09-03 14:17:29.315689: Yayy! New best EMA pseudo Dice: 0.897
2023-09-03 14:17:32.004460: 
2023-09-03 14:17:32.005611: Epoch 15
2023-09-03 14:17:32.006462: Current learning rate: backbone 0.00095489, others 0.00095489
2023-09-03 14:17:32.007705: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 14:18:34.032934: finished training epoch 15
2023-09-03 14:18:34.069485: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 14:18:34.071158: The split file contains 1 splits.
2023-09-03 14:18:34.071816: Desired fold for training: 0
2023-09-03 14:18:34.072445: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 14:24:15.868646: dsc: 90.89%
2023-09-03 14:24:15.870375: miou: 83.31%
2023-09-03 14:24:15.871341: acc: 95.41%, sen: 91.18%, spe: 96.83%
2023-09-03 14:24:15.872587: current best miou: 0.8369482446326413 at epoch: 13, (13, 0.8369482446326413, 0.9112376977175172)
2023-09-03 14:24:15.873303: current best dsc: 0.9112376977175172 at epoch: 13, (13, 0.8369482446326413, 0.9112376977175172)
2023-09-03 14:24:15.874109: finished real validation
2023-09-03 14:24:20.324711: train_loss -1.3388
2023-09-03 14:24:20.326358: val_loss -1.1726
2023-09-03 14:24:20.327497: Pseudo dice [0.9108]
2023-09-03 14:24:20.328237: Epoch time: 408.32 s
2023-09-03 14:24:20.328851: Yayy! New best EMA pseudo Dice: 0.8983
2023-09-03 14:24:23.056724: 
2023-09-03 14:24:23.057883: Epoch 16
2023-09-03 14:24:23.058694: Current learning rate: backbone 0.00095187, others 0.00095187
2023-09-03 14:24:23.060010: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 14:25:25.127908: finished training epoch 16
2023-09-03 14:25:25.157387: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 14:25:25.159015: The split file contains 1 splits.
2023-09-03 14:25:25.159683: Desired fold for training: 0
2023-09-03 14:25:25.160212: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 14:30:59.168975: dsc: 90.83%
2023-09-03 14:30:59.170226: miou: 83.20%
2023-09-03 14:30:59.170835: acc: 95.29%, sen: 92.76%, spe: 96.14%
2023-09-03 14:30:59.171712: current best miou: 0.8369482446326413 at epoch: 13, (13, 0.8369482446326413, 0.9112376977175172)
2023-09-03 14:30:59.172378: current best dsc: 0.9112376977175172 at epoch: 13, (13, 0.8369482446326413, 0.9112376977175172)
2023-09-03 14:30:59.172945: finished real validation
2023-09-03 14:31:03.496275: train_loss -1.3463
2023-09-03 14:31:03.497432: val_loss -1.1949
2023-09-03 14:31:03.498386: Pseudo dice [0.9143]
2023-09-03 14:31:03.499117: Epoch time: 400.44 s
2023-09-03 14:31:03.499843: Yayy! New best EMA pseudo Dice: 0.8999
2023-09-03 14:31:06.375145: 
2023-09-03 14:31:06.376329: Epoch 17
2023-09-03 14:31:06.377034: Current learning rate: backbone 0.00094885, others 0.00094885
2023-09-03 14:31:06.378270: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 14:32:09.169372: finished training epoch 17
2023-09-03 14:32:09.207391: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 14:32:09.209176: The split file contains 1 splits.
2023-09-03 14:32:09.209878: Desired fold for training: 0
2023-09-03 14:32:09.210474: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 14:38:02.151886: dsc: 91.08%
2023-09-03 14:38:02.154195: miou: 83.62%
2023-09-03 14:38:02.155472: acc: 95.56%, sen: 90.15%, spe: 97.37%
2023-09-03 14:38:02.157591: current best miou: 0.8369482446326413 at epoch: 13, (13, 0.8369482446326413, 0.9112376977175172)
2023-09-03 14:38:02.158709: current best dsc: 0.9112376977175172 at epoch: 13, (13, 0.8369482446326413, 0.9112376977175172)
2023-09-03 14:38:02.159451: finished real validation
2023-09-03 14:38:06.623379: train_loss -1.351
2023-09-03 14:38:06.624728: val_loss -1.1506
2023-09-03 14:38:06.625861: Pseudo dice [0.9056]
2023-09-03 14:38:06.626719: Epoch time: 420.25 s
2023-09-03 14:38:06.627342: Yayy! New best EMA pseudo Dice: 0.9005
2023-09-03 14:38:09.323226: 
2023-09-03 14:38:09.324447: Epoch 18
2023-09-03 14:38:09.325237: Current learning rate: backbone 0.00094583, others 0.00094583
2023-09-03 14:38:09.326544: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 14:39:11.809286: finished training epoch 18
2023-09-03 14:39:11.838496: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 14:39:11.839862: The split file contains 1 splits.
2023-09-03 14:39:11.840547: Desired fold for training: 0
2023-09-03 14:39:11.841165: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 14:45:02.411966: dsc: 91.00%
2023-09-03 14:45:02.413315: miou: 83.48%
2023-09-03 14:45:02.414004: acc: 95.49%, sen: 90.72%, spe: 97.09%
2023-09-03 14:45:02.415218: current best miou: 0.8369482446326413 at epoch: 13, (13, 0.8369482446326413, 0.9112376977175172)
2023-09-03 14:45:02.415910: current best dsc: 0.9112376977175172 at epoch: 13, (13, 0.8369482446326413, 0.9112376977175172)
2023-09-03 14:45:02.416574: finished real validation
2023-09-03 14:45:06.824485: train_loss -1.354
2023-09-03 14:45:06.825981: val_loss -1.1714
2023-09-03 14:45:06.827238: Pseudo dice [0.9106]
2023-09-03 14:45:06.828127: Epoch time: 417.5 s
2023-09-03 14:45:06.828874: Yayy! New best EMA pseudo Dice: 0.9015
2023-09-03 14:45:09.593436: 
2023-09-03 14:45:09.594540: Epoch 19
2023-09-03 14:45:09.595453: Current learning rate: backbone 0.00094282, others 0.00094282
2023-09-03 14:45:09.596898: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 14:46:12.452534: finished training epoch 19
2023-09-03 14:46:12.494196: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 14:46:12.496839: The split file contains 1 splits.
2023-09-03 14:46:12.497924: Desired fold for training: 0
2023-09-03 14:46:12.498775: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 14:52:28.480756: dsc: 90.85%
2023-09-03 14:52:28.482818: miou: 83.23%
2023-09-03 14:52:28.483628: acc: 95.43%, sen: 90.25%, spe: 97.17%
2023-09-03 14:52:28.485688: current best miou: 0.8369482446326413 at epoch: 13, (13, 0.8369482446326413, 0.9112376977175172)
2023-09-03 14:52:28.486577: current best dsc: 0.9112376977175172 at epoch: 13, (13, 0.8369482446326413, 0.9112376977175172)
2023-09-03 14:52:28.487300: finished real validation
2023-09-03 14:52:32.964990: train_loss -1.3609
2023-09-03 14:52:32.966389: val_loss -1.1721
2023-09-03 14:52:32.967564: Pseudo dice [0.9121]
2023-09-03 14:52:32.968382: Epoch time: 443.37 s
2023-09-03 14:52:35.101922: Yayy! New best EMA pseudo Dice: 0.9026
2023-09-03 14:52:37.789259: 
2023-09-03 14:52:37.790661: Epoch 20
2023-09-03 14:52:37.791436: Current learning rate: backbone 0.00093979, others 0.00093979
2023-09-03 14:52:37.792826: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 14:53:39.972402: finished training epoch 20
2023-09-03 14:53:40.076092: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 14:53:40.084976: The split file contains 1 splits.
2023-09-03 14:53:40.089319: Desired fold for training: 0
2023-09-03 14:53:40.092948: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 15:00:00.791707: dsc: 90.72%
2023-09-03 15:00:00.793228: miou: 83.02%
2023-09-03 15:00:00.793960: acc: 95.32%, sen: 91.01%, spe: 96.77%
2023-09-03 15:00:00.795156: current best miou: 0.8369482446326413 at epoch: 13, (13, 0.8369482446326413, 0.9112376977175172)
2023-09-03 15:00:00.795896: current best dsc: 0.9112376977175172 at epoch: 13, (13, 0.8369482446326413, 0.9112376977175172)
2023-09-03 15:00:00.796504: finished real validation
2023-09-03 15:00:05.241486: train_loss -1.3637
2023-09-03 15:00:05.242662: val_loss -1.1622
2023-09-03 15:00:05.243605: Pseudo dice [0.9091]
2023-09-03 15:00:05.244326: Epoch time: 447.45 s
2023-09-03 15:00:05.244983: Yayy! New best EMA pseudo Dice: 0.9032
2023-09-03 15:00:07.988439: 
2023-09-03 15:00:07.989688: Epoch 21
2023-09-03 15:00:07.990453: Current learning rate: backbone 0.00093677, others 0.00093677
2023-09-03 15:00:07.991647: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 15:01:10.832222: finished training epoch 21
2023-09-03 15:01:10.861744: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 15:01:10.863451: The split file contains 1 splits.
2023-09-03 15:01:10.864255: Desired fold for training: 0
2023-09-03 15:01:10.864973: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 15:07:12.153951: dsc: 90.77%
2023-09-03 15:07:12.155629: miou: 83.11%
2023-09-03 15:07:12.156865: acc: 95.32%, sen: 91.45%, spe: 96.62%
2023-09-03 15:07:12.158798: current best miou: 0.8369482446326413 at epoch: 13, (13, 0.8369482446326413, 0.9112376977175172)
2023-09-03 15:07:12.159857: current best dsc: 0.9112376977175172 at epoch: 13, (13, 0.8369482446326413, 0.9112376977175172)
2023-09-03 15:07:12.161000: finished real validation
2023-09-03 15:07:16.490329: train_loss -1.3701
2023-09-03 15:07:16.492677: val_loss -1.1518
2023-09-03 15:07:16.494435: Pseudo dice [0.9071]
2023-09-03 15:07:16.495288: Epoch time: 428.5 s
2023-09-03 15:07:16.496616: Yayy! New best EMA pseudo Dice: 0.9036
2023-09-03 15:07:19.222379: 
2023-09-03 15:07:19.223765: Epoch 22
2023-09-03 15:07:19.224637: Current learning rate: backbone 0.00093375, others 0.00093375
2023-09-03 15:07:19.226013: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 15:08:21.735170: finished training epoch 22
2023-09-03 15:08:21.773709: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 15:08:21.775276: The split file contains 1 splits.
2023-09-03 15:08:21.776013: Desired fold for training: 0
2023-09-03 15:08:21.777894: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 15:14:12.062544: dsc: 90.71%
2023-09-03 15:14:12.063623: miou: 83.00%
2023-09-03 15:14:12.064218: acc: 95.32%, sen: 90.75%, spe: 96.86%
2023-09-03 15:14:12.065363: current best miou: 0.8369482446326413 at epoch: 13, (13, 0.8369482446326413, 0.9112376977175172)
2023-09-03 15:14:12.066272: current best dsc: 0.9112376977175172 at epoch: 13, (13, 0.8369482446326413, 0.9112376977175172)
2023-09-03 15:14:12.066837: finished real validation
2023-09-03 15:14:16.434916: train_loss -1.3714
2023-09-03 15:14:16.436262: val_loss -1.1531
2023-09-03 15:14:16.437358: Pseudo dice [0.9108]
2023-09-03 15:14:16.438127: Epoch time: 417.21 s
2023-09-03 15:14:16.438771: Yayy! New best EMA pseudo Dice: 0.9043
2023-09-03 15:14:19.046221: 
2023-09-03 15:14:19.047569: Epoch 23
2023-09-03 15:14:19.048990: Current learning rate: backbone 0.00093073, others 0.00093073
2023-09-03 15:14:19.051056: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 15:15:21.605374: finished training epoch 23
2023-09-03 15:15:21.645125: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 15:15:21.647110: The split file contains 1 splits.
2023-09-03 15:15:21.647866: Desired fold for training: 0
2023-09-03 15:15:21.648522: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 15:21:09.159366: dsc: 90.70%
2023-09-03 15:21:09.160557: miou: 82.98%
2023-09-03 15:21:09.161245: acc: 95.29%, sen: 91.34%, spe: 96.61%
2023-09-03 15:21:09.162338: current best miou: 0.8369482446326413 at epoch: 13, (13, 0.8369482446326413, 0.9112376977175172)
2023-09-03 15:21:09.163001: current best dsc: 0.9112376977175172 at epoch: 13, (13, 0.8369482446326413, 0.9112376977175172)
2023-09-03 15:21:09.167211: finished real validation
2023-09-03 15:21:13.513237: train_loss -1.3753
2023-09-03 15:21:13.514345: val_loss -1.1235
2023-09-03 15:21:13.515326: Pseudo dice [0.9041]
2023-09-03 15:21:13.516057: Epoch time: 414.47 s
2023-09-03 15:21:14.598620: 
2023-09-03 15:21:14.599578: Epoch 24
2023-09-03 15:21:14.600370: Current learning rate: backbone 0.0009277, others 0.0009277
2023-09-03 15:21:14.601944: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 15:22:16.987168: finished training epoch 24
2023-09-03 15:22:17.025715: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 15:22:17.027331: The split file contains 1 splits.
2023-09-03 15:22:17.028181: Desired fold for training: 0
2023-09-03 15:22:17.028866: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 15:27:41.734752: dsc: 91.13%
2023-09-03 15:27:41.735923: miou: 83.71%
2023-09-03 15:27:41.736669: acc: 95.59%, sen: 90.13%, spe: 97.43%
2023-09-03 15:27:41.738918: current best miou: 0.8371336708905607 at epoch: 24, (24, 0.8371336708905607, 0.9113475890785405)
2023-09-03 15:27:41.740080: current best dsc: 0.9113475890785405 at epoch: 24, (24, 0.8371336708905607, 0.9113475890785405)
2023-09-03 15:27:43.279083: finished real validation
2023-09-03 15:27:47.595576: train_loss -1.3775
2023-09-03 15:27:47.596795: val_loss -1.1584
2023-09-03 15:27:47.597805: Pseudo dice [0.9098]
2023-09-03 15:27:47.598573: Epoch time: 393.0 s
2023-09-03 15:27:47.599279: Yayy! New best EMA pseudo Dice: 0.9049
2023-09-03 15:27:50.148710: 
2023-09-03 15:27:50.150014: Epoch 25
2023-09-03 15:27:50.150841: Current learning rate: backbone 0.00092468, others 0.00092468
2023-09-03 15:27:50.152017: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 15:28:52.319422: finished training epoch 25
2023-09-03 15:28:52.351214: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 15:28:52.354527: The split file contains 1 splits.
2023-09-03 15:28:52.355824: Desired fold for training: 0
2023-09-03 15:28:52.356946: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 15:34:16.683531: dsc: 91.08%
2023-09-03 15:34:16.684973: miou: 83.62%
2023-09-03 15:34:16.685657: acc: 95.51%, sen: 91.08%, spe: 97.00%
2023-09-03 15:34:16.686845: current best miou: 0.8371336708905607 at epoch: 24, (24, 0.8371336708905607, 0.9113475890785405)
2023-09-03 15:34:16.687513: current best dsc: 0.9113475890785405 at epoch: 24, (24, 0.8371336708905607, 0.9113475890785405)
2023-09-03 15:34:16.688146: finished real validation
2023-09-03 15:34:21.020667: train_loss -1.3795
2023-09-03 15:34:21.022032: val_loss -1.1722
2023-09-03 15:34:21.023110: Pseudo dice [0.9111]
2023-09-03 15:34:21.023893: Epoch time: 390.87 s
2023-09-03 15:34:21.024691: Yayy! New best EMA pseudo Dice: 0.9055
2023-09-03 15:34:23.606095: 
2023-09-03 15:34:23.607521: Epoch 26
2023-09-03 15:34:23.608456: Current learning rate: backbone 0.00092165, others 0.00092165
2023-09-03 15:34:23.610052: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 15:35:26.393558: finished training epoch 26
2023-09-03 15:35:26.433889: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 15:35:26.435650: The split file contains 1 splits.
2023-09-03 15:35:26.436402: Desired fold for training: 0
2023-09-03 15:35:26.437067: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 15:40:45.760728: dsc: 91.10%
2023-09-03 15:40:45.762647: miou: 83.65%
2023-09-03 15:40:45.764724: acc: 95.50%, sen: 91.60%, spe: 96.81%
2023-09-03 15:40:45.768406: current best miou: 0.8371336708905607 at epoch: 24, (24, 0.8371336708905607, 0.9113475890785405)
2023-09-03 15:40:45.770003: current best dsc: 0.9113475890785405 at epoch: 24, (24, 0.8371336708905607, 0.9113475890785405)
2023-09-03 15:40:45.772736: finished real validation
2023-09-03 15:40:50.108367: train_loss -1.3803
2023-09-03 15:40:50.109704: val_loss -1.1906
2023-09-03 15:40:50.110794: Pseudo dice [0.9166]
2023-09-03 15:40:50.111577: Epoch time: 386.5 s
2023-09-03 15:40:50.112286: Yayy! New best EMA pseudo Dice: 0.9066
2023-09-03 15:40:52.764569: 
2023-09-03 15:40:52.765545: Epoch 27
2023-09-03 15:40:52.766371: Current learning rate: backbone 0.00091862, others 0.00091862
2023-09-03 15:40:52.767550: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 15:41:55.306843: finished training epoch 27
2023-09-03 15:41:55.347494: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 15:41:55.349412: The split file contains 1 splits.
2023-09-03 15:41:55.350218: Desired fold for training: 0
2023-09-03 15:41:55.350986: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 15:47:22.600996: dsc: 91.05%
2023-09-03 15:47:22.602271: miou: 83.57%
2023-09-03 15:47:22.602999: acc: 95.49%, sen: 91.32%, spe: 96.88%
2023-09-03 15:47:22.603988: current best miou: 0.8371336708905607 at epoch: 24, (24, 0.8371336708905607, 0.9113475890785405)
2023-09-03 15:47:22.604712: current best dsc: 0.9113475890785405 at epoch: 24, (24, 0.8371336708905607, 0.9113475890785405)
2023-09-03 15:47:22.605427: finished real validation
2023-09-03 15:47:26.944859: train_loss -1.3834
2023-09-03 15:47:26.946160: val_loss -1.1434
2023-09-03 15:47:26.947831: Pseudo dice [0.9068]
2023-09-03 15:47:26.949094: Epoch time: 394.18 s
2023-09-03 15:47:26.950166: Yayy! New best EMA pseudo Dice: 0.9066
2023-09-03 15:47:29.548491: 
2023-09-03 15:47:29.550036: Epoch 28
2023-09-03 15:47:29.551034: Current learning rate: backbone 0.00091559, others 0.00091559
2023-09-03 15:47:29.552761: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 15:48:31.525020: finished training epoch 28
2023-09-03 15:48:31.571215: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 15:48:31.573612: The split file contains 1 splits.
2023-09-03 15:48:31.574722: Desired fold for training: 0
2023-09-03 15:48:31.575702: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 15:53:56.737691: dsc: 90.81%
2023-09-03 15:53:56.738970: miou: 83.17%
2023-09-03 15:53:56.739668: acc: 95.31%, sen: 92.15%, spe: 96.37%
2023-09-03 15:53:56.740668: current best miou: 0.8371336708905607 at epoch: 24, (24, 0.8371336708905607, 0.9113475890785405)
2023-09-03 15:53:56.741404: current best dsc: 0.9113475890785405 at epoch: 24, (24, 0.8371336708905607, 0.9113475890785405)
2023-09-03 15:53:56.742046: finished real validation
2023-09-03 15:54:01.084190: train_loss -1.3864
2023-09-03 15:54:01.085390: val_loss -1.1181
2023-09-03 15:54:01.086467: Pseudo dice [0.9051]
2023-09-03 15:54:01.087790: Epoch time: 391.54 s
2023-09-03 15:54:02.167609: 
2023-09-03 15:54:02.169253: Epoch 29
2023-09-03 15:54:02.170433: Current learning rate: backbone 0.00091256, others 0.00091256
2023-09-03 15:54:02.172030: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 15:55:03.957119: finished training epoch 29
2023-09-03 15:55:04.004902: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 15:55:04.006995: The split file contains 1 splits.
2023-09-03 15:55:04.007908: Desired fold for training: 0
2023-09-03 15:55:04.008718: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 16:01:46.218984: dsc: 91.16%
2023-09-03 16:01:46.220210: miou: 83.75%
2023-09-03 16:01:46.220937: acc: 95.57%, sen: 90.77%, spe: 97.19%
2023-09-03 16:01:46.222033: current best miou: 0.8375059080509812 at epoch: 29, (29, 0.8375059080509812, 0.9115681254481657)
2023-09-03 16:01:46.222754: current best dsc: 0.9115681254481657 at epoch: 29, (29, 0.8375059080509812, 0.9115681254481657)
2023-09-03 16:01:47.743380: finished real validation
2023-09-03 16:01:52.128296: train_loss -1.3884
2023-09-03 16:01:52.129933: val_loss -1.1583
2023-09-03 16:01:52.131560: Pseudo dice [0.9119]
2023-09-03 16:01:52.132715: Epoch time: 469.96 s
2023-09-03 16:01:53.678827: Yayy! New best EMA pseudo Dice: 0.907
2023-09-03 16:01:56.590717: 
2023-09-03 16:01:56.591990: Epoch 30
2023-09-03 16:01:56.592860: Current learning rate: backbone 0.00090953, others 0.00090953
2023-09-03 16:01:56.594034: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 16:02:58.442626: finished training epoch 30
2023-09-03 16:02:58.483011: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 16:02:58.485141: The split file contains 1 splits.
2023-09-03 16:02:58.485972: Desired fold for training: 0
2023-09-03 16:02:58.486707: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 16:08:48.806894: dsc: 91.18%
2023-09-03 16:08:48.808428: miou: 83.79%
2023-09-03 16:08:48.809234: acc: 95.62%, sen: 90.02%, spe: 97.50%
2023-09-03 16:08:48.810558: current best miou: 0.8378857201120921 at epoch: 30, (30, 0.8378857201120921, 0.9117930575803045)
2023-09-03 16:08:48.811326: current best dsc: 0.9117930575803045 at epoch: 30, (30, 0.8378857201120921, 0.9117930575803045)
2023-09-03 16:08:50.590832: finished real validation
2023-09-03 16:08:54.938816: train_loss -1.3907
2023-09-03 16:08:54.940130: val_loss -1.1618
2023-09-03 16:08:54.941278: Pseudo dice [0.914]
2023-09-03 16:08:54.942157: Epoch time: 418.35 s
2023-09-03 16:08:54.942909: Yayy! New best EMA pseudo Dice: 0.9077
2023-09-03 16:08:57.725038: 
2023-09-03 16:08:57.726281: Epoch 31
2023-09-03 16:08:57.727130: Current learning rate: backbone 0.0009065, others 0.0009065
2023-09-03 16:08:57.728551: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 16:10:00.572893: finished training epoch 31
2023-09-03 16:10:00.623374: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 16:10:00.625584: The split file contains 1 splits.
2023-09-03 16:10:00.626535: Desired fold for training: 0
2023-09-03 16:10:00.627279: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 16:15:29.623016: dsc: 91.09%
2023-09-03 16:15:29.624390: miou: 83.64%
2023-09-03 16:15:29.625100: acc: 95.49%, sen: 91.75%, spe: 96.74%
2023-09-03 16:15:29.626101: current best miou: 0.8378857201120921 at epoch: 30, (30, 0.8378857201120921, 0.9117930575803045)
2023-09-03 16:15:29.627024: current best dsc: 0.9117930575803045 at epoch: 30, (30, 0.8378857201120921, 0.9117930575803045)
2023-09-03 16:15:29.627999: finished real validation
2023-09-03 16:15:33.997460: train_loss -1.3915
2023-09-03 16:15:33.999030: val_loss -1.1253
2023-09-03 16:15:34.000258: Pseudo dice [0.9084]
2023-09-03 16:15:34.001090: Epoch time: 396.27 s
2023-09-03 16:15:34.001846: Yayy! New best EMA pseudo Dice: 0.9078
2023-09-03 16:15:36.777119: 
2023-09-03 16:15:36.778307: Epoch 32
2023-09-03 16:15:36.779202: Current learning rate: backbone 0.00090347, others 0.00090347
2023-09-03 16:15:36.780623: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 16:16:39.039327: finished training epoch 32
2023-09-03 16:16:39.070566: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 16:16:39.072678: The split file contains 1 splits.
2023-09-03 16:16:39.073469: Desired fold for training: 0
2023-09-03 16:16:39.074169: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 16:22:08.967276: dsc: 90.82%
2023-09-03 16:22:08.968846: miou: 83.19%
2023-09-03 16:22:08.969993: acc: 95.43%, sen: 89.94%, spe: 97.28%
2023-09-03 16:22:08.971988: current best miou: 0.8378857201120921 at epoch: 30, (30, 0.8378857201120921, 0.9117930575803045)
2023-09-03 16:22:08.973041: current best dsc: 0.9117930575803045 at epoch: 30, (30, 0.8378857201120921, 0.9117930575803045)
2023-09-03 16:22:08.973953: finished real validation
2023-09-03 16:22:13.329128: train_loss -1.3931
2023-09-03 16:22:13.331029: val_loss -1.122
2023-09-03 16:22:13.332542: Pseudo dice [0.9057]
2023-09-03 16:22:13.333816: Epoch time: 396.55 s
2023-09-03 16:22:14.428730: 
2023-09-03 16:22:14.429986: Epoch 33
2023-09-03 16:22:14.430871: Current learning rate: backbone 0.00090043, others 0.00090043
2023-09-03 16:22:14.432149: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 16:23:16.335864: finished training epoch 33
2023-09-03 16:23:16.374386: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 16:23:16.376291: The split file contains 1 splits.
2023-09-03 16:23:16.377308: Desired fold for training: 0
2023-09-03 16:23:16.377998: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 16:28:41.602944: dsc: 91.10%
2023-09-03 16:28:41.604193: miou: 83.65%
2023-09-03 16:28:41.604979: acc: 95.50%, sen: 91.50%, spe: 96.84%
2023-09-03 16:28:41.606472: current best miou: 0.8378857201120921 at epoch: 30, (30, 0.8378857201120921, 0.9117930575803045)
2023-09-03 16:28:41.607297: current best dsc: 0.9117930575803045 at epoch: 30, (30, 0.8378857201120921, 0.9117930575803045)
2023-09-03 16:28:41.608903: finished real validation
2023-09-03 16:28:45.952296: train_loss -1.3944
2023-09-03 16:28:45.954086: val_loss -1.1814
2023-09-03 16:28:45.955704: Pseudo dice [0.9186]
2023-09-03 16:28:45.956941: Epoch time: 391.52 s
2023-09-03 16:28:45.958025: Yayy! New best EMA pseudo Dice: 0.9087
2023-09-03 16:28:48.961423: 
2023-09-03 16:28:48.962566: Epoch 34
2023-09-03 16:28:48.963343: Current learning rate: backbone 0.0008974, others 0.0008974
2023-09-03 16:28:48.964640: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 16:29:51.080675: finished training epoch 34
2023-09-03 16:29:51.117966: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 16:29:51.119822: The split file contains 1 splits.
2023-09-03 16:29:51.120588: Desired fold for training: 0
2023-09-03 16:29:51.121255: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 16:35:16.453689: dsc: 90.60%
2023-09-03 16:35:16.455236: miou: 82.82%
2023-09-03 16:35:16.456369: acc: 95.30%, sen: 90.04%, spe: 97.07%
2023-09-03 16:35:16.458389: current best miou: 0.8378857201120921 at epoch: 30, (30, 0.8378857201120921, 0.9117930575803045)
2023-09-03 16:35:16.459457: current best dsc: 0.9117930575803045 at epoch: 30, (30, 0.8378857201120921, 0.9117930575803045)
2023-09-03 16:35:16.460414: finished real validation
2023-09-03 16:35:20.827771: train_loss -1.3942
2023-09-03 16:35:20.829361: val_loss -1.1362
2023-09-03 16:35:20.830921: Pseudo dice [0.9103]
2023-09-03 16:35:20.832129: Epoch time: 391.87 s
2023-09-03 16:35:20.833153: Yayy! New best EMA pseudo Dice: 0.9088
2023-09-03 16:35:23.510486: 
2023-09-03 16:35:23.512029: Epoch 35
2023-09-03 16:35:23.513005: Current learning rate: backbone 0.00089436, others 0.00089436
2023-09-03 16:35:23.515132: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 16:36:25.550164: finished training epoch 35
2023-09-03 16:36:25.582215: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 16:36:25.584194: The split file contains 1 splits.
2023-09-03 16:36:25.585086: Desired fold for training: 0
2023-09-03 16:36:25.585865: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 16:41:52.644419: dsc: 91.08%
2023-09-03 16:41:52.646628: miou: 83.61%
2023-09-03 16:41:52.647587: acc: 95.50%, sen: 91.35%, spe: 96.89%
2023-09-03 16:41:52.648668: current best miou: 0.8378857201120921 at epoch: 30, (30, 0.8378857201120921, 0.9117930575803045)
2023-09-03 16:41:52.649493: current best dsc: 0.9117930575803045 at epoch: 30, (30, 0.8378857201120921, 0.9117930575803045)
2023-09-03 16:41:52.650215: finished real validation
2023-09-03 16:41:56.992311: train_loss -1.398
2023-09-03 16:41:56.993770: val_loss -1.1413
2023-09-03 16:41:56.995555: Pseudo dice [0.9112]
2023-09-03 16:41:56.997119: Epoch time: 393.48 s
2023-09-03 16:41:56.998201: Yayy! New best EMA pseudo Dice: 0.9091
2023-09-03 16:41:59.840771: 
2023-09-03 16:41:59.841969: Epoch 36
2023-09-03 16:41:59.842891: Current learning rate: backbone 0.00089132, others 0.00089132
2023-09-03 16:41:59.844143: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 16:43:02.601520: finished training epoch 36
2023-09-03 16:43:02.642158: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 16:43:02.644047: The split file contains 1 splits.
2023-09-03 16:43:02.644860: Desired fold for training: 0
2023-09-03 16:43:02.646182: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 16:48:25.889984: dsc: 91.09%
2023-09-03 16:48:25.891642: miou: 83.64%
2023-09-03 16:48:25.892712: acc: 95.52%, sen: 91.04%, spe: 97.02%
2023-09-03 16:48:25.894534: current best miou: 0.8378857201120921 at epoch: 30, (30, 0.8378857201120921, 0.9117930575803045)
2023-09-03 16:48:25.895661: current best dsc: 0.9117930575803045 at epoch: 30, (30, 0.8378857201120921, 0.9117930575803045)
2023-09-03 16:48:25.896617: finished real validation
2023-09-03 16:48:30.236139: train_loss -1.397
2023-09-03 16:48:30.237472: val_loss -1.15
2023-09-03 16:48:30.238515: Pseudo dice [0.9145]
2023-09-03 16:48:30.239395: Epoch time: 390.4 s
2023-09-03 16:48:30.240186: Yayy! New best EMA pseudo Dice: 0.9096
2023-09-03 16:48:32.906971: 
2023-09-03 16:48:32.908178: Epoch 37
2023-09-03 16:48:32.909048: Current learning rate: backbone 0.00088828, others 0.00088828
2023-09-03 16:48:32.910319: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 16:49:35.330119: finished training epoch 37
2023-09-03 16:49:35.373154: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 16:49:35.376229: The split file contains 1 splits.
2023-09-03 16:49:35.378148: Desired fold for training: 0
2023-09-03 16:49:35.379540: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 16:54:59.327781: dsc: 90.91%
2023-09-03 16:54:59.329018: miou: 83.33%
2023-09-03 16:54:59.329796: acc: 95.41%, sen: 91.16%, spe: 96.84%
2023-09-03 16:54:59.330839: current best miou: 0.8378857201120921 at epoch: 30, (30, 0.8378857201120921, 0.9117930575803045)
2023-09-03 16:54:59.331591: current best dsc: 0.9117930575803045 at epoch: 30, (30, 0.8378857201120921, 0.9117930575803045)
2023-09-03 16:54:59.332261: finished real validation
2023-09-03 16:55:03.680542: train_loss -1.3975
2023-09-03 16:55:03.681913: val_loss -1.1108
2023-09-03 16:55:03.683774: Pseudo dice [0.9056]
2023-09-03 16:55:03.685143: Epoch time: 390.78 s
2023-09-03 16:55:04.813305: 
2023-09-03 16:55:04.814478: Epoch 38
2023-09-03 16:55:04.815358: Current learning rate: backbone 0.00088524, others 0.00088524
2023-09-03 16:55:04.816609: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 16:56:07.203067: finished training epoch 38
2023-09-03 16:56:07.240052: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 16:56:07.241613: The split file contains 1 splits.
2023-09-03 16:56:07.242547: Desired fold for training: 0
2023-09-03 16:56:07.243310: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 17:01:27.161151: dsc: 91.06%
2023-09-03 17:01:27.162308: miou: 83.58%
2023-09-03 17:01:27.163136: acc: 95.51%, sen: 90.89%, spe: 97.06%
2023-09-03 17:01:27.164337: current best miou: 0.8378857201120921 at epoch: 30, (30, 0.8378857201120921, 0.9117930575803045)
2023-09-03 17:01:27.165156: current best dsc: 0.9117930575803045 at epoch: 30, (30, 0.8378857201120921, 0.9117930575803045)
2023-09-03 17:01:27.165889: finished real validation
2023-09-03 17:01:31.508739: train_loss -1.3999
2023-09-03 17:01:31.510077: val_loss -1.1264
2023-09-03 17:01:31.511147: Pseudo dice [0.909]
2023-09-03 17:01:31.512042: Epoch time: 386.7 s
2023-09-03 17:01:32.628240: 
2023-09-03 17:01:32.629944: Epoch 39
2023-09-03 17:01:32.630917: Current learning rate: backbone 0.0008822, others 0.0008822
2023-09-03 17:01:32.632226: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 17:02:34.601601: finished training epoch 39
2023-09-03 17:02:34.638047: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 17:02:34.640561: The split file contains 1 splits.
2023-09-03 17:02:34.641432: Desired fold for training: 0
2023-09-03 17:02:34.642930: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 17:07:57.931512: dsc: 91.16%
2023-09-03 17:07:57.932732: miou: 83.76%
2023-09-03 17:07:57.933476: acc: 95.60%, sen: 90.23%, spe: 97.40%
2023-09-03 17:07:57.934550: current best miou: 0.8378857201120921 at epoch: 30, (30, 0.8378857201120921, 0.9117930575803045)
2023-09-03 17:07:57.935371: current best dsc: 0.9117930575803045 at epoch: 30, (30, 0.8378857201120921, 0.9117930575803045)
2023-09-03 17:07:57.936095: finished real validation
2023-09-03 17:08:02.270749: train_loss -1.4004
2023-09-03 17:08:02.272149: val_loss -1.1403
2023-09-03 17:08:02.273255: Pseudo dice [0.9106]
2023-09-03 17:08:02.274104: Epoch time: 389.64 s
2023-09-03 17:08:04.900012: 
2023-09-03 17:08:04.901255: Epoch 40
2023-09-03 17:08:04.902121: Current learning rate: backbone 0.00087916, others 0.00087916
2023-09-03 17:08:04.903370: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 17:09:06.994225: finished training epoch 40
2023-09-03 17:09:07.022870: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 17:09:07.024725: The split file contains 1 splits.
2023-09-03 17:09:07.025779: Desired fold for training: 0
2023-09-03 17:09:07.026525: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 17:14:34.747670: dsc: 91.26%
2023-09-03 17:14:34.749409: miou: 83.93%
2023-09-03 17:14:34.750839: acc: 95.63%, sen: 90.67%, spe: 97.30%
2023-09-03 17:14:34.752136: current best miou: 0.8393206239717438 at epoch: 40, (40, 0.8393206239717438, 0.912641997303715)
2023-09-03 17:14:34.753150: current best dsc: 0.912641997303715 at epoch: 40, (40, 0.8393206239717438, 0.912641997303715)
2023-09-03 17:14:36.309947: finished real validation
2023-09-03 17:14:40.648233: train_loss -1.4033
2023-09-03 17:14:40.649622: val_loss -1.1517
2023-09-03 17:14:40.651366: Pseudo dice [0.913]
2023-09-03 17:14:40.652345: Epoch time: 395.75 s
2023-09-03 17:14:40.653170: Yayy! New best EMA pseudo Dice: 0.9097
2023-09-03 17:14:43.320218: 
2023-09-03 17:14:43.321528: Epoch 41
2023-09-03 17:14:43.322439: Current learning rate: backbone 0.00087611, others 0.00087611
2023-09-03 17:14:43.323654: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 17:15:45.240500: finished training epoch 41
2023-09-03 17:15:45.277750: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 17:15:45.279688: The split file contains 1 splits.
2023-09-03 17:15:45.280551: Desired fold for training: 0
2023-09-03 17:15:45.281298: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 17:21:07.752333: dsc: 91.16%
2023-09-03 17:21:07.753553: miou: 83.75%
2023-09-03 17:21:07.754384: acc: 95.53%, sen: 91.66%, spe: 96.83%
2023-09-03 17:21:07.755479: current best miou: 0.8393206239717438 at epoch: 40, (40, 0.8393206239717438, 0.912641997303715)
2023-09-03 17:21:07.756480: current best dsc: 0.912641997303715 at epoch: 40, (40, 0.8393206239717438, 0.912641997303715)
2023-09-03 17:21:07.757558: finished real validation
2023-09-03 17:21:12.110018: train_loss -1.4032
2023-09-03 17:21:12.111430: val_loss -1.1178
2023-09-03 17:21:12.112603: Pseudo dice [0.91]
2023-09-03 17:21:12.113462: Epoch time: 388.79 s
2023-09-03 17:21:12.114253: Yayy! New best EMA pseudo Dice: 0.9097
2023-09-03 17:21:14.711099: 
2023-09-03 17:21:14.712540: Epoch 42
2023-09-03 17:21:14.713455: Current learning rate: backbone 0.00087307, others 0.00087307
2023-09-03 17:21:14.714902: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 17:22:16.999490: finished training epoch 42
2023-09-03 17:22:17.046384: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 17:22:17.048353: The split file contains 1 splits.
2023-09-03 17:22:17.049425: Desired fold for training: 0
2023-09-03 17:22:17.050299: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 17:27:37.047669: dsc: 90.97%
2023-09-03 17:27:37.049094: miou: 83.43%
2023-09-03 17:27:37.049946: acc: 95.54%, sen: 89.28%, spe: 97.65%
2023-09-03 17:27:37.051182: current best miou: 0.8393206239717438 at epoch: 40, (40, 0.8393206239717438, 0.912641997303715)
2023-09-03 17:27:37.051960: current best dsc: 0.912641997303715 at epoch: 40, (40, 0.8393206239717438, 0.912641997303715)
2023-09-03 17:27:37.052696: finished real validation
2023-09-03 17:27:41.403688: train_loss -1.4023
2023-09-03 17:27:41.405408: val_loss -1.1238
2023-09-03 17:27:41.406760: Pseudo dice [0.9083]
2023-09-03 17:27:41.407694: Epoch time: 386.69 s
2023-09-03 17:27:42.482672: 
2023-09-03 17:27:42.483829: Epoch 43
2023-09-03 17:27:42.484851: Current learning rate: backbone 0.00087002, others 0.00087002
2023-09-03 17:27:42.486305: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 17:28:44.383698: finished training epoch 43
2023-09-03 17:28:44.413975: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 17:28:44.415826: The split file contains 1 splits.
2023-09-03 17:28:44.416616: Desired fold for training: 0
2023-09-03 17:28:44.417742: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 17:34:05.745412: dsc: 91.22%
2023-09-03 17:34:05.746833: miou: 83.87%
2023-09-03 17:34:05.747697: acc: 95.61%, sen: 90.72%, spe: 97.26%
2023-09-03 17:34:05.748911: current best miou: 0.8393206239717438 at epoch: 40, (40, 0.8393206239717438, 0.912641997303715)
2023-09-03 17:34:05.749683: current best dsc: 0.912641997303715 at epoch: 40, (40, 0.8393206239717438, 0.912641997303715)
2023-09-03 17:34:05.750412: finished real validation
2023-09-03 17:34:10.097414: train_loss -1.4028
2023-09-03 17:34:10.098995: val_loss -1.1369
2023-09-03 17:34:10.100282: Pseudo dice [0.9115]
2023-09-03 17:34:10.101168: Epoch time: 387.62 s
2023-09-03 17:34:10.101984: Yayy! New best EMA pseudo Dice: 0.9098
2023-09-03 17:34:12.738722: 
2023-09-03 17:34:12.740068: Epoch 44
2023-09-03 17:34:12.741025: Current learning rate: backbone 0.00086698, others 0.00086698
2023-09-03 17:34:12.742460: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 17:35:14.351903: finished training epoch 44
2023-09-03 17:35:14.391121: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 17:35:14.393180: The split file contains 1 splits.
2023-09-03 17:35:14.394626: Desired fold for training: 0
2023-09-03 17:35:14.396097: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 17:40:41.784160: dsc: 91.19%
2023-09-03 17:40:41.785552: miou: 83.81%
2023-09-03 17:40:41.786391: acc: 95.60%, sen: 90.46%, spe: 97.33%
2023-09-03 17:40:41.787631: current best miou: 0.8393206239717438 at epoch: 40, (40, 0.8393206239717438, 0.912641997303715)
2023-09-03 17:40:41.788512: current best dsc: 0.912641997303715 at epoch: 40, (40, 0.8393206239717438, 0.912641997303715)
2023-09-03 17:40:41.789281: finished real validation
2023-09-03 17:40:46.123634: train_loss -1.4053
2023-09-03 17:40:46.125122: val_loss -1.1495
2023-09-03 17:40:46.126309: Pseudo dice [0.914]
2023-09-03 17:40:46.127282: Epoch time: 393.39 s
2023-09-03 17:40:46.128115: Yayy! New best EMA pseudo Dice: 0.9102
2023-09-03 17:40:48.692179: 
2023-09-03 17:40:48.693470: Epoch 45
2023-09-03 17:40:48.694405: Current learning rate: backbone 0.00086393, others 0.00086393
2023-09-03 17:40:48.695766: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 17:41:50.690447: finished training epoch 45
2023-09-03 17:41:50.738909: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 17:41:50.740942: The split file contains 1 splits.
2023-09-03 17:41:50.741931: Desired fold for training: 0
2023-09-03 17:41:50.742754: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 17:47:17.889912: dsc: 90.96%
2023-09-03 17:47:17.891724: miou: 83.42%
2023-09-03 17:47:17.892658: acc: 95.45%, sen: 91.04%, spe: 96.93%
2023-09-03 17:47:17.894494: current best miou: 0.8393206239717438 at epoch: 40, (40, 0.8393206239717438, 0.912641997303715)
2023-09-03 17:47:17.895715: current best dsc: 0.912641997303715 at epoch: 40, (40, 0.8393206239717438, 0.912641997303715)
2023-09-03 17:47:17.896756: finished real validation
2023-09-03 17:47:22.235976: train_loss -1.4073
2023-09-03 17:47:22.237451: val_loss -1.1179
2023-09-03 17:47:22.238675: Pseudo dice [0.9118]
2023-09-03 17:47:22.240259: Epoch time: 393.55 s
2023-09-03 17:47:22.241959: Yayy! New best EMA pseudo Dice: 0.9104
2023-09-03 17:47:24.850574: 
2023-09-03 17:47:24.851992: Epoch 46
2023-09-03 17:47:24.852978: Current learning rate: backbone 0.00086088, others 0.00086088
2023-09-03 17:47:24.854449: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 17:48:26.979666: finished training epoch 46
2023-09-03 17:48:27.028020: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 17:48:27.033289: The split file contains 1 splits.
2023-09-03 17:48:27.034416: Desired fold for training: 0
2023-09-03 17:48:27.035254: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 17:54:10.946614: dsc: 91.33%
2023-09-03 17:54:10.948252: miou: 84.04%
2023-09-03 17:54:10.949127: acc: 95.65%, sen: 90.99%, spe: 97.22%
2023-09-03 17:54:10.950534: current best miou: 0.8403578140177365 at epoch: 46, (46, 0.8403578140177365, 0.9132548112294836)
2023-09-03 17:54:10.951409: current best dsc: 0.9132548112294836 at epoch: 46, (46, 0.8403578140177365, 0.9132548112294836)
2023-09-03 17:54:12.532920: finished real validation
2023-09-03 17:54:16.885341: train_loss -1.4077
2023-09-03 17:54:16.886693: val_loss -1.169
2023-09-03 17:54:16.887887: Pseudo dice [0.9177]
2023-09-03 17:54:16.888812: Epoch time: 412.04 s
2023-09-03 17:54:16.889645: Yayy! New best EMA pseudo Dice: 0.9111
2023-09-03 17:54:19.522693: 
2023-09-03 17:54:19.523943: Epoch 47
2023-09-03 17:54:19.525096: Current learning rate: backbone 0.00085783, others 0.00085783
2023-09-03 17:54:19.526526: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 17:55:21.717222: finished training epoch 47
2023-09-03 17:55:21.759910: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 17:55:21.761959: The split file contains 1 splits.
2023-09-03 17:55:21.762819: Desired fold for training: 0
2023-09-03 17:55:21.763650: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 18:01:00.745881: dsc: 91.04%
2023-09-03 18:01:00.747253: miou: 83.55%
2023-09-03 18:01:00.748127: acc: 95.50%, sen: 90.83%, spe: 97.07%
2023-09-03 18:01:00.749331: current best miou: 0.8403578140177365 at epoch: 46, (46, 0.8403578140177365, 0.9132548112294836)
2023-09-03 18:01:00.750155: current best dsc: 0.9132548112294836 at epoch: 46, (46, 0.8403578140177365, 0.9132548112294836)
2023-09-03 18:01:00.750905: finished real validation
2023-09-03 18:01:05.114202: train_loss -1.4088
2023-09-03 18:01:05.115669: val_loss -1.1235
2023-09-03 18:01:05.116805: Pseudo dice [0.9124]
2023-09-03 18:01:05.117752: Epoch time: 405.59 s
2023-09-03 18:01:05.118612: Yayy! New best EMA pseudo Dice: 0.9112
2023-09-03 18:01:07.699293: 
2023-09-03 18:01:07.700440: Epoch 48
2023-09-03 18:01:07.701348: Current learning rate: backbone 0.00085477, others 0.00085477
2023-09-03 18:01:07.702677: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 18:02:09.648262: finished training epoch 48
2023-09-03 18:02:09.692516: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 18:02:09.696021: The split file contains 1 splits.
2023-09-03 18:02:09.699801: Desired fold for training: 0
2023-09-03 18:02:09.703007: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 18:07:31.804316: dsc: 91.07%
2023-09-03 18:07:31.805840: miou: 83.60%
2023-09-03 18:07:31.806744: acc: 95.54%, sen: 90.48%, spe: 97.24%
2023-09-03 18:07:31.807867: current best miou: 0.8403578140177365 at epoch: 46, (46, 0.8403578140177365, 0.9132548112294836)
2023-09-03 18:07:31.808662: current best dsc: 0.9132548112294836 at epoch: 46, (46, 0.8403578140177365, 0.9132548112294836)
2023-09-03 18:07:31.809452: finished real validation
2023-09-03 18:07:36.171812: train_loss -1.4082
2023-09-03 18:07:36.173167: val_loss -1.1164
2023-09-03 18:07:36.174414: Pseudo dice [0.9124]
2023-09-03 18:07:36.175348: Epoch time: 388.47 s
2023-09-03 18:07:36.176148: Yayy! New best EMA pseudo Dice: 0.9113
2023-09-03 18:07:38.793473: 
2023-09-03 18:07:38.794751: Epoch 49
2023-09-03 18:07:38.795663: Current learning rate: backbone 0.00085172, others 0.00085172
2023-09-03 18:07:38.797001: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 18:08:40.846441: finished training epoch 49
2023-09-03 18:08:40.881287: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 18:08:40.883460: The split file contains 1 splits.
2023-09-03 18:08:40.884252: Desired fold for training: 0
2023-09-03 18:08:40.884979: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 18:14:09.136026: dsc: 91.13%
2023-09-03 18:14:09.137456: miou: 83.70%
2023-09-03 18:14:09.138355: acc: 95.54%, sen: 91.03%, spe: 97.06%
2023-09-03 18:14:09.139560: current best miou: 0.8403578140177365 at epoch: 46, (46, 0.8403578140177365, 0.9132548112294836)
2023-09-03 18:14:09.140435: current best dsc: 0.9132548112294836 at epoch: 46, (46, 0.8403578140177365, 0.9132548112294836)
2023-09-03 18:14:09.141214: finished real validation
2023-09-03 18:14:13.489304: train_loss -1.409
2023-09-03 18:14:13.490745: val_loss -1.1151
2023-09-03 18:14:13.491925: Pseudo dice [0.9097]
2023-09-03 18:14:13.492969: Epoch time: 394.7 s
2023-09-03 18:14:16.099165: 
2023-09-03 18:14:16.100359: Epoch 50
2023-09-03 18:14:16.101252: Current learning rate: backbone 0.00084867, others 0.00084867
2023-09-03 18:14:16.102519: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 18:15:18.006327: finished training epoch 50
2023-09-03 18:15:18.052803: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 18:15:18.054956: The split file contains 1 splits.
2023-09-03 18:15:18.055893: Desired fold for training: 0
2023-09-03 18:15:18.056763: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 18:20:45.162272: dsc: 91.22%
2023-09-03 18:20:45.163538: miou: 83.86%
2023-09-03 18:20:45.164429: acc: 95.62%, sen: 90.47%, spe: 97.35%
2023-09-03 18:20:45.165623: current best miou: 0.8403578140177365 at epoch: 46, (46, 0.8403578140177365, 0.9132548112294836)
2023-09-03 18:20:45.166501: current best dsc: 0.9132548112294836 at epoch: 46, (46, 0.8403578140177365, 0.9132548112294836)
2023-09-03 18:20:45.167259: finished real validation
2023-09-03 18:20:49.529713: train_loss -1.411
2023-09-03 18:20:49.531144: val_loss -1.1321
2023-09-03 18:20:49.532398: Pseudo dice [0.9111]
2023-09-03 18:20:49.533393: Epoch time: 393.43 s
2023-09-03 18:20:50.618928: 
2023-09-03 18:20:50.620212: Epoch 51
2023-09-03 18:20:50.621408: Current learning rate: backbone 0.00084561, others 0.00084561
2023-09-03 18:20:50.623148: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 18:21:52.639565: finished training epoch 51
2023-09-03 18:21:52.689666: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 18:21:52.691676: The split file contains 1 splits.
2023-09-03 18:21:52.692673: Desired fold for training: 0
2023-09-03 18:21:52.693556: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 18:27:15.109837: dsc: 91.14%
2023-09-03 18:27:15.111136: miou: 83.73%
2023-09-03 18:27:15.112043: acc: 95.57%, sen: 90.75%, spe: 97.18%
2023-09-03 18:27:15.113240: current best miou: 0.8403578140177365 at epoch: 46, (46, 0.8403578140177365, 0.9132548112294836)
2023-09-03 18:27:15.114129: current best dsc: 0.9132548112294836 at epoch: 46, (46, 0.8403578140177365, 0.9132548112294836)
2023-09-03 18:27:15.114969: finished real validation
2023-09-03 18:27:19.468371: train_loss -1.4118
2023-09-03 18:27:19.470392: val_loss -1.1101
2023-09-03 18:27:19.472275: Pseudo dice [0.9087]
2023-09-03 18:27:19.473728: Epoch time: 388.85 s
2023-09-03 18:27:20.588859: 
2023-09-03 18:27:20.590183: Epoch 52
2023-09-03 18:27:20.591146: Current learning rate: backbone 0.00084255, others 0.00084255
2023-09-03 18:27:20.592505: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 18:28:22.141443: finished training epoch 52
2023-09-03 18:28:22.183066: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 18:28:22.184930: The split file contains 1 splits.
2023-09-03 18:28:22.185818: Desired fold for training: 0
2023-09-03 18:28:22.186657: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 18:33:49.820561: dsc: 91.23%
2023-09-03 18:33:49.822080: miou: 83.88%
2023-09-03 18:33:49.822975: acc: 95.59%, sen: 91.21%, spe: 97.06%
2023-09-03 18:33:49.824169: current best miou: 0.8403578140177365 at epoch: 46, (46, 0.8403578140177365, 0.9132548112294836)
2023-09-03 18:33:49.825172: current best dsc: 0.9132548112294836 at epoch: 46, (46, 0.8403578140177365, 0.9132548112294836)
2023-09-03 18:33:49.825981: finished real validation
2023-09-03 18:33:54.174586: train_loss -1.4109
2023-09-03 18:33:54.176025: val_loss -1.1304
2023-09-03 18:33:54.177207: Pseudo dice [0.9121]
2023-09-03 18:33:54.178206: Epoch time: 393.59 s
2023-09-03 18:33:55.264144: 
2023-09-03 18:33:55.265676: Epoch 53
2023-09-03 18:33:55.266645: Current learning rate: backbone 0.0008395, others 0.0008395
2023-09-03 18:33:55.268022: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 18:34:57.021148: finished training epoch 53
2023-09-03 18:34:57.067271: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 18:34:57.069046: The split file contains 1 splits.
2023-09-03 18:34:57.069944: Desired fold for training: 0
2023-09-03 18:34:57.070731: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 18:42:22.493445: dsc: 91.31%
2023-09-03 18:42:22.494887: miou: 84.02%
2023-09-03 18:42:22.495801: acc: 95.67%, sen: 90.42%, spe: 97.44%
2023-09-03 18:42:22.497030: current best miou: 0.8403578140177365 at epoch: 46, (46, 0.8403578140177365, 0.9132548112294836)
2023-09-03 18:42:22.497942: current best dsc: 0.9132548112294836 at epoch: 46, (46, 0.8403578140177365, 0.9132548112294836)
2023-09-03 18:42:22.498754: finished real validation
2023-09-03 18:42:26.873463: train_loss -1.413
2023-09-03 18:42:26.874925: val_loss -1.1416
2023-09-03 18:42:26.876189: Pseudo dice [0.9132]
2023-09-03 18:42:26.877172: Epoch time: 511.61 s
2023-09-03 18:42:27.989130: 
2023-09-03 18:42:27.990436: Epoch 54
2023-09-03 18:42:27.991395: Current learning rate: backbone 0.00083644, others 0.00083644
2023-09-03 18:42:27.992856: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 18:43:30.360642: finished training epoch 54
2023-09-03 18:43:30.403267: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 18:43:30.405004: The split file contains 1 splits.
2023-09-03 18:43:30.406207: Desired fold for training: 0
2023-09-03 18:43:30.407101: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 18:48:54.493541: dsc: 91.23%
2023-09-03 18:48:54.494976: miou: 83.87%
2023-09-03 18:48:54.495856: acc: 95.61%, sen: 90.86%, spe: 97.20%
2023-09-03 18:48:54.497001: current best miou: 0.8403578140177365 at epoch: 46, (46, 0.8403578140177365, 0.9132548112294836)
2023-09-03 18:48:54.497951: current best dsc: 0.9132548112294836 at epoch: 46, (46, 0.8403578140177365, 0.9132548112294836)
2023-09-03 18:48:54.498734: finished real validation
2023-09-03 18:48:58.855786: train_loss -1.4133
2023-09-03 18:48:58.857669: val_loss -1.1538
2023-09-03 18:48:58.859587: Pseudo dice [0.9162]
2023-09-03 18:48:58.860923: Epoch time: 390.87 s
2023-09-03 18:48:58.862055: Yayy! New best EMA pseudo Dice: 0.9117
2023-09-03 18:49:01.513999: 
2023-09-03 18:49:01.515655: Epoch 55
2023-09-03 18:49:01.516649: Current learning rate: backbone 0.00083337, others 0.00083337
2023-09-03 18:49:01.520744: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 18:50:03.561316: finished training epoch 55
2023-09-03 18:50:03.599359: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 18:50:03.601507: The split file contains 1 splits.
2023-09-03 18:50:03.602473: Desired fold for training: 0
2023-09-03 18:50:03.603286: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 18:55:24.899045: dsc: 91.31%
2023-09-03 18:55:24.900503: miou: 84.01%
2023-09-03 18:55:24.901422: acc: 95.66%, sen: 90.58%, spe: 97.37%
2023-09-03 18:55:24.902806: current best miou: 0.8403578140177365 at epoch: 46, (46, 0.8403578140177365, 0.9132548112294836)
2023-09-03 18:55:24.903701: current best dsc: 0.9132548112294836 at epoch: 46, (46, 0.8403578140177365, 0.9132548112294836)
2023-09-03 18:55:24.904552: finished real validation
2023-09-03 18:55:29.272684: train_loss -1.4143
2023-09-03 18:55:29.274070: val_loss -1.1144
2023-09-03 18:55:29.275171: Pseudo dice [0.9124]
2023-09-03 18:55:29.276119: Epoch time: 387.76 s
2023-09-03 18:55:29.277104: Yayy! New best EMA pseudo Dice: 0.9118
2023-09-03 18:55:31.905743: 
2023-09-03 18:55:31.906946: Epoch 56
2023-09-03 18:55:31.907896: Current learning rate: backbone 0.00083031, others 0.00083031
2023-09-03 18:55:31.909302: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 18:56:33.822562: finished training epoch 56
2023-09-03 18:56:33.863971: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 18:56:33.865908: The split file contains 1 splits.
2023-09-03 18:56:33.866841: Desired fold for training: 0
2023-09-03 18:56:33.867754: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 19:02:00.644183: dsc: 91.14%
2023-09-03 19:02:00.645765: miou: 83.71%
2023-09-03 19:02:00.646764: acc: 95.55%, sen: 90.87%, spe: 97.13%
2023-09-03 19:02:00.648107: current best miou: 0.8403578140177365 at epoch: 46, (46, 0.8403578140177365, 0.9132548112294836)
2023-09-03 19:02:00.649012: current best dsc: 0.9132548112294836 at epoch: 46, (46, 0.8403578140177365, 0.9132548112294836)
2023-09-03 19:02:00.649832: finished real validation
2023-09-03 19:02:05.001834: train_loss -1.4142
2023-09-03 19:02:05.003396: val_loss -1.1178
2023-09-03 19:02:05.004715: Pseudo dice [0.9113]
2023-09-03 19:02:05.005733: Epoch time: 393.1 s
2023-09-03 19:02:06.098183: 
2023-09-03 19:02:06.099747: Epoch 57
2023-09-03 19:02:06.100769: Current learning rate: backbone 0.00082725, others 0.00082725
2023-09-03 19:02:06.102304: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 19:03:07.860704: finished training epoch 57
2023-09-03 19:03:07.901276: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 19:03:07.904563: The split file contains 1 splits.
2023-09-03 19:03:07.906146: Desired fold for training: 0
2023-09-03 19:03:07.907631: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 19:08:34.617011: dsc: 91.15%
2023-09-03 19:08:34.619157: miou: 83.74%
2023-09-03 19:08:34.620142: acc: 95.58%, sen: 90.48%, spe: 97.30%
2023-09-03 19:08:34.621485: current best miou: 0.8403578140177365 at epoch: 46, (46, 0.8403578140177365, 0.9132548112294836)
2023-09-03 19:08:34.622383: current best dsc: 0.9132548112294836 at epoch: 46, (46, 0.8403578140177365, 0.9132548112294836)
2023-09-03 19:08:34.623508: finished real validation
2023-09-03 19:08:38.978518: train_loss -1.4128
2023-09-03 19:08:38.980103: val_loss -1.1454
2023-09-03 19:08:38.981373: Pseudo dice [0.9157]
2023-09-03 19:08:38.982371: Epoch time: 392.88 s
2023-09-03 19:08:38.983278: Yayy! New best EMA pseudo Dice: 0.9121
2023-09-03 19:08:41.651906: 
2023-09-03 19:08:41.653300: Epoch 58
2023-09-03 19:08:41.654307: Current learning rate: backbone 0.00082418, others 0.00082418
2023-09-03 19:08:41.655796: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 19:09:43.581548: finished training epoch 58
2023-09-03 19:09:43.623045: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 19:09:43.626538: The split file contains 1 splits.
2023-09-03 19:09:43.627519: Desired fold for training: 0
2023-09-03 19:09:43.628825: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 19:15:39.598206: dsc: 91.22%
2023-09-03 19:15:39.599715: miou: 83.86%
2023-09-03 19:15:39.600616: acc: 95.63%, sen: 90.33%, spe: 97.41%
2023-09-03 19:15:39.601851: current best miou: 0.8403578140177365 at epoch: 46, (46, 0.8403578140177365, 0.9132548112294836)
2023-09-03 19:15:39.602740: current best dsc: 0.9132548112294836 at epoch: 46, (46, 0.8403578140177365, 0.9132548112294836)
2023-09-03 19:15:39.603572: finished real validation
2023-09-03 19:15:43.954350: train_loss -1.4137
2023-09-03 19:15:43.956304: val_loss -1.1445
2023-09-03 19:15:43.957730: Pseudo dice [0.9138]
2023-09-03 19:15:43.958790: Epoch time: 422.3 s
2023-09-03 19:15:43.959727: Yayy! New best EMA pseudo Dice: 0.9123
2023-09-03 19:15:46.778635: 
2023-09-03 19:15:46.780111: Epoch 59
2023-09-03 19:15:46.781155: Current learning rate: backbone 0.00082112, others 0.00082112
2023-09-03 19:15:46.782746: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 19:16:48.908909: finished training epoch 59
2023-09-03 19:16:48.950161: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 19:16:48.952998: The split file contains 1 splits.
2023-09-03 19:16:48.954314: Desired fold for training: 0
2023-09-03 19:16:48.955416: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 19:22:28.948364: dsc: 91.21%
2023-09-03 19:22:28.950052: miou: 83.83%
2023-09-03 19:22:28.950978: acc: 95.61%, sen: 90.41%, spe: 97.36%
2023-09-03 19:22:28.952405: current best miou: 0.8403578140177365 at epoch: 46, (46, 0.8403578140177365, 0.9132548112294836)
2023-09-03 19:22:28.953309: current best dsc: 0.9132548112294836 at epoch: 46, (46, 0.8403578140177365, 0.9132548112294836)
2023-09-03 19:22:28.954145: finished real validation
2023-09-03 19:22:33.320191: train_loss -1.416
2023-09-03 19:22:33.321995: val_loss -1.1434
2023-09-03 19:22:33.323423: Pseudo dice [0.9151]
2023-09-03 19:22:33.324444: Epoch time: 406.54 s
2023-09-03 19:22:35.100746: Yayy! New best EMA pseudo Dice: 0.9126
2023-09-03 19:22:37.877426: 
2023-09-03 19:22:37.878820: Epoch 60
2023-09-03 19:22:37.879849: Current learning rate: backbone 0.00081805, others 0.00081805
2023-09-03 19:22:37.881420: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 19:23:40.071661: finished training epoch 60
2023-09-03 19:23:40.115151: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 19:23:40.117091: The split file contains 1 splits.
2023-09-03 19:23:40.118149: Desired fold for training: 0
2023-09-03 19:23:40.119332: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 19:29:15.024967: dsc: 91.24%
2023-09-03 19:29:15.026881: miou: 83.89%
2023-09-03 19:29:15.028007: acc: 95.60%, sen: 91.02%, spe: 97.14%
2023-09-03 19:29:15.029498: current best miou: 0.8403578140177365 at epoch: 46, (46, 0.8403578140177365, 0.9132548112294836)
2023-09-03 19:29:15.030419: current best dsc: 0.9132548112294836 at epoch: 46, (46, 0.8403578140177365, 0.9132548112294836)
2023-09-03 19:29:15.031595: finished real validation
2023-09-03 19:29:19.389733: train_loss -1.4154
2023-09-03 19:29:19.391304: val_loss -1.1293
2023-09-03 19:29:19.393190: Pseudo dice [0.9156]
2023-09-03 19:29:19.394704: Epoch time: 401.51 s
2023-09-03 19:29:19.397396: Yayy! New best EMA pseudo Dice: 0.9129
2023-09-03 19:29:22.215201: 
2023-09-03 19:29:22.216707: Epoch 61
2023-09-03 19:29:22.217825: Current learning rate: backbone 0.00081498, others 0.00081498
2023-09-03 19:29:22.219323: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 19:30:24.828357: finished training epoch 61
2023-09-03 19:30:24.867463: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 19:30:24.869653: The split file contains 1 splits.
2023-09-03 19:30:24.870816: Desired fold for training: 0
2023-09-03 19:30:24.871802: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 19:36:02.887304: dsc: 91.21%
2023-09-03 19:36:02.888898: miou: 83.84%
2023-09-03 19:36:02.889829: acc: 95.62%, sen: 90.42%, spe: 97.36%
2023-09-03 19:36:02.892391: current best miou: 0.8403578140177365 at epoch: 46, (46, 0.8403578140177365, 0.9132548112294836)
2023-09-03 19:36:02.893613: current best dsc: 0.9132548112294836 at epoch: 46, (46, 0.8403578140177365, 0.9132548112294836)
2023-09-03 19:36:02.894753: finished real validation
2023-09-03 19:36:07.268372: train_loss -1.4176
2023-09-03 19:36:07.269955: val_loss -1.1283
2023-09-03 19:36:07.271227: Pseudo dice [0.9129]
2023-09-03 19:36:07.272255: Epoch time: 405.05 s
2023-09-03 19:36:08.392722: 
2023-09-03 19:36:08.393938: Epoch 62
2023-09-03 19:36:08.394950: Current learning rate: backbone 0.00081191, others 0.00081191
2023-09-03 19:36:08.396503: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 19:37:11.018244: finished training epoch 62
2023-09-03 19:37:11.062419: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 19:37:11.064175: The split file contains 1 splits.
2023-09-03 19:37:11.065127: Desired fold for training: 0
2023-09-03 19:37:11.066002: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 19:42:41.896964: dsc: 91.07%
2023-09-03 19:42:41.898293: miou: 83.61%
2023-09-03 19:42:41.899226: acc: 95.51%, sen: 90.98%, spe: 97.04%
2023-09-03 19:42:41.900757: current best miou: 0.8403578140177365 at epoch: 46, (46, 0.8403578140177365, 0.9132548112294836)
2023-09-03 19:42:41.901733: current best dsc: 0.9132548112294836 at epoch: 46, (46, 0.8403578140177365, 0.9132548112294836)
2023-09-03 19:42:41.903142: finished real validation
2023-09-03 19:42:46.266001: train_loss -1.4174
2023-09-03 19:42:46.267387: val_loss -1.0929
2023-09-03 19:42:46.268529: Pseudo dice [0.9096]
2023-09-03 19:42:46.269494: Epoch time: 397.87 s
2023-09-03 19:42:47.361773: 
2023-09-03 19:42:47.363526: Epoch 63
2023-09-03 19:42:47.364783: Current learning rate: backbone 0.00080884, others 0.00080884
2023-09-03 19:42:47.366210: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 19:43:49.776172: finished training epoch 63
2023-09-03 19:43:49.837068: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 19:43:49.839103: The split file contains 1 splits.
2023-09-03 19:43:49.840159: Desired fold for training: 0
2023-09-03 19:43:49.841093: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 19:49:13.401136: dsc: 91.13%
2023-09-03 19:49:13.402684: miou: 83.71%
2023-09-03 19:49:13.403640: acc: 95.56%, sen: 90.68%, spe: 97.20%
2023-09-03 19:49:13.404957: current best miou: 0.8403578140177365 at epoch: 46, (46, 0.8403578140177365, 0.9132548112294836)
2023-09-03 19:49:13.406100: current best dsc: 0.9132548112294836 at epoch: 46, (46, 0.8403578140177365, 0.9132548112294836)
2023-09-03 19:49:13.406966: finished real validation
2023-09-03 19:49:17.767442: train_loss -1.4181
2023-09-03 19:49:17.769005: val_loss -1.1098
2023-09-03 19:49:17.770156: Pseudo dice [0.9108]
2023-09-03 19:49:17.771140: Epoch time: 390.41 s
2023-09-03 19:49:18.877686: 
2023-09-03 19:49:18.879071: Epoch 64
2023-09-03 19:49:18.880153: Current learning rate: backbone 0.00080577, others 0.00080577
2023-09-03 19:49:18.881761: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 19:50:20.733395: finished training epoch 64
2023-09-03 19:50:20.774463: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 19:50:20.776869: The split file contains 1 splits.
2023-09-03 19:50:20.778539: Desired fold for training: 0
2023-09-03 19:50:20.779842: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 19:55:58.589386: dsc: 91.19%
2023-09-03 19:55:58.591007: miou: 83.80%
2023-09-03 19:55:58.591966: acc: 95.60%, sen: 90.43%, spe: 97.34%
2023-09-03 19:55:58.593261: current best miou: 0.8403578140177365 at epoch: 46, (46, 0.8403578140177365, 0.9132548112294836)
2023-09-03 19:55:58.594188: current best dsc: 0.9132548112294836 at epoch: 46, (46, 0.8403578140177365, 0.9132548112294836)
2023-09-03 19:55:58.595080: finished real validation
2023-09-03 19:56:02.959278: train_loss -1.4185
2023-09-03 19:56:02.961079: val_loss -1.1208
2023-09-03 19:56:02.962503: Pseudo dice [0.9132]
2023-09-03 19:56:02.963731: Epoch time: 404.08 s
2023-09-03 19:56:04.070936: 
2023-09-03 19:56:04.072352: Epoch 65
2023-09-03 19:56:04.073385: Current learning rate: backbone 0.0008027, others 0.0008027
2023-09-03 19:56:04.075303: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 19:57:06.406515: finished training epoch 65
2023-09-03 19:57:06.438753: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 19:57:06.440685: The split file contains 1 splits.
2023-09-03 19:57:06.441623: Desired fold for training: 0
2023-09-03 19:57:06.442436: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 20:02:37.325239: dsc: 91.16%
2023-09-03 20:02:37.326849: miou: 83.76%
2023-09-03 20:02:37.327791: acc: 95.57%, sen: 90.84%, spe: 97.16%
2023-09-03 20:02:37.329716: current best miou: 0.8403578140177365 at epoch: 46, (46, 0.8403578140177365, 0.9132548112294836)
2023-09-03 20:02:37.330771: current best dsc: 0.9132548112294836 at epoch: 46, (46, 0.8403578140177365, 0.9132548112294836)
2023-09-03 20:02:37.331927: finished real validation
2023-09-03 20:02:41.705028: train_loss -1.4184
2023-09-03 20:02:41.706483: val_loss -1.1011
2023-09-03 20:02:41.707692: Pseudo dice [0.9117]
2023-09-03 20:02:41.708723: Epoch time: 397.64 s
2023-09-03 20:02:42.834919: 
2023-09-03 20:02:42.836184: Epoch 66
2023-09-03 20:02:42.837163: Current learning rate: backbone 0.00079962, others 0.00079962
2023-09-03 20:02:42.838634: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 20:03:45.093392: finished training epoch 66
2023-09-03 20:03:45.133399: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 20:03:45.135302: The split file contains 1 splits.
2023-09-03 20:03:45.136274: Desired fold for training: 0
2023-09-03 20:03:45.137223: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 20:09:15.048973: dsc: 91.32%
2023-09-03 20:09:15.050281: miou: 84.02%
2023-09-03 20:09:15.051208: acc: 95.67%, sen: 90.64%, spe: 97.35%
2023-09-03 20:09:15.052410: current best miou: 0.8403578140177365 at epoch: 46, (46, 0.8403578140177365, 0.9132548112294836)
2023-09-03 20:09:15.053336: current best dsc: 0.9132548112294836 at epoch: 46, (46, 0.8403578140177365, 0.9132548112294836)
2023-09-03 20:09:15.054206: finished real validation
2023-09-03 20:09:19.410866: train_loss -1.4192
2023-09-03 20:09:19.412272: val_loss -1.1134
2023-09-03 20:09:19.413517: Pseudo dice [0.9126]
2023-09-03 20:09:19.414527: Epoch time: 396.58 s
2023-09-03 20:09:20.535319: 
2023-09-03 20:09:20.536815: Epoch 67
2023-09-03 20:09:20.537858: Current learning rate: backbone 0.00079655, others 0.00079655
2023-09-03 20:09:20.539328: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 20:10:22.909965: finished training epoch 67
2023-09-03 20:10:22.976792: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 20:10:22.979110: The split file contains 1 splits.
2023-09-03 20:10:22.980374: Desired fold for training: 0
2023-09-03 20:10:22.981338: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 20:15:53.027894: dsc: 91.08%
2023-09-03 20:15:53.029558: miou: 83.62%
2023-09-03 20:15:53.030594: acc: 95.54%, sen: 90.51%, spe: 97.23%
2023-09-03 20:15:53.031962: current best miou: 0.8403578140177365 at epoch: 46, (46, 0.8403578140177365, 0.9132548112294836)
2023-09-03 20:15:53.033036: current best dsc: 0.9132548112294836 at epoch: 46, (46, 0.8403578140177365, 0.9132548112294836)
2023-09-03 20:15:53.033997: finished real validation
2023-09-03 20:15:57.403481: train_loss -1.4196
2023-09-03 20:15:57.405432: val_loss -1.1274
2023-09-03 20:15:57.407353: Pseudo dice [0.916]
2023-09-03 20:15:57.408781: Epoch time: 396.87 s
2023-09-03 20:15:58.550889: 
2023-09-03 20:15:58.552288: Epoch 68
2023-09-03 20:15:58.553415: Current learning rate: backbone 0.00079347, others 0.00079347
2023-09-03 20:15:58.555244: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 20:17:00.877967: finished training epoch 68
2023-09-03 20:17:00.916482: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 20:17:00.918363: The split file contains 1 splits.
2023-09-03 20:17:00.919366: Desired fold for training: 0
2023-09-03 20:17:00.920294: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 20:22:26.154076: dsc: 91.06%
2023-09-03 20:22:26.155696: miou: 83.58%
2023-09-03 20:22:26.156711: acc: 95.56%, sen: 89.93%, spe: 97.45%
2023-09-03 20:22:26.158140: current best miou: 0.8403578140177365 at epoch: 46, (46, 0.8403578140177365, 0.9132548112294836)
2023-09-03 20:22:26.159739: current best dsc: 0.9132548112294836 at epoch: 46, (46, 0.8403578140177365, 0.9132548112294836)
2023-09-03 20:22:26.160638: finished real validation
2023-09-03 20:22:30.534186: train_loss -1.4209
2023-09-03 20:22:30.537169: val_loss -1.1149
2023-09-03 20:22:30.539247: Pseudo dice [0.9134]
2023-09-03 20:22:30.540768: Epoch time: 391.99 s
2023-09-03 20:22:31.728455: 
2023-09-03 20:22:31.730175: Epoch 69
2023-09-03 20:22:31.731255: Current learning rate: backbone 0.00079039, others 0.00079039
2023-09-03 20:22:31.733164: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 20:23:34.669712: finished training epoch 69
2023-09-03 20:23:34.720039: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 20:23:34.721959: The split file contains 1 splits.
2023-09-03 20:23:34.723191: Desired fold for training: 0
2023-09-03 20:23:34.724246: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 20:29:00.679430: dsc: 91.16%
2023-09-03 20:29:00.681168: miou: 83.76%
2023-09-03 20:29:00.682146: acc: 95.58%, sen: 90.65%, spe: 97.24%
2023-09-03 20:29:00.683668: current best miou: 0.8403578140177365 at epoch: 46, (46, 0.8403578140177365, 0.9132548112294836)
2023-09-03 20:29:00.684694: current best dsc: 0.9132548112294836 at epoch: 46, (46, 0.8403578140177365, 0.9132548112294836)
2023-09-03 20:29:00.685618: finished real validation
2023-09-03 20:29:05.039455: train_loss -1.4189
2023-09-03 20:29:05.041009: val_loss -1.1123
2023-09-03 20:29:05.042354: Pseudo dice [0.9135]
2023-09-03 20:29:05.043388: Epoch time: 393.31 s
2023-09-03 20:29:06.571019: Yayy! New best EMA pseudo Dice: 0.9129
2023-09-03 20:29:09.215238: 
2023-09-03 20:29:09.216774: Epoch 70
2023-09-03 20:29:09.217927: Current learning rate: backbone 0.00078731, others 0.00078731
2023-09-03 20:29:09.219694: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 20:30:11.738554: finished training epoch 70
2023-09-03 20:30:11.786497: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 20:30:11.788699: The split file contains 1 splits.
2023-09-03 20:30:11.789793: Desired fold for training: 0
2023-09-03 20:30:11.790801: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 20:35:36.491735: dsc: 91.02%
2023-09-03 20:35:36.493260: miou: 83.52%
2023-09-03 20:35:36.494194: acc: 95.53%, sen: 90.09%, spe: 97.36%
2023-09-03 20:35:36.495409: current best miou: 0.8403578140177365 at epoch: 46, (46, 0.8403578140177365, 0.9132548112294836)
2023-09-03 20:35:36.496347: current best dsc: 0.9132548112294836 at epoch: 46, (46, 0.8403578140177365, 0.9132548112294836)
2023-09-03 20:35:36.497208: finished real validation
2023-09-03 20:35:40.852390: train_loss -1.4199
2023-09-03 20:35:40.853897: val_loss -1.1151
2023-09-03 20:35:40.855131: Pseudo dice [0.9105]
2023-09-03 20:35:40.856174: Epoch time: 391.64 s
2023-09-03 20:35:41.995024: 
2023-09-03 20:35:41.996485: Epoch 71
2023-09-03 20:35:41.997533: Current learning rate: backbone 0.00078423, others 0.00078423
2023-09-03 20:35:41.998998: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 20:36:43.786904: finished training epoch 71
2023-09-03 20:36:43.816324: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 20:36:43.818202: The split file contains 1 splits.
2023-09-03 20:36:43.819198: Desired fold for training: 0
2023-09-03 20:36:43.820125: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 20:42:18.754067: dsc: 91.27%
2023-09-03 20:42:18.756943: miou: 83.95%
2023-09-03 20:42:18.758315: acc: 95.63%, sen: 90.87%, spe: 97.23%
2023-09-03 20:42:18.760806: current best miou: 0.8403578140177365 at epoch: 46, (46, 0.8403578140177365, 0.9132548112294836)
2023-09-03 20:42:18.762048: current best dsc: 0.9132548112294836 at epoch: 46, (46, 0.8403578140177365, 0.9132548112294836)
2023-09-03 20:42:18.763261: finished real validation
2023-09-03 20:42:23.144227: train_loss -1.4199
2023-09-03 20:42:23.146227: val_loss -1.1266
2023-09-03 20:42:23.148354: Pseudo dice [0.914]
2023-09-03 20:42:23.149771: Epoch time: 401.15 s
2023-09-03 20:42:24.291190: 
2023-09-03 20:42:24.292481: Epoch 72
2023-09-03 20:42:24.293612: Current learning rate: backbone 0.00078115, others 0.00078115
2023-09-03 20:42:24.295274: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 20:43:26.154800: finished training epoch 72
2023-09-03 20:43:26.203460: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 20:43:26.205481: The split file contains 1 splits.
2023-09-03 20:43:26.206941: Desired fold for training: 0
2023-09-03 20:43:26.207868: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 20:49:00.312244: dsc: 91.26%
2023-09-03 20:49:00.313799: miou: 83.93%
2023-09-03 20:49:00.314781: acc: 95.61%, sen: 91.11%, spe: 97.13%
2023-09-03 20:49:00.316054: current best miou: 0.8403578140177365 at epoch: 46, (46, 0.8403578140177365, 0.9132548112294836)
2023-09-03 20:49:00.316950: current best dsc: 0.9132548112294836 at epoch: 46, (46, 0.8403578140177365, 0.9132548112294836)
2023-09-03 20:49:00.317851: finished real validation
2023-09-03 20:49:04.666459: train_loss -1.421
2023-09-03 20:49:04.668039: val_loss -1.1234
2023-09-03 20:49:04.669353: Pseudo dice [0.9156]
2023-09-03 20:49:04.670444: Epoch time: 400.38 s
2023-09-03 20:49:04.671405: Yayy! New best EMA pseudo Dice: 0.9131
2023-09-03 20:49:07.462236: 
2023-09-03 20:49:07.463583: Epoch 73
2023-09-03 20:49:07.464604: Current learning rate: backbone 0.00077806, others 0.00077806
2023-09-03 20:49:07.466111: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 20:50:09.641556: finished training epoch 73
2023-09-03 20:50:09.711968: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 20:50:09.714289: The split file contains 1 splits.
2023-09-03 20:50:09.715469: Desired fold for training: 0
2023-09-03 20:50:09.716551: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 20:55:48.803938: dsc: 91.19%
2023-09-03 20:55:48.805670: miou: 83.81%
2023-09-03 20:55:48.806683: acc: 95.61%, sen: 90.47%, spe: 97.33%
2023-09-03 20:55:48.808205: current best miou: 0.8403578140177365 at epoch: 46, (46, 0.8403578140177365, 0.9132548112294836)
2023-09-03 20:55:48.809179: current best dsc: 0.9132548112294836 at epoch: 46, (46, 0.8403578140177365, 0.9132548112294836)
2023-09-03 20:55:48.810099: finished real validation
2023-09-03 20:55:53.193241: train_loss -1.4214
2023-09-03 20:55:53.195765: val_loss -1.0843
2023-09-03 20:55:53.197938: Pseudo dice [0.9107]
2023-09-03 20:55:53.199108: Epoch time: 405.73 s
2023-09-03 20:55:54.387534: 
2023-09-03 20:55:54.389526: Epoch 74
2023-09-03 20:55:54.390774: Current learning rate: backbone 0.00077498, others 0.00077498
2023-09-03 20:55:54.393025: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 20:56:57.410285: finished training epoch 74
2023-09-03 20:56:57.446933: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 20:56:57.449067: The split file contains 1 splits.
2023-09-03 20:56:57.450116: Desired fold for training: 0
2023-09-03 20:56:57.451102: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 21:02:40.010728: dsc: 91.36%
2023-09-03 21:02:40.012251: miou: 84.10%
2023-09-03 21:02:40.013248: acc: 95.66%, sen: 91.34%, spe: 97.11%
2023-09-03 21:02:40.014525: current best miou: 0.8409641944317505 at epoch: 74, (74, 0.8409641944317505, 0.9136127655012112)
2023-09-03 21:02:40.015562: current best dsc: 0.9136127655012112 at epoch: 74, (74, 0.8409641944317505, 0.9136127655012112)
2023-09-03 21:02:41.719360: finished real validation
2023-09-03 21:02:46.071373: train_loss -1.4219
2023-09-03 21:02:46.072797: val_loss -1.1309
2023-09-03 21:02:46.074039: Pseudo dice [0.914]
2023-09-03 21:02:46.075080: Epoch time: 411.69 s
2023-09-03 21:02:47.189094: 
2023-09-03 21:02:47.190823: Epoch 75
2023-09-03 21:02:47.191961: Current learning rate: backbone 0.00077189, others 0.00077189
2023-09-03 21:02:47.193489: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 21:03:49.782974: finished training epoch 75
2023-09-03 21:03:49.882849: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 21:03:49.886722: The split file contains 1 splits.
2023-09-03 21:03:49.888368: Desired fold for training: 0
2023-09-03 21:03:49.889887: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 21:09:24.110844: dsc: 91.30%
2023-09-03 21:09:24.112495: miou: 84.00%
2023-09-03 21:09:24.113496: acc: 95.63%, sen: 91.31%, spe: 97.08%
2023-09-03 21:09:24.114860: current best miou: 0.8409641944317505 at epoch: 74, (74, 0.8409641944317505, 0.9136127655012112)
2023-09-03 21:09:24.115843: current best dsc: 0.9136127655012112 at epoch: 74, (74, 0.8409641944317505, 0.9136127655012112)
2023-09-03 21:09:24.116750: finished real validation
2023-09-03 21:09:28.509003: train_loss -1.421
2023-09-03 21:09:28.510600: val_loss -1.0862
2023-09-03 21:09:28.511914: Pseudo dice [0.9102]
2023-09-03 21:09:28.512980: Epoch time: 401.32 s
2023-09-03 21:09:29.644575: 
2023-09-03 21:09:29.646726: Epoch 76
2023-09-03 21:09:29.648428: Current learning rate: backbone 0.0007688, others 0.0007688
2023-09-03 21:09:29.650875: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 21:10:31.671592: finished training epoch 76
2023-09-03 21:10:31.711205: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 21:10:31.713259: The split file contains 1 splits.
2023-09-03 21:10:31.714364: Desired fold for training: 0
2023-09-03 21:10:31.715360: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 21:16:19.520319: dsc: 91.12%
2023-09-03 21:16:19.522210: miou: 83.69%
2023-09-03 21:16:19.523200: acc: 95.52%, sen: 91.42%, spe: 96.90%
2023-09-03 21:16:19.524974: current best miou: 0.8409641944317505 at epoch: 74, (74, 0.8409641944317505, 0.9136127655012112)
2023-09-03 21:16:19.525973: current best dsc: 0.9136127655012112 at epoch: 74, (74, 0.8409641944317505, 0.9136127655012112)
2023-09-03 21:16:19.527131: finished real validation
2023-09-03 21:16:28.775587: train_loss -1.4225
2023-09-03 21:16:28.777184: val_loss -1.1112
2023-09-03 21:16:28.778697: Pseudo dice [0.9142]
2023-09-03 21:16:28.779733: Epoch time: 419.13 s
2023-09-03 21:16:30.042714: 
2023-09-03 21:16:30.044183: Epoch 77
2023-09-03 21:16:30.045286: Current learning rate: backbone 0.00076571, others 0.00076571
2023-09-03 21:16:30.046928: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 21:17:33.448087: finished training epoch 77
2023-09-03 21:23:57.524177: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 21:23:57.526407: The split file contains 1 splits.
2023-09-03 21:23:57.527551: Desired fold for training: 0
2023-09-03 21:23:57.528534: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 21:58:49.004608: dsc: 91.12%
2023-09-03 21:58:49.013966: miou: 83.69%
2023-09-03 21:58:49.015031: acc: 95.55%, sen: 90.79%, spe: 97.15%
2023-09-03 21:58:49.016583: current best miou: 0.8409641944317505 at epoch: 74, (74, 0.8409641944317505, 0.9136127655012112)
2023-09-03 21:58:49.017590: current best dsc: 0.9136127655012112 at epoch: 74, (74, 0.8409641944317505, 0.9136127655012112)
2023-09-03 21:58:49.018478: finished real validation
2023-09-03 21:58:53.437034: train_loss -1.4238
2023-09-03 21:58:53.438691: val_loss -1.0927
2023-09-03 21:58:53.440269: Pseudo dice [0.9099]
2023-09-03 21:58:53.441463: Epoch time: 2543.4 s
2023-09-03 21:58:54.632928: 
2023-09-03 21:58:54.634743: Epoch 78
2023-09-03 21:58:54.635912: Current learning rate: backbone 0.00076262, others 0.00076262
2023-09-03 21:58:54.637798: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 21:59:56.792527: finished training epoch 78
2023-09-03 21:59:56.822728: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 21:59:56.824824: The split file contains 1 splits.
2023-09-03 21:59:56.825942: Desired fold for training: 0
2023-09-03 21:59:56.826959: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 22:05:54.662536: dsc: 90.94%
2023-09-03 22:05:54.673893: miou: 83.38%
2023-09-03 22:05:54.675085: acc: 95.48%, sen: 90.12%, spe: 97.28%
2023-09-03 22:05:54.676523: current best miou: 0.8409641944317505 at epoch: 74, (74, 0.8409641944317505, 0.9136127655012112)
2023-09-03 22:05:54.677652: current best dsc: 0.9136127655012112 at epoch: 74, (74, 0.8409641944317505, 0.9136127655012112)
2023-09-03 22:05:54.678760: finished real validation
2023-09-03 22:05:59.068377: train_loss -1.4239
2023-09-03 22:05:59.070117: val_loss -1.0636
2023-09-03 22:05:59.071593: Pseudo dice [0.9075]
2023-09-03 22:05:59.072779: Epoch time: 424.44 s
2023-09-03 22:06:00.334264: 
2023-09-03 22:06:00.335998: Epoch 79
2023-09-03 22:06:00.337627: Current learning rate: backbone 0.00075953, others 0.00075953
2023-09-03 22:06:00.339186: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 22:07:02.483704: finished training epoch 79
2023-09-03 22:07:02.515004: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 22:07:02.517295: The split file contains 1 splits.
2023-09-03 22:07:02.518359: Desired fold for training: 0
2023-09-03 22:07:02.519573: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 22:12:18.703741: dsc: 91.11%
2023-09-03 22:12:18.705519: miou: 83.67%
2023-09-03 22:12:18.706541: acc: 95.53%, sen: 90.98%, spe: 97.07%
2023-09-03 22:12:18.707851: current best miou: 0.8409641944317505 at epoch: 74, (74, 0.8409641944317505, 0.9136127655012112)
2023-09-03 22:12:18.708948: current best dsc: 0.9136127655012112 at epoch: 74, (74, 0.8409641944317505, 0.9136127655012112)
2023-09-03 22:12:18.709862: finished real validation
2023-09-03 22:12:23.089606: train_loss -1.4233
2023-09-03 22:12:23.091208: val_loss -1.0738
2023-09-03 22:12:23.092556: Pseudo dice [0.9067]
2023-09-03 22:12:23.093742: Epoch time: 382.76 s
2023-09-03 22:12:25.933914: 
2023-09-03 22:12:25.935328: Epoch 80
2023-09-03 22:12:25.936427: Current learning rate: backbone 0.00075643, others 0.00075643
2023-09-03 22:12:25.937843: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 22:13:27.661161: finished training epoch 80
2023-09-03 22:13:27.698673: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 22:13:27.701874: The split file contains 1 splits.
2023-09-03 22:13:27.703122: Desired fold for training: 0
2023-09-03 22:13:27.710457: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 22:18:32.966039: dsc: 91.17%
2023-09-03 22:18:32.967637: miou: 83.78%
2023-09-03 22:18:32.968704: acc: 95.60%, sen: 90.29%, spe: 97.39%
2023-09-03 22:18:32.970475: current best miou: 0.8409641944317505 at epoch: 74, (74, 0.8409641944317505, 0.9136127655012112)
2023-09-03 22:18:32.971742: current best dsc: 0.9136127655012112 at epoch: 74, (74, 0.8409641944317505, 0.9136127655012112)
2023-09-03 22:18:32.972864: finished real validation
2023-09-03 22:18:37.366513: train_loss -1.424
2023-09-03 22:18:37.368035: val_loss -1.1257
2023-09-03 22:18:37.369284: Pseudo dice [0.9155]
2023-09-03 22:18:37.370399: Epoch time: 371.43 s
2023-09-03 22:18:38.565238: 
2023-09-03 22:18:38.566536: Epoch 81
2023-09-03 22:18:38.567595: Current learning rate: backbone 0.00075334, others 0.00075334
2023-09-03 22:18:38.569018: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 22:19:40.281620: finished training epoch 81
2023-09-03 22:19:40.318254: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 22:19:40.320007: The split file contains 1 splits.
2023-09-03 22:19:40.321187: Desired fold for training: 0
2023-09-03 22:19:40.322144: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 22:25:53.602518: dsc: 91.07%
2023-09-03 22:25:53.603945: miou: 83.61%
2023-09-03 22:25:53.604956: acc: 95.53%, sen: 90.66%, spe: 97.17%
2023-09-03 22:25:53.606167: current best miou: 0.8409641944317505 at epoch: 74, (74, 0.8409641944317505, 0.9136127655012112)
2023-09-03 22:25:53.607168: current best dsc: 0.9136127655012112 at epoch: 74, (74, 0.8409641944317505, 0.9136127655012112)
2023-09-03 22:25:53.608088: finished real validation
2023-09-03 22:25:57.957077: train_loss -1.4239
2023-09-03 22:25:57.958541: val_loss -1.1091
2023-09-03 22:25:57.959866: Pseudo dice [0.9147]
2023-09-03 22:25:57.960865: Epoch time: 439.39 s
2023-09-03 22:25:59.127609: 
2023-09-03 22:25:59.129220: Epoch 82
2023-09-03 22:25:59.130336: Current learning rate: backbone 0.00075024, others 0.00075024
2023-09-03 22:25:59.131847: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 22:27:00.685201: finished training epoch 82
2023-09-03 22:27:00.750443: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 22:27:00.753734: The split file contains 1 splits.
2023-09-03 22:27:00.755311: Desired fold for training: 0
2023-09-03 22:27:00.756475: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 22:32:12.130435: dsc: 90.99%
2023-09-03 22:32:12.131697: miou: 83.46%
2023-09-03 22:32:12.132860: acc: 95.47%, sen: 90.96%, spe: 96.98%
2023-09-03 22:32:12.134551: current best miou: 0.8409641944317505 at epoch: 74, (74, 0.8409641944317505, 0.9136127655012112)
2023-09-03 22:32:12.135607: current best dsc: 0.9136127655012112 at epoch: 74, (74, 0.8409641944317505, 0.9136127655012112)
2023-09-03 22:32:12.137022: finished real validation
2023-09-03 22:32:16.488602: train_loss -1.4252
2023-09-03 22:32:16.490188: val_loss -1.0822
2023-09-03 22:32:16.491488: Pseudo dice [0.9096]
2023-09-03 22:32:16.492563: Epoch time: 377.36 s
2023-09-03 22:32:17.611884: 
2023-09-03 22:32:17.613819: Epoch 83
2023-09-03 22:32:17.615249: Current learning rate: backbone 0.00074714, others 0.00074714
2023-09-03 22:32:17.617080: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 22:33:19.322728: finished training epoch 83
2023-09-03 22:33:19.354158: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 22:33:19.356175: The split file contains 1 splits.
2023-09-03 22:33:19.357243: Desired fold for training: 0
2023-09-03 22:33:19.358332: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 22:38:37.331001: dsc: 91.06%
2023-09-03 22:38:37.332431: miou: 83.58%
2023-09-03 22:38:37.333551: acc: 95.51%, sen: 90.93%, spe: 97.05%
2023-09-03 22:38:37.335050: current best miou: 0.8409641944317505 at epoch: 74, (74, 0.8409641944317505, 0.9136127655012112)
2023-09-03 22:38:37.336315: current best dsc: 0.9136127655012112 at epoch: 74, (74, 0.8409641944317505, 0.9136127655012112)
2023-09-03 22:38:37.337440: finished real validation
2023-09-03 22:38:41.697710: train_loss -1.425
2023-09-03 22:38:41.699328: val_loss -1.119
2023-09-03 22:38:41.700692: Pseudo dice [0.9127]
2023-09-03 22:38:41.701761: Epoch time: 384.09 s
2023-09-03 22:38:42.819896: 
2023-09-03 22:38:42.821862: Epoch 84
2023-09-03 22:38:42.823455: Current learning rate: backbone 0.00074405, others 0.00074405
2023-09-03 22:38:42.825310: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 22:39:44.447194: finished training epoch 84
2023-09-03 22:39:44.475013: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 22:39:44.476903: The split file contains 1 splits.
2023-09-03 22:39:44.477979: Desired fold for training: 0
2023-09-03 22:39:44.479389: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 22:44:57.688368: dsc: 91.16%
2023-09-03 22:44:57.689689: miou: 83.76%
2023-09-03 22:44:57.690784: acc: 95.57%, sen: 90.84%, spe: 97.16%
2023-09-03 22:44:57.692196: current best miou: 0.8409641944317505 at epoch: 74, (74, 0.8409641944317505, 0.9136127655012112)
2023-09-03 22:44:57.693232: current best dsc: 0.9136127655012112 at epoch: 74, (74, 0.8409641944317505, 0.9136127655012112)
2023-09-03 22:44:57.694230: finished real validation
2023-09-03 22:45:02.049872: train_loss -1.4252
2023-09-03 22:45:02.052198: val_loss -1.1079
2023-09-03 22:45:02.054702: Pseudo dice [0.9137]
2023-09-03 22:45:02.056896: Epoch time: 379.23 s
2023-09-03 22:45:03.196211: 
2023-09-03 22:45:03.197950: Epoch 85
2023-09-03 22:45:03.199244: Current learning rate: backbone 0.00074094, others 0.00074094
2023-09-03 22:45:03.201014: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 22:46:04.894762: finished training epoch 85
2023-09-03 22:46:04.942526: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 22:46:04.944348: The split file contains 1 splits.
2023-09-03 22:46:04.945430: Desired fold for training: 0
2023-09-03 22:46:04.946754: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 22:51:17.585614: dsc: 91.00%
2023-09-03 22:51:17.586945: miou: 83.48%
2023-09-03 22:51:17.587844: acc: 95.50%, sen: 90.46%, spe: 97.19%
2023-09-03 22:51:17.589070: current best miou: 0.8409641944317505 at epoch: 74, (74, 0.8409641944317505, 0.9136127655012112)
2023-09-03 22:51:17.590000: current best dsc: 0.9136127655012112 at epoch: 74, (74, 0.8409641944317505, 0.9136127655012112)
2023-09-03 22:51:17.590896: finished real validation
2023-09-03 22:51:21.951868: train_loss -1.4255
2023-09-03 22:51:21.953593: val_loss -1.0879
2023-09-03 22:51:21.954973: Pseudo dice [0.9107]
2023-09-03 22:51:21.956108: Epoch time: 378.76 s
2023-09-03 22:51:23.094004: 
2023-09-03 22:51:23.095474: Epoch 86
2023-09-03 22:51:23.096635: Current learning rate: backbone 0.00073784, others 0.00073784
2023-09-03 22:51:23.098132: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 22:52:24.698596: finished training epoch 86
2023-09-03 22:52:24.739496: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 22:52:24.741577: The split file contains 1 splits.
2023-09-03 22:52:24.742635: Desired fold for training: 0
2023-09-03 22:52:24.743620: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 22:57:38.529817: dsc: 91.01%
2023-09-03 22:57:38.531116: miou: 83.50%
2023-09-03 22:57:38.532038: acc: 95.51%, sen: 90.27%, spe: 97.28%
2023-09-03 22:57:38.533275: current best miou: 0.8409641944317505 at epoch: 74, (74, 0.8409641944317505, 0.9136127655012112)
2023-09-03 22:57:38.534175: current best dsc: 0.9136127655012112 at epoch: 74, (74, 0.8409641944317505, 0.9136127655012112)
2023-09-03 22:57:38.535148: finished real validation
2023-09-03 22:57:42.888323: train_loss -1.4253
2023-09-03 22:57:42.889814: val_loss -1.1007
2023-09-03 22:57:42.891106: Pseudo dice [0.9114]
2023-09-03 22:57:42.892205: Epoch time: 379.8 s
2023-09-03 22:57:44.021291: 
2023-09-03 22:57:44.022734: Epoch 87
2023-09-03 22:57:44.024138: Current learning rate: backbone 0.00073474, others 0.00073474
2023-09-03 22:57:44.025831: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 22:58:45.642035: finished training epoch 87
2023-09-03 22:58:45.704634: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 22:58:45.706461: The split file contains 1 splits.
2023-09-03 22:58:45.707544: Desired fold for training: 0
2023-09-03 22:58:45.708557: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 23:04:05.103776: dsc: 91.41%
2023-09-03 23:04:05.105320: miou: 84.17%
2023-09-03 23:04:05.106477: acc: 95.68%, sen: 91.35%, spe: 97.14%
2023-09-03 23:04:05.108031: current best miou: 0.8417323196941785 at epoch: 87, (87, 0.8417323196941785, 0.9140658614645466)
2023-09-03 23:04:05.109221: current best dsc: 0.9140658614645466 at epoch: 87, (87, 0.8417323196941785, 0.9140658614645466)
2023-09-03 23:04:06.734447: finished real validation
2023-09-03 23:04:11.081208: train_loss -1.4255
2023-09-03 23:04:11.082947: val_loss -1.0996
2023-09-03 23:04:11.084278: Pseudo dice [0.9136]
2023-09-03 23:04:11.085387: Epoch time: 387.06 s
2023-09-03 23:04:12.207887: 
2023-09-03 23:04:12.209264: Epoch 88
2023-09-03 23:04:12.210450: Current learning rate: backbone 0.00073163, others 0.00073163
2023-09-03 23:04:12.212088: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 23:05:13.723332: finished training epoch 88
2023-09-03 23:05:13.763637: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 23:05:13.765861: The split file contains 1 splits.
2023-09-03 23:05:13.766965: Desired fold for training: 0
2023-09-03 23:05:13.767974: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 23:10:24.243788: dsc: 91.23%
2023-09-03 23:10:24.245067: miou: 83.87%
2023-09-03 23:10:24.246078: acc: 95.58%, sen: 91.27%, spe: 97.03%
2023-09-03 23:10:24.247395: current best miou: 0.8417323196941785 at epoch: 87, (87, 0.8417323196941785, 0.9140658614645466)
2023-09-03 23:10:24.248415: current best dsc: 0.9140658614645466 at epoch: 87, (87, 0.8417323196941785, 0.9140658614645466)
2023-09-03 23:10:24.249369: finished real validation
2023-09-03 23:10:28.590462: train_loss -1.4251
2023-09-03 23:10:28.592226: val_loss -1.0976
2023-09-03 23:10:28.593642: Pseudo dice [0.9124]
2023-09-03 23:10:28.594816: Epoch time: 376.38 s
2023-09-03 23:10:29.720834: 
2023-09-03 23:10:29.722357: Epoch 89
2023-09-03 23:10:29.723595: Current learning rate: backbone 0.00072853, others 0.00072853
2023-09-03 23:10:29.725192: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 23:11:31.910741: finished training epoch 89
2023-09-03 23:11:31.958025: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 23:11:31.959796: The split file contains 1 splits.
2023-09-03 23:11:31.960857: Desired fold for training: 0
2023-09-03 23:11:31.965533: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 23:16:43.431679: dsc: 91.32%
2023-09-03 23:16:43.433167: miou: 84.03%
2023-09-03 23:16:43.434278: acc: 95.64%, sen: 91.28%, spe: 97.10%
2023-09-03 23:16:43.435664: current best miou: 0.8417323196941785 at epoch: 87, (87, 0.8417323196941785, 0.9140658614645466)
2023-09-03 23:16:43.437025: current best dsc: 0.9140658614645466 at epoch: 87, (87, 0.8417323196941785, 0.9140658614645466)
2023-09-03 23:16:43.437985: finished real validation
2023-09-03 23:16:47.815510: train_loss -1.4275
2023-09-03 23:16:47.817433: val_loss -1.0948
2023-09-03 23:16:47.818823: Pseudo dice [0.912]
2023-09-03 23:16:47.819998: Epoch time: 378.1 s
2023-09-03 23:16:50.512621: 
2023-09-03 23:16:50.514210: Epoch 90
2023-09-03 23:16:50.515532: Current learning rate: backbone 0.00072542, others 0.00072542
2023-09-03 23:16:50.517161: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 23:17:52.057490: finished training epoch 90
2023-09-03 23:17:52.095012: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 23:17:52.097592: The split file contains 1 splits.
2023-09-03 23:17:52.098792: Desired fold for training: 0
2023-09-03 23:17:52.100142: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 23:23:04.208496: dsc: 91.10%
2023-09-03 23:23:04.210009: miou: 83.65%
2023-09-03 23:23:04.211271: acc: 95.55%, sen: 90.63%, spe: 97.20%
2023-09-03 23:23:04.212566: current best miou: 0.8417323196941785 at epoch: 87, (87, 0.8417323196941785, 0.9140658614645466)
2023-09-03 23:23:04.213671: current best dsc: 0.9140658614645466 at epoch: 87, (87, 0.8417323196941785, 0.9140658614645466)
2023-09-03 23:23:04.214638: finished real validation
2023-09-03 23:23:08.561380: train_loss -1.4267
2023-09-03 23:23:08.562955: val_loss -1.1035
2023-09-03 23:23:08.564245: Pseudo dice [0.9129]
2023-09-03 23:23:08.565331: Epoch time: 378.05 s
2023-09-03 23:23:09.674345: 
2023-09-03 23:23:09.675710: Epoch 91
2023-09-03 23:23:09.677582: Current learning rate: backbone 0.00072231, others 0.00072231
2023-09-03 23:23:09.679159: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 23:24:11.210533: finished training epoch 91
2023-09-03 23:24:11.254493: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 23:24:11.256631: The split file contains 1 splits.
2023-09-03 23:24:11.257960: Desired fold for training: 0
2023-09-03 23:24:11.259100: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 23:29:24.996538: dsc: 91.45%
2023-09-03 23:29:24.997909: miou: 84.25%
2023-09-03 23:29:24.998904: acc: 95.69%, sen: 91.69%, spe: 97.03%
2023-09-03 23:29:25.000278: current best miou: 0.8424533035516987 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-03 23:29:25.001288: current best dsc: 0.9144908062827978 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-03 23:29:26.514372: finished real validation
2023-09-03 23:29:30.858186: train_loss -1.4265
2023-09-03 23:29:30.859698: val_loss -1.129
2023-09-03 23:29:30.861066: Pseudo dice [0.9184]
2023-09-03 23:29:30.862240: Epoch time: 381.19 s
2023-09-03 23:29:31.975341: 
2023-09-03 23:29:31.976715: Epoch 92
2023-09-03 23:29:31.977820: Current learning rate: backbone 0.0007192, others 0.0007192
2023-09-03 23:29:31.979397: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 23:30:33.464046: finished training epoch 92
2023-09-03 23:30:33.502546: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 23:30:33.504778: The split file contains 1 splits.
2023-09-03 23:30:33.505801: Desired fold for training: 0
2023-09-03 23:30:33.506756: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 23:35:52.453768: dsc: 91.22%
2023-09-03 23:35:52.455350: miou: 83.85%
2023-09-03 23:35:52.456747: acc: 95.58%, sen: 91.22%, spe: 97.05%
2023-09-03 23:35:52.458407: current best miou: 0.8424533035516987 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-03 23:35:52.460038: current best dsc: 0.9144908062827978 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-03 23:35:52.461034: finished real validation
2023-09-03 23:35:56.812142: train_loss -1.4269
2023-09-03 23:35:56.813728: val_loss -1.1096
2023-09-03 23:35:56.815040: Pseudo dice [0.9138]
2023-09-03 23:35:56.816144: Epoch time: 384.84 s
2023-09-03 23:35:57.933296: 
2023-09-03 23:35:57.934865: Epoch 93
2023-09-03 23:35:57.936118: Current learning rate: backbone 0.00071608, others 0.00071608
2023-09-03 23:35:57.937766: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 23:36:59.480622: finished training epoch 93
2023-09-03 23:36:59.515802: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 23:36:59.517889: The split file contains 1 splits.
2023-09-03 23:36:59.519018: Desired fold for training: 0
2023-09-03 23:36:59.520022: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 23:42:12.576023: dsc: 91.05%
2023-09-03 23:42:12.577866: miou: 83.57%
2023-09-03 23:42:12.579191: acc: 95.50%, sen: 91.00%, spe: 97.01%
2023-09-03 23:42:12.580536: current best miou: 0.8424533035516987 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-03 23:42:12.581727: current best dsc: 0.9144908062827978 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-03 23:42:12.583091: finished real validation
2023-09-03 23:42:16.946204: train_loss -1.4278
2023-09-03 23:42:16.948793: val_loss -1.0838
2023-09-03 23:42:16.950377: Pseudo dice [0.9127]
2023-09-03 23:42:16.951895: Epoch time: 379.01 s
2023-09-03 23:42:18.076312: 
2023-09-03 23:42:18.078451: Epoch 94
2023-09-03 23:42:18.080097: Current learning rate: backbone 0.00071297, others 0.00071297
2023-09-03 23:42:18.082007: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 23:43:19.609484: finished training epoch 94
2023-09-03 23:43:19.649549: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 23:43:19.651729: The split file contains 1 splits.
2023-09-03 23:43:19.652867: Desired fold for training: 0
2023-09-03 23:43:19.653952: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 23:48:32.378216: dsc: 91.30%
2023-09-03 23:48:32.379454: miou: 83.99%
2023-09-03 23:48:32.380492: acc: 95.63%, sen: 91.04%, spe: 97.18%
2023-09-03 23:48:32.381738: current best miou: 0.8424533035516987 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-03 23:48:32.382737: current best dsc: 0.9144908062827978 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-03 23:48:32.383672: finished real validation
2023-09-03 23:48:36.719549: train_loss -1.4283
2023-09-03 23:48:36.721167: val_loss -1.0537
2023-09-03 23:48:36.722548: Pseudo dice [0.9092]
2023-09-03 23:48:36.723713: Epoch time: 378.65 s
2023-09-03 23:48:37.843726: 
2023-09-03 23:48:37.845323: Epoch 95
2023-09-03 23:48:37.846549: Current learning rate: backbone 0.00070985, others 0.00070985
2023-09-03 23:48:37.848120: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 23:49:39.336448: finished training epoch 95
2023-09-03 23:49:39.375010: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 23:49:39.377300: The split file contains 1 splits.
2023-09-03 23:49:39.378387: Desired fold for training: 0
2023-09-03 23:49:39.379433: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 23:54:54.825764: dsc: 91.15%
2023-09-03 23:54:54.827660: miou: 83.74%
2023-09-03 23:54:54.828718: acc: 95.58%, sen: 90.46%, spe: 97.30%
2023-09-03 23:54:54.830014: current best miou: 0.8424533035516987 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-03 23:54:54.831046: current best dsc: 0.9144908062827978 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-03 23:54:54.832088: finished real validation
2023-09-03 23:54:59.178886: train_loss -1.428
2023-09-03 23:54:59.180447: val_loss -1.1069
2023-09-03 23:54:59.181914: Pseudo dice [0.9154]
2023-09-03 23:54:59.183173: Epoch time: 381.34 s
2023-09-03 23:55:00.305629: 
2023-09-03 23:55:00.307460: Epoch 96
2023-09-03 23:55:00.308740: Current learning rate: backbone 0.00070674, others 0.00070674
2023-09-03 23:55:00.310559: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 23:56:01.792940: finished training epoch 96
2023-09-03 23:56:01.823433: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 23:56:01.826470: The split file contains 1 splits.
2023-09-03 23:56:01.828144: Desired fold for training: 0
2023-09-03 23:56:01.829541: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 00:01:18.934641: dsc: 91.09%
2023-09-04 00:01:18.936178: miou: 83.64%
2023-09-04 00:01:18.937353: acc: 95.54%, sen: 90.67%, spe: 97.18%
2023-09-04 00:01:18.940014: current best miou: 0.8424533035516987 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 00:01:18.941266: current best dsc: 0.9144908062827978 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 00:01:18.942320: finished real validation
2023-09-04 00:01:23.298379: train_loss -1.4281
2023-09-04 00:01:23.300439: val_loss -1.0904
2023-09-04 00:01:23.302052: Pseudo dice [0.9147]
2023-09-04 00:01:23.303240: Epoch time: 382.99 s
2023-09-04 00:01:24.429434: 
2023-09-04 00:01:24.430875: Epoch 97
2023-09-04 00:01:24.432021: Current learning rate: backbone 0.00070362, others 0.00070362
2023-09-04 00:01:24.433547: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 00:02:26.555788: finished training epoch 97
2023-09-04 00:02:26.593009: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 00:02:26.594969: The split file contains 1 splits.
2023-09-04 00:02:26.596009: Desired fold for training: 0
2023-09-04 00:02:26.596919: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 00:07:41.263070: dsc: 91.24%
2023-09-04 00:07:41.264729: miou: 83.89%
2023-09-04 00:07:41.265827: acc: 95.60%, sen: 91.06%, spe: 97.13%
2023-09-04 00:07:41.267631: current best miou: 0.8424533035516987 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 00:07:41.268808: current best dsc: 0.9144908062827978 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 00:07:41.269894: finished real validation
2023-09-04 00:07:45.664344: train_loss -1.429
2023-09-04 00:07:45.666039: val_loss -1.1017
2023-09-04 00:07:45.667512: Pseudo dice [0.9141]
2023-09-04 00:07:45.668772: Epoch time: 381.24 s
2023-09-04 00:07:45.669907: Yayy! New best EMA pseudo Dice: 0.9131
2023-09-04 00:07:48.328535: 
2023-09-04 00:07:48.330037: Epoch 98
2023-09-04 00:07:48.331351: Current learning rate: backbone 0.0007005, others 0.0007005
2023-09-04 00:07:48.333002: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 00:08:49.957639: finished training epoch 98
2023-09-04 00:08:50.014645: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 00:08:50.016890: The split file contains 1 splits.
2023-09-04 00:08:50.018044: Desired fold for training: 0
2023-09-04 00:08:50.019078: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 00:14:05.366966: dsc: 91.21%
2023-09-04 00:14:05.368393: miou: 83.84%
2023-09-04 00:14:05.369498: acc: 95.57%, sen: 91.32%, spe: 97.00%
2023-09-04 00:14:05.370940: current best miou: 0.8424533035516987 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 00:14:05.372070: current best dsc: 0.9144908062827978 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 00:14:05.373092: finished real validation
2023-09-04 00:14:09.702550: train_loss -1.4291
2023-09-04 00:14:09.704468: val_loss -1.0834
2023-09-04 00:14:09.706474: Pseudo dice [0.9138]
2023-09-04 00:14:09.707753: Epoch time: 381.38 s
2023-09-04 00:14:09.708857: Yayy! New best EMA pseudo Dice: 0.9132
2023-09-04 00:14:12.363559: 
2023-09-04 00:14:12.365189: Epoch 99
2023-09-04 00:14:12.366823: Current learning rate: backbone 0.00069738, others 0.00069738
2023-09-04 00:14:12.369031: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 00:15:14.005799: finished training epoch 99
2023-09-04 00:15:14.044677: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 00:15:14.046871: The split file contains 1 splits.
2023-09-04 00:15:14.048002: Desired fold for training: 0
2023-09-04 00:15:14.049075: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 00:20:25.224761: dsc: 91.03%
2023-09-04 00:20:25.226458: miou: 83.53%
2023-09-04 00:20:25.227518: acc: 95.54%, sen: 89.94%, spe: 97.42%
2023-09-04 00:20:25.229002: current best miou: 0.8424533035516987 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 00:20:25.230120: current best dsc: 0.9144908062827978 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 00:20:25.231159: finished real validation
2023-09-04 00:20:29.559118: train_loss -1.4289
2023-09-04 00:20:29.560860: val_loss -1.0864
2023-09-04 00:20:29.562615: Pseudo dice [0.9111]
2023-09-04 00:20:29.563814: Epoch time: 377.2 s
2023-09-04 00:20:32.258522: 
2023-09-04 00:20:32.260063: Epoch 100
2023-09-04 00:20:32.261408: Current learning rate: backbone 0.00069425, others 0.00069425
2023-09-04 00:20:32.263922: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 00:21:33.829515: finished training epoch 100
2023-09-04 00:21:33.880054: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 00:21:33.887966: The split file contains 1 splits.
2023-09-04 00:21:33.889586: Desired fold for training: 0
2023-09-04 00:21:33.891195: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 00:26:48.783077: dsc: 91.31%
2023-09-04 00:26:48.784991: miou: 84.02%
2023-09-04 00:26:48.786180: acc: 95.63%, sen: 91.33%, spe: 97.08%
2023-09-04 00:26:48.787643: current best miou: 0.8424533035516987 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 00:26:48.788799: current best dsc: 0.9144908062827978 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 00:26:48.789834: finished real validation
2023-09-04 00:26:53.111345: train_loss -1.4293
2023-09-04 00:26:53.113031: val_loss -1.0944
2023-09-04 00:26:53.115058: Pseudo dice [0.9124]
2023-09-04 00:26:53.116841: Epoch time: 380.85 s
2023-09-04 00:26:54.249814: 
2023-09-04 00:26:54.251189: Epoch 101
2023-09-04 00:26:54.252508: Current learning rate: backbone 0.00069113, others 0.00069113
2023-09-04 00:26:54.253894: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 00:27:55.735798: finished training epoch 101
2023-09-04 00:27:55.775563: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 00:27:55.777787: The split file contains 1 splits.
2023-09-04 00:27:55.778935: Desired fold for training: 0
2023-09-04 00:27:55.779999: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 00:33:09.188643: dsc: 91.17%
2023-09-04 00:33:09.192915: miou: 83.77%
2023-09-04 00:33:09.195710: acc: 95.56%, sen: 91.08%, spe: 97.07%
2023-09-04 00:33:09.198766: current best miou: 0.8424533035516987 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 00:33:09.201116: current best dsc: 0.9144908062827978 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 00:33:09.202806: finished real validation
2023-09-04 00:33:13.564898: train_loss -1.43
2023-09-04 00:33:13.566551: val_loss -1.0674
2023-09-04 00:33:13.567993: Pseudo dice [0.9118]
2023-09-04 00:33:13.569194: Epoch time: 379.32 s
2023-09-04 00:33:14.704582: 
2023-09-04 00:33:14.706191: Epoch 102
2023-09-04 00:33:14.707591: Current learning rate: backbone 0.000688, others 0.000688
2023-09-04 00:33:14.709511: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 00:34:16.365397: finished training epoch 102
2023-09-04 00:34:16.394691: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 00:34:16.396942: The split file contains 1 splits.
2023-09-04 00:34:16.398077: Desired fold for training: 0
2023-09-04 00:34:16.399129: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 00:40:43.612164: dsc: 91.14%
2023-09-04 00:40:43.613806: miou: 83.72%
2023-09-04 00:40:43.614933: acc: 95.55%, sen: 90.92%, spe: 97.11%
2023-09-04 00:40:43.616536: current best miou: 0.8424533035516987 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 00:40:43.617679: current best dsc: 0.9144908062827978 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 00:40:43.618745: finished real validation
2023-09-04 00:40:47.992328: train_loss -1.4306
2023-09-04 00:40:47.994097: val_loss -1.0838
2023-09-04 00:40:47.995465: Pseudo dice [0.9121]
2023-09-04 00:40:47.996658: Epoch time: 453.29 s
2023-09-04 00:40:49.236378: 
2023-09-04 00:40:49.237838: Epoch 103
2023-09-04 00:40:49.239038: Current learning rate: backbone 0.00068487, others 0.00068487
2023-09-04 00:40:49.240562: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 00:41:51.178425: finished training epoch 103
2023-09-04 00:41:51.218343: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 00:41:51.220464: The split file contains 1 splits.
2023-09-04 00:41:51.221623: Desired fold for training: 0
2023-09-04 00:41:51.222739: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 00:47:04.375591: dsc: 91.25%
2023-09-04 00:47:04.377200: miou: 83.91%
2023-09-04 00:47:04.378350: acc: 95.62%, sen: 90.86%, spe: 97.21%
2023-09-04 00:47:04.379791: current best miou: 0.8424533035516987 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 00:47:04.380905: current best dsc: 0.9144908062827978 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 00:47:04.381974: finished real validation
2023-09-04 00:47:08.758035: train_loss -1.43
2023-09-04 00:47:08.759696: val_loss -1.0968
2023-09-04 00:47:08.761118: Pseudo dice [0.9158]
2023-09-04 00:47:08.762689: Epoch time: 379.52 s
2023-09-04 00:47:09.885439: 
2023-09-04 00:47:09.887102: Epoch 104
2023-09-04 00:47:09.888298: Current learning rate: backbone 0.00068174, others 0.00068174
2023-09-04 00:47:09.889792: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 00:48:11.654173: finished training epoch 104
2023-09-04 00:48:11.693072: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 00:48:11.695482: The split file contains 1 splits.
2023-09-04 00:48:11.696550: Desired fold for training: 0
2023-09-04 00:48:11.697610: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 00:53:23.548967: dsc: 91.16%
2023-09-04 00:53:23.550601: miou: 83.76%
2023-09-04 00:53:23.551909: acc: 95.56%, sen: 91.12%, spe: 97.05%
2023-09-04 00:53:23.553435: current best miou: 0.8424533035516987 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 00:53:23.554674: current best dsc: 0.9144908062827978 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 00:53:23.555810: finished real validation
2023-09-04 00:53:27.888322: train_loss -1.4313
2023-09-04 00:53:27.889910: val_loss -1.0761
2023-09-04 00:53:27.891252: Pseudo dice [0.9137]
2023-09-04 00:53:27.893124: Epoch time: 378.0 s
2023-09-04 00:53:29.016538: 
2023-09-04 00:53:29.018105: Epoch 105
2023-09-04 00:53:29.019365: Current learning rate: backbone 0.00067861, others 0.00067861
2023-09-04 00:53:29.020959: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 00:54:30.772686: finished training epoch 105
2023-09-04 00:54:30.814165: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 00:54:30.817509: The split file contains 1 splits.
2023-09-04 00:54:30.819019: Desired fold for training: 0
2023-09-04 00:54:30.820469: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 00:59:46.819612: dsc: 91.38%
2023-09-04 00:59:46.821393: miou: 84.13%
2023-09-04 00:59:46.822723: acc: 95.68%, sen: 91.13%, spe: 97.20%
2023-09-04 00:59:46.824882: current best miou: 0.8424533035516987 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 00:59:46.826201: current best dsc: 0.9144908062827978 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 00:59:46.827453: finished real validation
2023-09-04 00:59:51.194992: train_loss -1.4301
2023-09-04 00:59:51.196761: val_loss -1.0938
2023-09-04 00:59:51.198301: Pseudo dice [0.9143]
2023-09-04 00:59:51.199612: Epoch time: 382.18 s
2023-09-04 00:59:51.200861: Yayy! New best EMA pseudo Dice: 0.9132
2023-09-04 00:59:53.849698: 
2023-09-04 00:59:53.851374: Epoch 106
2023-09-04 00:59:53.852717: Current learning rate: backbone 0.00067548, others 0.00067548
2023-09-04 00:59:53.854281: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 01:00:55.443388: finished training epoch 106
2023-09-04 01:00:55.473299: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 01:00:55.475946: The split file contains 1 splits.
2023-09-04 01:00:55.477999: Desired fold for training: 0
2023-09-04 01:00:55.479817: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 01:06:06.592755: dsc: 91.23%
2023-09-04 01:06:06.594443: miou: 83.87%
2023-09-04 01:06:06.595602: acc: 95.59%, sen: 91.15%, spe: 97.09%
2023-09-04 01:06:06.597139: current best miou: 0.8424533035516987 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 01:06:06.598409: current best dsc: 0.9144908062827978 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 01:06:06.599570: finished real validation
2023-09-04 01:06:10.925563: train_loss -1.4309
2023-09-04 01:06:10.927312: val_loss -1.0861
2023-09-04 01:06:10.928795: Pseudo dice [0.9133]
2023-09-04 01:06:10.930079: Epoch time: 377.08 s
2023-09-04 01:06:10.931314: Yayy! New best EMA pseudo Dice: 0.9132
2023-09-04 01:06:13.605922: 
2023-09-04 01:06:13.607724: Epoch 107
2023-09-04 01:06:13.608943: Current learning rate: backbone 0.00067235, others 0.00067235
2023-09-04 01:06:13.610695: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 01:07:15.131000: finished training epoch 107
2023-09-04 01:07:15.171008: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 01:07:15.173181: The split file contains 1 splits.
2023-09-04 01:07:15.174394: Desired fold for training: 0
2023-09-04 01:07:15.175884: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 01:12:30.838896: dsc: 91.30%
2023-09-04 01:12:30.840525: miou: 83.99%
2023-09-04 01:12:30.841760: acc: 95.65%, sen: 90.84%, spe: 97.26%
2023-09-04 01:12:30.843190: current best miou: 0.8424533035516987 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 01:12:30.844315: current best dsc: 0.9144908062827978 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 01:12:30.845316: finished real validation
2023-09-04 01:12:35.187864: train_loss -1.4312
2023-09-04 01:12:35.189606: val_loss -1.0884
2023-09-04 01:12:35.191187: Pseudo dice [0.9139]
2023-09-04 01:12:35.192366: Epoch time: 381.58 s
2023-09-04 01:12:35.193456: Yayy! New best EMA pseudo Dice: 0.9133
2023-09-04 01:12:37.828121: 
2023-09-04 01:12:37.829687: Epoch 108
2023-09-04 01:12:37.830980: Current learning rate: backbone 0.00066921, others 0.00066921
2023-09-04 01:12:37.832652: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 01:13:39.393679: finished training epoch 108
2023-09-04 01:13:39.422331: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 01:13:39.425178: The split file contains 1 splits.
2023-09-04 01:13:39.426907: Desired fold for training: 0
2023-09-04 01:13:39.428451: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 01:18:51.868737: dsc: 91.14%
2023-09-04 01:18:51.870758: miou: 83.72%
2023-09-04 01:18:51.872283: acc: 95.53%, sen: 91.32%, spe: 96.95%
2023-09-04 01:18:51.874614: current best miou: 0.8424533035516987 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 01:18:51.876114: current best dsc: 0.9144908062827978 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 01:18:51.877645: finished real validation
2023-09-04 01:18:56.227894: train_loss -1.4307
2023-09-04 01:18:56.229472: val_loss -1.0363
2023-09-04 01:18:56.230888: Pseudo dice [0.9073]
2023-09-04 01:18:56.232123: Epoch time: 378.4 s
2023-09-04 01:18:57.362384: 
2023-09-04 01:18:57.363853: Epoch 109
2023-09-04 01:18:57.365330: Current learning rate: backbone 0.00066607, others 0.00066607
2023-09-04 01:18:57.367067: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 01:19:59.147815: finished training epoch 109
2023-09-04 01:19:59.176470: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 01:19:59.178607: The split file contains 1 splits.
2023-09-04 01:19:59.180172: Desired fold for training: 0
2023-09-04 01:19:59.181348: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 01:25:14.180166: dsc: 91.19%
2023-09-04 01:25:14.182012: miou: 83.81%
2023-09-04 01:25:14.183154: acc: 95.59%, sen: 90.68%, spe: 97.25%
2023-09-04 01:25:14.184796: current best miou: 0.8424533035516987 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 01:25:14.185920: current best dsc: 0.9144908062827978 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 01:25:14.186997: finished real validation
2023-09-04 01:25:18.520287: train_loss -1.4311
2023-09-04 01:25:18.522339: val_loss -1.0565
2023-09-04 01:25:18.524029: Pseudo dice [0.9095]
2023-09-04 01:25:18.525305: Epoch time: 381.16 s
2023-09-04 01:25:21.158191: 
2023-09-04 01:25:21.159853: Epoch 110
2023-09-04 01:25:21.161191: Current learning rate: backbone 0.00066293, others 0.00066293
2023-09-04 01:25:21.163033: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 01:26:23.028601: finished training epoch 110
2023-09-04 01:26:23.058204: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 01:26:23.060266: The split file contains 1 splits.
2023-09-04 01:26:23.061468: Desired fold for training: 0
2023-09-04 01:26:23.062556: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 01:31:35.841322: dsc: 91.14%
2023-09-04 01:31:35.843124: miou: 83.73%
2023-09-04 01:31:35.844304: acc: 95.56%, sen: 90.90%, spe: 97.12%
2023-09-04 01:31:35.845777: current best miou: 0.8424533035516987 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 01:31:35.846920: current best dsc: 0.9144908062827978 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 01:31:35.847984: finished real validation
2023-09-04 01:31:40.208154: train_loss -1.4318
2023-09-04 01:31:40.210102: val_loss -1.0733
2023-09-04 01:31:40.212397: Pseudo dice [0.9134]
2023-09-04 01:31:40.214105: Epoch time: 379.05 s
2023-09-04 01:31:41.350153: 
2023-09-04 01:31:41.352009: Epoch 111
2023-09-04 01:31:41.353245: Current learning rate: backbone 0.00065979, others 0.00065979
2023-09-04 01:31:41.354895: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 01:32:43.095933: finished training epoch 111
2023-09-04 01:32:43.135551: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 01:32:43.137936: The split file contains 1 splits.
2023-09-04 01:32:43.139415: Desired fold for training: 0
2023-09-04 01:32:43.140880: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 01:38:05.649934: dsc: 91.18%
2023-09-04 01:38:05.651602: miou: 83.80%
2023-09-04 01:38:05.653258: acc: 95.55%, sen: 91.47%, spe: 96.92%
2023-09-04 01:38:05.654842: current best miou: 0.8424533035516987 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 01:38:05.656363: current best dsc: 0.9144908062827978 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 01:38:05.657508: finished real validation
2023-09-04 01:38:10.012118: train_loss -1.4317
2023-09-04 01:38:10.013707: val_loss -1.0806
2023-09-04 01:38:10.015118: Pseudo dice [0.9115]
2023-09-04 01:38:10.016379: Epoch time: 388.66 s
2023-09-04 01:38:11.144408: 
2023-09-04 01:38:11.146130: Epoch 112
2023-09-04 01:38:11.147436: Current learning rate: backbone 0.00065665, others 0.00065665
2023-09-04 01:38:11.149129: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 01:39:12.674738: finished training epoch 112
2023-09-04 01:39:12.702941: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 01:39:12.704889: The split file contains 1 splits.
2023-09-04 01:39:12.706582: Desired fold for training: 0
2023-09-04 01:39:12.707745: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 01:44:28.933511: dsc: 91.28%
2023-09-04 01:44:28.935437: miou: 83.96%
2023-09-04 01:44:28.936671: acc: 95.64%, sen: 90.76%, spe: 97.28%
2023-09-04 01:44:28.938345: current best miou: 0.8424533035516987 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 01:44:28.939606: current best dsc: 0.9144908062827978 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 01:44:28.940767: finished real validation
2023-09-04 01:44:33.284546: train_loss -1.4321
2023-09-04 01:44:33.286233: val_loss -1.088
2023-09-04 01:44:33.287716: Pseudo dice [0.9139]
2023-09-04 01:44:33.289056: Epoch time: 382.14 s
2023-09-04 01:44:34.412033: 
2023-09-04 01:44:34.414200: Epoch 113
2023-09-04 01:44:34.415532: Current learning rate: backbone 0.0006535, others 0.0006535
2023-09-04 01:44:34.417277: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 01:45:35.999526: finished training epoch 113
2023-09-04 01:45:36.028695: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 01:45:36.031057: The split file contains 1 splits.
2023-09-04 01:45:36.032288: Desired fold for training: 0
2023-09-04 01:45:36.033448: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 01:50:48.152387: dsc: 91.13%
2023-09-04 01:50:48.153856: miou: 83.70%
2023-09-04 01:50:48.155367: acc: 95.55%, sen: 90.80%, spe: 97.15%
2023-09-04 01:50:48.156934: current best miou: 0.8424533035516987 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 01:50:48.158067: current best dsc: 0.9144908062827978 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 01:50:48.159131: finished real validation
2023-09-04 01:50:52.484146: train_loss -1.4318
2023-09-04 01:50:52.485739: val_loss -1.0836
2023-09-04 01:50:52.488101: Pseudo dice [0.9133]
2023-09-04 01:50:52.489930: Epoch time: 378.07 s
2023-09-04 01:50:53.660894: 
2023-09-04 01:50:53.662318: Epoch 114
2023-09-04 01:50:53.663577: Current learning rate: backbone 0.00065036, others 0.00065036
2023-09-04 01:50:53.665154: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 01:51:55.164191: finished training epoch 114
2023-09-04 01:51:55.192454: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 01:51:55.194476: The split file contains 1 splits.
2023-09-04 01:51:55.195715: Desired fold for training: 0
2023-09-04 01:51:55.196857: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 01:57:07.726419: dsc: 91.02%
2023-09-04 01:57:07.728086: miou: 83.52%
2023-09-04 01:57:07.729315: acc: 95.49%, sen: 90.81%, spe: 97.06%
2023-09-04 01:57:07.731019: current best miou: 0.8424533035516987 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 01:57:07.732178: current best dsc: 0.9144908062827978 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 01:57:07.733293: finished real validation
2023-09-04 01:57:12.080008: train_loss -1.4319
2023-09-04 01:57:12.081816: val_loss -1.0519
2023-09-04 01:57:12.083384: Pseudo dice [0.9074]
2023-09-04 01:57:12.084686: Epoch time: 378.42 s
2023-09-04 01:57:13.212278: 
2023-09-04 01:57:13.213931: Epoch 115
2023-09-04 01:57:13.215246: Current learning rate: backbone 0.00064721, others 0.00064721
2023-09-04 01:57:13.216922: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 01:58:15.025874: finished training epoch 115
2023-09-04 01:58:15.054668: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 01:58:15.057556: The split file contains 1 splits.
2023-09-04 01:58:15.059278: Desired fold for training: 0
2023-09-04 01:58:15.060656: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 02:03:24.626214: dsc: 91.21%
2023-09-04 02:03:24.627848: miou: 83.84%
2023-09-04 02:03:24.628952: acc: 95.60%, sen: 90.80%, spe: 97.21%
2023-09-04 02:03:24.630316: current best miou: 0.8424533035516987 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 02:03:24.631919: current best dsc: 0.9144908062827978 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 02:03:24.632918: finished real validation
2023-09-04 02:03:28.970715: train_loss -1.4329
2023-09-04 02:03:28.972418: val_loss -1.0774
2023-09-04 02:03:28.974321: Pseudo dice [0.9116]
2023-09-04 02:03:28.976310: Epoch time: 375.76 s
2023-09-04 02:03:30.138065: 
2023-09-04 02:03:30.139627: Epoch 116
2023-09-04 02:03:30.140862: Current learning rate: backbone 0.00064406, others 0.00064406
2023-09-04 02:03:30.142457: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 02:04:31.674455: finished training epoch 116
2023-09-04 02:04:31.702804: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 02:04:31.704621: The split file contains 1 splits.
2023-09-04 02:04:31.705917: Desired fold for training: 0
2023-09-04 02:04:31.709657: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 02:09:46.849786: dsc: 91.07%
2023-09-04 02:09:46.851404: miou: 83.61%
2023-09-04 02:09:46.852608: acc: 95.53%, sen: 90.69%, spe: 97.15%
2023-09-04 02:09:46.854126: current best miou: 0.8424533035516987 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 02:09:46.855362: current best dsc: 0.9144908062827978 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 02:09:46.856570: finished real validation
2023-09-04 02:09:51.189458: train_loss -1.4331
2023-09-04 02:09:51.191277: val_loss -1.072
2023-09-04 02:09:51.192946: Pseudo dice [0.9106]
2023-09-04 02:09:51.194159: Epoch time: 381.05 s
2023-09-04 02:09:52.343905: 
2023-09-04 02:09:52.345367: Epoch 117
2023-09-04 02:09:52.346611: Current learning rate: backbone 0.00064091, others 0.00064091
2023-09-04 02:09:52.348118: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 02:10:54.027714: finished training epoch 117
2023-09-04 02:11:09.602034: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 02:11:09.606502: The split file contains 1 splits.
2023-09-04 02:11:09.607751: Desired fold for training: 0
2023-09-04 02:11:09.608931: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 02:16:24.491359: dsc: 91.22%
2023-09-04 02:16:24.493660: miou: 83.86%
2023-09-04 02:16:24.495198: acc: 95.61%, sen: 90.72%, spe: 97.25%
2023-09-04 02:16:24.497540: current best miou: 0.8424533035516987 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 02:16:24.498846: current best dsc: 0.9144908062827978 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 02:16:24.500246: finished real validation
2023-09-04 02:16:28.843378: train_loss -1.433
2023-09-04 02:16:28.845286: val_loss -1.0398
2023-09-04 02:16:28.846715: Pseudo dice [0.9078]
2023-09-04 02:16:28.847966: Epoch time: 396.5 s
2023-09-04 02:16:29.990239: 
2023-09-04 02:16:29.992081: Epoch 118
2023-09-04 02:16:29.993392: Current learning rate: backbone 0.00063776, others 0.00063776
2023-09-04 02:16:29.994969: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 02:17:31.443446: finished training epoch 118
2023-09-04 02:17:31.473471: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 02:17:31.475779: The split file contains 1 splits.
2023-09-04 02:17:31.477135: Desired fold for training: 0
2023-09-04 02:17:31.478301: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 02:22:47.064508: dsc: 91.22%
2023-09-04 02:22:47.066337: miou: 83.87%
2023-09-04 02:22:47.067577: acc: 95.58%, sen: 91.42%, spe: 96.97%
2023-09-04 02:22:47.069831: current best miou: 0.8424533035516987 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 02:22:47.071036: current best dsc: 0.9144908062827978 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 02:22:47.072155: finished real validation
2023-09-04 02:22:51.413678: train_loss -1.4329
2023-09-04 02:22:51.415945: val_loss -1.0604
2023-09-04 02:22:51.417919: Pseudo dice [0.9115]
2023-09-04 02:22:51.419559: Epoch time: 381.42 s
2023-09-04 02:22:52.602700: 
2023-09-04 02:22:52.604472: Epoch 119
2023-09-04 02:22:52.605898: Current learning rate: backbone 0.0006346, others 0.0006346
2023-09-04 02:22:52.607856: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 02:23:54.204152: finished training epoch 119
2023-09-04 02:23:54.244706: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 02:23:54.246973: The split file contains 1 splits.
2023-09-04 02:23:54.248149: Desired fold for training: 0
2023-09-04 02:23:54.249291: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 02:29:06.354951: dsc: 91.29%
2023-09-04 02:29:06.357101: miou: 83.97%
2023-09-04 02:29:06.358651: acc: 95.63%, sen: 91.10%, spe: 97.14%
2023-09-04 02:29:06.360930: current best miou: 0.8424533035516987 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 02:29:06.362547: current best dsc: 0.9144908062827978 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 02:29:06.364077: finished real validation
2023-09-04 02:29:10.710423: train_loss -1.4333
2023-09-04 02:29:10.712733: val_loss -1.0893
2023-09-04 02:29:10.714630: Pseudo dice [0.9152]
2023-09-04 02:29:10.716156: Epoch time: 378.11 s
2023-09-04 02:29:13.533886: 
2023-09-04 02:29:13.535844: Epoch 120
2023-09-04 02:29:13.537256: Current learning rate: backbone 0.00063145, others 0.00063145
2023-09-04 02:29:13.539031: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 02:30:15.232417: finished training epoch 120
2023-09-04 02:30:15.265284: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 02:30:15.267830: The split file contains 1 splits.
2023-09-04 02:30:15.269231: Desired fold for training: 0
2023-09-04 02:30:15.270530: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 02:35:31.324452: dsc: 91.19%
2023-09-04 02:35:31.326289: miou: 83.80%
2023-09-04 02:35:31.327771: acc: 95.58%, sen: 90.89%, spe: 97.16%
2023-09-04 02:35:31.329697: current best miou: 0.8424533035516987 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 02:35:31.330959: current best dsc: 0.9144908062827978 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 02:35:31.332074: finished real validation
2023-09-04 02:35:35.675501: train_loss -1.433
2023-09-04 02:35:35.677294: val_loss -1.0792
2023-09-04 02:35:35.678880: Pseudo dice [0.9137]
2023-09-04 02:35:35.680200: Epoch time: 382.14 s
2023-09-04 02:35:36.874455: 
2023-09-04 02:35:36.875928: Epoch 121
2023-09-04 02:35:36.877166: Current learning rate: backbone 0.00062829, others 0.00062829
2023-09-04 02:35:36.878856: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 02:36:39.824909: finished training epoch 121
2023-09-04 02:36:39.865540: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 02:36:39.868656: The split file contains 1 splits.
2023-09-04 02:36:39.870185: Desired fold for training: 0
2023-09-04 02:36:39.871428: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 02:42:03.638183: dsc: 91.24%
2023-09-04 02:42:03.639575: miou: 83.89%
2023-09-04 02:42:03.640745: acc: 95.62%, sen: 90.76%, spe: 97.25%
2023-09-04 02:42:03.642158: current best miou: 0.8424533035516987 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 02:42:03.643335: current best dsc: 0.9144908062827978 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 02:42:03.644408: finished real validation
2023-09-04 02:42:08.029965: train_loss -1.4331
2023-09-04 02:42:08.031574: val_loss -1.0975
2023-09-04 02:42:08.032995: Pseudo dice [0.9163]
2023-09-04 02:42:08.034261: Epoch time: 391.16 s
2023-09-04 02:42:09.183224: 
2023-09-04 02:42:09.184877: Epoch 122
2023-09-04 02:42:09.186291: Current learning rate: backbone 0.00062513, others 0.00062513
2023-09-04 02:42:09.187961: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 02:43:10.885612: finished training epoch 122
2023-09-04 02:43:10.956420: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 02:43:10.958532: The split file contains 1 splits.
2023-09-04 02:43:10.960598: Desired fold for training: 0
2023-09-04 02:43:10.962029: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 02:48:29.471123: dsc: 91.08%
2023-09-04 02:48:29.473219: miou: 83.62%
2023-09-04 02:48:29.474453: acc: 95.49%, sen: 91.61%, spe: 96.79%
2023-09-04 02:48:29.475960: current best miou: 0.8424533035516987 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 02:48:29.477265: current best dsc: 0.9144908062827978 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 02:48:29.478636: finished real validation
2023-09-04 02:48:33.808813: train_loss -1.434
2023-09-04 02:48:33.810611: val_loss -1.0622
2023-09-04 02:48:33.812173: Pseudo dice [0.9114]
2023-09-04 02:48:33.813574: Epoch time: 384.63 s
2023-09-04 02:48:34.985556: 
2023-09-04 02:48:34.987041: Epoch 123
2023-09-04 02:48:34.988336: Current learning rate: backbone 0.00062197, others 0.00062197
2023-09-04 02:48:34.990072: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 02:49:36.905993: finished training epoch 123
2023-09-04 02:49:36.934779: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 02:49:36.936777: The split file contains 1 splits.
2023-09-04 02:49:36.938299: Desired fold for training: 0
2023-09-04 02:49:36.939430: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 02:54:54.666894: dsc: 91.24%
2023-09-04 02:54:54.668521: miou: 83.88%
2023-09-04 02:54:54.669772: acc: 95.60%, sen: 91.09%, spe: 97.11%
2023-09-04 02:54:54.671313: current best miou: 0.8424533035516987 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 02:54:54.672592: current best dsc: 0.9144908062827978 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 02:54:54.673730: finished real validation
2023-09-04 02:54:59.091565: train_loss -1.4347
2023-09-04 02:54:59.093549: val_loss -1.0626
2023-09-04 02:54:59.095322: Pseudo dice [0.9117]
2023-09-04 02:54:59.096811: Epoch time: 384.11 s
2023-09-04 02:55:00.299436: 
2023-09-04 02:55:00.301502: Epoch 124
2023-09-04 02:55:00.303025: Current learning rate: backbone 0.0006188, others 0.0006188
2023-09-04 02:55:00.305752: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 02:56:02.089080: finished training epoch 124
2023-09-04 02:56:02.122645: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 02:56:02.125093: The split file contains 1 splits.
2023-09-04 02:56:02.126301: Desired fold for training: 0
2023-09-04 02:56:02.127444: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 03:01:19.720996: dsc: 91.16%
2023-09-04 03:01:19.722580: miou: 83.76%
2023-09-04 03:01:19.723754: acc: 95.58%, sen: 90.66%, spe: 97.23%
2023-09-04 03:01:19.725198: current best miou: 0.8424533035516987 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 03:01:19.726384: current best dsc: 0.9144908062827978 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 03:01:19.727506: finished real validation
2023-09-04 03:01:24.093705: train_loss -1.4332
2023-09-04 03:01:24.095530: val_loss -1.0839
2023-09-04 03:01:24.097118: Pseudo dice [0.9129]
2023-09-04 03:01:24.098897: Epoch time: 383.8 s
2023-09-04 03:01:25.334588: 
2023-09-04 03:01:25.336473: Epoch 125
2023-09-04 03:01:25.338127: Current learning rate: backbone 0.00061564, others 0.00061564
2023-09-04 03:01:25.340448: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 03:02:27.019617: finished training epoch 125
2023-09-04 03:02:27.062709: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 03:02:27.065420: The split file contains 1 splits.
2023-09-04 03:02:27.066770: Desired fold for training: 0
2023-09-04 03:02:27.068161: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 03:07:45.134388: dsc: 91.24%
2023-09-04 03:07:45.136133: miou: 83.90%
2023-09-04 03:07:45.137381: acc: 95.59%, sen: 91.37%, spe: 97.01%
2023-09-04 03:07:45.139133: current best miou: 0.8424533035516987 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 03:07:45.140362: current best dsc: 0.9144908062827978 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 03:07:45.141513: finished real validation
2023-09-04 03:07:49.489023: train_loss -1.4335
2023-09-04 03:07:49.490757: val_loss -1.0838
2023-09-04 03:07:49.492297: Pseudo dice [0.9149]
2023-09-04 03:07:49.493568: Epoch time: 384.16 s
2023-09-04 03:07:50.643164: 
2023-09-04 03:07:50.644966: Epoch 126
2023-09-04 03:07:50.646387: Current learning rate: backbone 0.00061247, others 0.00061247
2023-09-04 03:07:50.648237: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 03:08:52.163048: finished training epoch 126
2023-09-04 03:08:52.198846: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 03:08:52.201517: The split file contains 1 splits.
2023-09-04 03:08:52.203537: Desired fold for training: 0
2023-09-04 03:08:52.204785: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 03:14:05.870149: dsc: 91.10%
2023-09-04 03:14:05.871854: miou: 83.65%
2023-09-04 03:14:05.873161: acc: 95.50%, sen: 91.45%, spe: 96.87%
2023-09-04 03:14:05.874798: current best miou: 0.8424533035516987 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 03:14:05.876127: current best dsc: 0.9144908062827978 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 03:14:05.877411: finished real validation
2023-09-04 03:14:10.225317: train_loss -1.4338
2023-09-04 03:14:10.227195: val_loss -1.0672
2023-09-04 03:14:10.228682: Pseudo dice [0.9138]
2023-09-04 03:14:10.230027: Epoch time: 379.58 s
2023-09-04 03:14:11.379612: 
2023-09-04 03:14:11.381173: Epoch 127
2023-09-04 03:14:11.382884: Current learning rate: backbone 0.0006093, others 0.0006093
2023-09-04 03:14:11.384705: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 03:15:12.867669: finished training epoch 127
2023-09-04 03:15:12.908323: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 03:15:12.910587: The split file contains 1 splits.
2023-09-04 03:15:12.911894: Desired fold for training: 0
2023-09-04 03:15:12.913108: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 03:21:42.642338: dsc: 91.12%
2023-09-04 03:21:42.643905: miou: 83.68%
2023-09-04 03:21:42.645065: acc: 95.53%, sen: 91.10%, spe: 97.02%
2023-09-04 03:21:42.646481: current best miou: 0.8424533035516987 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 03:21:42.647871: current best dsc: 0.9144908062827978 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 03:21:42.649027: finished real validation
2023-09-04 03:21:47.000772: train_loss -1.4345
2023-09-04 03:21:47.002611: val_loss -1.045
2023-09-04 03:21:47.004199: Pseudo dice [0.9094]
2023-09-04 03:21:47.005527: Epoch time: 455.62 s
2023-09-04 03:21:48.284398: 
2023-09-04 03:21:48.286162: Epoch 128
2023-09-04 03:21:48.287463: Current learning rate: backbone 0.00060613, others 0.00060613
2023-09-04 03:21:48.289212: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 03:22:50.111884: finished training epoch 128
2023-09-04 03:22:50.196075: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 03:22:50.198389: The split file contains 1 splits.
2023-09-04 03:22:50.201482: Desired fold for training: 0
2023-09-04 03:22:50.205645: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 03:28:08.207944: dsc: 91.21%
2023-09-04 03:28:08.209675: miou: 83.84%
2023-09-04 03:28:08.210969: acc: 95.58%, sen: 91.20%, spe: 97.05%
2023-09-04 03:28:08.212538: current best miou: 0.8424533035516987 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 03:28:08.213833: current best dsc: 0.9144908062827978 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 03:28:08.215027: finished real validation
2023-09-04 03:28:12.566867: train_loss -1.4356
2023-09-04 03:28:12.568691: val_loss -1.0837
2023-09-04 03:28:12.570361: Pseudo dice [0.9145]
2023-09-04 03:28:12.571707: Epoch time: 384.28 s
2023-09-04 03:28:13.713078: 
2023-09-04 03:28:13.715801: Epoch 129
2023-09-04 03:28:13.717646: Current learning rate: backbone 0.00060296, others 0.00060296
2023-09-04 03:28:13.720147: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 03:29:15.765602: finished training epoch 129
2023-09-04 03:29:15.796547: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 03:29:15.798560: The split file contains 1 splits.
2023-09-04 03:29:15.799821: Desired fold for training: 0
2023-09-04 03:29:15.801020: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 03:34:47.424141: dsc: 91.21%
2023-09-04 03:34:47.425789: miou: 83.84%
2023-09-04 03:34:47.427133: acc: 95.59%, sen: 90.86%, spe: 97.19%
2023-09-04 03:34:47.428717: current best miou: 0.8424533035516987 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 03:34:47.429980: current best dsc: 0.9144908062827978 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 03:34:47.431165: finished real validation
2023-09-04 03:34:51.789340: train_loss -1.4349
2023-09-04 03:34:51.791248: val_loss -1.082
2023-09-04 03:34:51.792904: Pseudo dice [0.9148]
2023-09-04 03:34:51.794229: Epoch time: 398.08 s
2023-09-04 03:34:54.466984: 
2023-09-04 03:34:54.468632: Epoch 130
2023-09-04 03:34:54.469894: Current learning rate: backbone 0.00059978, others 0.00059978
2023-09-04 03:34:54.471582: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 03:35:56.625501: finished training epoch 130
2023-09-04 03:35:56.658649: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 03:35:56.661990: The split file contains 1 splits.
2023-09-04 03:35:56.663823: Desired fold for training: 0
2023-09-04 03:35:56.665486: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 03:41:09.887677: dsc: 91.23%
2023-09-04 03:41:09.890370: miou: 83.88%
2023-09-04 03:41:09.892022: acc: 95.59%, sen: 91.18%, spe: 97.07%
2023-09-04 03:41:09.894396: current best miou: 0.8424533035516987 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 03:41:09.896047: current best dsc: 0.9144908062827978 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 03:41:09.897654: finished real validation
2023-09-04 03:41:14.233864: train_loss -1.4346
2023-09-04 03:41:14.235983: val_loss -1.0889
2023-09-04 03:41:14.237541: Pseudo dice [0.9153]
2023-09-04 03:41:14.238830: Epoch time: 379.77 s
2023-09-04 03:41:15.425160: 
2023-09-04 03:41:15.427009: Epoch 131
2023-09-04 03:41:15.428380: Current learning rate: backbone 0.00059661, others 0.00059661
2023-09-04 03:41:15.430219: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 03:42:17.229755: finished training epoch 131
2023-09-04 03:42:17.270471: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 03:42:17.272907: The split file contains 1 splits.
2023-09-04 03:42:17.274297: Desired fold for training: 0
2023-09-04 03:42:17.276015: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 03:47:58.888233: dsc: 91.15%
2023-09-04 03:47:58.890148: miou: 83.74%
2023-09-04 03:47:58.891468: acc: 95.57%, sen: 90.81%, spe: 97.16%
2023-09-04 03:47:58.893009: current best miou: 0.8424533035516987 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 03:47:58.894338: current best dsc: 0.9144908062827978 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 03:47:58.895543: finished real validation
2023-09-04 03:48:03.257283: train_loss -1.4348
2023-09-04 03:48:03.259080: val_loss -1.0618
2023-09-04 03:48:03.260717: Pseudo dice [0.9121]
2023-09-04 03:48:03.262252: Epoch time: 407.83 s
2023-09-04 03:48:04.406929: 
2023-09-04 03:48:04.408726: Epoch 132
2023-09-04 03:48:04.410145: Current learning rate: backbone 0.00059343, others 0.00059343
2023-09-04 03:48:04.411761: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 03:49:06.344351: finished training epoch 132
2023-09-04 03:49:17.946795: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 03:49:17.949101: The split file contains 1 splits.
2023-09-04 03:49:17.950962: Desired fold for training: 0
2023-09-04 03:49:17.952544: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 03:54:29.809645: dsc: 91.04%
2023-09-04 03:54:29.811415: miou: 83.56%
2023-09-04 03:54:29.812739: acc: 95.50%, sen: 90.90%, spe: 97.04%
2023-09-04 03:54:29.814392: current best miou: 0.8424533035516987 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 03:54:29.815736: current best dsc: 0.9144908062827978 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 03:54:29.816990: finished real validation
2023-09-04 03:54:34.172031: train_loss -1.4356
2023-09-04 03:54:34.173867: val_loss -1.0522
2023-09-04 03:54:34.175445: Pseudo dice [0.911]
2023-09-04 03:54:34.176761: Epoch time: 389.77 s
2023-09-04 03:54:35.329191: 
2023-09-04 03:54:35.330732: Epoch 133
2023-09-04 03:54:35.332098: Current learning rate: backbone 0.00059025, others 0.00059025
2023-09-04 03:54:35.333718: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 03:55:37.930008: finished training epoch 133
2023-09-04 03:55:37.965265: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 03:55:37.968093: The split file contains 1 splits.
2023-09-04 03:55:37.969554: Desired fold for training: 0
2023-09-04 03:55:37.970864: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 04:00:56.001879: dsc: 91.07%
2023-09-04 04:00:56.003839: miou: 83.61%
2023-09-04 04:00:56.005197: acc: 95.53%, sen: 90.69%, spe: 97.15%
2023-09-04 04:00:56.007689: current best miou: 0.8424533035516987 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 04:00:56.009287: current best dsc: 0.9144908062827978 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 04:00:56.010761: finished real validation
2023-09-04 04:01:00.362879: train_loss -1.4356
2023-09-04 04:01:00.364521: val_loss -1.0493
2023-09-04 04:01:00.365973: Pseudo dice [0.91]
2023-09-04 04:01:00.367264: Epoch time: 385.04 s
2023-09-04 04:01:01.510520: 
2023-09-04 04:01:01.512353: Epoch 134
2023-09-04 04:01:01.513797: Current learning rate: backbone 0.00058707, others 0.00058707
2023-09-04 04:01:01.515534: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 04:02:03.848673: finished training epoch 134
2023-09-04 04:02:03.890640: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 04:02:03.893755: The split file contains 1 splits.
2023-09-04 04:02:03.895532: Desired fold for training: 0
2023-09-04 04:02:03.897236: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 04:07:25.242385: dsc: 91.23%
2023-09-04 04:07:25.244417: miou: 83.88%
2023-09-04 04:07:25.245890: acc: 95.59%, sen: 91.22%, spe: 97.06%
2023-09-04 04:07:25.248127: current best miou: 0.8424533035516987 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 04:07:25.249806: current best dsc: 0.9144908062827978 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 04:07:25.251218: finished real validation
2023-09-04 04:07:29.591933: train_loss -1.436
2023-09-04 04:07:29.593657: val_loss -1.0867
2023-09-04 04:07:29.595256: Pseudo dice [0.915]
2023-09-04 04:07:29.596625: Epoch time: 388.08 s
2023-09-04 04:07:30.745399: 
2023-09-04 04:07:30.747042: Epoch 135
2023-09-04 04:07:30.748353: Current learning rate: backbone 0.00058388, others 0.00058388
2023-09-04 04:07:30.749938: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 04:08:32.300246: finished training epoch 135
2023-09-04 04:08:32.342165: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 04:08:32.344319: The split file contains 1 splits.
2023-09-04 04:08:32.345622: Desired fold for training: 0
2023-09-04 04:08:32.346843: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 04:13:48.373180: dsc: 91.14%
2023-09-04 04:13:48.374909: miou: 83.71%
2023-09-04 04:13:48.376179: acc: 95.53%, sen: 91.33%, spe: 96.94%
2023-09-04 04:13:48.377834: current best miou: 0.8424533035516987 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 04:13:48.379085: current best dsc: 0.9144908062827978 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 04:13:48.380264: finished real validation
2023-09-04 04:13:52.720955: train_loss -1.4358
2023-09-04 04:13:52.722756: val_loss -1.0523
2023-09-04 04:13:52.724300: Pseudo dice [0.9113]
2023-09-04 04:13:52.725704: Epoch time: 381.98 s
2023-09-04 04:13:53.877228: 
2023-09-04 04:13:53.879039: Epoch 136
2023-09-04 04:13:53.881432: Current learning rate: backbone 0.0005807, others 0.0005807
2023-09-04 04:13:53.883258: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 04:14:55.376328: finished training epoch 136
2023-09-04 04:14:55.417811: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 04:14:55.421017: The split file contains 1 splits.
2023-09-04 04:14:55.422540: Desired fold for training: 0
2023-09-04 04:14:55.423795: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 04:20:17.419625: dsc: 91.25%
2023-09-04 04:20:17.421446: miou: 83.91%
2023-09-04 04:20:17.422740: acc: 95.60%, sen: 91.25%, spe: 97.06%
2023-09-04 04:20:17.424282: current best miou: 0.8424533035516987 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 04:20:17.425553: current best dsc: 0.9144908062827978 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 04:20:17.426799: finished real validation
2023-09-04 04:20:21.782114: train_loss -1.436
2023-09-04 04:20:21.784201: val_loss -1.077
2023-09-04 04:20:21.785899: Pseudo dice [0.9138]
2023-09-04 04:20:21.787371: Epoch time: 387.91 s
2023-09-04 04:20:22.944896: 
2023-09-04 04:20:22.946659: Epoch 137
2023-09-04 04:20:22.948047: Current learning rate: backbone 0.00057751, others 0.00057751
2023-09-04 04:20:22.949851: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 04:21:24.393948: finished training epoch 137
2023-09-04 04:21:24.434114: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 04:21:24.436480: The split file contains 1 splits.
2023-09-04 04:21:24.437787: Desired fold for training: 0
2023-09-04 04:21:24.439043: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 04:26:50.031168: dsc: 91.10%
2023-09-04 04:26:50.033142: miou: 83.66%
2023-09-04 04:26:50.034375: acc: 95.55%, sen: 90.52%, spe: 97.25%
2023-09-04 04:26:50.035904: current best miou: 0.8424533035516987 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 04:26:50.037157: current best dsc: 0.9144908062827978 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 04:26:50.038336: finished real validation
2023-09-04 04:26:54.377355: train_loss -1.4357
2023-09-04 04:26:54.379256: val_loss -1.0743
2023-09-04 04:26:54.380788: Pseudo dice [0.9143]
2023-09-04 04:26:54.382220: Epoch time: 391.43 s
2023-09-04 04:26:55.530674: 
2023-09-04 04:26:55.532444: Epoch 138
2023-09-04 04:26:55.533835: Current learning rate: backbone 0.00057432, others 0.00057432
2023-09-04 04:26:55.535506: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 04:27:57.243957: finished training epoch 138
2023-09-04 04:27:57.276741: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 04:27:57.279195: The split file contains 1 splits.
2023-09-04 04:27:57.280492: Desired fold for training: 0
2023-09-04 04:27:57.281731: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 04:33:15.926868: dsc: 91.18%
2023-09-04 04:33:15.928851: miou: 83.79%
2023-09-04 04:33:15.930205: acc: 95.59%, sen: 90.55%, spe: 97.29%
2023-09-04 04:33:15.932095: current best miou: 0.8424533035516987 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 04:33:15.933393: current best dsc: 0.9144908062827978 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 04:33:15.934606: finished real validation
2023-09-04 04:33:20.272818: train_loss -1.4355
2023-09-04 04:33:20.274961: val_loss -1.0333
2023-09-04 04:33:20.276577: Pseudo dice [0.9078]
2023-09-04 04:33:20.277976: Epoch time: 384.74 s
2023-09-04 04:33:21.432558: 
2023-09-04 04:33:21.434268: Epoch 139
2023-09-04 04:33:21.435565: Current learning rate: backbone 0.00057113, others 0.00057113
2023-09-04 04:33:21.437577: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 04:34:22.906283: finished training epoch 139
2023-09-04 04:34:22.935432: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 04:34:22.938813: The split file contains 1 splits.
2023-09-04 04:34:22.940648: Desired fold for training: 0
2023-09-04 04:34:22.942257: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 04:39:36.697601: dsc: 91.27%
2023-09-04 04:39:36.699586: miou: 83.94%
2023-09-04 04:39:36.701175: acc: 95.60%, sen: 91.38%, spe: 97.02%
2023-09-04 04:39:36.703054: current best miou: 0.8424533035516987 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 04:39:36.704359: current best dsc: 0.9144908062827978 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 04:39:36.707085: finished real validation
2023-09-04 04:39:41.052897: train_loss -1.4365
2023-09-04 04:39:41.054673: val_loss -1.0699
2023-09-04 04:39:41.056195: Pseudo dice [0.9155]
2023-09-04 04:39:41.057732: Epoch time: 379.62 s
2023-09-04 04:39:43.726676: 
2023-09-04 04:39:43.728602: Epoch 140
2023-09-04 04:39:43.730129: Current learning rate: backbone 0.00056794, others 0.00056794
2023-09-04 04:39:43.731916: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 04:40:45.264702: finished training epoch 140
2023-09-04 04:40:45.294080: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 04:40:45.296539: The split file contains 1 splits.
2023-09-04 04:40:45.297819: Desired fold for training: 0
2023-09-04 04:40:45.299007: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 04:46:00.543245: dsc: 91.13%
2023-09-04 04:46:00.545267: miou: 83.70%
2023-09-04 04:46:00.546663: acc: 95.57%, sen: 90.45%, spe: 97.29%
2023-09-04 04:46:00.548295: current best miou: 0.8424533035516987 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 04:46:00.549675: current best dsc: 0.9144908062827978 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 04:46:00.551001: finished real validation
2023-09-04 04:46:04.893121: train_loss -1.4366
2023-09-04 04:46:04.895138: val_loss -1.0532
2023-09-04 04:46:04.896882: Pseudo dice [0.9114]
2023-09-04 04:46:04.898340: Epoch time: 381.17 s
2023-09-04 04:46:06.060124: 
2023-09-04 04:46:06.061772: Epoch 141
2023-09-04 04:46:06.063355: Current learning rate: backbone 0.00056474, others 0.00056474
2023-09-04 04:46:06.065200: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 04:47:08.801976: finished training epoch 141
2023-09-04 04:47:08.833431: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 04:47:08.835808: The split file contains 1 splits.
2023-09-04 04:47:08.837197: Desired fold for training: 0
2023-09-04 04:47:08.838458: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 04:52:23.663869: dsc: 91.21%
2023-09-04 04:52:23.665534: miou: 83.84%
2023-09-04 04:52:23.666893: acc: 95.58%, sen: 91.16%, spe: 97.07%
2023-09-04 04:52:23.668517: current best miou: 0.8424533035516987 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 04:52:23.669921: current best dsc: 0.9144908062827978 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 04:52:23.671203: finished real validation
2023-09-04 04:52:28.011585: train_loss -1.4365
2023-09-04 04:52:28.013885: val_loss -1.0471
2023-09-04 04:52:28.015655: Pseudo dice [0.911]
2023-09-04 04:52:28.017064: Epoch time: 381.95 s
2023-09-04 04:52:29.182511: 
2023-09-04 04:52:29.184152: Epoch 142
2023-09-04 04:52:29.185490: Current learning rate: backbone 0.00056154, others 0.00056154
2023-09-04 04:52:29.187970: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 04:53:31.814633: finished training epoch 142
2023-09-04 04:53:31.846095: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 04:53:31.848966: The split file contains 1 splits.
2023-09-04 04:53:31.850527: Desired fold for training: 0
2023-09-04 04:53:31.851895: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 04:58:42.431845: dsc: 91.16%
2023-09-04 04:58:42.433471: miou: 83.76%
2023-09-04 04:58:42.434729: acc: 95.56%, sen: 91.05%, spe: 97.08%
2023-09-04 04:58:42.436342: current best miou: 0.8424533035516987 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 04:58:42.437573: current best dsc: 0.9144908062827978 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 04:58:42.438786: finished real validation
2023-09-04 04:58:46.766058: train_loss -1.4375
2023-09-04 04:58:46.767923: val_loss -1.0549
2023-09-04 04:58:46.769513: Pseudo dice [0.9125]
2023-09-04 04:58:46.770916: Epoch time: 377.58 s
2023-09-04 04:58:47.933935: 
2023-09-04 04:58:47.935722: Epoch 143
2023-09-04 04:58:47.937195: Current learning rate: backbone 0.00055834, others 0.00055834
2023-09-04 04:58:47.939011: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 04:59:49.612777: finished training epoch 143
2023-09-04 04:59:49.660299: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 04:59:49.662528: The split file contains 1 splits.
2023-09-04 04:59:49.663972: Desired fold for training: 0
2023-09-04 04:59:49.665337: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 05:05:06.259509: dsc: 91.39%
2023-09-04 05:05:06.261291: miou: 84.15%
2023-09-04 05:05:06.262577: acc: 95.65%, sen: 91.83%, spe: 96.93%
2023-09-04 05:05:06.264267: current best miou: 0.8424533035516987 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 05:05:06.266248: current best dsc: 0.9144908062827978 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 05:05:06.267823: finished real validation
2023-09-04 05:05:10.608905: train_loss -1.4365
2023-09-04 05:05:10.610872: val_loss -1.066
2023-09-04 05:05:10.612516: Pseudo dice [0.9119]
2023-09-04 05:05:10.614025: Epoch time: 382.68 s
2023-09-04 05:05:11.793269: 
2023-09-04 05:05:11.794810: Epoch 144
2023-09-04 05:05:11.796205: Current learning rate: backbone 0.00055514, others 0.00055514
2023-09-04 05:05:11.797949: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 05:06:13.283334: finished training epoch 144
2023-09-04 05:06:13.318688: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 05:06:13.321068: The split file contains 1 splits.
2023-09-04 05:06:13.322458: Desired fold for training: 0
2023-09-04 05:06:13.323723: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 05:11:23.978454: dsc: 91.23%
2023-09-04 05:11:23.980312: miou: 83.87%
2023-09-04 05:11:23.981747: acc: 95.60%, sen: 90.98%, spe: 97.15%
2023-09-04 05:11:23.983408: current best miou: 0.8424533035516987 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 05:11:23.985342: current best dsc: 0.9144908062827978 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 05:11:23.986876: finished real validation
2023-09-04 05:11:28.339123: train_loss -1.4367
2023-09-04 05:11:28.340979: val_loss -1.0701
2023-09-04 05:11:28.342624: Pseudo dice [0.9141]
2023-09-04 05:11:28.344045: Epoch time: 376.55 s
2023-09-04 05:11:29.509454: 
2023-09-04 05:11:29.511083: Epoch 145
2023-09-04 05:11:29.512485: Current learning rate: backbone 0.00055194, others 0.00055194
2023-09-04 05:11:29.514450: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 05:12:31.020572: finished training epoch 145
2023-09-04 05:12:31.059419: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 05:12:31.061723: The split file contains 1 splits.
2023-09-04 05:12:31.063076: Desired fold for training: 0
2023-09-04 05:12:31.064404: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 05:17:49.005753: dsc: 91.26%
2023-09-04 05:17:49.007282: miou: 83.93%
2023-09-04 05:17:49.008715: acc: 95.63%, sen: 90.81%, spe: 97.24%
2023-09-04 05:17:49.010472: current best miou: 0.8424533035516987 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 05:17:49.011917: current best dsc: 0.9144908062827978 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 05:17:49.013352: finished real validation
2023-09-04 05:17:53.349749: train_loss -1.4366
2023-09-04 05:17:53.351749: val_loss -1.075
2023-09-04 05:17:53.353629: Pseudo dice [0.9147]
2023-09-04 05:17:53.355328: Epoch time: 383.84 s
2023-09-04 05:17:54.512049: 
2023-09-04 05:17:54.513744: Epoch 146
2023-09-04 05:17:54.515134: Current learning rate: backbone 0.00054873, others 0.00054873
2023-09-04 05:17:54.516883: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 05:18:55.945963: finished training epoch 146
2023-09-04 05:18:55.975920: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 05:18:55.978242: The split file contains 1 splits.
2023-09-04 05:18:55.979609: Desired fold for training: 0
2023-09-04 05:18:55.980860: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 05:24:11.967942: dsc: 91.21%
2023-09-04 05:24:11.969826: miou: 83.85%
2023-09-04 05:24:11.971181: acc: 95.59%, sen: 91.00%, spe: 97.13%
2023-09-04 05:24:11.972798: current best miou: 0.8424533035516987 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 05:24:11.974233: current best dsc: 0.9144908062827978 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 05:24:11.975573: finished real validation
2023-09-04 05:24:16.320405: train_loss -1.4376
2023-09-04 05:24:16.322106: val_loss -1.0642
2023-09-04 05:24:16.323860: Pseudo dice [0.9139]
2023-09-04 05:24:16.325256: Epoch time: 381.81 s
2023-09-04 05:24:17.513757: 
2023-09-04 05:24:17.515424: Epoch 147
2023-09-04 05:24:17.516876: Current learning rate: backbone 0.00054552, others 0.00054552
2023-09-04 05:24:17.518532: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 05:25:18.911540: finished training epoch 147
2023-09-04 05:25:18.940745: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 05:25:18.942882: The split file contains 1 splits.
2023-09-04 05:25:18.944396: Desired fold for training: 0
2023-09-04 05:25:18.945818: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 05:30:32.117982: dsc: 91.23%
2023-09-04 05:30:32.119907: miou: 83.87%
2023-09-04 05:30:32.121251: acc: 95.60%, sen: 91.01%, spe: 97.14%
2023-09-04 05:30:32.122983: current best miou: 0.8424533035516987 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 05:30:32.124268: current best dsc: 0.9144908062827978 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 05:30:32.125515: finished real validation
2023-09-04 05:30:36.462959: train_loss -1.4378
2023-09-04 05:30:36.464836: val_loss -1.0778
2023-09-04 05:30:36.466503: Pseudo dice [0.9152]
2023-09-04 05:30:36.467887: Epoch time: 378.95 s
2023-09-04 05:30:37.640975: 
2023-09-04 05:30:37.642686: Epoch 148
2023-09-04 05:30:37.644134: Current learning rate: backbone 0.00054231, others 0.00054231
2023-09-04 05:30:37.645945: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 05:31:39.011864: finished training epoch 148
2023-09-04 05:31:39.059264: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 05:31:39.061750: The split file contains 1 splits.
2023-09-04 05:31:39.063155: Desired fold for training: 0
2023-09-04 05:31:39.064506: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 05:36:50.513792: dsc: 91.17%
2023-09-04 05:36:50.515553: miou: 83.78%
2023-09-04 05:36:50.516889: acc: 95.55%, sen: 91.36%, spe: 96.96%
2023-09-04 05:36:50.518502: current best miou: 0.8424533035516987 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 05:36:50.519782: current best dsc: 0.9144908062827978 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 05:36:50.521079: finished real validation
2023-09-04 05:36:54.852224: train_loss -1.4378
2023-09-04 05:36:54.854563: val_loss -1.0606
2023-09-04 05:36:54.856870: Pseudo dice [0.914]
2023-09-04 05:36:54.859357: Epoch time: 377.21 s
2023-09-04 05:36:56.049057: 
2023-09-04 05:36:56.050872: Epoch 149
2023-09-04 05:36:56.052263: Current learning rate: backbone 0.0005391, others 0.0005391
2023-09-04 05:36:56.053974: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 05:37:57.836488: finished training epoch 149
2023-09-04 05:37:57.907265: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 05:37:57.909759: The split file contains 1 splits.
2023-09-04 05:37:57.911288: Desired fold for training: 0
2023-09-04 05:37:57.912625: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 05:43:10.378442: dsc: 91.10%
2023-09-04 05:43:10.380202: miou: 83.65%
2023-09-04 05:43:10.381507: acc: 95.52%, sen: 91.22%, spe: 96.96%
2023-09-04 05:43:10.383098: current best miou: 0.8424533035516987 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 05:43:10.384370: current best dsc: 0.9144908062827978 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 05:43:10.385590: finished real validation
2023-09-04 05:43:14.722797: train_loss -1.437
2023-09-04 05:43:14.724487: val_loss -1.0553
2023-09-04 05:43:14.726205: Pseudo dice [0.9138]
2023-09-04 05:43:14.727617: Epoch time: 378.68 s
2023-09-04 05:43:17.461236: 
2023-09-04 05:43:17.462881: Epoch 150
2023-09-04 05:43:17.464236: Current learning rate: backbone 0.00053589, others 0.00053589
2023-09-04 05:43:17.465902: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 05:44:19.217314: finished training epoch 150
2023-09-04 05:44:19.246941: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 05:44:19.250506: The split file contains 1 splits.
2023-09-04 05:44:19.252702: Desired fold for training: 0
2023-09-04 05:44:19.254556: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 05:49:35.906324: dsc: 91.34%
2023-09-04 05:49:35.908120: miou: 84.05%
2023-09-04 05:49:35.909434: acc: 95.64%, sen: 91.37%, spe: 97.07%
2023-09-04 05:49:35.911049: current best miou: 0.8424533035516987 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 05:49:35.912330: current best dsc: 0.9144908062827978 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 05:49:35.913555: finished real validation
2023-09-04 05:49:40.286114: train_loss -1.4382
2023-09-04 05:49:40.288580: val_loss -1.0621
2023-09-04 05:49:40.290724: Pseudo dice [0.9141]
2023-09-04 05:49:40.292370: Epoch time: 382.83 s
2023-09-04 05:49:40.293966: Yayy! New best EMA pseudo Dice: 0.9133
2023-09-04 05:49:43.369970: 
2023-09-04 05:49:43.372202: Epoch 151
2023-09-04 05:49:43.374040: Current learning rate: backbone 0.00053267, others 0.00053267
2023-09-04 05:49:43.376139: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 05:50:44.909139: finished training epoch 151
2023-09-04 05:50:44.958106: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 05:50:44.960295: The split file contains 1 splits.
2023-09-04 05:50:44.961716: Desired fold for training: 0
2023-09-04 05:50:44.963094: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 05:56:03.329633: dsc: 91.18%
2023-09-04 05:56:03.331267: miou: 83.78%
2023-09-04 05:56:03.332536: acc: 95.56%, sen: 91.17%, spe: 97.04%
2023-09-04 05:56:03.334077: current best miou: 0.8424533035516987 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 05:56:03.335317: current best dsc: 0.9144908062827978 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 05:56:03.336573: finished real validation
2023-09-04 05:56:07.676953: train_loss -1.4378
2023-09-04 05:56:07.678826: val_loss -1.0504
2023-09-04 05:56:07.680463: Pseudo dice [0.9128]
2023-09-04 05:56:07.681807: Epoch time: 384.31 s
2023-09-04 05:56:08.871821: 
2023-09-04 05:56:08.873715: Epoch 152
2023-09-04 05:56:08.875145: Current learning rate: backbone 0.00052945, others 0.00052945
2023-09-04 05:56:08.876803: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 05:57:10.297071: finished training epoch 152
2023-09-04 05:57:10.336658: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 05:57:10.339090: The split file contains 1 splits.
2023-09-04 05:57:10.340546: Desired fold for training: 0
2023-09-04 05:57:10.341974: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 06:02:26.948289: dsc: 91.28%
2023-09-04 06:02:26.950360: miou: 83.96%
2023-09-04 06:02:26.951777: acc: 95.62%, sen: 91.09%, spe: 97.14%
2023-09-04 06:02:26.953564: current best miou: 0.8424533035516987 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 06:02:26.954933: current best dsc: 0.9144908062827978 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 06:02:26.956233: finished real validation
2023-09-04 06:02:31.309937: train_loss -1.4384
2023-09-04 06:02:31.311893: val_loss -1.0656
2023-09-04 06:02:31.313723: Pseudo dice [0.9158]
2023-09-04 06:02:31.315205: Epoch time: 382.44 s
2023-09-04 06:02:31.316952: Yayy! New best EMA pseudo Dice: 0.9135
2023-09-04 06:02:34.109770: 
2023-09-04 06:02:34.111556: Epoch 153
2023-09-04 06:02:34.113031: Current learning rate: backbone 0.00052623, others 0.00052623
2023-09-04 06:02:34.114877: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 06:03:35.742835: finished training epoch 153
2023-09-04 06:03:35.772352: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 06:03:35.774557: The split file contains 1 splits.
2023-09-04 06:03:35.776845: Desired fold for training: 0
2023-09-04 06:03:35.778373: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 06:08:46.017438: dsc: 91.28%
2023-09-04 06:08:46.019822: miou: 83.95%
2023-09-04 06:08:46.021454: acc: 95.61%, sen: 91.43%, spe: 97.01%
2023-09-04 06:08:46.023691: current best miou: 0.8424533035516987 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 06:08:46.025461: current best dsc: 0.9144908062827978 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 06:08:46.027142: finished real validation
2023-09-04 06:08:50.385767: train_loss -1.4378
2023-09-04 06:08:50.387717: val_loss -1.0874
2023-09-04 06:08:50.390208: Pseudo dice [0.9166]
2023-09-04 06:08:50.392135: Epoch time: 376.28 s
2023-09-04 06:08:50.393892: Yayy! New best EMA pseudo Dice: 0.9139
2023-09-04 06:08:53.145860: 
2023-09-04 06:08:53.147987: Epoch 154
2023-09-04 06:08:53.149484: Current learning rate: backbone 0.00052301, others 0.00052301
2023-09-04 06:08:53.151556: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 06:09:54.607845: finished training epoch 154
2023-09-04 06:09:54.650151: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 06:09:54.652391: The split file contains 1 splits.
2023-09-04 06:09:54.653912: Desired fold for training: 0
2023-09-04 06:09:54.655272: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 06:15:05.066099: dsc: 91.09%
2023-09-04 06:15:05.067727: miou: 83.65%
2023-09-04 06:15:05.069168: acc: 95.50%, sen: 91.41%, spe: 96.88%
2023-09-04 06:15:05.070756: current best miou: 0.8424533035516987 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 06:15:05.072124: current best dsc: 0.9144908062827978 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 06:15:05.073385: finished real validation
2023-09-04 06:15:09.404755: train_loss -1.4377
2023-09-04 06:15:09.406736: val_loss -1.0282
2023-09-04 06:15:09.408612: Pseudo dice [0.9093]
2023-09-04 06:15:09.410133: Epoch time: 376.26 s
2023-09-04 06:15:10.592247: 
2023-09-04 06:15:10.593977: Epoch 155
2023-09-04 06:15:10.595645: Current learning rate: backbone 0.00051978, others 0.00051978
2023-09-04 06:15:10.598244: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 06:16:11.994750: finished training epoch 155
2023-09-04 06:16:12.031635: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 06:16:12.034112: The split file contains 1 splits.
2023-09-04 06:16:12.035485: Desired fold for training: 0
2023-09-04 06:16:12.036801: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 06:21:24.576182: dsc: 91.29%
2023-09-04 06:21:24.578123: miou: 83.98%
2023-09-04 06:21:24.579454: acc: 95.61%, sen: 91.41%, spe: 97.03%
2023-09-04 06:21:24.581190: current best miou: 0.8424533035516987 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 06:21:24.582633: current best dsc: 0.9144908062827978 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 06:21:24.583914: finished real validation
2023-09-04 06:21:28.954000: train_loss -1.4381
2023-09-04 06:21:28.956049: val_loss -1.027
2023-09-04 06:21:28.957822: Pseudo dice [0.9096]
2023-09-04 06:21:28.959288: Epoch time: 378.36 s
2023-09-04 06:21:30.149953: 
2023-09-04 06:21:30.151699: Epoch 156
2023-09-04 06:21:30.153075: Current learning rate: backbone 0.00051656, others 0.00051656
2023-09-04 06:21:30.155176: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 06:22:31.613415: finished training epoch 156
2023-09-04 06:22:31.671520: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 06:22:31.674024: The split file contains 1 splits.
2023-09-04 06:22:31.675520: Desired fold for training: 0
2023-09-04 06:22:31.676916: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 06:27:56.904237: dsc: 91.22%
2023-09-04 06:27:56.905781: miou: 83.86%
2023-09-04 06:27:56.907066: acc: 95.61%, sen: 90.78%, spe: 97.23%
2023-09-04 06:27:56.909327: current best miou: 0.8424533035516987 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 06:27:56.910576: current best dsc: 0.9144908062827978 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 06:27:56.911905: finished real validation
2023-09-04 06:28:01.244344: train_loss -1.438
2023-09-04 06:28:01.246218: val_loss -1.0318
2023-09-04 06:28:01.247956: Pseudo dice [0.9114]
2023-09-04 06:28:01.249485: Epoch time: 391.1 s
2023-09-04 06:28:02.421956: 
2023-09-04 06:28:02.423683: Epoch 157
2023-09-04 06:28:02.425629: Current learning rate: backbone 0.00051333, others 0.00051333
2023-09-04 06:28:02.428006: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 06:29:04.120028: finished training epoch 157
2023-09-04 06:29:04.149399: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 06:29:04.152214: The split file contains 1 splits.
2023-09-04 06:29:04.153791: Desired fold for training: 0
2023-09-04 06:29:04.155218: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 06:34:18.916298: dsc: 91.24%
2023-09-04 06:34:18.919639: miou: 83.90%
2023-09-04 06:34:18.921145: acc: 95.62%, sen: 90.77%, spe: 97.25%
2023-09-04 06:34:18.923351: current best miou: 0.8424533035516987 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 06:34:18.924933: current best dsc: 0.9144908062827978 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 06:34:18.926290: finished real validation
2023-09-04 06:34:23.269780: train_loss -1.438
2023-09-04 06:34:23.272304: val_loss -1.0586
2023-09-04 06:34:23.275110: Pseudo dice [0.9126]
2023-09-04 06:34:23.277082: Epoch time: 380.85 s
2023-09-04 06:34:24.468808: 
2023-09-04 06:34:24.470717: Epoch 158
2023-09-04 06:34:24.472218: Current learning rate: backbone 0.00051009, others 0.00051009
2023-09-04 06:34:24.473988: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 06:35:25.898605: finished training epoch 158
2023-09-04 06:35:25.942952: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 06:35:25.945492: The split file contains 1 splits.
2023-09-04 06:35:25.946938: Desired fold for training: 0
2023-09-04 06:35:25.948641: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 06:41:03.711498: dsc: 91.20%
2023-09-04 06:41:03.713211: miou: 83.83%
2023-09-04 06:41:03.715170: acc: 95.59%, sen: 90.97%, spe: 97.14%
2023-09-04 06:41:03.717017: current best miou: 0.8424533035516987 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 06:41:03.718479: current best dsc: 0.9144908062827978 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 06:41:03.719887: finished real validation
2023-09-04 06:41:08.063610: train_loss -1.4381
2023-09-04 06:41:08.065710: val_loss -1.053
2023-09-04 06:41:08.067556: Pseudo dice [0.912]
2023-09-04 06:41:08.069311: Epoch time: 403.6 s
2023-09-04 06:41:09.254999: 
2023-09-04 06:41:09.257005: Epoch 159
2023-09-04 06:41:09.258487: Current learning rate: backbone 0.00050686, others 0.00050686
2023-09-04 06:41:09.260677: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 06:42:10.968124: finished training epoch 159
2023-09-04 06:42:11.003594: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 06:42:11.005905: The split file contains 1 splits.
2023-09-04 06:42:11.007410: Desired fold for training: 0
2023-09-04 06:42:11.008803: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 06:47:21.188512: dsc: 91.06%
2023-09-04 06:47:21.190346: miou: 83.59%
2023-09-04 06:47:21.191738: acc: 95.53%, sen: 90.62%, spe: 97.18%
2023-09-04 06:47:21.193386: current best miou: 0.8424533035516987 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 06:47:21.194776: current best dsc: 0.9144908062827978 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 06:47:21.196109: finished real validation
2023-09-04 06:47:25.535487: train_loss -1.4387
2023-09-04 06:47:25.537435: val_loss -1.0753
2023-09-04 06:47:25.539221: Pseudo dice [0.9155]
2023-09-04 06:47:25.540889: Epoch time: 376.28 s
2023-09-04 06:47:28.227975: 
2023-09-04 06:47:28.229894: Epoch 160
2023-09-04 06:47:28.231401: Current learning rate: backbone 0.00050362, others 0.00050362
2023-09-04 06:47:28.233186: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 06:48:29.917620: finished training epoch 160
2023-09-04 06:48:29.954871: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 06:48:29.957660: The split file contains 1 splits.
2023-09-04 06:48:29.959169: Desired fold for training: 0
2023-09-04 06:48:29.960540: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 06:53:41.670887: dsc: 91.27%
2023-09-04 06:53:41.672724: miou: 83.94%
2023-09-04 06:53:41.674146: acc: 95.60%, sen: 91.40%, spe: 97.02%
2023-09-04 06:53:41.675913: current best miou: 0.8424533035516987 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 06:53:41.677250: current best dsc: 0.9144908062827978 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 06:53:41.678571: finished real validation
2023-09-04 06:53:46.010856: train_loss -1.4389
2023-09-04 06:53:46.012721: val_loss -1.0262
2023-09-04 06:53:46.014421: Pseudo dice [0.9099]
2023-09-04 06:53:46.015852: Epoch time: 377.78 s
2023-09-04 06:53:47.215693: 
2023-09-04 06:53:47.217438: Epoch 161
2023-09-04 06:53:47.218947: Current learning rate: backbone 0.00050038, others 0.00050038
2023-09-04 06:53:47.220862: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 06:54:48.675928: finished training epoch 161
2023-09-04 06:54:48.705388: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 06:54:48.707775: The split file contains 1 splits.
2023-09-04 06:54:48.709344: Desired fold for training: 0
2023-09-04 06:54:48.710821: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 07:00:01.712416: dsc: 91.30%
2023-09-04 07:00:01.714134: miou: 83.98%
2023-09-04 07:00:01.715538: acc: 95.60%, sen: 91.66%, spe: 96.93%
2023-09-04 07:00:01.717273: current best miou: 0.8424533035516987 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 07:00:01.718713: current best dsc: 0.9144908062827978 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 07:00:01.720012: finished real validation
2023-09-04 07:00:06.073886: train_loss -1.439
2023-09-04 07:00:06.076084: val_loss -1.0189
2023-09-04 07:00:06.078513: Pseudo dice [0.9083]
2023-09-04 07:00:06.080493: Epoch time: 378.86 s
2023-09-04 07:00:07.262138: 
2023-09-04 07:00:07.263940: Epoch 162
2023-09-04 07:00:07.265440: Current learning rate: backbone 0.00049714, others 0.00049714
2023-09-04 07:00:07.267334: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 07:01:08.822639: finished training epoch 162
2023-09-04 07:01:08.862699: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 07:01:08.865297: The split file contains 1 splits.
2023-09-04 07:01:08.866810: Desired fold for training: 0
2023-09-04 07:01:08.868265: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 07:06:21.193810: dsc: 91.05%
2023-09-04 07:06:21.195603: miou: 83.56%
2023-09-04 07:06:21.197058: acc: 95.52%, sen: 90.54%, spe: 97.20%
2023-09-04 07:06:21.198766: current best miou: 0.8424533035516987 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 07:06:21.200467: current best dsc: 0.9144908062827978 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 07:06:21.202149: finished real validation
2023-09-04 07:06:25.548838: train_loss -1.4394
2023-09-04 07:06:25.550698: val_loss -1.0752
2023-09-04 07:06:25.552355: Pseudo dice [0.9158]
2023-09-04 07:06:25.553851: Epoch time: 378.29 s
2023-09-04 07:06:26.737501: 
2023-09-04 07:06:26.738958: Epoch 163
2023-09-04 07:06:26.740232: Current learning rate: backbone 0.0004939, others 0.0004939
2023-09-04 07:06:26.742148: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 07:07:28.162999: finished training epoch 163
2023-09-04 07:07:28.198573: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 07:07:28.200939: The split file contains 1 splits.
2023-09-04 07:07:28.202460: Desired fold for training: 0
2023-09-04 07:07:28.203915: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 07:12:45.176439: dsc: 91.20%
2023-09-04 07:12:45.178242: miou: 83.83%
2023-09-04 07:12:45.179677: acc: 95.58%, sen: 91.09%, spe: 97.09%
2023-09-04 07:12:45.181458: current best miou: 0.8424533035516987 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 07:12:45.182845: current best dsc: 0.9144908062827978 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 07:12:45.184338: finished real validation
2023-09-04 07:12:49.525740: train_loss -1.4385
2023-09-04 07:12:49.527898: val_loss -1.0474
2023-09-04 07:12:49.529887: Pseudo dice [0.9105]
2023-09-04 07:12:49.531737: Epoch time: 382.79 s
2023-09-04 07:12:50.711608: 
2023-09-04 07:12:50.713414: Epoch 164
2023-09-04 07:12:50.715055: Current learning rate: backbone 0.00049065, others 0.00049065
2023-09-04 07:12:50.716993: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 07:13:52.183255: finished training epoch 164
2023-09-04 07:13:52.223218: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 07:13:52.225415: The split file contains 1 splits.
2023-09-04 07:13:52.226843: Desired fold for training: 0
2023-09-04 07:13:52.228210: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 07:19:04.847927: dsc: 91.17%
2023-09-04 07:19:04.849766: miou: 83.77%
2023-09-04 07:19:04.851233: acc: 95.58%, sen: 90.76%, spe: 97.19%
2023-09-04 07:19:04.853019: current best miou: 0.8424533035516987 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 07:19:04.854509: current best dsc: 0.9144908062827978 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 07:19:04.855918: finished real validation
2023-09-04 07:19:09.240643: train_loss -1.439
2023-09-04 07:19:09.242806: val_loss -1.0711
2023-09-04 07:19:09.244645: Pseudo dice [0.9147]
2023-09-04 07:19:09.246295: Epoch time: 378.53 s
2023-09-04 07:19:10.393744: 
2023-09-04 07:19:10.395617: Epoch 165
2023-09-04 07:19:10.397463: Current learning rate: backbone 0.00048741, others 0.00048741
2023-09-04 07:19:10.399668: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 07:20:11.849336: finished training epoch 165
2023-09-04 07:20:11.883169: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 07:20:11.886842: The split file contains 1 splits.
2023-09-04 07:20:11.888442: Desired fold for training: 0
2023-09-04 07:20:11.889865: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 07:25:27.419283: dsc: 91.15%
2023-09-04 07:25:27.421158: miou: 83.74%
2023-09-04 07:25:27.422691: acc: 95.55%, sen: 91.05%, spe: 97.07%
2023-09-04 07:25:27.424841: current best miou: 0.8424533035516987 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 07:25:27.426385: current best dsc: 0.9144908062827978 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 07:25:27.427833: finished real validation
2023-09-04 07:25:31.779363: train_loss -1.4389
2023-09-04 07:25:31.781306: val_loss -1.0571
2023-09-04 07:25:31.783067: Pseudo dice [0.9131]
2023-09-04 07:25:31.784914: Epoch time: 381.39 s
2023-09-04 07:25:32.942012: 
2023-09-04 07:25:32.943969: Epoch 166
2023-09-04 07:25:32.945630: Current learning rate: backbone 0.00048416, others 0.00048416
2023-09-04 07:25:32.947784: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 07:26:34.354991: finished training epoch 166
2023-09-04 07:26:34.420900: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 07:26:34.423206: The split file contains 1 splits.
2023-09-04 07:26:34.424716: Desired fold for training: 0
2023-09-04 07:26:34.426281: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 07:31:53.537915: dsc: 91.19%
2023-09-04 07:31:53.539769: miou: 83.81%
2023-09-04 07:31:53.541319: acc: 95.58%, sen: 91.00%, spe: 97.12%
2023-09-04 07:31:53.543161: current best miou: 0.8424533035516987 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 07:31:53.544662: current best dsc: 0.9144908062827978 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 07:31:53.546507: finished real validation
2023-09-04 07:31:57.884835: train_loss -1.4398
2023-09-04 07:31:57.886981: val_loss -1.0716
2023-09-04 07:31:57.888917: Pseudo dice [0.9137]
2023-09-04 07:31:57.890561: Epoch time: 384.94 s
2023-09-04 07:31:59.042641: 
2023-09-04 07:31:59.044486: Epoch 167
2023-09-04 07:31:59.046250: Current learning rate: backbone 0.0004809, others 0.0004809
2023-09-04 07:31:59.049018: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 07:33:00.560488: finished training epoch 167
2023-09-04 07:33:00.601781: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 07:33:00.604313: The split file contains 1 splits.
2023-09-04 07:33:00.605707: Desired fold for training: 0
2023-09-04 07:33:00.607043: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 07:38:20.912131: dsc: 91.29%
2023-09-04 07:38:20.914174: miou: 83.97%
2023-09-04 07:38:20.915825: acc: 95.63%, sen: 91.04%, spe: 97.17%
2023-09-04 07:38:20.917696: current best miou: 0.8424533035516987 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 07:38:20.919274: current best dsc: 0.9144908062827978 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 07:38:20.921066: finished real validation
2023-09-04 07:38:25.246938: train_loss -1.4393
2023-09-04 07:38:25.248766: val_loss -1.0822
2023-09-04 07:38:25.251042: Pseudo dice [0.9158]
2023-09-04 07:38:25.252426: Epoch time: 386.21 s
2023-09-04 07:38:26.432327: 
2023-09-04 07:38:26.434036: Epoch 168
2023-09-04 07:38:26.435571: Current learning rate: backbone 0.00047765, others 0.00047765
2023-09-04 07:38:26.437367: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 07:39:28.540928: finished training epoch 168
2023-09-04 07:39:28.581161: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 07:39:28.583480: The split file contains 1 splits.
2023-09-04 07:39:28.584909: Desired fold for training: 0
2023-09-04 07:39:28.586277: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 07:45:04.584549: dsc: 91.24%
2023-09-04 07:45:04.586243: miou: 83.88%
2023-09-04 07:45:04.587698: acc: 95.63%, sen: 90.41%, spe: 97.39%
2023-09-04 07:45:04.589485: current best miou: 0.8424533035516987 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 07:45:04.590919: current best dsc: 0.9144908062827978 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 07:45:04.592296: finished real validation
2023-09-04 07:45:08.953495: train_loss -1.44
2023-09-04 07:45:08.955658: val_loss -1.0489
2023-09-04 07:45:08.957616: Pseudo dice [0.9136]
2023-09-04 07:45:08.959325: Epoch time: 402.52 s
2023-09-04 07:45:10.231928: 
2023-09-04 07:45:10.234022: Epoch 169
2023-09-04 07:45:10.235682: Current learning rate: backbone 0.00047439, others 0.00047439
2023-09-04 07:45:10.238088: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 07:46:12.542234: finished training epoch 169
2023-09-04 07:46:12.589112: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 07:46:12.591367: The split file contains 1 splits.
2023-09-04 07:46:12.592864: Desired fold for training: 0
2023-09-04 07:46:12.594330: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 07:51:24.192761: dsc: 91.23%
2023-09-04 07:51:24.194603: miou: 83.88%
2023-09-04 07:51:24.195992: acc: 95.58%, sen: 91.50%, spe: 96.94%
2023-09-04 07:51:24.198295: current best miou: 0.8424533035516987 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 07:51:24.200597: current best dsc: 0.9144908062827978 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 07:51:24.202057: finished real validation
2023-09-04 07:51:28.545190: train_loss -1.4395
2023-09-04 07:51:28.547177: val_loss -1.0544
2023-09-04 07:51:28.548887: Pseudo dice [0.9131]
2023-09-04 07:51:28.550399: Epoch time: 378.31 s
2023-09-04 07:51:31.232494: 
2023-09-04 07:51:31.234584: Epoch 170
2023-09-04 07:51:31.236139: Current learning rate: backbone 0.00047113, others 0.00047113
2023-09-04 07:51:31.238219: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 07:52:33.499471: finished training epoch 170
2023-09-04 07:52:33.531248: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 07:52:33.533934: The split file contains 1 splits.
2023-09-04 07:52:33.535390: Desired fold for training: 0
2023-09-04 07:52:33.536840: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 07:57:49.651477: dsc: 91.11%
2023-09-04 07:57:49.653465: miou: 83.67%
2023-09-04 07:57:49.655243: acc: 95.52%, sen: 91.27%, spe: 96.95%
2023-09-04 07:57:49.657948: current best miou: 0.8424533035516987 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 07:57:49.659653: current best dsc: 0.9144908062827978 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 07:57:49.661289: finished real validation
2023-09-04 07:57:54.007322: train_loss -1.4398
2023-09-04 07:57:54.009226: val_loss -1.0336
2023-09-04 07:57:54.010916: Pseudo dice [0.9111]
2023-09-04 07:57:54.012443: Epoch time: 382.78 s
2023-09-04 07:57:55.180724: 
2023-09-04 07:57:55.182508: Epoch 171
2023-09-04 07:57:55.184204: Current learning rate: backbone 0.00046787, others 0.00046787
2023-09-04 07:57:55.186216: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 07:58:57.048628: finished training epoch 171
2023-09-04 07:58:57.093781: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 07:58:57.096488: The split file contains 1 splits.
2023-09-04 07:58:57.098377: Desired fold for training: 0
2023-09-04 07:58:57.100117: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 08:04:15.906965: dsc: 91.19%
2023-09-04 08:04:15.908546: miou: 83.81%
2023-09-04 08:04:15.909797: acc: 95.59%, sen: 90.84%, spe: 97.18%
2023-09-04 08:04:15.911366: current best miou: 0.8424533035516987 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 08:04:15.912829: current best dsc: 0.9144908062827978 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 08:04:15.914156: finished real validation
2023-09-04 08:04:20.270801: train_loss -1.4402
2023-09-04 08:04:20.273095: val_loss -1.0545
2023-09-04 08:04:20.274973: Pseudo dice [0.9149]
2023-09-04 08:04:20.276682: Epoch time: 385.09 s
2023-09-04 08:04:21.454715: 
2023-09-04 08:04:21.456615: Epoch 172
2023-09-04 08:04:21.458140: Current learning rate: backbone 0.0004646, others 0.0004646
2023-09-04 08:04:21.460005: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 08:05:23.389122: finished training epoch 172
2023-09-04 08:05:23.435660: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 08:05:23.437958: The split file contains 1 splits.
2023-09-04 08:05:23.439463: Desired fold for training: 0
2023-09-04 08:05:23.440815: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 08:10:35.874364: dsc: 91.05%
2023-09-04 08:10:35.876303: miou: 83.57%
2023-09-04 08:10:35.877859: acc: 95.50%, sen: 90.94%, spe: 97.04%
2023-09-04 08:10:35.879814: current best miou: 0.8424533035516987 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 08:10:35.881798: current best dsc: 0.9144908062827978 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 08:10:35.883379: finished real validation
2023-09-04 08:10:40.225910: train_loss -1.439
2023-09-04 08:10:40.227984: val_loss -1.065
2023-09-04 08:10:40.229858: Pseudo dice [0.9139]
2023-09-04 08:10:40.231485: Epoch time: 378.77 s
2023-09-04 08:10:41.439840: 
2023-09-04 08:10:41.441886: Epoch 173
2023-09-04 08:10:41.443446: Current learning rate: backbone 0.00046133, others 0.00046133
2023-09-04 08:10:41.445451: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 08:11:43.257666: finished training epoch 173
2023-09-04 08:11:43.297064: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 08:11:43.299525: The split file contains 1 splits.
2023-09-04 08:11:43.301045: Desired fold for training: 0
2023-09-04 08:11:43.303162: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 08:16:53.145133: dsc: 91.09%
2023-09-04 08:16:53.147079: miou: 83.64%
2023-09-04 08:16:53.148608: acc: 95.53%, sen: 90.88%, spe: 97.09%
2023-09-04 08:16:53.150502: current best miou: 0.8424533035516987 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 08:16:53.152046: current best dsc: 0.9144908062827978 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 08:16:53.153529: finished real validation
2023-09-04 08:16:57.484696: train_loss -1.439
2023-09-04 08:16:57.486739: val_loss -1.056
2023-09-04 08:16:57.488516: Pseudo dice [0.9121]
2023-09-04 08:16:57.490095: Epoch time: 376.05 s
2023-09-04 08:16:58.659535: 
2023-09-04 08:16:58.661402: Epoch 174
2023-09-04 08:16:58.662974: Current learning rate: backbone 0.00045806, others 0.00045806
2023-09-04 08:16:58.664834: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 08:18:00.258451: finished training epoch 174
2023-09-04 08:18:00.310519: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 08:18:00.313007: The split file contains 1 splits.
2023-09-04 08:18:00.314763: Desired fold for training: 0
2023-09-04 08:18:00.316473: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 08:23:23.735697: dsc: 91.19%
2023-09-04 08:23:23.737628: miou: 83.81%
2023-09-04 08:23:23.739084: acc: 95.58%, sen: 90.96%, spe: 97.13%
2023-09-04 08:23:23.740854: current best miou: 0.8424533035516987 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 08:23:23.742293: current best dsc: 0.9144908062827978 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 08:23:23.743689: finished real validation
2023-09-04 08:23:28.058031: train_loss -1.4403
2023-09-04 08:23:28.060005: val_loss -1.0779
2023-09-04 08:23:28.061791: Pseudo dice [0.9138]
2023-09-04 08:23:28.063446: Epoch time: 389.4 s
2023-09-04 08:23:29.242152: 
2023-09-04 08:23:29.244040: Epoch 175
2023-09-04 08:23:29.245590: Current learning rate: backbone 0.00045479, others 0.00045479
2023-09-04 08:23:29.247544: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 08:24:31.007062: finished training epoch 175
2023-09-04 08:24:31.041947: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 08:24:31.054947: The split file contains 1 splits.
2023-09-04 08:24:31.059665: Desired fold for training: 0
2023-09-04 08:24:31.061337: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 08:29:47.657238: dsc: 91.05%
2023-09-04 08:29:47.659033: miou: 83.57%
2023-09-04 08:29:47.660445: acc: 95.51%, sen: 90.84%, spe: 97.08%
2023-09-04 08:29:47.662202: current best miou: 0.8424533035516987 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 08:29:47.663597: current best dsc: 0.9144908062827978 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 08:29:47.664950: finished real validation
2023-09-04 08:29:51.997660: train_loss -1.441
2023-09-04 08:29:51.999940: val_loss -1.0575
2023-09-04 08:29:52.002355: Pseudo dice [0.9135]
2023-09-04 08:29:52.004411: Epoch time: 382.76 s
2023-09-04 08:29:53.169806: 
2023-09-04 08:29:53.171531: Epoch 176
2023-09-04 08:29:53.172968: Current learning rate: backbone 0.00045151, others 0.00045151
2023-09-04 08:29:53.174705: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 08:30:55.030374: finished training epoch 176
2023-09-04 08:30:55.062310: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 08:30:55.065978: The split file contains 1 splits.
2023-09-04 08:30:55.067969: Desired fold for training: 0
2023-09-04 08:30:55.069702: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 08:36:06.121206: dsc: 91.31%
2023-09-04 08:36:06.126335: miou: 84.00%
2023-09-04 08:36:06.130753: acc: 95.63%, sen: 91.24%, spe: 97.10%
2023-09-04 08:36:06.136662: current best miou: 0.8424533035516987 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 08:36:06.141394: current best dsc: 0.9144908062827978 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 08:36:06.147045: finished real validation
2023-09-04 08:36:10.495209: train_loss -1.4399
2023-09-04 08:36:10.497161: val_loss -1.0491
2023-09-04 08:36:10.499207: Pseudo dice [0.9146]
2023-09-04 08:36:10.501777: Epoch time: 377.33 s
2023-09-04 08:36:11.705664: 
2023-09-04 08:36:11.707873: Epoch 177
2023-09-04 08:36:11.709993: Current learning rate: backbone 0.00044823, others 0.00044823
2023-09-04 08:36:11.712512: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 08:37:14.109013: finished training epoch 177
2023-09-04 08:37:14.153802: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 08:37:14.160645: The split file contains 1 splits.
2023-09-04 08:37:14.162295: Desired fold for training: 0
2023-09-04 08:37:14.163732: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 08:42:36.847153: dsc: 91.22%
2023-09-04 08:42:36.849012: miou: 83.86%
2023-09-04 08:42:36.850508: acc: 95.57%, sen: 91.43%, spe: 96.97%
2023-09-04 08:42:36.852345: current best miou: 0.8424533035516987 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 08:42:36.853882: current best dsc: 0.9144908062827978 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 08:42:36.855328: finished real validation
2023-09-04 08:42:41.248186: train_loss -1.4408
2023-09-04 08:42:41.250133: val_loss -1.0591
2023-09-04 08:42:41.252040: Pseudo dice [0.9155]
2023-09-04 08:42:41.253660: Epoch time: 389.54 s
2023-09-04 08:42:42.512756: 
2023-09-04 08:42:42.514507: Epoch 178
2023-09-04 08:42:42.516352: Current learning rate: backbone 0.00044495, others 0.00044495
2023-09-04 08:42:42.518585: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 08:43:44.195855: finished training epoch 178
2023-09-04 08:43:44.228675: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 08:43:44.230990: The split file contains 1 splits.
2023-09-04 08:43:44.232905: Desired fold for training: 0
2023-09-04 08:43:44.234563: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 08:49:01.531605: dsc: 91.31%
2023-09-04 08:49:01.533413: miou: 84.02%
2023-09-04 08:49:01.535144: acc: 95.63%, sen: 91.35%, spe: 97.07%
2023-09-04 08:49:01.536955: current best miou: 0.8424533035516987 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 08:49:01.538384: current best dsc: 0.9144908062827978 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 08:49:01.539801: finished real validation
2023-09-04 08:49:05.856969: train_loss -1.4404
2023-09-04 08:49:05.858867: val_loss -1.0583
2023-09-04 08:49:05.860742: Pseudo dice [0.9141]
2023-09-04 08:49:05.862333: Epoch time: 383.35 s
2023-09-04 08:49:07.027766: 
2023-09-04 08:49:07.029673: Epoch 179
2023-09-04 08:49:07.031238: Current learning rate: backbone 0.00044167, others 0.00044167
2023-09-04 08:49:07.033103: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 08:50:08.591241: finished training epoch 179
2023-09-04 08:50:08.623867: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 08:50:08.626504: The split file contains 1 splits.
2023-09-04 08:50:08.627959: Desired fold for training: 0
2023-09-04 08:50:08.629361: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 08:55:21.282087: dsc: 91.28%
2023-09-04 08:55:21.283971: miou: 83.96%
2023-09-04 08:55:21.285498: acc: 95.62%, sen: 91.26%, spe: 97.08%
2023-09-04 08:55:21.287776: current best miou: 0.8424533035516987 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 08:55:21.289308: current best dsc: 0.9144908062827978 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 08:55:21.290832: finished real validation
2023-09-04 08:55:25.609458: train_loss -1.4404
2023-09-04 08:55:25.611442: val_loss -1.0821
2023-09-04 08:55:25.613267: Pseudo dice [0.9174]
2023-09-04 08:55:25.615329: Epoch time: 378.58 s
2023-09-04 08:55:27.135777: Yayy! New best EMA pseudo Dice: 0.914
2023-09-04 08:55:29.783776: 
2023-09-04 08:55:29.785554: Epoch 180
2023-09-04 08:55:29.787044: Current learning rate: backbone 0.00043838, others 0.00043838
2023-09-04 08:55:29.788845: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 08:56:31.306982: finished training epoch 180
2023-09-04 08:56:31.355165: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 08:56:31.357432: The split file contains 1 splits.
2023-09-04 08:56:31.358958: Desired fold for training: 0
2023-09-04 08:56:31.364457: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 09:01:54.318265: dsc: 91.18%
2023-09-04 09:01:54.320462: miou: 83.80%
2023-09-04 09:01:54.322486: acc: 95.57%, sen: 91.00%, spe: 97.11%
2023-09-04 09:01:54.324389: current best miou: 0.8424533035516987 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 09:01:54.325884: current best dsc: 0.9144908062827978 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 09:01:54.327377: finished real validation
2023-09-04 09:01:58.666835: train_loss -1.4407
2023-09-04 09:01:58.669694: val_loss -1.0491
2023-09-04 09:01:58.671503: Pseudo dice [0.9146]
2023-09-04 09:01:58.673050: Epoch time: 388.88 s
2023-09-04 09:01:58.674567: Yayy! New best EMA pseudo Dice: 0.914
2023-09-04 09:02:01.388614: 
2023-09-04 09:02:01.390459: Epoch 181
2023-09-04 09:02:01.392118: Current learning rate: backbone 0.00043509, others 0.00043509
2023-09-04 09:02:01.394069: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 09:03:03.234209: finished training epoch 181
2023-09-04 09:03:03.271815: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 09:03:03.274526: The split file contains 1 splits.
2023-09-04 09:03:03.276131: Desired fold for training: 0
2023-09-04 09:03:03.277682: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 09:08:13.407504: dsc: 91.22%
2023-09-04 09:08:13.409436: miou: 83.85%
2023-09-04 09:08:13.411058: acc: 95.58%, sen: 91.16%, spe: 97.07%
2023-09-04 09:08:13.413333: current best miou: 0.8424533035516987 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 09:08:13.414845: current best dsc: 0.9144908062827978 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 09:08:13.416304: finished real validation
2023-09-04 09:08:17.780566: train_loss -1.4407
2023-09-04 09:08:17.782706: val_loss -1.0333
2023-09-04 09:08:17.784699: Pseudo dice [0.9105]
2023-09-04 09:08:17.786624: Epoch time: 376.39 s
2023-09-04 09:08:18.959041: 
2023-09-04 09:08:18.960940: Epoch 182
2023-09-04 09:08:18.962624: Current learning rate: backbone 0.0004318, others 0.0004318
2023-09-04 09:08:18.964898: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 09:09:20.564925: finished training epoch 182
2023-09-04 09:09:20.637880: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 09:09:20.640514: The split file contains 1 splits.
2023-09-04 09:09:20.642005: Desired fold for training: 0
2023-09-04 09:09:20.644137: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 09:14:42.531297: dsc: 91.20%
2023-09-04 09:14:42.533286: miou: 83.83%
2023-09-04 09:14:42.534774: acc: 95.59%, sen: 90.94%, spe: 97.15%
2023-09-04 09:14:42.536556: current best miou: 0.8424533035516987 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 09:14:42.538016: current best dsc: 0.9144908062827978 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 09:14:42.539442: finished real validation
2023-09-04 09:14:46.882118: train_loss -1.4408
2023-09-04 09:14:46.884112: val_loss -1.0579
2023-09-04 09:14:46.885979: Pseudo dice [0.9137]
2023-09-04 09:14:46.887624: Epoch time: 387.92 s
2023-09-04 09:14:48.048947: 
2023-09-04 09:14:48.051008: Epoch 183
2023-09-04 09:14:48.052655: Current learning rate: backbone 0.00042851, others 0.00042851
2023-09-04 09:14:48.054705: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 09:15:49.762969: finished training epoch 183
2023-09-04 09:15:49.799552: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 09:15:49.802011: The split file contains 1 splits.
2023-09-04 09:15:49.803587: Desired fold for training: 0
2023-09-04 09:15:49.805046: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 09:21:00.349243: dsc: 91.08%
2023-09-04 09:21:00.351094: miou: 83.63%
2023-09-04 09:21:00.352559: acc: 95.53%, sen: 90.87%, spe: 97.09%
2023-09-04 09:21:00.354813: current best miou: 0.8424533035516987 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 09:21:00.357014: current best dsc: 0.9144908062827978 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 09:21:00.358381: finished real validation
2023-09-04 09:21:04.685560: train_loss -1.44
2023-09-04 09:21:04.687561: val_loss -1.019
2023-09-04 09:21:04.689339: Pseudo dice [0.9108]
2023-09-04 09:21:04.691568: Epoch time: 376.64 s
2023-09-04 09:21:05.874412: 
2023-09-04 09:21:05.876438: Epoch 184
2023-09-04 09:21:05.878271: Current learning rate: backbone 0.00042521, others 0.00042521
2023-09-04 09:21:05.880377: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 09:22:07.315359: finished training epoch 184
2023-09-04 09:22:07.355340: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 09:22:07.357922: The split file contains 1 splits.
2023-09-04 09:22:07.359487: Desired fold for training: 0
2023-09-04 09:22:07.360983: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 09:27:25.795188: dsc: 91.19%
2023-09-04 09:27:25.797131: miou: 83.81%
2023-09-04 09:27:25.798705: acc: 95.55%, sen: 91.62%, spe: 96.87%
2023-09-04 09:27:25.800558: current best miou: 0.8424533035516987 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 09:27:25.802137: current best dsc: 0.9144908062827978 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 09:27:25.803643: finished real validation
2023-09-04 09:27:30.189806: train_loss -1.4407
2023-09-04 09:27:30.191944: val_loss -1.0355
2023-09-04 09:27:30.193815: Pseudo dice [0.9134]
2023-09-04 09:27:30.195620: Epoch time: 384.32 s
2023-09-04 09:27:31.415831: 
2023-09-04 09:27:31.418752: Epoch 185
2023-09-04 09:27:31.420360: Current learning rate: backbone 0.00042191, others 0.00042191
2023-09-04 09:27:31.422681: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 09:28:33.950460: finished training epoch 185
2023-09-04 09:28:33.991302: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 09:28:33.994180: The split file contains 1 splits.
2023-09-04 09:28:33.995873: Desired fold for training: 0
2023-09-04 09:28:33.997503: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 09:33:49.571188: dsc: 91.20%
2023-09-04 09:33:49.573112: miou: 83.82%
2023-09-04 09:33:49.574546: acc: 95.58%, sen: 91.07%, spe: 97.10%
2023-09-04 09:33:49.576295: current best miou: 0.8424533035516987 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 09:33:49.577757: current best dsc: 0.9144908062827978 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 09:33:49.579197: finished real validation
2023-09-04 09:33:53.915977: train_loss -1.4412
2023-09-04 09:33:53.918122: val_loss -1.0443
2023-09-04 09:33:53.919994: Pseudo dice [0.9125]
2023-09-04 09:33:53.921678: Epoch time: 382.5 s
2023-09-04 09:33:55.097467: 
2023-09-04 09:33:55.099491: Epoch 186
2023-09-04 09:33:55.101058: Current learning rate: backbone 0.00041861, others 0.00041861
2023-09-04 09:33:55.103489: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 09:34:56.630074: finished training epoch 186
2023-09-04 09:34:56.712681: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 09:34:56.715936: The split file contains 1 splits.
2023-09-04 09:34:56.718442: Desired fold for training: 0
2023-09-04 09:34:56.720783: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 09:40:11.040752: dsc: 91.26%
2023-09-04 09:40:11.042784: miou: 83.92%
2023-09-04 09:40:11.044329: acc: 95.61%, sen: 91.15%, spe: 97.11%
2023-09-04 09:40:11.046099: current best miou: 0.8424533035516987 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 09:40:11.047660: current best dsc: 0.9144908062827978 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 09:40:11.049196: finished real validation
2023-09-04 09:40:15.376531: train_loss -1.441
2023-09-04 09:40:15.378680: val_loss -1.0602
2023-09-04 09:40:15.380545: Pseudo dice [0.9144]
2023-09-04 09:40:15.382151: Epoch time: 380.28 s
2023-09-04 09:40:16.551433: 
2023-09-04 09:40:16.553241: Epoch 187
2023-09-04 09:40:16.554931: Current learning rate: backbone 0.0004153, others 0.0004153
2023-09-04 09:40:16.556905: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 09:41:18.002058: finished training epoch 187
2023-09-04 09:41:18.046415: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 09:41:18.049856: The split file contains 1 splits.
2023-09-04 09:41:18.051867: Desired fold for training: 0
2023-09-04 09:41:18.053601: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 09:46:31.788304: dsc: 91.14%
2023-09-04 09:46:31.790569: miou: 83.72%
2023-09-04 09:46:31.792539: acc: 95.56%, sen: 90.76%, spe: 97.17%
2023-09-04 09:46:31.795320: current best miou: 0.8424533035516987 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 09:46:31.797147: current best dsc: 0.9144908062827978 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 09:46:31.798846: finished real validation
2023-09-04 09:46:36.110459: train_loss -1.4412
2023-09-04 09:46:36.112478: val_loss -1.0456
2023-09-04 09:46:36.114277: Pseudo dice [0.9143]
2023-09-04 09:46:36.115901: Epoch time: 379.56 s
2023-09-04 09:46:37.284194: 
2023-09-04 09:46:37.286083: Epoch 188
2023-09-04 09:46:37.287617: Current learning rate: backbone 0.00041199, others 0.00041199
2023-09-04 09:46:37.289560: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 09:47:38.676813: finished training epoch 188
2023-09-04 09:47:38.719452: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 09:47:38.721819: The split file contains 1 splits.
2023-09-04 09:47:38.723433: Desired fold for training: 0
2023-09-04 09:47:38.725052: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 09:52:55.212513: dsc: 91.12%
2023-09-04 09:52:55.214647: miou: 83.69%
2023-09-04 09:52:55.216411: acc: 95.54%, sen: 91.07%, spe: 97.04%
2023-09-04 09:52:55.218495: current best miou: 0.8424533035516987 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 09:52:55.220423: current best dsc: 0.9144908062827978 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 09:52:55.222026: finished real validation
2023-09-04 09:52:59.525346: train_loss -1.4409
2023-09-04 09:52:59.527344: val_loss -1.0103
2023-09-04 09:52:59.529120: Pseudo dice [0.91]
2023-09-04 09:52:59.530848: Epoch time: 382.24 s
2023-09-04 09:53:00.701571: 
2023-09-04 09:53:00.703506: Epoch 189
2023-09-04 09:53:00.705330: Current learning rate: backbone 0.00040868, others 0.00040868
2023-09-04 09:53:00.707442: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 09:54:02.174342: finished training epoch 189
2023-09-04 09:54:02.249221: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 09:54:02.251736: The split file contains 1 splits.
2023-09-04 09:54:02.253286: Desired fold for training: 0
2023-09-04 09:54:02.254737: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 09:59:17.418650: dsc: 91.18%
2023-09-04 09:59:17.420588: miou: 83.80%
2023-09-04 09:59:17.422266: acc: 95.57%, sen: 91.14%, spe: 97.06%
2023-09-04 09:59:17.424249: current best miou: 0.8424533035516987 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 09:59:17.425823: current best dsc: 0.9144908062827978 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 09:59:17.427341: finished real validation
2023-09-04 09:59:21.771464: train_loss -1.4408
2023-09-04 09:59:21.773437: val_loss -1.0476
2023-09-04 09:59:21.775293: Pseudo dice [0.9148]
2023-09-04 09:59:21.776894: Epoch time: 381.07 s
2023-09-04 09:59:24.495740: 
2023-09-04 09:59:24.497805: Epoch 190
2023-09-04 09:59:24.499378: Current learning rate: backbone 0.00040536, others 0.00040536
2023-09-04 09:59:24.501309: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 10:00:25.984376: finished training epoch 190
2023-09-04 10:00:26.015038: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 10:00:26.017678: The split file contains 1 splits.
2023-09-04 10:00:26.019320: Desired fold for training: 0
2023-09-04 10:00:26.020907: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 10:05:39.107681: dsc: 91.12%
2023-09-04 10:05:39.109546: miou: 83.68%
2023-09-04 10:05:39.111699: acc: 95.53%, sen: 91.24%, spe: 96.96%
2023-09-04 10:05:39.113538: current best miou: 0.8424533035516987 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 10:05:39.115443: current best dsc: 0.9144908062827978 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 10:05:39.116914: finished real validation
2023-09-04 10:05:43.448263: train_loss -1.4414
2023-09-04 10:05:43.450514: val_loss -1.0368
2023-09-04 10:05:43.452404: Pseudo dice [0.9142]
2023-09-04 10:05:43.454110: Epoch time: 378.95 s
2023-09-04 10:05:44.628721: 
2023-09-04 10:05:44.630561: Epoch 191
2023-09-04 10:05:44.632213: Current learning rate: backbone 0.00040205, others 0.00040205
2023-09-04 10:05:44.634186: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 10:06:46.586419: finished training epoch 191
2023-09-04 10:06:46.615849: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 10:06:46.618786: The split file contains 1 splits.
2023-09-04 10:06:46.620517: Desired fold for training: 0
2023-09-04 10:06:46.622102: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 10:12:06.790980: dsc: 91.20%
2023-09-04 10:12:06.793258: miou: 83.83%
2023-09-04 10:12:06.794977: acc: 95.57%, sen: 91.36%, spe: 96.98%
2023-09-04 10:12:06.796885: current best miou: 0.8424533035516987 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 10:12:06.798588: current best dsc: 0.9144908062827978 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 10:12:06.800325: finished real validation
2023-09-04 10:12:11.113805: train_loss -1.4412
2023-09-04 10:12:11.116082: val_loss -1.0489
2023-09-04 10:12:11.118402: Pseudo dice [0.9133]
2023-09-04 10:12:11.120305: Epoch time: 386.49 s
2023-09-04 10:12:12.292194: 
2023-09-04 10:12:12.294049: Epoch 192
2023-09-04 10:12:12.295659: Current learning rate: backbone 0.00039872, others 0.00039872
2023-09-04 10:12:12.297671: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 10:13:14.392710: finished training epoch 192
2023-09-04 10:13:14.436699: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 10:13:14.439314: The split file contains 1 splits.
2023-09-04 10:13:14.440932: Desired fold for training: 0
2023-09-04 10:13:14.442471: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 10:18:26.683033: dsc: 91.18%
2023-09-04 10:18:26.685031: miou: 83.79%
2023-09-04 10:18:26.686712: acc: 95.57%, sen: 91.11%, spe: 97.06%
2023-09-04 10:18:26.688665: current best miou: 0.8424533035516987 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 10:18:26.690364: current best dsc: 0.9144908062827978 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 10:18:26.692119: finished real validation
2023-09-04 10:18:31.006930: train_loss -1.4409
2023-09-04 10:18:31.008963: val_loss -1.0079
2023-09-04 10:18:31.010881: Pseudo dice [0.9069]
2023-09-04 10:18:31.012542: Epoch time: 378.72 s
2023-09-04 10:18:32.189660: 
2023-09-04 10:18:32.191814: Epoch 193
2023-09-04 10:18:32.193607: Current learning rate: backbone 0.0003954, others 0.0003954
2023-09-04 10:18:32.195650: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 10:19:33.789704: finished training epoch 193
2023-09-04 10:19:33.832166: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 10:19:33.834612: The split file contains 1 splits.
2023-09-04 10:19:33.836483: Desired fold for training: 0
2023-09-04 10:19:33.838063: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 10:24:51.154529: dsc: 91.22%
2023-09-04 10:24:51.215041: miou: 83.86%
2023-09-04 10:24:51.217275: acc: 95.60%, sen: 90.87%, spe: 97.19%
2023-09-04 10:24:51.219611: current best miou: 0.8424533035516987 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 10:24:51.221244: current best dsc: 0.9144908062827978 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 10:24:51.223002: finished real validation
2023-09-04 10:24:55.592134: train_loss -1.4412
2023-09-04 10:24:55.594352: val_loss -1.0428
2023-09-04 10:24:55.596266: Pseudo dice [0.9124]
2023-09-04 10:24:55.597891: Epoch time: 383.4 s
2023-09-04 10:24:56.813591: 
2023-09-04 10:24:56.815591: Epoch 194
2023-09-04 10:24:56.817297: Current learning rate: backbone 0.00039207, others 0.00039207
2023-09-04 10:24:56.819537: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 10:25:59.458575: finished training epoch 194
2023-09-04 10:25:59.506787: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 10:25:59.509497: The split file contains 1 splits.
2023-09-04 10:25:59.511420: Desired fold for training: 0
2023-09-04 10:25:59.512992: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 10:31:34.716898: dsc: 91.22%
2023-09-04 10:31:34.719073: miou: 83.86%
2023-09-04 10:31:34.720782: acc: 95.60%, sen: 90.90%, spe: 97.18%
2023-09-04 10:31:34.722834: current best miou: 0.8424533035516987 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 10:31:34.724440: current best dsc: 0.9144908062827978 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 10:31:34.726117: finished real validation
2023-09-04 10:31:39.059557: train_loss -1.4416
2023-09-04 10:31:39.061701: val_loss -1.0585
2023-09-04 10:31:39.063588: Pseudo dice [0.9158]
2023-09-04 10:31:39.065289: Epoch time: 402.25 s
2023-09-04 10:31:40.254627: 
2023-09-04 10:31:40.256498: Epoch 195
2023-09-04 10:31:40.258178: Current learning rate: backbone 0.00038874, others 0.00038874
2023-09-04 10:31:40.260206: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 10:32:41.792505: finished training epoch 195
2023-09-04 10:32:41.825618: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 10:32:41.829685: The split file contains 1 splits.
2023-09-04 10:32:41.831816: Desired fold for training: 0
2023-09-04 10:32:41.833915: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 10:37:56.894413: dsc: 91.18%
2023-09-04 10:37:56.896404: miou: 83.79%
2023-09-04 10:37:56.898087: acc: 95.56%, sen: 91.29%, spe: 96.99%
2023-09-04 10:37:56.900034: current best miou: 0.8424533035516987 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 10:37:56.901668: current best dsc: 0.9144908062827978 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 10:37:56.903258: finished real validation
2023-09-04 10:38:01.245497: train_loss -1.4415
2023-09-04 10:38:01.248218: val_loss -1.0446
2023-09-04 10:38:01.250391: Pseudo dice [0.9131]
2023-09-04 10:38:01.252117: Epoch time: 380.99 s
2023-09-04 10:38:02.437424: 
2023-09-04 10:38:02.439466: Epoch 196
2023-09-04 10:38:02.441228: Current learning rate: backbone 0.00038541, others 0.00038541
2023-09-04 10:38:02.443470: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 10:39:03.930847: finished training epoch 196
2023-09-04 10:39:03.970508: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 10:39:03.973205: The split file contains 1 splits.
2023-09-04 10:39:03.974838: Desired fold for training: 0
2023-09-04 10:39:03.976442: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 10:44:19.254442: dsc: 91.23%
2023-09-04 10:44:19.256604: miou: 83.87%
2023-09-04 10:44:19.258242: acc: 95.60%, sen: 91.01%, spe: 97.14%
2023-09-04 10:44:19.260199: current best miou: 0.8424533035516987 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 10:44:19.261947: current best dsc: 0.9144908062827978 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 10:44:19.263737: finished real validation
2023-09-04 10:44:23.618262: train_loss -1.442
2023-09-04 10:44:23.620629: val_loss -1.0415
2023-09-04 10:44:23.622663: Pseudo dice [0.9152]
2023-09-04 10:44:23.624569: Epoch time: 381.18 s
2023-09-04 10:44:24.812027: 
2023-09-04 10:44:24.814195: Epoch 197
2023-09-04 10:44:24.816035: Current learning rate: backbone 0.00038207, others 0.00038207
2023-09-04 10:44:24.818306: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 10:45:26.330210: finished training epoch 197
2023-09-04 10:45:26.364041: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 10:45:26.366564: The split file contains 1 splits.
2023-09-04 10:45:26.368227: Desired fold for training: 0
2023-09-04 10:45:26.369795: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 10:50:40.029355: dsc: 91.28%
2023-09-04 10:50:40.031675: miou: 83.96%
2023-09-04 10:50:40.033455: acc: 95.62%, sen: 91.26%, spe: 97.08%
2023-09-04 10:50:40.035375: current best miou: 0.8424533035516987 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 10:50:40.036989: current best dsc: 0.9144908062827978 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 10:50:40.038605: finished real validation
2023-09-04 10:50:44.389576: train_loss -1.4421
2023-09-04 10:50:44.391631: val_loss -1.06
2023-09-04 10:50:44.393654: Pseudo dice [0.9169]
2023-09-04 10:50:44.395386: Epoch time: 379.58 s
2023-09-04 10:50:45.584098: 
2023-09-04 10:50:45.585844: Epoch 198
2023-09-04 10:50:45.587462: Current learning rate: backbone 0.00037873, others 0.00037873
2023-09-04 10:50:45.589332: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 10:51:47.156502: finished training epoch 198
2023-09-04 10:51:47.197812: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 10:51:47.200445: The split file contains 1 splits.
2023-09-04 10:51:47.202619: Desired fold for training: 0
2023-09-04 10:51:47.204732: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 10:57:00.868906: dsc: 91.25%
2023-09-04 10:57:00.870762: miou: 83.91%
2023-09-04 10:57:00.872329: acc: 95.61%, sen: 91.01%, spe: 97.16%
2023-09-04 10:57:00.874203: current best miou: 0.8424533035516987 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 10:57:00.875723: current best dsc: 0.9144908062827978 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 10:57:00.877248: finished real validation
2023-09-04 10:57:05.219608: train_loss -1.4418
2023-09-04 10:57:05.221584: val_loss -1.0586
2023-09-04 10:57:05.223560: Pseudo dice [0.9154]
2023-09-04 10:57:05.225281: Epoch time: 379.64 s
2023-09-04 10:57:06.412087: 
2023-09-04 10:57:06.414237: Epoch 199
2023-09-04 10:57:06.416148: Current learning rate: backbone 0.00037539, others 0.00037539
2023-09-04 10:57:06.418335: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 10:58:08.084478: finished training epoch 199
2023-09-04 10:58:08.114281: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 10:58:08.116735: The split file contains 1 splits.
2023-09-04 10:58:08.118377: Desired fold for training: 0
2023-09-04 10:58:08.119928: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 11:03:21.769689: dsc: 91.20%
2023-09-04 11:03:21.771750: miou: 83.82%
2023-09-04 11:03:21.773373: acc: 95.58%, sen: 91.05%, spe: 97.10%
2023-09-04 11:03:21.775512: current best miou: 0.8424533035516987 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 11:03:21.777276: current best dsc: 0.9144908062827978 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 11:03:21.779075: finished real validation
2023-09-04 11:03:26.163401: train_loss -1.4425
2023-09-04 11:03:26.165708: val_loss -1.0397
2023-09-04 11:03:26.167922: Pseudo dice [0.9125]
2023-09-04 11:03:26.169859: Epoch time: 379.75 s
2023-09-04 11:03:29.159335: 
2023-09-04 11:03:29.161539: Epoch 200
2023-09-04 11:03:29.163466: Current learning rate: backbone 0.00037204, others 0.00037204
2023-09-04 11:03:29.166116: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 11:04:31.231404: finished training epoch 200
2023-09-04 11:04:31.292102: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 11:04:31.294686: The split file contains 1 splits.
2023-09-04 11:04:31.296565: Desired fold for training: 0
2023-09-04 11:04:31.298271: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 11:09:45.481086: dsc: 91.27%
2023-09-04 11:09:45.483204: miou: 83.95%
2023-09-04 11:09:45.484832: acc: 95.62%, sen: 91.04%, spe: 97.16%
2023-09-04 11:09:45.486804: current best miou: 0.8424533035516987 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 11:09:45.488433: current best dsc: 0.9144908062827978 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 11:09:45.490020: finished real validation
2023-09-04 11:09:49.865283: train_loss -1.4421
2023-09-04 11:09:49.867481: val_loss -1.0516
2023-09-04 11:09:49.869471: Pseudo dice [0.9141]
2023-09-04 11:09:49.871349: Epoch time: 380.71 s
2023-09-04 11:09:51.054088: 
2023-09-04 11:09:51.056302: Epoch 201
2023-09-04 11:09:51.058194: Current learning rate: backbone 0.00036869, others 0.00036869
2023-09-04 11:09:51.060138: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 11:10:52.744868: finished training epoch 201
2023-09-04 11:10:52.788241: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 11:10:52.791344: The split file contains 1 splits.
2023-09-04 11:10:52.793102: Desired fold for training: 0
2023-09-04 11:10:52.794802: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 11:16:08.340199: dsc: 91.27%
2023-09-04 11:16:08.342274: miou: 83.94%
2023-09-04 11:16:08.347663: acc: 95.61%, sen: 91.20%, spe: 97.09%
2023-09-04 11:16:08.349791: current best miou: 0.8424533035516987 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 11:16:08.351451: current best dsc: 0.9144908062827978 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 11:16:08.352987: finished real validation
2023-09-04 11:16:12.749565: train_loss -1.443
2023-09-04 11:16:12.751895: val_loss -1.0316
2023-09-04 11:16:12.753891: Pseudo dice [0.9119]
2023-09-04 11:16:12.755795: Epoch time: 381.7 s
2023-09-04 11:16:14.017335: 
2023-09-04 11:16:14.019430: Epoch 202
2023-09-04 11:16:14.021139: Current learning rate: backbone 0.00036534, others 0.00036534
2023-09-04 11:16:14.023208: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 11:17:15.642528: finished training epoch 202
2023-09-04 11:17:15.684242: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 11:17:15.686712: The split file contains 1 splits.
2023-09-04 11:17:15.688379: Desired fold for training: 0
2023-09-04 11:17:15.689999: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 11:22:51.742443: dsc: 91.19%
2023-09-04 11:22:51.744366: miou: 83.81%
2023-09-04 11:22:51.746260: acc: 95.57%, sen: 91.12%, spe: 97.07%
2023-09-04 11:22:51.748890: current best miou: 0.8424533035516987 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 11:22:51.750705: current best dsc: 0.9144908062827978 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 11:22:51.752532: finished real validation
2023-09-04 11:22:56.116749: train_loss -1.4429
2023-09-04 11:22:56.119021: val_loss -1.0444
2023-09-04 11:22:56.120898: Pseudo dice [0.9141]
2023-09-04 11:22:56.122674: Epoch time: 402.1 s
2023-09-04 11:22:57.358798: 
2023-09-04 11:22:57.361230: Epoch 203
2023-09-04 11:22:57.363167: Current learning rate: backbone 0.00036198, others 0.00036198
2023-09-04 11:22:57.365723: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 11:23:58.827316: finished training epoch 203
2023-09-04 11:23:58.864493: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 11:23:58.868032: The split file contains 1 splits.
2023-09-04 11:23:58.869764: Desired fold for training: 0
2023-09-04 11:23:58.871370: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 11:29:11.490717: dsc: 91.18%
2023-09-04 11:29:11.492876: miou: 83.80%
2023-09-04 11:29:11.494542: acc: 95.56%, sen: 91.30%, spe: 96.99%
2023-09-04 11:29:11.496428: current best miou: 0.8424533035516987 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 11:29:11.498052: current best dsc: 0.9144908062827978 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 11:29:11.499694: finished real validation
2023-09-04 11:29:15.830365: train_loss -1.4426
2023-09-04 11:29:15.832779: val_loss -1.0456
2023-09-04 11:29:15.834914: Pseudo dice [0.9121]
2023-09-04 11:29:15.836770: Epoch time: 378.47 s
2023-09-04 11:29:17.021181: 
2023-09-04 11:29:17.023068: Epoch 204
2023-09-04 11:29:17.024813: Current learning rate: backbone 0.00035862, others 0.00035862
2023-09-04 11:29:17.026872: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 11:30:18.659832: finished training epoch 204
2023-09-04 11:30:18.698508: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 11:30:18.701386: The split file contains 1 splits.
2023-09-04 11:30:18.703125: Desired fold for training: 0
2023-09-04 11:30:18.704707: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 11:35:33.684426: dsc: 91.14%
2023-09-04 11:35:33.686573: miou: 83.72%
2023-09-04 11:35:33.688151: acc: 95.56%, sen: 90.86%, spe: 97.13%
2023-09-04 11:35:33.690158: current best miou: 0.8424533035516987 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 11:35:33.692173: current best dsc: 0.9144908062827978 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 11:35:33.694095: finished real validation
2023-09-04 11:35:38.053635: train_loss -1.4429
2023-09-04 11:35:38.055804: val_loss -1.0453
2023-09-04 11:35:38.057773: Pseudo dice [0.9132]
2023-09-04 11:35:38.059608: Epoch time: 381.03 s
2023-09-04 11:35:39.246248: 
2023-09-04 11:35:39.248215: Epoch 205
2023-09-04 11:35:39.250226: Current learning rate: backbone 0.00035526, others 0.00035526
2023-09-04 11:35:39.252709: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 11:36:40.859763: finished training epoch 205
2023-09-04 11:36:40.900464: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 11:36:40.903224: The split file contains 1 splits.
2023-09-04 11:36:40.904853: Desired fold for training: 0
2023-09-04 11:36:40.906445: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 11:41:56.446918: dsc: 91.30%
2023-09-04 11:41:56.449146: miou: 83.99%
2023-09-04 11:41:56.450842: acc: 95.63%, sen: 91.21%, spe: 97.11%
2023-09-04 11:41:56.452841: current best miou: 0.8424533035516987 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 11:41:56.454517: current best dsc: 0.9144908062827978 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 11:41:56.456204: finished real validation
2023-09-04 11:42:00.788967: train_loss -1.4429
2023-09-04 11:42:00.791414: val_loss -1.0575
2023-09-04 11:42:00.793542: Pseudo dice [0.9148]
2023-09-04 11:42:00.795457: Epoch time: 381.54 s
2023-09-04 11:42:01.923806: 
2023-09-04 11:42:01.925813: Epoch 206
2023-09-04 11:42:01.927535: Current learning rate: backbone 0.00035189, others 0.00035189
2023-09-04 11:42:01.929690: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 11:43:03.593341: finished training epoch 206
2023-09-04 11:43:03.633849: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 11:43:03.637157: The split file contains 1 splits.
2023-09-04 11:43:03.638829: Desired fold for training: 0
2023-09-04 11:43:03.640337: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 11:48:14.932603: dsc: 91.18%
2023-09-04 11:48:14.934741: miou: 83.79%
2023-09-04 11:48:14.936408: acc: 95.55%, sen: 91.39%, spe: 96.95%
2023-09-04 11:48:14.938721: current best miou: 0.8424533035516987 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 11:48:14.940385: current best dsc: 0.9144908062827978 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 11:48:14.941970: finished real validation
2023-09-04 11:48:19.299249: train_loss -1.4425
2023-09-04 11:48:19.301641: val_loss -1.0381
2023-09-04 11:48:19.303726: Pseudo dice [0.9128]
2023-09-04 11:48:19.305493: Epoch time: 377.38 s
2023-09-04 11:48:20.436463: 
2023-09-04 11:48:20.438601: Epoch 207
2023-09-04 11:48:20.440290: Current learning rate: backbone 0.00034852, others 0.00034852
2023-09-04 11:48:20.442494: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 11:49:22.063499: finished training epoch 207
2023-09-04 11:49:22.111317: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 11:49:22.113878: The split file contains 1 splits.
2023-09-04 11:49:22.115611: Desired fold for training: 0
2023-09-04 11:49:22.117298: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 11:54:49.347221: dsc: 91.07%
2023-09-04 11:54:49.349365: miou: 83.61%
2023-09-04 11:54:49.351013: acc: 95.52%, sen: 90.85%, spe: 97.09%
2023-09-04 11:54:49.353441: current best miou: 0.8424533035516987 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 11:54:49.356672: current best dsc: 0.9144908062827978 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 11:54:49.358291: finished real validation
2023-09-04 11:54:53.705972: train_loss -1.4427
2023-09-04 11:54:53.708112: val_loss -1.0203
2023-09-04 11:54:53.710129: Pseudo dice [0.9122]
2023-09-04 11:54:53.711959: Epoch time: 393.27 s
2023-09-04 11:54:54.837222: 
2023-09-04 11:54:54.839235: Epoch 208
2023-09-04 11:54:54.841307: Current learning rate: backbone 0.00034514, others 0.00034514
2023-09-04 11:54:54.843542: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 11:55:56.501973: finished training epoch 208
2023-09-04 11:55:56.538288: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 11:55:56.542302: The split file contains 1 splits.
2023-09-04 11:55:56.544502: Desired fold for training: 0
2023-09-04 11:55:56.546622: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 12:01:08.834989: dsc: 91.15%
2023-09-04 12:01:08.836974: miou: 83.74%
2023-09-04 12:01:08.838696: acc: 95.54%, sen: 91.28%, spe: 96.98%
2023-09-04 12:01:08.840728: current best miou: 0.8424533035516987 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 12:01:08.842444: current best dsc: 0.9144908062827978 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 12:01:08.844223: finished real validation
2023-09-04 12:01:13.165152: train_loss -1.4424
2023-09-04 12:01:13.167615: val_loss -1.0415
2023-09-04 12:01:13.169724: Pseudo dice [0.9137]
2023-09-04 12:01:13.171513: Epoch time: 378.33 s
2023-09-04 12:01:14.294987: 
2023-09-04 12:01:14.297048: Epoch 209
2023-09-04 12:01:14.298795: Current learning rate: backbone 0.00034177, others 0.00034177
2023-09-04 12:01:14.301020: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 12:02:15.854208: finished training epoch 209
2023-09-04 12:02:15.892649: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 12:02:15.895173: The split file contains 1 splits.
2023-09-04 12:02:15.896934: Desired fold for training: 0
2023-09-04 12:02:15.899141: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 12:07:35.150614: dsc: 91.24%
2023-09-04 12:07:35.152804: miou: 83.88%
2023-09-04 12:07:35.154583: acc: 95.60%, sen: 91.05%, spe: 97.13%
2023-09-04 12:07:35.156547: current best miou: 0.8424533035516987 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 12:07:35.158372: current best dsc: 0.9144908062827978 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 12:07:35.160113: finished real validation
2023-09-04 12:07:39.508909: train_loss -1.4437
2023-09-04 12:07:39.511210: val_loss -1.0201
2023-09-04 12:07:39.513341: Pseudo dice [0.91]
2023-09-04 12:07:39.515145: Epoch time: 385.22 s
2023-09-04 12:07:42.189327: 
2023-09-04 12:07:42.191382: Epoch 210
2023-09-04 12:07:42.193083: Current learning rate: backbone 0.00033838, others 0.00033838
2023-09-04 12:07:42.195149: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 12:08:44.124362: finished training epoch 210
2023-09-04 12:08:44.172132: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 12:08:44.174662: The split file contains 1 splits.
2023-09-04 12:08:44.176335: Desired fold for training: 0
2023-09-04 12:08:44.177990: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 12:13:59.329318: dsc: 91.34%
2023-09-04 12:13:59.335334: miou: 84.06%
2023-09-04 12:13:59.337054: acc: 95.66%, sen: 91.01%, spe: 97.22%
2023-09-04 12:13:59.338978: current best miou: 0.8424533035516987 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 12:13:59.340573: current best dsc: 0.9144908062827978 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 12:13:59.342153: finished real validation
2023-09-04 12:14:03.666969: train_loss -1.4428
2023-09-04 12:14:03.669323: val_loss -1.0433
2023-09-04 12:14:03.671312: Pseudo dice [0.9155]
2023-09-04 12:14:03.673175: Epoch time: 381.48 s
2023-09-04 12:14:04.801655: 
2023-09-04 12:14:04.803886: Epoch 211
2023-09-04 12:14:04.805869: Current learning rate: backbone 0.000335, others 0.000335
2023-09-04 12:14:04.808134: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 12:15:06.894394: finished training epoch 211
2023-09-04 12:15:06.932944: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 12:15:06.935755: The split file contains 1 splits.
2023-09-04 12:15:06.937514: Desired fold for training: 0
2023-09-04 12:15:06.939433: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 12:20:53.865403: dsc: 91.30%
2023-09-04 12:20:53.867791: miou: 83.99%
2023-09-04 12:20:53.869562: acc: 95.64%, sen: 90.94%, spe: 97.22%
2023-09-04 12:20:53.871901: current best miou: 0.8424533035516987 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 12:20:53.873624: current best dsc: 0.9144908062827978 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 12:20:53.875402: finished real validation
2023-09-04 12:20:58.309609: train_loss -1.4429
2023-09-04 12:20:58.312023: val_loss -1.0372
2023-09-04 12:20:58.314184: Pseudo dice [0.9131]
2023-09-04 12:20:58.316276: Epoch time: 413.51 s
2023-09-04 12:20:59.518337: 
2023-09-04 12:20:59.520586: Epoch 212
2023-09-04 12:20:59.522333: Current learning rate: backbone 0.00033161, others 0.00033161
2023-09-04 12:20:59.524564: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 12:22:02.094363: finished training epoch 212
2023-09-04 12:22:02.139443: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 12:22:02.142349: The split file contains 1 splits.
2023-09-04 12:22:02.144396: Desired fold for training: 0
2023-09-04 12:22:02.146404: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 12:27:22.188388: dsc: 91.27%
2023-09-04 12:27:22.190567: miou: 83.94%
2023-09-04 12:27:22.192313: acc: 95.62%, sen: 91.10%, spe: 97.13%
2023-09-04 12:27:22.194357: current best miou: 0.8424533035516987 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 12:27:22.195984: current best dsc: 0.9144908062827978 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 12:27:22.197541: finished real validation
2023-09-04 12:27:26.548578: train_loss -1.443
2023-09-04 12:27:26.550751: val_loss -1.0259
2023-09-04 12:27:26.552655: Pseudo dice [0.9114]
2023-09-04 12:27:26.554356: Epoch time: 387.03 s
2023-09-04 12:27:27.692110: 
2023-09-04 12:27:27.694485: Epoch 213
2023-09-04 12:27:27.696261: Current learning rate: backbone 0.00032821, others 0.00032821
2023-09-04 12:27:27.698552: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 12:28:30.149777: finished training epoch 213
2023-09-04 12:28:30.192223: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 12:28:30.195284: The split file contains 1 splits.
2023-09-04 12:28:30.197177: Desired fold for training: 0
2023-09-04 12:28:30.198923: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 12:33:46.222898: dsc: 91.15%
2023-09-04 12:33:46.224964: miou: 83.74%
2023-09-04 12:33:46.226604: acc: 95.55%, sen: 91.05%, spe: 97.07%
2023-09-04 12:33:46.228548: current best miou: 0.8424533035516987 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 12:33:46.230232: current best dsc: 0.9144908062827978 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 12:33:46.231842: finished real validation
2023-09-04 12:33:50.553862: train_loss -1.4429
2023-09-04 12:33:50.555994: val_loss -1.0553
2023-09-04 12:33:50.557973: Pseudo dice [0.9156]
2023-09-04 12:33:50.559768: Epoch time: 382.86 s
2023-09-04 12:33:51.743426: 
2023-09-04 12:33:51.745326: Epoch 214
2023-09-04 12:33:51.747058: Current learning rate: backbone 0.00032482, others 0.00032482
2023-09-04 12:33:51.749295: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 12:34:53.907555: finished training epoch 214
2023-09-04 12:34:53.943233: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 12:34:53.946300: The split file contains 1 splits.
2023-09-04 12:34:53.948180: Desired fold for training: 0
2023-09-04 12:34:53.949981: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 12:40:25.725762: dsc: 91.23%
2023-09-04 12:40:25.727891: miou: 83.87%
2023-09-04 12:40:25.729582: acc: 95.60%, sen: 90.85%, spe: 97.20%
2023-09-04 12:40:25.731543: current best miou: 0.8424533035516987 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 12:40:25.733234: current best dsc: 0.9144908062827978 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 12:40:25.734898: finished real validation
2023-09-04 12:40:30.130631: train_loss -1.4433
2023-09-04 12:40:30.133749: val_loss -1.0447
2023-09-04 12:40:30.136734: Pseudo dice [0.9128]
2023-09-04 12:40:30.139167: Epoch time: 398.39 s
2023-09-04 12:40:31.344783: 
2023-09-04 12:40:31.346840: Epoch 215
2023-09-04 12:40:31.348542: Current learning rate: backbone 0.00032142, others 0.00032142
2023-09-04 12:40:31.350676: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 12:41:33.232172: finished training epoch 215
2023-09-04 12:41:33.264176: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 12:41:33.266808: The split file contains 1 splits.
2023-09-04 12:41:33.268505: Desired fold for training: 0
2023-09-04 12:41:33.270193: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 12:46:44.601644: dsc: 91.19%
2023-09-04 12:46:44.603876: miou: 83.81%
2023-09-04 12:46:44.605631: acc: 95.56%, sen: 91.40%, spe: 96.96%
2023-09-04 12:46:44.607801: current best miou: 0.8424533035516987 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 12:46:44.609485: current best dsc: 0.9144908062827978 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 12:46:44.611121: finished real validation
2023-09-04 12:46:48.949877: train_loss -1.4423
2023-09-04 12:46:48.952349: val_loss -1.0304
2023-09-04 12:46:48.954722: Pseudo dice [0.9148]
2023-09-04 12:46:48.956766: Epoch time: 377.61 s
2023-09-04 12:46:50.135998: 
2023-09-04 12:46:50.138449: Epoch 216
2023-09-04 12:46:50.140370: Current learning rate: backbone 0.00031801, others 0.00031801
2023-09-04 12:46:50.142743: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 12:47:52.161826: finished training epoch 216
2023-09-04 12:47:52.197222: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 12:47:52.200282: The split file contains 1 splits.
2023-09-04 12:47:52.202105: Desired fold for training: 0
2023-09-04 12:47:52.203885: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 12:53:08.841240: dsc: 91.11%
2023-09-04 12:53:08.843105: miou: 83.67%
2023-09-04 12:53:08.844742: acc: 95.53%, sen: 91.13%, spe: 97.00%
2023-09-04 12:53:08.846642: current best miou: 0.8424533035516987 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 12:53:08.848265: current best dsc: 0.9144908062827978 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 12:53:08.849852: finished real validation
2023-09-04 12:53:13.247837: train_loss -1.4433
2023-09-04 12:53:13.250647: val_loss -1.0368
2023-09-04 12:53:13.252861: Pseudo dice [0.9146]
2023-09-04 12:53:13.254749: Epoch time: 383.11 s
2023-09-04 12:53:14.468051: 
2023-09-04 12:53:14.470510: Epoch 217
2023-09-04 12:53:14.472686: Current learning rate: backbone 0.0003146, others 0.0003146
2023-09-04 12:53:14.475672: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 12:54:16.182827: finished training epoch 217
2023-09-04 12:54:16.234809: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 12:54:16.237805: The split file contains 1 splits.
2023-09-04 12:54:16.239764: Desired fold for training: 0
2023-09-04 12:54:16.241631: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 12:59:32.526848: dsc: 91.19%
2023-09-04 12:59:32.528999: miou: 83.81%
2023-09-04 12:59:32.530731: acc: 95.58%, sen: 90.99%, spe: 97.12%
2023-09-04 12:59:32.532720: current best miou: 0.8424533035516987 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 12:59:32.534416: current best dsc: 0.9144908062827978 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 12:59:32.536018: finished real validation
2023-09-04 12:59:36.890097: train_loss -1.4432
2023-09-04 12:59:36.892919: val_loss -1.0555
2023-09-04 12:59:36.895660: Pseudo dice [0.9166]
2023-09-04 12:59:36.897939: Epoch time: 382.42 s
2023-09-04 12:59:38.054517: 
2023-09-04 12:59:38.056487: Epoch 218
2023-09-04 12:59:38.058732: Current learning rate: backbone 0.00031119, others 0.00031119
2023-09-04 12:59:38.061249: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 13:00:39.713349: finished training epoch 218
2023-09-04 13:00:39.766402: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 13:00:39.768930: The split file contains 1 splits.
2023-09-04 13:00:39.770752: Desired fold for training: 0
2023-09-04 13:00:39.775897: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 13:05:50.569516: dsc: 91.22%
2023-09-04 13:05:50.571538: miou: 83.86%
2023-09-04 13:05:50.573209: acc: 95.61%, sen: 90.79%, spe: 97.23%
2023-09-04 13:05:50.575186: current best miou: 0.8424533035516987 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 13:05:50.576869: current best dsc: 0.9144908062827978 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 13:05:50.578554: finished real validation
2023-09-04 13:05:54.928191: train_loss -1.443
2023-09-04 13:05:54.930424: val_loss -1.0359
2023-09-04 13:05:54.932485: Pseudo dice [0.9127]
2023-09-04 13:05:54.934275: Epoch time: 376.88 s
2023-09-04 13:05:56.105915: 
2023-09-04 13:05:56.107842: Epoch 219
2023-09-04 13:05:56.109580: Current learning rate: backbone 0.00030777, others 0.00030777
2023-09-04 13:05:56.111768: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 13:06:57.703378: finished training epoch 219
2023-09-04 13:06:57.741719: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 13:06:57.744950: The split file contains 1 splits.
2023-09-04 13:06:57.746888: Desired fold for training: 0
2023-09-04 13:06:57.748809: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 13:12:10.728089: dsc: 91.24%
2023-09-04 13:12:10.730264: miou: 83.90%
2023-09-04 13:12:10.732224: acc: 95.60%, sen: 91.23%, spe: 97.06%
2023-09-04 13:12:10.734348: current best miou: 0.8424533035516987 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 13:12:10.736134: current best dsc: 0.9144908062827978 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 13:12:10.737907: finished real validation
2023-09-04 13:12:15.144354: train_loss -1.4437
2023-09-04 13:12:15.146861: val_loss -1.0318
2023-09-04 13:12:15.149177: Pseudo dice [0.9135]
2023-09-04 13:12:15.151115: Epoch time: 379.04 s
2023-09-04 13:12:18.067903: 
2023-09-04 13:12:18.070070: Epoch 220
2023-09-04 13:12:18.072544: Current learning rate: backbone 0.00030435, others 0.00030435
2023-09-04 13:12:18.075083: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 13:13:20.012993: finished training epoch 220
2023-09-04 13:13:20.060596: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 13:13:20.065516: The split file contains 1 splits.
2023-09-04 13:13:20.069573: Desired fold for training: 0
2023-09-04 13:13:20.071284: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 13:18:28.758123: dsc: 91.24%
2023-09-04 13:18:28.760652: miou: 83.90%
2023-09-04 13:18:28.762443: acc: 95.60%, sen: 91.09%, spe: 97.12%
2023-09-04 13:18:28.764704: current best miou: 0.8424533035516987 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 13:18:28.766562: current best dsc: 0.9144908062827978 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 13:18:28.768800: finished real validation
2023-09-04 13:18:33.102445: train_loss -1.4434
2023-09-04 13:18:33.104488: val_loss -1.0294
2023-09-04 13:18:33.106557: Pseudo dice [0.915]
2023-09-04 13:18:33.108514: Epoch time: 375.04 s
2023-09-04 13:18:34.226569: 
2023-09-04 13:18:34.228524: Epoch 221
2023-09-04 13:18:34.230221: Current learning rate: backbone 0.00030092, others 0.00030092
2023-09-04 13:18:34.232338: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 13:19:35.829524: finished training epoch 221
2023-09-04 13:19:35.858118: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 13:19:35.860698: The split file contains 1 splits.
2023-09-04 13:19:35.862643: Desired fold for training: 0
2023-09-04 13:19:35.864376: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 13:24:49.910991: dsc: 91.25%
2023-09-04 13:24:49.913042: miou: 83.91%
2023-09-04 13:24:49.914713: acc: 95.60%, sen: 91.22%, spe: 97.08%
2023-09-04 13:24:49.916683: current best miou: 0.8424533035516987 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 13:24:49.918383: current best dsc: 0.9144908062827978 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 13:24:49.920004: finished real validation
2023-09-04 13:24:54.260073: train_loss -1.4438
2023-09-04 13:24:54.262229: val_loss -1.0772
2023-09-04 13:24:54.264250: Pseudo dice [0.9163]
2023-09-04 13:24:54.266340: Epoch time: 380.03 s
2023-09-04 13:24:54.268239: Yayy! New best EMA pseudo Dice: 0.9141
2023-09-04 13:24:56.954119: 
2023-09-04 13:24:56.956174: Epoch 222
2023-09-04 13:24:56.958014: Current learning rate: backbone 0.00029749, others 0.00029749
2023-09-04 13:24:56.960124: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 13:25:58.691123: finished training epoch 222
2023-09-04 13:25:58.750674: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 13:25:58.753449: The split file contains 1 splits.
2023-09-04 13:25:58.755295: Desired fold for training: 0
2023-09-04 13:25:58.757102: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 13:31:15.305683: dsc: 91.23%
2023-09-04 13:31:15.307846: miou: 83.87%
2023-09-04 13:31:15.309620: acc: 95.61%, sen: 90.74%, spe: 97.25%
2023-09-04 13:31:15.311644: current best miou: 0.8424533035516987 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 13:31:15.313370: current best dsc: 0.9144908062827978 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 13:31:15.315068: finished real validation
2023-09-04 13:31:19.622337: train_loss -1.4435
2023-09-04 13:31:19.624511: val_loss -1.0197
2023-09-04 13:31:19.626609: Pseudo dice [0.9137]
2023-09-04 13:31:19.628491: Epoch time: 382.67 s
2023-09-04 13:31:20.763552: 
2023-09-04 13:31:20.765597: Epoch 223
2023-09-04 13:31:20.767387: Current learning rate: backbone 0.00029406, others 0.00029406
2023-09-04 13:31:20.769516: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 13:32:22.952739: finished training epoch 223
2023-09-04 13:32:22.997037: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 13:32:22.999503: The split file contains 1 splits.
2023-09-04 13:32:23.001099: Desired fold for training: 0
2023-09-04 13:32:23.002879: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 13:37:38.753071: dsc: 91.11%
2023-09-04 13:37:38.755411: miou: 83.67%
2023-09-04 13:37:38.757231: acc: 95.52%, sen: 91.23%, spe: 96.97%
2023-09-04 13:37:38.759539: current best miou: 0.8424533035516987 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 13:37:38.761338: current best dsc: 0.9144908062827978 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 13:37:38.763028: finished real validation
2023-09-04 13:37:43.100931: train_loss -1.4436
2023-09-04 13:37:43.103367: val_loss -1.0337
2023-09-04 13:37:43.105359: Pseudo dice [0.9146]
2023-09-04 13:37:43.107147: Epoch time: 382.34 s
2023-09-04 13:37:43.108829: Yayy! New best EMA pseudo Dice: 0.9141
2023-09-04 13:37:45.811011: 
2023-09-04 13:37:45.813333: Epoch 224
2023-09-04 13:37:45.815308: Current learning rate: backbone 0.00029062, others 0.00029062
2023-09-04 13:37:45.817672: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 13:38:47.934568: finished training epoch 224
2023-09-04 13:38:47.968390: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 13:38:47.971561: The split file contains 1 splits.
2023-09-04 13:38:47.973484: Desired fold for training: 0
2023-09-04 13:38:47.975405: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 13:44:10.793772: dsc: 91.24%
2023-09-04 13:44:10.796118: miou: 83.90%
2023-09-04 13:44:10.798013: acc: 95.60%, sen: 91.11%, spe: 97.11%
2023-09-04 13:44:10.800210: current best miou: 0.8424533035516987 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 13:44:10.802239: current best dsc: 0.9144908062827978 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 13:44:10.803996: finished real validation
2023-09-04 13:44:15.170927: train_loss -1.4436
2023-09-04 13:44:15.173555: val_loss -1.0329
2023-09-04 13:44:15.175879: Pseudo dice [0.914]
2023-09-04 13:44:15.178083: Epoch time: 389.36 s
2023-09-04 13:44:16.333331: 
2023-09-04 13:44:16.336700: Epoch 225
2023-09-04 13:44:16.338792: Current learning rate: backbone 0.00028717, others 0.00028717
2023-09-04 13:44:16.343035: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 13:45:19.077192: finished training epoch 225
2023-09-04 13:45:19.107014: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 13:45:19.110147: The split file contains 1 splits.
2023-09-04 13:45:19.111984: Desired fold for training: 0
2023-09-04 13:45:19.113798: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 13:50:26.420046: dsc: 91.23%
2023-09-04 13:50:26.422099: miou: 83.87%
2023-09-04 13:50:26.423845: acc: 95.60%, sen: 91.02%, spe: 97.13%
2023-09-04 13:50:26.425936: current best miou: 0.8424533035516987 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 13:50:26.428741: current best dsc: 0.9144908062827978 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 13:50:26.431097: finished real validation
2023-09-04 13:50:30.780986: train_loss -1.4434
2023-09-04 13:50:30.783493: val_loss -1.0724
2023-09-04 13:50:30.785686: Pseudo dice [0.9172]
2023-09-04 13:50:30.787563: Epoch time: 374.45 s
2023-09-04 13:50:30.789316: Yayy! New best EMA pseudo Dice: 0.9144
2023-09-04 13:50:33.513603: 
2023-09-04 13:50:33.515785: Epoch 226
2023-09-04 13:50:33.517935: Current learning rate: backbone 0.00028373, others 0.00028373
2023-09-04 13:50:33.520302: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 13:51:35.336713: finished training epoch 226
2023-09-04 13:51:35.372977: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 13:51:35.376179: The split file contains 1 splits.
2023-09-04 13:51:35.378091: Desired fold for training: 0
2023-09-04 13:51:35.379956: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 13:56:52.667639: dsc: 91.11%
2023-09-04 13:56:52.669838: miou: 83.66%
2023-09-04 13:56:52.671962: acc: 95.53%, sen: 90.93%, spe: 97.08%
2023-09-04 13:56:52.674509: current best miou: 0.8424533035516987 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 13:56:52.676736: current best dsc: 0.9144908062827978 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 13:56:52.678293: finished real validation
2023-09-04 13:56:57.020511: train_loss -1.443
2023-09-04 13:56:57.022819: val_loss -1.0186
2023-09-04 13:56:57.025617: Pseudo dice [0.9119]
2023-09-04 13:56:57.027524: Epoch time: 383.51 s
2023-09-04 13:56:58.211433: 
2023-09-04 13:56:58.213718: Epoch 227
2023-09-04 13:56:58.215622: Current learning rate: backbone 0.00028027, others 0.00028027
2023-09-04 13:56:58.217870: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 13:57:59.790366: finished training epoch 227
2023-09-04 13:57:59.843818: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 13:57:59.846651: The split file contains 1 splits.
2023-09-04 13:57:59.848474: Desired fold for training: 0
2023-09-04 13:57:59.850193: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 14:03:29.137058: dsc: 91.17%
2023-09-04 14:03:29.139244: miou: 83.78%
2023-09-04 14:03:29.141018: acc: 95.57%, sen: 90.94%, spe: 97.13%
2023-09-04 14:03:29.143005: current best miou: 0.8424533035516987 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 14:03:29.144727: current best dsc: 0.9144908062827978 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 14:03:29.146383: finished real validation
2023-09-04 14:03:33.487360: train_loss -1.4433
2023-09-04 14:03:33.489533: val_loss -1.0504
2023-09-04 14:03:33.491554: Pseudo dice [0.9149]
2023-09-04 14:03:33.493384: Epoch time: 395.28 s
2023-09-04 14:03:34.691250: 
2023-09-04 14:03:34.693331: Epoch 228
2023-09-04 14:03:34.695329: Current learning rate: backbone 0.00027682, others 0.00027682
2023-09-04 14:03:34.697515: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 14:04:36.305225: finished training epoch 228
2023-09-04 14:04:36.350180: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 14:04:36.352986: The split file contains 1 splits.
2023-09-04 14:04:36.354971: Desired fold for training: 0
2023-09-04 14:04:36.356724: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 14:09:52.282054: dsc: 91.25%
2023-09-04 14:09:52.284161: miou: 83.90%
2023-09-04 14:09:52.285911: acc: 95.61%, sen: 91.04%, spe: 97.14%
2023-09-04 14:09:52.287938: current best miou: 0.8424533035516987 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 14:09:52.289649: current best dsc: 0.9144908062827978 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 14:09:52.291313: finished real validation
2023-09-04 14:09:56.632022: train_loss -1.444
2023-09-04 14:09:56.634264: val_loss -1.0486
2023-09-04 14:09:56.636292: Pseudo dice [0.9153]
2023-09-04 14:09:56.638326: Epoch time: 381.94 s
2023-09-04 14:09:57.761614: 
2023-09-04 14:09:57.763685: Epoch 229
2023-09-04 14:09:57.765954: Current learning rate: backbone 0.00027335, others 0.00027335
2023-09-04 14:09:57.768217: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 14:10:59.286171: finished training epoch 229
2023-09-04 14:10:59.328907: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 14:10:59.331937: The split file contains 1 splits.
2023-09-04 14:10:59.333807: Desired fold for training: 0
2023-09-04 14:10:59.335631: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 14:16:10.700176: dsc: 91.19%
2023-09-04 14:16:10.702536: miou: 83.80%
2023-09-04 14:16:10.704333: acc: 95.59%, sen: 90.69%, spe: 97.24%
2023-09-04 14:16:10.706931: current best miou: 0.8424533035516987 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 14:16:10.708925: current best dsc: 0.9144908062827978 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 14:16:10.710949: finished real validation
2023-09-04 14:16:15.057386: train_loss -1.4438
2023-09-04 14:16:15.059805: val_loss -1.0023
2023-09-04 14:16:15.061979: Pseudo dice [0.9087]
2023-09-04 14:16:15.063848: Epoch time: 377.3 s
2023-09-04 14:16:18.194559: 
2023-09-04 14:16:18.196704: Epoch 230
2023-09-04 14:16:18.198627: Current learning rate: backbone 0.00026989, others 0.00026989
2023-09-04 14:16:18.200870: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 14:17:19.787014: finished training epoch 230
2023-09-04 14:17:19.822179: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 14:17:19.825401: The split file contains 1 splits.
2023-09-04 14:17:19.828010: Desired fold for training: 0
2023-09-04 14:17:19.830361: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 14:22:39.373733: dsc: 91.26%
2023-09-04 14:22:39.416223: miou: 83.93%
2023-09-04 14:22:39.418830: acc: 95.61%, sen: 91.18%, spe: 97.10%
2023-09-04 14:22:39.422382: current best miou: 0.8424533035516987 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 14:22:39.424655: current best dsc: 0.9144908062827978 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 14:22:39.426856: finished real validation
2023-09-04 14:22:43.823878: train_loss -1.4442
2023-09-04 14:22:43.826154: val_loss -1.0152
2023-09-04 14:22:43.828275: Pseudo dice [0.9127]
2023-09-04 14:22:43.830683: Epoch time: 385.63 s
2023-09-04 14:22:45.358491: 
2023-09-04 14:22:45.360565: Epoch 231
2023-09-04 14:22:45.362456: Current learning rate: backbone 0.00026641, others 0.00026641
2023-09-04 14:22:45.364764: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 14:23:47.480215: finished training epoch 231
2023-09-04 14:23:47.580259: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 14:23:47.585666: The split file contains 1 splits.
2023-09-04 14:23:47.590330: Desired fold for training: 0
2023-09-04 14:23:47.595156: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 14:28:56.304417: dsc: 91.20%
2023-09-04 14:28:56.307039: miou: 83.82%
2023-09-04 14:28:56.308926: acc: 95.57%, sen: 91.24%, spe: 97.02%
2023-09-04 14:28:56.311088: current best miou: 0.8424533035516987 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 14:28:56.313938: current best dsc: 0.9144908062827978 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 14:28:56.316077: finished real validation
2023-09-04 14:29:00.667073: train_loss -1.4436
2023-09-04 14:29:00.669048: val_loss -0.9718
2023-09-04 14:29:00.676334: Pseudo dice [0.9058]
2023-09-04 14:29:00.680393: Epoch time: 375.31 s
2023-09-04 14:29:01.828719: 
2023-09-04 14:29:01.834586: Epoch 232
2023-09-04 14:29:01.837850: Current learning rate: backbone 0.00026294, others 0.00026294
2023-09-04 14:29:01.841225: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 14:30:03.476738: finished training epoch 232
2023-09-04 14:30:03.514872: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 14:30:03.517741: The split file contains 1 splits.
2023-09-04 14:30:03.519953: Desired fold for training: 0
2023-09-04 14:30:03.522013: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 14:35:27.222501: dsc: 91.26%
2023-09-04 14:35:27.248293: miou: 83.92%
2023-09-04 14:35:27.250405: acc: 95.61%, sen: 91.19%, spe: 97.09%
2023-09-04 14:35:27.253570: current best miou: 0.8424533035516987 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 14:35:27.255872: current best dsc: 0.9144908062827978 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 14:35:27.258382: finished real validation
2023-09-04 14:35:31.595267: train_loss -1.4442
2023-09-04 14:35:31.597595: val_loss -1.019
2023-09-04 14:35:31.599640: Pseudo dice [0.911]
2023-09-04 14:35:31.601463: Epoch time: 389.77 s
2023-09-04 14:35:32.731613: 
2023-09-04 14:35:32.733800: Epoch 233
2023-09-04 14:35:32.735476: Current learning rate: backbone 0.00025945, others 0.00025945
2023-09-04 14:35:32.737564: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 14:36:34.345300: finished training epoch 233
2023-09-04 14:36:34.401728: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 14:36:34.405645: The split file contains 1 splits.
2023-09-04 14:36:34.407342: Desired fold for training: 0
2023-09-04 14:36:34.410492: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 14:41:47.588477: dsc: 91.15%
2023-09-04 14:41:47.590893: miou: 83.74%
2023-09-04 14:41:47.592734: acc: 95.55%, sen: 91.02%, spe: 97.08%
2023-09-04 14:41:47.594988: current best miou: 0.8424533035516987 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 14:41:47.597264: current best dsc: 0.9144908062827978 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 14:41:47.599261: finished real validation
2023-09-04 14:41:51.949642: train_loss -1.4445
2023-09-04 14:41:51.951981: val_loss -1.0055
2023-09-04 14:41:51.954019: Pseudo dice [0.9086]
2023-09-04 14:41:51.955848: Epoch time: 379.22 s
2023-09-04 14:41:53.083752: 
2023-09-04 14:41:53.085976: Epoch 234
2023-09-04 14:41:53.087924: Current learning rate: backbone 0.00025596, others 0.00025596
2023-09-04 14:41:53.090204: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 14:42:54.959116: finished training epoch 234
2023-09-04 14:42:55.008496: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 14:42:55.015125: The split file contains 1 splits.
2023-09-04 14:42:55.021410: Desired fold for training: 0
2023-09-04 14:42:55.023552: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 14:48:17.314775: dsc: 91.23%
2023-09-04 14:48:17.317025: miou: 83.88%
2023-09-04 14:48:17.318866: acc: 95.59%, sen: 91.19%, spe: 97.07%
2023-09-04 14:48:17.320926: current best miou: 0.8424533035516987 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 14:48:17.322686: current best dsc: 0.9144908062827978 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 14:48:17.324457: finished real validation
2023-09-04 14:48:21.672344: train_loss -1.444
2023-09-04 14:48:21.674655: val_loss -1.048
2023-09-04 14:48:21.677344: Pseudo dice [0.9158]
2023-09-04 14:48:21.679435: Epoch time: 388.59 s
2023-09-04 14:48:22.821057: 
2023-09-04 14:48:22.823270: Epoch 235
2023-09-04 14:48:22.825189: Current learning rate: backbone 0.00025247, others 0.00025247
2023-09-04 14:48:22.827465: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 14:49:24.463707: finished training epoch 235
2023-09-04 14:49:24.507703: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 14:49:24.510453: The split file contains 1 splits.
2023-09-04 14:49:24.512311: Desired fold for training: 0
2023-09-04 14:49:24.514112: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 14:54:45.037614: dsc: 91.23%
2023-09-04 14:54:45.039977: miou: 83.87%
2023-09-04 14:54:45.041724: acc: 95.61%, sen: 90.86%, spe: 97.20%
2023-09-04 14:54:45.043752: current best miou: 0.8424533035516987 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 14:54:45.045533: current best dsc: 0.9144908062827978 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 14:54:45.047232: finished real validation
2023-09-04 14:54:49.392475: train_loss -1.4446
2023-09-04 14:54:49.394845: val_loss -1.023
2023-09-04 14:54:49.397033: Pseudo dice [0.9125]
2023-09-04 14:54:49.398843: Epoch time: 386.57 s
2023-09-04 14:54:50.524550: 
2023-09-04 14:54:50.526869: Epoch 236
2023-09-04 14:54:50.528765: Current learning rate: backbone 0.00024897, others 0.00024897
2023-09-04 14:54:50.530860: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 14:55:52.072052: finished training epoch 236
2023-09-04 14:55:52.112850: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 14:55:52.117158: The split file contains 1 splits.
2023-09-04 14:55:52.119691: Desired fold for training: 0
2023-09-04 14:55:52.121997: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 15:01:05.525454: dsc: 91.30%
2023-09-04 15:01:05.527763: miou: 83.99%
2023-09-04 15:01:05.529618: acc: 95.63%, sen: 91.07%, spe: 97.17%
2023-09-04 15:01:05.531649: current best miou: 0.8424533035516987 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 15:01:05.533451: current best dsc: 0.9144908062827978 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 15:01:05.535173: finished real validation
2023-09-04 15:01:09.879530: train_loss -1.4448
2023-09-04 15:01:09.881977: val_loss -1.0534
2023-09-04 15:01:09.884201: Pseudo dice [0.9159]
2023-09-04 15:01:09.886213: Epoch time: 379.36 s
2023-09-04 15:01:11.018346: 
2023-09-04 15:01:11.020603: Epoch 237
2023-09-04 15:01:11.022524: Current learning rate: backbone 0.00024547, others 0.00024547
2023-09-04 15:01:11.024710: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 15:02:12.758180: finished training epoch 237
2023-09-04 15:02:12.804938: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 15:02:12.807868: The split file contains 1 splits.
2023-09-04 15:02:12.809901: Desired fold for training: 0
2023-09-04 15:02:12.811801: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 15:07:25.844162: dsc: 91.23%
2023-09-04 15:07:25.846570: miou: 83.87%
2023-09-04 15:07:25.848640: acc: 95.60%, sen: 91.00%, spe: 97.14%
2023-09-04 15:07:25.850702: current best miou: 0.8424533035516987 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 15:07:25.852478: current best dsc: 0.9144908062827978 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 15:07:25.854273: finished real validation
2023-09-04 15:07:30.186524: train_loss -1.444
2023-09-04 15:07:30.188862: val_loss -1.0316
2023-09-04 15:07:30.190907: Pseudo dice [0.9131]
2023-09-04 15:07:30.192808: Epoch time: 379.17 s
2023-09-04 15:07:31.313052: 
2023-09-04 15:07:31.315770: Epoch 238
2023-09-04 15:07:31.317578: Current learning rate: backbone 0.00024196, others 0.00024196
2023-09-04 15:07:31.320406: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 15:08:32.980888: finished training epoch 238
2023-09-04 15:08:33.021822: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 15:08:33.024973: The split file contains 1 splits.
2023-09-04 15:08:33.026971: Desired fold for training: 0
2023-09-04 15:08:33.028999: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 15:13:46.704745: dsc: 91.27%
2023-09-04 15:13:46.707557: miou: 83.94%
2023-09-04 15:13:46.709572: acc: 95.61%, sen: 91.18%, spe: 97.10%
2023-09-04 15:13:46.711685: current best miou: 0.8424533035516987 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 15:13:46.713440: current best dsc: 0.9144908062827978 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 15:13:46.715114: finished real validation
2023-09-04 15:13:51.068922: train_loss -1.4442
2023-09-04 15:13:51.071323: val_loss -1.0489
2023-09-04 15:13:51.073488: Pseudo dice [0.9173]
2023-09-04 15:13:51.075654: Epoch time: 379.76 s
2023-09-04 15:13:52.218391: 
2023-09-04 15:13:52.220708: Epoch 239
2023-09-04 15:13:52.222615: Current learning rate: backbone 0.00023844, others 0.00023844
2023-09-04 15:13:52.224839: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 15:14:54.161031: finished training epoch 239
2023-09-04 15:14:54.193859: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 15:14:54.196752: The split file contains 1 splits.
2023-09-04 15:14:54.198736: Desired fold for training: 0
2023-09-04 15:14:54.200615: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 15:20:31.294380: dsc: 91.21%
2023-09-04 15:20:31.296575: miou: 83.84%
2023-09-04 15:20:31.298514: acc: 95.59%, sen: 91.02%, spe: 97.12%
2023-09-04 15:20:31.300961: current best miou: 0.8424533035516987 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 15:20:31.302605: current best dsc: 0.9144908062827978 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 15:20:31.304301: finished real validation
2023-09-04 15:20:35.637490: train_loss -1.444
2023-09-04 15:20:35.639952: val_loss -1.043
2023-09-04 15:20:35.642172: Pseudo dice [0.9146]
2023-09-04 15:20:35.644295: Epoch time: 403.42 s
2023-09-04 15:20:38.327785: 
2023-09-04 15:20:38.330047: Epoch 240
2023-09-04 15:20:38.331905: Current learning rate: backbone 0.00023492, others 0.00023492
2023-09-04 15:20:38.334125: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 15:21:40.162934: finished training epoch 240
2023-09-04 15:21:40.196404: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 15:21:40.199719: The split file contains 1 splits.
2023-09-04 15:21:40.201756: Desired fold for training: 0
2023-09-04 15:21:40.203690: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 15:26:56.464196: dsc: 91.21%
2023-09-04 15:26:56.466455: miou: 83.84%
2023-09-04 15:26:56.468254: acc: 95.58%, sen: 91.17%, spe: 97.06%
2023-09-04 15:26:56.470345: current best miou: 0.8424533035516987 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 15:26:56.472075: current best dsc: 0.9144908062827978 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 15:26:56.473820: finished real validation
2023-09-04 15:27:00.859404: train_loss -1.444
2023-09-04 15:27:00.861965: val_loss -1.0561
2023-09-04 15:27:00.864273: Pseudo dice [0.9167]
2023-09-04 15:27:00.866233: Epoch time: 382.53 s
2023-09-04 15:27:02.040207: 
2023-09-04 15:27:02.042715: Epoch 241
2023-09-04 15:27:02.044678: Current learning rate: backbone 0.0002314, others 0.0002314
2023-09-04 15:27:02.047258: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 15:28:03.574086: finished training epoch 241
2023-09-04 15:28:03.643155: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 15:28:03.654133: The split file contains 1 splits.
2023-09-04 15:28:03.656286: Desired fold for training: 0
2023-09-04 15:28:03.658143: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 15:33:18.607747: dsc: 91.15%
2023-09-04 15:33:18.609919: miou: 83.73%
2023-09-04 15:33:18.611736: acc: 95.54%, sen: 91.23%, spe: 96.99%
2023-09-04 15:33:18.613836: current best miou: 0.8424533035516987 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 15:33:18.616443: current best dsc: 0.9144908062827978 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 15:33:18.618525: finished real validation
2023-09-04 15:33:22.966219: train_loss -1.4445
2023-09-04 15:33:22.968457: val_loss -1.0146
2023-09-04 15:33:22.970432: Pseudo dice [0.912]
2023-09-04 15:33:22.972247: Epoch time: 380.93 s
2023-09-04 15:33:24.115698: 
2023-09-04 15:33:24.117741: Epoch 242
2023-09-04 15:33:24.119658: Current learning rate: backbone 0.00022786, others 0.00022786
2023-09-04 15:33:24.121789: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 15:34:25.660996: finished training epoch 242
2023-09-04 15:34:25.711308: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 15:34:25.713984: The split file contains 1 splits.
2023-09-04 15:34:25.715832: Desired fold for training: 0
2023-09-04 15:34:25.717575: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 15:39:39.453175: dsc: 91.26%
2023-09-04 15:39:39.455332: miou: 83.92%
2023-09-04 15:39:39.457104: acc: 95.61%, sen: 91.14%, spe: 97.11%
2023-09-04 15:39:39.459200: current best miou: 0.8424533035516987 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 15:39:39.461037: current best dsc: 0.9144908062827978 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 15:39:39.462792: finished real validation
2023-09-04 15:39:43.810682: train_loss -1.4443
2023-09-04 15:39:43.813049: val_loss -1.0258
2023-09-04 15:39:43.815099: Pseudo dice [0.9133]
2023-09-04 15:39:43.816938: Epoch time: 379.7 s
2023-09-04 15:39:44.968738: 
2023-09-04 15:39:44.971020: Epoch 243
2023-09-04 15:39:44.973151: Current learning rate: backbone 0.00022433, others 0.00022433
2023-09-04 15:39:44.975602: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 15:40:46.424858: finished training epoch 243
2023-09-04 15:40:46.476728: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 15:40:46.479359: The split file contains 1 splits.
2023-09-04 15:40:46.481238: Desired fold for training: 0
2023-09-04 15:40:46.483046: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 15:45:56.271988: dsc: 91.25%
2023-09-04 15:45:56.274255: miou: 83.91%
2023-09-04 15:45:56.276169: acc: 95.59%, sen: 91.43%, spe: 96.99%
2023-09-04 15:45:56.278328: current best miou: 0.8424533035516987 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 15:45:56.280238: current best dsc: 0.9144908062827978 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 15:45:56.282564: finished real validation
2023-09-04 15:46:00.642810: train_loss -1.4447
2023-09-04 15:46:00.645280: val_loss -1.0354
2023-09-04 15:46:00.647441: Pseudo dice [0.9149]
2023-09-04 15:46:00.649431: Epoch time: 375.68 s
2023-09-04 15:46:01.843945: 
2023-09-04 15:46:01.846421: Epoch 244
2023-09-04 15:46:01.848431: Current learning rate: backbone 0.00022078, others 0.00022078
2023-09-04 15:46:01.851190: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 15:47:03.404231: finished training epoch 244
2023-09-04 15:47:03.436698: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 15:47:03.439542: The split file contains 1 splits.
2023-09-04 15:47:03.441404: Desired fold for training: 0
2023-09-04 15:47:03.443319: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 15:52:34.620586: dsc: 91.19%
2023-09-04 15:52:34.622946: miou: 83.81%
2023-09-04 15:52:34.624816: acc: 95.56%, sen: 91.28%, spe: 97.00%
2023-09-04 15:52:34.626984: current best miou: 0.8424533035516987 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 15:52:34.628772: current best dsc: 0.9144908062827978 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 15:52:34.630590: finished real validation
2023-09-04 15:52:38.984808: train_loss -1.4446
2023-09-04 15:52:38.987299: val_loss -0.9806
2023-09-04 15:52:38.989584: Pseudo dice [0.9086]
2023-09-04 15:52:38.991453: Epoch time: 397.14 s
2023-09-04 15:52:40.139485: 
2023-09-04 15:52:40.141977: Epoch 245
2023-09-04 15:52:40.144075: Current learning rate: backbone 0.00021723, others 0.00021723
2023-09-04 15:52:40.146626: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 15:53:41.518516: finished training epoch 245
2023-09-04 15:53:41.565931: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 15:53:41.568674: The split file contains 1 splits.
2023-09-04 15:53:41.570649: Desired fold for training: 0
2023-09-04 15:53:41.572574: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 15:58:54.098822: dsc: 91.20%
2023-09-04 15:58:54.101400: miou: 83.83%
2023-09-04 15:58:54.103446: acc: 95.58%, sen: 91.12%, spe: 97.08%
2023-09-04 15:58:54.105817: current best miou: 0.8424533035516987 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 15:58:54.108255: current best dsc: 0.9144908062827978 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 15:58:54.110351: finished real validation
2023-09-04 15:58:58.453705: train_loss -1.445
2023-09-04 15:58:58.456488: val_loss -1.0226
2023-09-04 15:58:58.459110: Pseudo dice [0.9116]
2023-09-04 15:58:58.461487: Epoch time: 378.32 s
2023-09-04 15:58:59.608894: 
2023-09-04 15:58:59.611434: Epoch 246
2023-09-04 15:58:59.613675: Current learning rate: backbone 0.00021367, others 0.00021367
2023-09-04 15:58:59.616119: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 16:00:01.121245: finished training epoch 246
2023-09-04 16:00:01.194969: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 16:00:01.197862: The split file contains 1 splits.
2023-09-04 16:00:01.199761: Desired fold for training: 0
2023-09-04 16:00:01.201692: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 16:05:17.585650: dsc: 91.12%
2023-09-04 16:05:17.588139: miou: 83.68%
2023-09-04 16:05:17.590021: acc: 95.54%, sen: 90.93%, spe: 97.09%
2023-09-04 16:05:17.595553: current best miou: 0.8424533035516987 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 16:05:17.598010: current best dsc: 0.9144908062827978 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 16:05:17.600301: finished real validation
2023-09-04 16:05:21.945472: train_loss -1.4448
2023-09-04 16:05:21.947902: val_loss -1.0164
2023-09-04 16:05:21.950047: Pseudo dice [0.9132]
2023-09-04 16:05:21.952503: Epoch time: 382.34 s
2023-09-04 16:05:23.103334: 
2023-09-04 16:05:23.105591: Epoch 247
2023-09-04 16:05:23.107548: Current learning rate: backbone 0.00021011, others 0.00021011
2023-09-04 16:05:23.109864: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 16:06:24.585435: finished training epoch 247
2023-09-04 16:06:24.638275: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 16:06:24.641449: The split file contains 1 splits.
2023-09-04 16:06:24.643336: Desired fold for training: 0
2023-09-04 16:06:24.645133: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 16:11:35.766999: dsc: 91.20%
2023-09-04 16:11:35.769233: miou: 83.82%
2023-09-04 16:11:35.771039: acc: 95.59%, sen: 90.92%, spe: 97.16%
2023-09-04 16:11:35.773203: current best miou: 0.8424533035516987 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 16:11:35.775293: current best dsc: 0.9144908062827978 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 16:11:35.777342: finished real validation
2023-09-04 16:11:40.124355: train_loss -1.4445
2023-09-04 16:11:40.126965: val_loss -1.0278
2023-09-04 16:11:40.129235: Pseudo dice [0.9133]
2023-09-04 16:11:40.131289: Epoch time: 377.02 s
2023-09-04 16:11:41.287745: 
2023-09-04 16:11:41.289818: Epoch 248
2023-09-04 16:11:41.291698: Current learning rate: backbone 0.00020654, others 0.00020654
2023-09-04 16:11:41.293941: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 16:12:42.798719: finished training epoch 248
2023-09-04 16:12:42.834875: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 16:12:42.837947: The split file contains 1 splits.
2023-09-04 16:12:42.839869: Desired fold for training: 0
2023-09-04 16:12:42.841762: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 16:17:58.792946: dsc: 91.18%
2023-09-04 16:17:58.795174: miou: 83.79%
2023-09-04 16:17:58.797018: acc: 95.58%, sen: 90.95%, spe: 97.13%
2023-09-04 16:17:58.799177: current best miou: 0.8424533035516987 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 16:17:58.801026: current best dsc: 0.9144908062827978 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 16:17:58.802747: finished real validation
2023-09-04 16:18:03.151394: train_loss -1.4448
2023-09-04 16:18:03.154299: val_loss -1.0518
2023-09-04 16:18:03.157217: Pseudo dice [0.9158]
2023-09-04 16:18:03.159699: Epoch time: 381.87 s
2023-09-04 16:18:04.312553: 
2023-09-04 16:18:04.314828: Epoch 249
2023-09-04 16:18:04.316937: Current learning rate: backbone 0.00020296, others 0.00020296
2023-09-04 16:18:04.319494: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 16:19:05.774889: finished training epoch 249
2023-09-04 16:19:05.813171: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 16:19:05.816011: The split file contains 1 splits.
2023-09-04 16:19:05.817932: Desired fold for training: 0
2023-09-04 16:19:05.819818: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 16:24:20.096670: dsc: 91.21%
2023-09-04 16:24:20.098984: miou: 83.84%
2023-09-04 16:24:20.100824: acc: 95.59%, sen: 90.98%, spe: 97.14%
2023-09-04 16:24:20.102985: current best miou: 0.8424533035516987 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 16:24:20.104832: current best dsc: 0.9144908062827978 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 16:24:20.106857: finished real validation
2023-09-04 16:24:24.443792: train_loss -1.4451
2023-09-04 16:24:24.446482: val_loss -0.9684
2023-09-04 16:24:24.448659: Pseudo dice [0.9066]
2023-09-04 16:24:24.450524: Epoch time: 380.13 s
2023-09-04 16:24:27.165249: 
2023-09-04 16:24:27.167740: Epoch 250
2023-09-04 16:24:27.169679: Current learning rate: backbone 0.00019937, others 0.00019937
2023-09-04 16:24:27.172056: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 16:25:28.635753: finished training epoch 250
2023-09-04 16:25:28.670446: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 16:25:28.673624: The split file contains 1 splits.
2023-09-04 16:25:28.675771: Desired fold for training: 0
2023-09-04 16:25:28.677762: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 16:31:04.353331: dsc: 91.18%
2023-09-04 16:31:04.356039: miou: 83.78%
2023-09-04 16:31:04.358418: acc: 95.56%, sen: 91.13%, spe: 97.05%
2023-09-04 16:31:04.361511: current best miou: 0.8424533035516987 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 16:31:04.363660: current best dsc: 0.9144908062827978 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 16:31:04.366405: finished real validation
2023-09-04 16:31:08.738128: train_loss -1.445
2023-09-04 16:31:08.740625: val_loss -1.0088
2023-09-04 16:31:08.742837: Pseudo dice [0.9132]
2023-09-04 16:31:08.745507: Epoch time: 401.58 s
2023-09-04 16:31:09.915711: 
2023-09-04 16:31:09.918688: Epoch 251
2023-09-04 16:31:09.921222: Current learning rate: backbone 0.00019578, others 0.00019578
2023-09-04 16:31:09.924191: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 16:32:11.505163: finished training epoch 251
2023-09-04 16:32:11.549809: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 16:32:11.553070: The split file contains 1 splits.
2023-09-04 16:32:11.555036: Desired fold for training: 0
2023-09-04 16:32:11.556933: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 16:37:27.409822: dsc: 91.18%
2023-09-04 16:37:27.412131: miou: 83.79%
2023-09-04 16:37:27.414166: acc: 95.56%, sen: 91.18%, spe: 97.04%
2023-09-04 16:37:27.416613: current best miou: 0.8424533035516987 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 16:37:27.418428: current best dsc: 0.9144908062827978 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 16:37:27.420228: finished real validation
2023-09-04 16:37:31.835315: train_loss -1.4448
2023-09-04 16:37:31.837969: val_loss -1.0193
2023-09-04 16:37:31.840307: Pseudo dice [0.914]
2023-09-04 16:37:31.842394: Epoch time: 381.92 s
2023-09-04 16:37:32.990377: 
2023-09-04 16:37:32.992557: Epoch 252
2023-09-04 16:37:32.994936: Current learning rate: backbone 0.00019218, others 0.00019218
2023-09-04 16:37:32.998086: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 16:38:34.888468: finished training epoch 252
2023-09-04 16:38:34.918498: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 16:38:34.921133: The split file contains 1 splits.
2023-09-04 16:38:34.923046: Desired fold for training: 0
2023-09-04 16:38:34.924871: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 16:44:42.063218: dsc: 91.23%
2023-09-04 16:44:42.065599: miou: 83.88%
2023-09-04 16:44:42.067610: acc: 95.59%, sen: 91.33%, spe: 97.02%
2023-09-04 16:44:42.069992: current best miou: 0.8424533035516987 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 16:44:42.072216: current best dsc: 0.9144908062827978 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 16:44:42.074085: finished real validation
2023-09-04 16:44:46.420025: train_loss -1.4451
2023-09-04 16:44:46.422579: val_loss -0.9999
2023-09-04 16:44:46.424807: Pseudo dice [0.9101]
2023-09-04 16:44:46.426773: Epoch time: 433.43 s
2023-09-04 16:44:47.644247: 
2023-09-04 16:44:47.646719: Epoch 253
2023-09-04 16:44:47.648942: Current learning rate: backbone 0.00018857, others 0.00018857
2023-09-04 16:44:47.651372: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 16:45:48.991540: finished training epoch 253
2023-09-04 16:45:49.073316: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 16:45:49.077469: The split file contains 1 splits.
2023-09-04 16:45:49.080098: Desired fold for training: 0
2023-09-04 16:45:49.082514: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 16:51:09.215085: dsc: 91.15%
2023-09-04 16:51:09.217252: miou: 83.74%
2023-09-04 16:51:09.219163: acc: 95.56%, sen: 90.89%, spe: 97.13%
2023-09-04 16:51:09.221273: current best miou: 0.8424533035516987 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 16:51:09.223176: current best dsc: 0.9144908062827978 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 16:51:09.225021: finished real validation
2023-09-04 16:51:13.590985: train_loss -1.4451
2023-09-04 16:51:13.593797: val_loss -1.0209
2023-09-04 16:51:13.596366: Pseudo dice [0.9133]
2023-09-04 16:51:13.598366: Epoch time: 385.95 s
2023-09-04 16:51:14.741763: 
2023-09-04 16:51:14.743795: Epoch 254
2023-09-04 16:51:14.745625: Current learning rate: backbone 0.00018496, others 0.00018496
2023-09-04 16:51:14.747925: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 16:52:16.085418: finished training epoch 254
2023-09-04 16:52:16.121435: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 16:52:16.124173: The split file contains 1 splits.
2023-09-04 16:52:16.126124: Desired fold for training: 0
2023-09-04 16:52:16.127995: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 16:57:30.920075: dsc: 91.22%
2023-09-04 16:57:30.922425: miou: 83.87%
2023-09-04 16:57:30.924290: acc: 95.57%, sen: 91.57%, spe: 96.91%
2023-09-04 16:57:30.926542: current best miou: 0.8424533035516987 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 16:57:30.928432: current best dsc: 0.9144908062827978 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 16:57:30.930208: finished real validation
2023-09-04 16:57:35.277560: train_loss -1.4447
2023-09-04 16:57:35.280379: val_loss -1.034
2023-09-04 16:57:35.282922: Pseudo dice [0.9152]
2023-09-04 16:57:35.285070: Epoch time: 380.54 s
2023-09-04 16:57:36.434081: 
2023-09-04 16:57:36.436558: Epoch 255
2023-09-04 16:57:36.438529: Current learning rate: backbone 0.00018134, others 0.00018134
2023-09-04 16:57:36.440914: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 16:58:37.891603: finished training epoch 255
2023-09-04 16:58:37.935349: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 16:58:37.938238: The split file contains 1 splits.
2023-09-04 16:58:37.940168: Desired fold for training: 0
2023-09-04 16:58:37.942022: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 17:03:55.941562: dsc: 91.08%
2023-09-04 17:03:55.944195: miou: 83.62%
2023-09-04 17:03:55.946097: acc: 95.51%, sen: 91.05%, spe: 97.02%
2023-09-04 17:03:55.948552: current best miou: 0.8424533035516987 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 17:03:55.950444: current best dsc: 0.9144908062827978 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 17:03:55.952248: finished real validation
2023-09-04 17:04:00.296960: train_loss -1.4447
2023-09-04 17:04:00.299495: val_loss -0.9951
2023-09-04 17:04:00.301752: Pseudo dice [0.9107]
2023-09-04 17:04:00.303692: Epoch time: 383.86 s
2023-09-04 17:04:01.480445: 
2023-09-04 17:04:01.482979: Epoch 256
2023-09-04 17:04:01.485143: Current learning rate: backbone 0.0001777, others 0.0001777
2023-09-04 17:04:01.487714: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 17:05:03.168336: finished training epoch 256
2023-09-04 17:05:03.199270: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 17:05:03.202317: The split file contains 1 splits.
2023-09-04 17:05:03.204339: Desired fold for training: 0
2023-09-04 17:05:03.206226: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 17:10:32.387804: dsc: 91.29%
2023-09-04 17:10:32.390485: miou: 83.98%
2023-09-04 17:10:32.392512: acc: 95.61%, sen: 91.55%, spe: 96.97%
2023-09-04 17:10:32.394829: current best miou: 0.8424533035516987 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 17:10:32.396991: current best dsc: 0.9144908062827978 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 17:10:32.399012: finished real validation
2023-09-04 17:10:36.780625: train_loss -1.4456
2023-09-04 17:10:36.783194: val_loss -1.0347
2023-09-04 17:10:36.785515: Pseudo dice [0.9156]
2023-09-04 17:10:36.787483: Epoch time: 395.3 s
2023-09-04 17:10:37.940882: 
2023-09-04 17:10:37.943218: Epoch 257
2023-09-04 17:10:37.945169: Current learning rate: backbone 0.00017407, others 0.00017407
2023-09-04 17:10:37.947558: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 17:11:39.697315: finished training epoch 257
2023-09-04 17:11:39.728628: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 17:11:39.733572: The split file contains 1 splits.
2023-09-04 17:11:39.736176: Desired fold for training: 0
2023-09-04 17:11:39.738647: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 17:16:52.280640: dsc: 91.20%
2023-09-04 17:16:52.283027: miou: 83.82%
2023-09-04 17:16:52.284977: acc: 95.58%, sen: 91.01%, spe: 97.12%
2023-09-04 17:16:52.287605: current best miou: 0.8424533035516987 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 17:16:52.289620: current best dsc: 0.9144908062827978 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 17:16:52.291691: finished real validation
2023-09-04 17:16:56.674773: train_loss -1.4454
2023-09-04 17:16:56.677360: val_loss -1.0175
2023-09-04 17:16:56.679948: Pseudo dice [0.9116]
2023-09-04 17:16:56.682084: Epoch time: 378.74 s
2023-09-04 17:16:57.827963: 
2023-09-04 17:16:57.830378: Epoch 258
2023-09-04 17:16:57.832705: Current learning rate: backbone 0.00017042, others 0.00017042
2023-09-04 17:16:57.835481: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 17:17:59.372366: finished training epoch 258
2023-09-04 17:17:59.412853: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 17:17:59.415839: The split file contains 1 splits.
2023-09-04 17:17:59.417835: Desired fold for training: 0
2023-09-04 17:17:59.419785: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 17:23:11.249834: dsc: 91.09%
2023-09-04 17:23:11.252344: miou: 83.63%
2023-09-04 17:23:11.254354: acc: 95.54%, sen: 90.66%, spe: 97.18%
2023-09-04 17:23:11.256608: current best miou: 0.8424533035516987 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 17:23:11.258555: current best dsc: 0.9144908062827978 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 17:23:11.260552: finished real validation
2023-09-04 17:23:15.619427: train_loss -1.4449
2023-09-04 17:23:15.621887: val_loss -1.0245
2023-09-04 17:23:15.624078: Pseudo dice [0.9129]
2023-09-04 17:23:15.626072: Epoch time: 377.79 s
2023-09-04 17:23:16.773636: 
2023-09-04 17:23:16.775837: Epoch 259
2023-09-04 17:23:16.777858: Current learning rate: backbone 0.00016676, others 0.00016676
2023-09-04 17:23:16.780123: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 17:24:18.488183: finished training epoch 259
2023-09-04 17:24:18.524578: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 17:24:18.528210: The split file contains 1 splits.
2023-09-04 17:24:18.530420: Desired fold for training: 0
2023-09-04 17:24:18.532533: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 17:29:37.691466: dsc: 91.17%
2023-09-04 17:29:37.694102: miou: 83.77%
2023-09-04 17:29:37.696066: acc: 95.58%, sen: 90.83%, spe: 97.17%
2023-09-04 17:29:37.698325: current best miou: 0.8424533035516987 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 17:29:37.700210: current best dsc: 0.9144908062827978 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 17:29:37.702020: finished real validation
2023-09-04 17:29:42.070507: train_loss -1.4456
2023-09-04 17:29:42.073116: val_loss -1.0316
2023-09-04 17:29:42.075463: Pseudo dice [0.9141]
2023-09-04 17:29:42.077629: Epoch time: 385.3 s
2023-09-04 17:29:44.770719: 
2023-09-04 17:29:44.772827: Epoch 260
2023-09-04 17:29:44.774752: Current learning rate: backbone 0.0001631, others 0.0001631
2023-09-04 17:29:44.777006: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 17:30:46.446520: finished training epoch 260
2023-09-04 17:30:46.489570: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 17:30:46.492531: The split file contains 1 splits.
2023-09-04 17:30:46.494495: Desired fold for training: 0
2023-09-04 17:30:46.496406: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 17:36:04.204944: dsc: 91.07%
2023-09-04 17:36:04.210514: miou: 83.60%
2023-09-04 17:36:04.212639: acc: 95.51%, sen: 90.90%, spe: 97.07%
2023-09-04 17:36:04.214964: current best miou: 0.8424533035516987 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 17:36:04.216925: current best dsc: 0.9144908062827978 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 17:36:04.218888: finished real validation
2023-09-04 17:36:08.580286: train_loss -1.4449
2023-09-04 17:36:08.582958: val_loss -0.9981
2023-09-04 17:36:08.585283: Pseudo dice [0.9098]
2023-09-04 17:36:08.587490: Epoch time: 383.81 s
2023-09-04 17:36:09.737467: 
2023-09-04 17:36:09.739666: Epoch 261
2023-09-04 17:36:09.741736: Current learning rate: backbone 0.00015942, others 0.00015942
2023-09-04 17:36:09.744818: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 17:37:11.307219: finished training epoch 261
2023-09-04 17:37:11.365357: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 17:37:11.368628: The split file contains 1 splits.
2023-09-04 17:37:11.370678: Desired fold for training: 0
2023-09-04 17:37:11.372607: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 17:42:31.727589: dsc: 91.13%
2023-09-04 17:42:31.730092: miou: 83.70%
2023-09-04 17:42:31.732283: acc: 95.54%, sen: 91.08%, spe: 97.04%
2023-09-04 17:42:31.735459: current best miou: 0.8424533035516987 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 17:42:31.737739: current best dsc: 0.9144908062827978 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 17:42:31.739867: finished real validation
2023-09-04 17:42:36.074287: train_loss -1.4451
2023-09-04 17:42:36.076883: val_loss -1.0409
2023-09-04 17:42:36.079170: Pseudo dice [0.9149]
2023-09-04 17:42:36.081328: Epoch time: 386.34 s
2023-09-04 17:42:37.230380: 
2023-09-04 17:42:37.232516: Epoch 262
2023-09-04 17:42:37.234565: Current learning rate: backbone 0.00015574, others 0.00015574
2023-09-04 17:42:37.236866: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 17:43:38.636536: finished training epoch 262
2023-09-04 17:43:38.681259: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 17:43:38.684287: The split file contains 1 splits.
2023-09-04 17:43:38.686390: Desired fold for training: 0
2023-09-04 17:43:38.688504: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 17:48:55.820879: dsc: 91.25%
2023-09-04 17:48:55.823380: miou: 83.90%
2023-09-04 17:48:55.825312: acc: 95.60%, sen: 91.20%, spe: 97.08%
2023-09-04 17:48:55.827673: current best miou: 0.8424533035516987 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 17:48:55.829596: current best dsc: 0.9144908062827978 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 17:48:55.831458: finished real validation
2023-09-04 17:49:00.177836: train_loss -1.4448
2023-09-04 17:49:00.180305: val_loss -1.0102
2023-09-04 17:49:00.182570: Pseudo dice [0.9126]
2023-09-04 17:49:00.185612: Epoch time: 382.95 s
2023-09-04 17:49:01.333685: 
2023-09-04 17:49:01.335854: Epoch 263
2023-09-04 17:49:01.337821: Current learning rate: backbone 0.00015205, others 0.00015205
2023-09-04 17:49:01.340402: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 17:50:02.728423: finished training epoch 263
2023-09-04 17:50:02.758943: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 17:50:02.762569: The split file contains 1 splits.
2023-09-04 17:50:02.764541: Desired fold for training: 0
2023-09-04 17:50:02.766373: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 17:55:14.152546: dsc: 91.14%
2023-09-04 17:55:14.155102: miou: 83.72%
2023-09-04 17:55:14.157404: acc: 95.56%, sen: 90.89%, spe: 97.13%
2023-09-04 17:55:14.160633: current best miou: 0.8424533035516987 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 17:55:14.163419: current best dsc: 0.9144908062827978 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 17:55:14.166102: finished real validation
2023-09-04 17:55:18.492874: train_loss -1.4452
2023-09-04 17:55:18.495620: val_loss -1.0257
2023-09-04 17:55:18.498415: Pseudo dice [0.9138]
2023-09-04 17:55:18.500808: Epoch time: 377.16 s
2023-09-04 17:55:19.661685: 
2023-09-04 17:55:19.664077: Epoch 264
2023-09-04 17:55:19.666041: Current learning rate: backbone 0.00014834, others 0.00014834
2023-09-04 17:55:19.668428: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 17:56:21.277486: finished training epoch 264
2023-09-04 17:56:21.308910: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 17:56:21.311966: The split file contains 1 splits.
2023-09-04 17:56:21.313942: Desired fold for training: 0
2023-09-04 17:56:21.315896: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 18:01:41.712631: dsc: 91.20%
2023-09-04 18:01:41.715657: miou: 83.82%
2023-09-04 18:01:41.719021: acc: 95.58%, sen: 90.97%, spe: 97.13%
2023-09-04 18:01:41.721565: current best miou: 0.8424533035516987 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 18:01:41.723706: current best dsc: 0.9144908062827978 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 18:01:41.725586: finished real validation
2023-09-04 18:01:46.065814: train_loss -1.4455
2023-09-04 18:01:46.067960: val_loss -1.0351
2023-09-04 18:01:46.070033: Pseudo dice [0.914]
2023-09-04 18:01:46.071924: Epoch time: 386.41 s
2023-09-04 18:01:47.206666: 
2023-09-04 18:01:47.209192: Epoch 265
2023-09-04 18:01:47.211376: Current learning rate: backbone 0.00014463, others 0.00014463
2023-09-04 18:01:47.213865: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 18:02:48.681890: finished training epoch 265
2023-09-04 18:02:48.752624: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 18:02:48.755435: The split file contains 1 splits.
2023-09-04 18:02:48.757470: Desired fold for training: 0
2023-09-04 18:02:48.759446: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 18:08:06.791853: dsc: 91.10%
2023-09-04 18:08:06.794493: miou: 83.66%
2023-09-04 18:08:06.796508: acc: 95.53%, sen: 90.97%, spe: 97.06%
2023-09-04 18:08:06.798845: current best miou: 0.8424533035516987 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 18:08:06.800771: current best dsc: 0.9144908062827978 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 18:08:06.802602: finished real validation
2023-09-04 18:08:11.145000: train_loss -1.4454
2023-09-04 18:08:11.147905: val_loss -1.0227
2023-09-04 18:08:11.150514: Pseudo dice [0.9148]
2023-09-04 18:08:11.153106: Epoch time: 383.94 s
2023-09-04 18:08:12.301814: 
2023-09-04 18:08:12.304208: Epoch 266
2023-09-04 18:08:12.306185: Current learning rate: backbone 0.0001409, others 0.0001409
2023-09-04 18:08:12.308614: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 18:09:14.033078: finished training epoch 266
2023-09-04 18:09:14.084815: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 18:09:14.087523: The split file contains 1 splits.
2023-09-04 18:09:14.089568: Desired fold for training: 0
2023-09-04 18:09:14.091482: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 18:14:25.450350: dsc: 91.12%
2023-09-04 18:14:25.452728: miou: 83.68%
2023-09-04 18:14:25.455344: acc: 95.54%, sen: 90.85%, spe: 97.12%
2023-09-04 18:14:25.457607: current best miou: 0.8424533035516987 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 18:14:25.459479: current best dsc: 0.9144908062827978 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 18:14:25.461832: finished real validation
2023-09-04 18:14:29.807031: train_loss -1.4455
2023-09-04 18:14:29.810191: val_loss -1.0187
2023-09-04 18:14:29.813239: Pseudo dice [0.9119]
2023-09-04 18:14:29.815912: Epoch time: 377.51 s
2023-09-04 18:14:30.950974: 
2023-09-04 18:14:30.953607: Epoch 267
2023-09-04 18:14:30.955796: Current learning rate: backbone 0.00013717, others 0.00013717
2023-09-04 18:14:30.958349: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 18:15:32.552055: finished training epoch 267
2023-09-04 18:15:32.591732: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 18:15:32.594575: The split file contains 1 splits.
2023-09-04 18:15:32.596590: Desired fold for training: 0
2023-09-04 18:15:32.598604: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 18:20:45.850519: dsc: 91.16%
2023-09-04 18:20:45.853385: miou: 83.75%
2023-09-04 18:20:45.855834: acc: 95.56%, sen: 90.98%, spe: 97.10%
2023-09-04 18:20:45.858423: current best miou: 0.8424533035516987 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 18:20:45.860415: current best dsc: 0.9144908062827978 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 18:20:45.862540: finished real validation
2023-09-04 18:20:50.200643: train_loss -1.4453
2023-09-04 18:20:50.203218: val_loss -1.0009
2023-09-04 18:20:50.205445: Pseudo dice [0.9122]
2023-09-04 18:20:50.207776: Epoch time: 379.25 s
2023-09-04 18:20:51.348325: 
2023-09-04 18:20:51.350922: Epoch 268
2023-09-04 18:20:51.353180: Current learning rate: backbone 0.00013342, others 0.00013342
2023-09-04 18:20:51.355771: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 18:21:52.802555: finished training epoch 268
2023-09-04 18:21:52.834822: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 18:21:52.838967: The split file contains 1 splits.
2023-09-04 18:21:52.841506: Desired fold for training: 0
2023-09-04 18:21:52.843900: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 18:27:13.247860: dsc: 91.13%
2023-09-04 18:27:13.250268: miou: 83.70%
2023-09-04 18:27:13.252248: acc: 95.55%, sen: 90.88%, spe: 97.12%
2023-09-04 18:27:13.254556: current best miou: 0.8424533035516987 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 18:27:13.256516: current best dsc: 0.9144908062827978 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 18:27:13.258433: finished real validation
2023-09-04 18:27:17.620607: train_loss -1.4459
2023-09-04 18:27:17.623107: val_loss -0.9728
2023-09-04 18:27:17.625269: Pseudo dice [0.9077]
2023-09-04 18:27:17.627313: Epoch time: 386.27 s
2023-09-04 18:27:18.762085: 
2023-09-04 18:27:18.764347: Epoch 269
2023-09-04 18:27:18.766456: Current learning rate: backbone 0.00012966, others 0.00012966
2023-09-04 18:27:18.768784: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 18:28:20.228318: finished training epoch 269
2023-09-04 18:28:20.261094: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 18:28:20.265132: The split file contains 1 splits.
2023-09-04 18:28:20.267469: Desired fold for training: 0
2023-09-04 18:28:20.270334: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 18:33:45.608480: dsc: 91.17%
2023-09-04 18:33:45.611504: miou: 83.77%
2023-09-04 18:33:45.613582: acc: 95.57%, sen: 90.80%, spe: 97.18%
2023-09-04 18:33:45.616074: current best miou: 0.8424533035516987 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 18:33:45.618080: current best dsc: 0.9144908062827978 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 18:33:45.620024: finished real validation
2023-09-04 18:33:49.975174: train_loss -1.4455
2023-09-04 18:33:49.977857: val_loss -1.0287
2023-09-04 18:33:49.980282: Pseudo dice [0.9124]
2023-09-04 18:33:49.982533: Epoch time: 391.21 s
2023-09-04 18:33:52.675553: 
2023-09-04 18:33:52.678123: Epoch 270
2023-09-04 18:33:52.680155: Current learning rate: backbone 0.00012589, others 0.00012589
2023-09-04 18:33:52.682564: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 18:34:54.055829: finished training epoch 270
2023-09-04 18:35:00.847108: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 18:35:00.850170: The split file contains 1 splits.
2023-09-04 18:35:00.852267: Desired fold for training: 0
2023-09-04 18:35:00.854326: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 18:40:16.322811: dsc: 91.21%
2023-09-04 18:40:16.325341: miou: 83.84%
2023-09-04 18:40:16.327363: acc: 95.59%, sen: 91.05%, spe: 97.11%
2023-09-04 18:40:16.329716: current best miou: 0.8424533035516987 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 18:40:16.331883: current best dsc: 0.9144908062827978 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 18:40:16.333817: finished real validation
2023-09-04 18:40:20.667141: train_loss -1.4456
2023-09-04 18:40:20.669578: val_loss -0.9992
2023-09-04 18:40:20.671858: Pseudo dice [0.9082]
2023-09-04 18:40:20.673970: Epoch time: 387.99 s
2023-09-04 18:40:21.807081: 
2023-09-04 18:40:21.809476: Epoch 271
2023-09-04 18:40:21.811538: Current learning rate: backbone 0.00012211, others 0.00012211
2023-09-04 18:40:21.813882: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 18:41:23.344393: finished training epoch 271
2023-09-04 18:41:23.387453: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 18:41:23.390322: The split file contains 1 splits.
2023-09-04 18:41:23.392457: Desired fold for training: 0
2023-09-04 18:41:23.394612: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 18:46:36.593621: dsc: 91.11%
2023-09-04 18:46:36.596066: miou: 83.67%
2023-09-04 18:46:36.598104: acc: 95.54%, sen: 90.85%, spe: 97.11%
2023-09-04 18:46:36.600406: current best miou: 0.8424533035516987 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 18:46:36.602473: current best dsc: 0.9144908062827978 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 18:46:36.604397: finished real validation
2023-09-04 18:46:40.946375: train_loss -1.4455
2023-09-04 18:46:40.948994: val_loss -1.0083
2023-09-04 18:46:40.951514: Pseudo dice [0.9124]
2023-09-04 18:46:40.953649: Epoch time: 379.14 s
2023-09-04 18:46:42.089496: 
2023-09-04 18:46:42.091909: Epoch 272
2023-09-04 18:46:42.094046: Current learning rate: backbone 0.00011831, others 0.00011831
2023-09-04 18:46:42.096467: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 18:47:43.651520: finished training epoch 272
2023-09-04 18:47:43.682918: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 18:47:43.687558: The split file contains 1 splits.
2023-09-04 18:47:43.690532: Desired fold for training: 0
2023-09-04 18:47:43.693302: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 18:53:03.228111: dsc: 91.16%
2023-09-04 18:53:03.230572: miou: 83.76%
2023-09-04 18:53:03.232651: acc: 95.56%, sen: 91.05%, spe: 97.08%
2023-09-04 18:53:03.234944: current best miou: 0.8424533035516987 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 18:53:03.236918: current best dsc: 0.9144908062827978 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 18:53:03.238795: finished real validation
2023-09-04 18:53:07.558368: train_loss -1.4459
2023-09-04 18:53:07.560905: val_loss -1.015
2023-09-04 18:53:07.563199: Pseudo dice [0.913]
2023-09-04 18:53:07.565159: Epoch time: 385.47 s
2023-09-04 18:53:08.707160: 
2023-09-04 18:53:08.709553: Epoch 273
2023-09-04 18:53:08.711843: Current learning rate: backbone 0.0001145, others 0.0001145
2023-09-04 18:53:08.714302: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 18:54:10.093586: finished training epoch 273
2023-09-04 18:54:10.134437: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 18:54:10.137718: The split file contains 1 splits.
2023-09-04 18:54:10.139862: Desired fold for training: 0
2023-09-04 18:54:10.141937: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 18:59:23.466167: dsc: 91.14%
2023-09-04 18:59:23.468552: miou: 83.73%
2023-09-04 18:59:23.470582: acc: 95.55%, sen: 91.02%, spe: 97.07%
2023-09-04 18:59:23.472939: current best miou: 0.8424533035516987 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 18:59:23.474993: current best dsc: 0.9144908062827978 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 18:59:23.477024: finished real validation
2023-09-04 18:59:27.796917: train_loss -1.4458
2023-09-04 18:59:27.799474: val_loss -1.0325
2023-09-04 18:59:27.801756: Pseudo dice [0.9123]
2023-09-04 18:59:27.803805: Epoch time: 379.09 s
2023-09-04 18:59:28.941401: 
2023-09-04 18:59:28.943890: Epoch 274
2023-09-04 18:59:28.946194: Current learning rate: backbone 0.00011068, others 0.00011068
2023-09-04 18:59:28.949122: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 19:00:30.293115: finished training epoch 274
2023-09-04 19:00:30.364501: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 19:00:30.367699: The split file contains 1 splits.
2023-09-04 19:00:30.369867: Desired fold for training: 0
2023-09-04 19:00:30.371927: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 19:05:41.484323: dsc: 91.19%
2023-09-04 19:05:41.486629: miou: 83.81%
2023-09-04 19:05:41.488728: acc: 95.58%, sen: 90.91%, spe: 97.15%
2023-09-04 19:05:41.491209: current best miou: 0.8424533035516987 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 19:05:41.493420: current best dsc: 0.9144908062827978 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 19:05:41.495585: finished real validation
2023-09-04 19:05:45.851771: train_loss -1.4461
2023-09-04 19:05:45.854624: val_loss -1.0337
2023-09-04 19:05:45.857300: Pseudo dice [0.9152]
2023-09-04 19:05:45.859549: Epoch time: 376.91 s
2023-09-04 19:05:46.992426: 
2023-09-04 19:05:46.995394: Epoch 275
2023-09-04 19:05:46.997325: Current learning rate: backbone 0.00010684, others 0.00010684
2023-09-04 19:05:46.999551: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 19:06:48.396199: finished training epoch 275
2023-09-04 19:06:48.453822: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 19:06:48.457425: The split file contains 1 splits.
2023-09-04 19:06:48.460403: Desired fold for training: 0
2023-09-04 19:06:48.462515: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 19:12:02.079892: dsc: 91.20%
2023-09-04 19:12:02.082031: miou: 83.82%
2023-09-04 19:12:02.084331: acc: 95.58%, sen: 91.05%, spe: 97.10%
2023-09-04 19:12:02.087397: current best miou: 0.8424533035516987 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 19:12:02.089624: current best dsc: 0.9144908062827978 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 19:12:02.091751: finished real validation
2023-09-04 19:12:06.440324: train_loss -1.4459
2023-09-04 19:12:06.442947: val_loss -1.0033
2023-09-04 19:12:06.445416: Pseudo dice [0.9114]
2023-09-04 19:12:06.447742: Epoch time: 379.45 s
2023-09-04 19:12:07.594994: 
2023-09-04 19:12:07.597415: Epoch 276
2023-09-04 19:12:07.599574: Current learning rate: backbone 0.00010299, others 0.00010299
2023-09-04 19:12:07.601995: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 19:13:08.995781: finished training epoch 276
2023-09-04 19:13:09.062945: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 19:13:09.070774: The split file contains 1 splits.
2023-09-04 19:13:09.073824: Desired fold for training: 0
2023-09-04 19:13:09.076610: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 19:18:18.265365: dsc: 91.20%
2023-09-04 19:18:18.267507: miou: 83.82%
2023-09-04 19:18:18.269449: acc: 95.57%, sen: 91.22%, spe: 97.03%
2023-09-04 19:18:18.271775: current best miou: 0.8424533035516987 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 19:18:18.273689: current best dsc: 0.9144908062827978 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 19:18:18.276737: finished real validation
2023-09-04 19:18:22.615021: train_loss -1.4454
2023-09-04 19:18:22.617753: val_loss -1.0144
2023-09-04 19:18:22.620247: Pseudo dice [0.9125]
2023-09-04 19:18:22.622360: Epoch time: 375.02 s
2023-09-04 19:18:23.750814: 
2023-09-04 19:18:23.753160: Epoch 277
2023-09-04 19:18:23.755311: Current learning rate: backbone 9.912e-05, others 9.912e-05
2023-09-04 19:18:23.757788: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 19:19:25.944838: finished training epoch 277
2023-09-04 19:19:26.013272: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 19:19:26.016174: The split file contains 1 splits.
2023-09-04 19:19:26.018467: Desired fold for training: 0
2023-09-04 19:19:26.020560: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 19:25:02.971522: dsc: 91.21%
2023-09-04 19:25:02.974046: miou: 83.85%
2023-09-04 19:25:02.976025: acc: 95.59%, sen: 91.06%, spe: 97.11%
2023-09-04 19:25:02.978294: current best miou: 0.8424533035516987 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 19:25:02.980268: current best dsc: 0.9144908062827978 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 19:25:02.982248: finished real validation
2023-09-04 19:25:07.325038: train_loss -1.4458
2023-09-04 19:25:07.327735: val_loss -1.0221
2023-09-04 19:25:07.329910: Pseudo dice [0.9125]
2023-09-04 19:25:07.331937: Epoch time: 403.58 s
2023-09-04 19:25:08.532203: 
2023-09-04 19:25:08.534437: Epoch 278
2023-09-04 19:25:08.536864: Current learning rate: backbone 9.523e-05, others 9.523e-05
2023-09-04 19:25:08.539902: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 19:26:09.934795: finished training epoch 278
2023-09-04 19:26:09.973637: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 19:26:09.976734: The split file contains 1 splits.
2023-09-04 19:26:09.978882: Desired fold for training: 0
2023-09-04 19:26:09.980931: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 19:31:19.594865: dsc: 91.19%
2023-09-04 19:31:19.597281: miou: 83.80%
2023-09-04 19:31:19.599306: acc: 95.58%, sen: 90.97%, spe: 97.13%
2023-09-04 19:31:19.601637: current best miou: 0.8424533035516987 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 19:31:19.603690: current best dsc: 0.9144908062827978 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 19:31:19.605762: finished real validation
2023-09-04 19:31:23.954547: train_loss -1.4457
2023-09-04 19:31:23.957498: val_loss -1.0258
2023-09-04 19:31:23.960101: Pseudo dice [0.9138]
2023-09-04 19:31:23.962413: Epoch time: 375.42 s
2023-09-04 19:31:25.099242: 
2023-09-04 19:31:25.101436: Epoch 279
2023-09-04 19:31:25.103409: Current learning rate: backbone 9.132e-05, others 9.132e-05
2023-09-04 19:31:25.105737: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 19:32:26.707124: finished training epoch 279
2023-09-04 19:32:26.743005: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 19:32:26.746390: The split file contains 1 splits.
2023-09-04 19:32:26.748664: Desired fold for training: 0
2023-09-04 19:32:26.750796: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 19:37:47.222652: dsc: 91.18%
2023-09-04 19:37:47.225277: miou: 83.79%
2023-09-04 19:37:47.227288: acc: 95.58%, sen: 90.91%, spe: 97.15%
2023-09-04 19:37:47.229672: current best miou: 0.8424533035516987 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 19:37:47.231694: current best dsc: 0.9144908062827978 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 19:37:47.233691: finished real validation
2023-09-04 19:37:51.587049: train_loss -1.4461
2023-09-04 19:37:51.589583: val_loss -1.0147
2023-09-04 19:37:51.591805: Pseudo dice [0.9124]
2023-09-04 19:37:51.594482: Epoch time: 386.49 s
2023-09-04 19:37:54.250341: 
2023-09-04 19:37:54.252929: Epoch 280
2023-09-04 19:37:54.255229: Current learning rate: backbone 8.74e-05, others 8.74e-05
2023-09-04 19:37:54.257914: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 19:38:55.608200: finished training epoch 280
2023-09-04 19:38:55.650487: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 19:38:55.653835: The split file contains 1 splits.
2023-09-04 19:38:55.656003: Desired fold for training: 0
2023-09-04 19:38:55.658117: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 19:44:05.110066: dsc: 91.19%
2023-09-04 19:44:05.112562: miou: 83.81%
2023-09-04 19:44:05.114672: acc: 95.58%, sen: 91.06%, spe: 97.09%
2023-09-04 19:44:05.117108: current best miou: 0.8424533035516987 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 19:44:05.119222: current best dsc: 0.9144908062827978 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 19:44:05.121264: finished real validation
2023-09-04 19:44:09.495031: train_loss -1.4461
2023-09-04 19:44:09.497637: val_loss -1.0205
2023-09-04 19:44:09.499892: Pseudo dice [0.9116]
2023-09-04 19:44:09.501991: Epoch time: 375.25 s
2023-09-04 19:44:10.637015: 
2023-09-04 19:44:10.639518: Epoch 281
2023-09-04 19:44:10.641783: Current learning rate: backbone 8.346e-05, others 8.346e-05
2023-09-04 19:44:10.644164: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 19:45:12.106271: finished training epoch 281
2023-09-04 19:45:12.147129: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 19:45:12.150191: The split file contains 1 splits.
2023-09-04 19:45:12.152283: Desired fold for training: 0
2023-09-04 19:45:12.154257: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 19:50:23.549873: dsc: 91.21%
2023-09-04 19:50:23.552495: miou: 83.84%
2023-09-04 19:50:23.554454: acc: 95.59%, sen: 90.89%, spe: 97.17%
2023-09-04 19:50:23.556870: current best miou: 0.8424533035516987 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 19:50:23.558873: current best dsc: 0.9144908062827978 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 19:50:23.561070: finished real validation
2023-09-04 19:50:27.922487: train_loss -1.4457
2023-09-04 19:50:27.924956: val_loss -0.9961
2023-09-04 19:50:27.927239: Pseudo dice [0.9109]
2023-09-04 19:50:27.929389: Epoch time: 377.29 s
2023-09-04 19:50:29.066442: 
2023-09-04 19:50:29.068928: Epoch 282
2023-09-04 19:50:29.071609: Current learning rate: backbone 7.949e-05, others 7.949e-05
2023-09-04 19:50:29.074888: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 19:51:30.710521: finished training epoch 282
2023-09-04 19:51:30.741572: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 19:51:30.746095: The split file contains 1 splits.
2023-09-04 19:51:30.748464: Desired fold for training: 0
2023-09-04 19:51:30.750453: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 19:56:59.468976: dsc: 91.20%
2023-09-04 19:56:59.471425: miou: 83.83%
2023-09-04 19:56:59.473619: acc: 95.58%, sen: 91.05%, spe: 97.11%
2023-09-04 19:56:59.476101: current best miou: 0.8424533035516987 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 19:56:59.478447: current best dsc: 0.9144908062827978 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 19:56:59.480812: finished real validation
2023-09-04 19:57:03.835099: train_loss -1.4456
2023-09-04 19:57:03.837614: val_loss -1.0328
2023-09-04 19:57:03.840016: Pseudo dice [0.914]
2023-09-04 19:57:03.842168: Epoch time: 394.77 s
2023-09-04 19:57:04.985225: 
2023-09-04 19:57:04.987700: Epoch 283
2023-09-04 19:57:04.989958: Current learning rate: backbone 7.551e-05, others 7.551e-05
2023-09-04 19:57:04.992795: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 19:58:06.795612: finished training epoch 283
2023-09-04 19:58:06.831509: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 19:58:06.834610: The split file contains 1 splits.
2023-09-04 19:58:06.836753: Desired fold for training: 0
2023-09-04 19:58:06.838811: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 20:03:20.582644: dsc: 91.24%
2023-09-04 20:03:20.585231: miou: 83.90%
2023-09-04 20:03:20.587315: acc: 95.61%, sen: 91.04%, spe: 97.14%
2023-09-04 20:03:20.590338: current best miou: 0.8424533035516987 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 20:03:20.592367: current best dsc: 0.9144908062827978 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 20:03:20.594186: finished real validation
2023-09-04 20:03:24.966784: train_loss -1.446
2023-09-04 20:03:24.969267: val_loss -1.0107
2023-09-04 20:03:24.972193: Pseudo dice [0.9131]
2023-09-04 20:03:24.974577: Epoch time: 379.98 s
2023-09-04 20:03:26.105034: 
2023-09-04 20:03:26.107640: Epoch 284
2023-09-04 20:03:26.109901: Current learning rate: backbone 7.15e-05, others 7.15e-05
2023-09-04 20:03:26.112624: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 20:04:27.739826: finished training epoch 284
2023-09-04 20:04:27.769717: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 20:04:27.772648: The split file contains 1 splits.
2023-09-04 20:04:27.775144: Desired fold for training: 0
2023-09-04 20:04:27.777334: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 20:09:47.189863: dsc: 91.19%
2023-09-04 20:09:47.192156: miou: 83.81%
2023-09-04 20:09:47.194162: acc: 95.58%, sen: 90.94%, spe: 97.14%
2023-09-04 20:09:47.196472: current best miou: 0.8424533035516987 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 20:09:47.198500: current best dsc: 0.9144908062827978 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 20:09:47.200511: finished real validation
2023-09-04 20:09:51.538500: train_loss -1.446
2023-09-04 20:09:51.541192: val_loss -1.0381
2023-09-04 20:09:51.543525: Pseudo dice [0.9149]
2023-09-04 20:09:51.545767: Epoch time: 385.43 s
2023-09-04 20:09:52.685549: 
2023-09-04 20:09:52.687814: Epoch 285
2023-09-04 20:09:52.690569: Current learning rate: backbone 6.746e-05, others 6.746e-05
2023-09-04 20:09:52.693127: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 20:10:54.816164: finished training epoch 285
2023-09-04 20:10:54.854954: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 20:10:54.858601: The split file contains 1 splits.
2023-09-04 20:10:54.860907: Desired fold for training: 0
2023-09-04 20:10:54.863107: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 20:16:09.467745: dsc: 91.22%
2023-09-04 20:16:09.470744: miou: 83.85%
2023-09-04 20:16:09.473120: acc: 95.58%, sen: 91.23%, spe: 97.04%
2023-09-04 20:16:09.476302: current best miou: 0.8424533035516987 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 20:16:09.478671: current best dsc: 0.9144908062827978 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 20:16:09.481019: finished real validation
2023-09-04 20:16:13.815758: train_loss -1.4459
2023-09-04 20:16:13.818374: val_loss -1.0162
2023-09-04 20:16:13.820840: Pseudo dice [0.9114]
2023-09-04 20:16:13.822955: Epoch time: 381.13 s
2023-09-04 20:16:14.957738: 
2023-09-04 20:16:14.960130: Epoch 286
2023-09-04 20:16:14.962425: Current learning rate: backbone 6.34e-05, others 6.34e-05
2023-09-04 20:16:14.965537: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 20:17:16.423031: finished training epoch 286
2023-09-04 20:17:16.459193: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 20:17:16.463074: The split file contains 1 splits.
2023-09-04 20:17:16.465631: Desired fold for training: 0
2023-09-04 20:17:16.467873: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 20:22:30.171728: dsc: 91.19%
2023-09-04 20:22:30.175149: miou: 83.81%
2023-09-04 20:22:30.177123: acc: 95.57%, sen: 91.09%, spe: 97.08%
2023-09-04 20:22:30.179465: current best miou: 0.8424533035516987 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 20:22:30.181421: current best dsc: 0.9144908062827978 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 20:22:30.183413: finished real validation
2023-09-04 20:22:34.516236: train_loss -1.446
2023-09-04 20:22:34.518944: val_loss -1.0025
2023-09-04 20:22:34.521392: Pseudo dice [0.911]
2023-09-04 20:22:34.523923: Epoch time: 379.56 s
2023-09-04 20:22:35.705039: 
2023-09-04 20:22:35.707591: Epoch 287
2023-09-04 20:22:35.709775: Current learning rate: backbone 5.931e-05, others 5.931e-05
2023-09-04 20:22:35.712218: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 20:23:37.159391: finished training epoch 287
2023-09-04 20:23:37.207018: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 20:23:37.209811: The split file contains 1 splits.
2023-09-04 20:23:37.211981: Desired fold for training: 0
2023-09-04 20:23:37.214070: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 20:28:50.149719: dsc: 91.23%
2023-09-04 20:28:50.152325: miou: 83.87%
2023-09-04 20:28:50.154394: acc: 95.60%, sen: 91.02%, spe: 97.13%
2023-09-04 20:28:50.156749: current best miou: 0.8424533035516987 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 20:28:50.158790: current best dsc: 0.9144908062827978 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 20:28:50.160839: finished real validation
2023-09-04 20:28:54.504972: train_loss -1.4457
2023-09-04 20:28:54.507521: val_loss -1.0404
2023-09-04 20:28:54.509888: Pseudo dice [0.9144]
2023-09-04 20:28:54.512020: Epoch time: 378.8 s
2023-09-04 20:28:55.669819: 
2023-09-04 20:28:55.672199: Epoch 288
2023-09-04 20:28:55.674382: Current learning rate: backbone 5.519e-05, others 5.519e-05
2023-09-04 20:28:55.677011: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 20:29:57.170925: finished training epoch 288
2023-09-04 20:29:57.202572: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 20:29:57.205485: The split file contains 1 splits.
2023-09-04 20:29:57.207552: Desired fold for training: 0
2023-09-04 20:29:57.209644: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 20:35:14.791243: dsc: 91.19%
2023-09-04 20:35:14.793697: miou: 83.81%
2023-09-04 20:35:14.795752: acc: 95.58%, sen: 90.97%, spe: 97.13%
2023-09-04 20:35:14.798041: current best miou: 0.8424533035516987 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 20:35:14.800085: current best dsc: 0.9144908062827978 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 20:35:14.802064: finished real validation
2023-09-04 20:35:19.136164: train_loss -1.4459
2023-09-04 20:35:19.138922: val_loss -0.9873
2023-09-04 20:35:19.141577: Pseudo dice [0.9107]
2023-09-04 20:35:19.143974: Epoch time: 383.47 s
2023-09-04 20:35:20.289015: 
2023-09-04 20:35:20.291275: Epoch 289
2023-09-04 20:35:20.293429: Current learning rate: backbone 5.103e-05, others 5.103e-05
2023-09-04 20:35:20.296256: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 20:36:21.967359: finished training epoch 289
2023-09-04 20:36:21.998171: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 20:36:22.001157: The split file contains 1 splits.
2023-09-04 20:36:22.003381: Desired fold for training: 0
2023-09-04 20:36:22.005502: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 20:41:37.765221: dsc: 91.22%
2023-09-04 20:41:37.767922: miou: 83.86%
2023-09-04 20:41:37.770057: acc: 95.60%, sen: 91.00%, spe: 97.14%
2023-09-04 20:41:37.772648: current best miou: 0.8424533035516987 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 20:41:37.775378: current best dsc: 0.9144908062827978 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 20:41:37.777911: finished real validation
2023-09-04 20:41:42.118294: train_loss -1.4465
2023-09-04 20:41:42.121125: val_loss -1.0371
2023-09-04 20:41:42.123566: Pseudo dice [0.9153]
2023-09-04 20:41:42.125737: Epoch time: 381.83 s
2023-09-04 20:41:44.824300: 
2023-09-04 20:41:44.827644: Epoch 290
2023-09-04 20:41:44.829771: Current learning rate: backbone 4.684e-05, others 4.684e-05
2023-09-04 20:41:44.832329: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 20:42:46.338916: finished training epoch 290
2023-09-04 20:42:46.377660: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 20:42:46.380722: The split file contains 1 splits.
2023-09-04 20:42:46.382905: Desired fold for training: 0
2023-09-04 20:42:46.385046: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 20:48:00.001551: dsc: 91.20%
2023-09-04 20:48:00.004335: miou: 83.83%
2023-09-04 20:48:00.006829: acc: 95.58%, sen: 91.06%, spe: 97.10%
2023-09-04 20:48:00.010175: current best miou: 0.8424533035516987 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 20:48:00.012685: current best dsc: 0.9144908062827978 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 20:48:00.015048: finished real validation
2023-09-04 20:48:04.362550: train_loss -1.446
2023-09-04 20:48:04.365594: val_loss -1.0239
2023-09-04 20:48:04.368163: Pseudo dice [0.9134]
2023-09-04 20:48:04.370704: Epoch time: 379.54 s
2023-09-04 20:48:05.566160: 
2023-09-04 20:48:05.568687: Epoch 291
2023-09-04 20:48:05.570901: Current learning rate: backbone 4.26e-05, others 4.26e-05
2023-09-04 20:48:05.573580: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 20:49:06.977716: finished training epoch 291
2023-09-04 20:49:07.023485: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 20:49:07.026567: The split file contains 1 splits.
2023-09-04 20:49:07.028678: Desired fold for training: 0
2023-09-04 20:49:07.030764: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 20:54:15.077643: dsc: 91.17%
2023-09-04 20:54:15.079793: miou: 83.78%
2023-09-04 20:54:15.082010: acc: 95.57%, sen: 91.04%, spe: 97.09%
2023-09-04 20:54:15.085036: current best miou: 0.8424533035516987 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 20:54:15.087314: current best dsc: 0.9144908062827978 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 20:54:15.089385: finished real validation
2023-09-04 20:54:19.459477: train_loss -1.4462
2023-09-04 20:54:19.461900: val_loss -0.9884
2023-09-04 20:54:19.464138: Pseudo dice [0.9094]
2023-09-04 20:54:19.466806: Epoch time: 373.89 s
2023-09-04 20:54:20.622132: 
2023-09-04 20:54:20.625382: Epoch 292
2023-09-04 20:54:20.627782: Current learning rate: backbone 3.832e-05, others 3.832e-05
2023-09-04 20:54:20.630553: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 20:55:22.096379: finished training epoch 292
2023-09-04 20:55:22.138133: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 20:55:22.141124: The split file contains 1 splits.
2023-09-04 20:55:22.143271: Desired fold for training: 0
2023-09-04 20:55:22.145357: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 21:00:43.205448: dsc: 91.20%
2023-09-04 21:00:43.207971: miou: 83.82%
2023-09-04 21:00:43.210490: acc: 95.59%, sen: 90.96%, spe: 97.14%
2023-09-04 21:00:43.213841: current best miou: 0.8424533035516987 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 21:00:43.216327: current best dsc: 0.9144908062827978 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 21:00:43.218651: finished real validation
2023-09-04 21:00:47.566416: train_loss -1.4463
2023-09-04 21:00:47.568902: val_loss -1.0513
2023-09-04 21:00:47.571204: Pseudo dice [0.9178]
2023-09-04 21:00:47.573361: Epoch time: 386.95 s
2023-09-04 21:00:48.728943: 
2023-09-04 21:00:48.731647: Epoch 293
2023-09-04 21:00:48.734283: Current learning rate: backbone 3.398e-05, others 3.398e-05
2023-09-04 21:00:48.737309: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 21:01:50.106331: finished training epoch 293
2023-09-04 21:01:50.147746: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 21:01:50.150981: The split file contains 1 splits.
2023-09-04 21:01:50.153207: Desired fold for training: 0
2023-09-04 21:01:50.155367: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 21:07:03.510822: dsc: 91.18%
2023-09-04 21:07:03.513329: miou: 83.80%
2023-09-04 21:07:03.515437: acc: 95.57%, sen: 91.13%, spe: 97.06%
2023-09-04 21:07:03.517782: current best miou: 0.8424533035516987 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 21:07:03.519859: current best dsc: 0.9144908062827978 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 21:07:03.521914: finished real validation
2023-09-04 21:07:07.861943: train_loss -1.4457
2023-09-04 21:07:07.864507: val_loss -1.0123
2023-09-04 21:07:07.866881: Pseudo dice [0.9139]
2023-09-04 21:07:07.869137: Epoch time: 379.13 s
2023-09-04 21:07:09.039335: 
2023-09-04 21:07:09.041563: Epoch 294
2023-09-04 21:07:09.044233: Current learning rate: backbone 2.958e-05, others 2.958e-05
2023-09-04 21:07:09.046620: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 21:08:10.684865: finished training epoch 294
2023-09-04 21:08:10.726614: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 21:08:10.729935: The split file contains 1 splits.
2023-09-04 21:08:10.732139: Desired fold for training: 0
2023-09-04 21:08:10.734304: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 21:13:20.889367: dsc: 91.22%
2023-09-04 21:13:20.891772: miou: 83.86%
2023-09-04 21:13:20.893978: acc: 95.59%, sen: 91.04%, spe: 97.13%
2023-09-04 21:13:20.896609: current best miou: 0.8424533035516987 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 21:13:20.898805: current best dsc: 0.9144908062827978 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 21:13:20.900962: finished real validation
2023-09-04 21:13:25.267856: train_loss -1.4457
2023-09-04 21:13:25.270512: val_loss -1.0115
2023-09-04 21:13:25.272993: Pseudo dice [0.9115]
2023-09-04 21:13:25.275255: Epoch time: 376.23 s
2023-09-04 21:13:26.432473: 
2023-09-04 21:13:26.434972: Epoch 295
2023-09-04 21:13:26.437148: Current learning rate: backbone 2.51e-05, others 2.51e-05
2023-09-04 21:13:26.439667: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 21:14:28.409062: finished training epoch 295
2023-09-04 21:14:28.442570: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 21:14:28.446249: The split file contains 1 splits.
2023-09-04 21:14:28.448714: Desired fold for training: 0
2023-09-04 21:14:28.451152: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 21:19:43.347220: dsc: 91.17%
2023-09-04 21:19:43.349891: miou: 83.77%
2023-09-04 21:19:43.352031: acc: 95.57%, sen: 90.98%, spe: 97.11%
2023-09-04 21:19:43.354779: current best miou: 0.8424533035516987 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 21:19:43.357197: current best dsc: 0.9144908062827978 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 21:19:43.359503: finished real validation
2023-09-04 21:19:47.696948: train_loss -1.4466
2023-09-04 21:19:47.699826: val_loss -1.0753
2023-09-04 21:19:47.702299: Pseudo dice [0.9193]
2023-09-04 21:19:47.704446: Epoch time: 381.27 s
2023-09-04 21:19:48.865448: 
2023-09-04 21:19:48.867937: Epoch 296
2023-09-04 21:19:48.870517: Current learning rate: backbone 2.053e-05, others 2.053e-05
2023-09-04 21:19:48.873958: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 21:20:50.584616: finished training epoch 296
2023-09-04 21:20:50.639300: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 21:20:50.642315: The split file contains 1 splits.
2023-09-04 21:20:50.644498: Desired fold for training: 0
2023-09-04 21:20:50.646590: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 21:26:20.838651: dsc: 91.18%
2023-09-04 21:26:20.841105: miou: 83.80%
2023-09-04 21:26:20.843352: acc: 95.57%, sen: 91.02%, spe: 97.10%
2023-09-04 21:26:20.845816: current best miou: 0.8424533035516987 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 21:26:20.847773: current best dsc: 0.9144908062827978 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 21:26:20.849612: finished real validation
2023-09-04 21:26:25.233850: train_loss -1.4461
2023-09-04 21:26:25.236674: val_loss -0.9834
2023-09-04 21:26:25.239104: Pseudo dice [0.9088]
2023-09-04 21:26:25.241284: Epoch time: 396.37 s
2023-09-04 21:26:26.399598: 
2023-09-04 21:26:26.401878: Epoch 297
2023-09-04 21:26:26.405074: Current learning rate: backbone 1.585e-05, others 1.585e-05
2023-09-04 21:26:26.407398: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 21:27:28.486721: finished training epoch 297
2023-09-04 21:27:28.524894: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 21:27:28.527956: The split file contains 1 splits.
2023-09-04 21:27:28.530163: Desired fold for training: 0
2023-09-04 21:27:28.532296: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 21:32:44.216410: dsc: 91.17%
2023-09-04 21:32:44.218916: miou: 83.77%
2023-09-04 21:32:44.221028: acc: 95.56%, sen: 91.01%, spe: 97.10%
2023-09-04 21:32:44.223598: current best miou: 0.8424533035516987 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 21:32:44.225730: current best dsc: 0.9144908062827978 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 21:32:44.227904: finished real validation
2023-09-04 21:32:48.571585: train_loss -1.4463
2023-09-04 21:32:48.574233: val_loss -1.0301
2023-09-04 21:32:48.577350: Pseudo dice [0.9151]
2023-09-04 21:32:48.580055: Epoch time: 382.17 s
2023-09-04 21:32:49.737825: 
2023-09-04 21:32:49.740537: Epoch 298
2023-09-04 21:32:49.742936: Current learning rate: backbone 1.1e-05, others 1.1e-05
2023-09-04 21:32:49.745465: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 21:33:51.400746: finished training epoch 298
2023-09-04 21:33:51.443322: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 21:33:51.446354: The split file contains 1 splits.
2023-09-04 21:33:51.448560: Desired fold for training: 0
2023-09-04 21:33:51.450679: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 21:39:05.549029: dsc: 91.19%
2023-09-04 21:39:05.551663: miou: 83.81%
2023-09-04 21:39:05.553800: acc: 95.57%, sen: 91.06%, spe: 97.09%
2023-09-04 21:39:05.556249: current best miou: 0.8424533035516987 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 21:39:05.558379: current best dsc: 0.9144908062827978 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 21:39:05.560809: finished real validation
2023-09-04 21:39:09.891564: train_loss -1.4456
2023-09-04 21:39:09.894150: val_loss -1.001
2023-09-04 21:39:09.896576: Pseudo dice [0.9105]
2023-09-04 21:39:09.898801: Epoch time: 380.16 s
2023-09-04 21:39:11.065933: 
2023-09-04 21:39:11.068733: Epoch 299
2023-09-04 21:39:11.071015: Current learning rate: backbone 5.9e-06, others 5.9e-06
2023-09-04 21:39:11.073746: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 21:40:13.426383: finished training epoch 299
2023-09-04 21:40:13.457218: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 21:40:13.460345: The split file contains 1 splits.
2023-09-04 21:40:13.462615: Desired fold for training: 0
2023-09-04 21:40:13.464733: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 21:45:22.731723: dsc: 91.17%
2023-09-04 21:45:22.734314: miou: 83.78%
2023-09-04 21:45:22.736416: acc: 95.57%, sen: 91.03%, spe: 97.09%
2023-09-04 21:45:22.738795: current best miou: 0.8424533035516987 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 21:45:22.740889: current best dsc: 0.9144908062827978 at epoch: 91, (91, 0.8424533035516987, 0.9144908062827978)
2023-09-04 21:45:22.742978: finished real validation
2023-09-04 21:45:27.050749: train_loss -1.4458
2023-09-04 21:45:27.053373: val_loss -1.0507
2023-09-04 21:45:27.056078: Pseudo dice [0.9159]
2023-09-04 21:45:27.058708: Epoch time: 375.99 s
2023-09-04 21:45:29.763417: Training done.
2023-09-04 21:45:29.851302: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 21:45:29.853865: The split file contains 1 splits.
2023-09-04 21:45:29.855844: Desired fold for training: 0
2023-09-04 21:45:29.857726: This split has 1886 training and 808 validation cases.
2023-09-04 21:45:29.874954: predicting val_0
2023-09-04 21:45:30.057936: predicting val_1
2023-09-04 21:45:30.229233: predicting val_10
2023-09-04 21:45:30.385601: predicting val_100
2023-09-04 21:45:30.599482: predicting val_101
2023-09-04 21:45:30.762312: predicting val_102
2023-09-04 21:45:30.922593: predicting val_103
2023-09-04 21:45:31.083736: predicting val_104
2023-09-04 21:45:31.244886: predicting val_105
2023-09-04 21:45:31.401638: predicting val_106
2023-09-04 21:45:31.557559: predicting val_107
2023-09-04 21:45:31.716697: predicting val_108
2023-09-04 21:45:31.988944: predicting val_109
2023-09-04 21:45:32.156582: predicting val_11
2023-09-04 21:45:32.319003: predicting val_110
2023-09-04 21:45:32.478108: predicting val_111
2023-09-04 21:45:32.623826: predicting val_112
2023-09-04 21:45:32.772095: predicting val_113
2023-09-04 21:45:32.919028: predicting val_114
2023-09-04 21:45:33.068935: predicting val_115
2023-09-04 21:45:33.227068: predicting val_116
2023-09-04 21:45:33.374216: predicting val_117
2023-09-04 21:45:33.549599: predicting val_118
2023-09-04 21:45:33.708817: predicting val_119
2023-09-04 21:46:16.002124: predicting val_12
2023-09-04 21:46:16.172130: predicting val_120
2023-09-04 21:46:16.341701: predicting val_121
2023-09-04 21:46:16.514226: predicting val_122
2023-09-04 21:46:16.662973: predicting val_123
2023-09-04 21:46:16.823897: predicting val_124
2023-09-04 21:46:16.974167: predicting val_125
2023-09-04 21:46:17.119439: predicting val_126
2023-09-04 21:46:17.263699: predicting val_127
2023-09-04 21:46:17.408493: predicting val_128
2023-09-04 21:46:17.557410: predicting val_129
2023-09-04 21:46:17.698159: predicting val_13
2023-09-04 21:46:17.860665: predicting val_130
2023-09-04 21:46:18.006413: predicting val_131
2023-09-04 21:46:18.155874: predicting val_132
2023-09-04 21:46:18.306632: predicting val_133
2023-09-04 21:46:18.449729: predicting val_134
2023-09-04 21:46:18.591847: predicting val_135
2023-09-04 21:46:18.733833: predicting val_136
2023-09-04 21:46:18.875177: predicting val_137
2023-09-04 21:46:19.017698: predicting val_138
2023-09-04 21:46:19.160599: predicting val_139
2023-09-04 21:46:19.300860: predicting val_14
2023-09-04 21:46:19.441256: predicting val_140
2023-09-04 21:46:19.583933: predicting val_141
2023-09-04 21:46:19.725239: predicting val_142
2023-09-04 21:46:19.866549: predicting val_143
2023-09-04 21:46:20.008835: predicting val_144
2023-09-04 21:46:20.154506: predicting val_145
2023-09-04 21:46:20.298483: predicting val_146
2023-09-04 21:46:20.440292: predicting val_147
2023-09-04 21:46:20.581738: predicting val_148
2023-09-04 21:46:20.724872: predicting val_149
2023-09-04 21:46:20.873315: predicting val_15
2023-09-04 21:46:21.022260: predicting val_150
2023-09-04 21:46:21.163564: predicting val_151
2023-09-04 21:46:21.301650: predicting val_152
2023-09-04 21:46:21.442074: predicting val_153
2023-09-04 21:46:21.583207: predicting val_154
2023-09-04 21:46:21.734888: predicting val_155
2023-09-04 21:46:21.878819: predicting val_156
2023-09-04 21:46:22.018221: predicting val_157
2023-09-04 21:46:22.158964: predicting val_158
2023-09-04 21:46:22.303562: predicting val_159
2023-09-04 21:46:22.444798: predicting val_16
2023-09-04 21:46:22.592045: predicting val_160
2023-09-04 21:46:22.743850: predicting val_161
2023-09-04 21:46:22.890660: predicting val_162
2023-09-04 21:46:23.045025: predicting val_163
2023-09-04 21:46:23.199292: predicting val_164
2023-09-04 21:46:23.338551: predicting val_165
2023-09-04 21:46:23.481948: predicting val_166
2023-09-04 21:46:23.627714: predicting val_167
2023-09-04 21:46:23.773821: predicting val_168
2023-09-04 21:46:23.914881: predicting val_169
2023-09-04 21:46:24.059659: predicting val_17
2023-09-04 21:46:24.215379: predicting val_170
2023-09-04 21:46:24.363862: predicting val_171
2023-09-04 21:46:24.509826: predicting val_172
2023-09-04 21:46:24.654874: predicting val_173
2023-09-04 21:46:24.798923: predicting val_174
2023-09-04 21:46:24.944634: predicting val_175
2023-09-04 21:46:25.089776: predicting val_176
2023-09-04 21:46:25.239029: predicting val_177
2023-09-04 21:46:25.381670: predicting val_178
2023-09-04 21:46:25.526799: predicting val_179
2023-09-04 21:46:25.671553: predicting val_18
2023-09-04 21:46:25.815554: predicting val_180
2023-09-04 21:46:25.961654: predicting val_181
2023-09-04 21:46:26.104551: predicting val_182
2023-09-04 21:46:26.256864: predicting val_183
2023-09-04 21:46:26.406528: predicting val_184
2023-09-04 21:46:26.552875: predicting val_185
2023-09-04 21:46:26.697659: predicting val_186
2023-09-04 21:46:26.837860: predicting val_187
2023-09-04 21:46:26.980966: predicting val_188
2023-09-04 21:46:27.123352: predicting val_189
2023-09-04 21:46:27.263329: predicting val_19
2023-09-04 21:46:27.403867: predicting val_190
2023-09-04 21:46:27.544499: predicting val_191
2023-09-04 21:46:27.688946: predicting val_192
2023-09-04 21:46:27.834790: predicting val_193
2023-09-04 21:46:27.976591: predicting val_194
2023-09-04 21:46:28.126109: predicting val_195
2023-09-04 21:46:28.276869: predicting val_196
2023-09-04 21:46:28.417231: predicting val_197
2023-09-04 21:46:28.556319: predicting val_198
2023-09-04 21:46:28.708896: predicting val_199
2023-09-04 21:46:28.857821: predicting val_2
2023-09-04 21:46:29.005286: predicting val_20
2023-09-04 21:46:29.152037: predicting val_200
2023-09-04 21:46:29.299547: predicting val_201
2023-09-04 21:46:29.451964: predicting val_202
2023-09-04 21:46:29.596347: predicting val_203
2023-09-04 21:46:29.737934: predicting val_204
2023-09-04 21:46:29.883393: predicting val_205
2023-09-04 21:46:30.030662: predicting val_206
2023-09-04 21:46:30.171558: predicting val_207
2023-09-04 21:46:30.318923: predicting val_208
2023-09-04 21:46:30.464359: predicting val_209
2023-09-04 21:46:30.609875: predicting val_21
2023-09-04 21:46:30.755359: predicting val_210
2023-09-04 21:46:30.900203: predicting val_211
2023-09-04 21:46:31.044939: predicting val_212
2023-09-04 21:46:31.188633: predicting val_213
2023-09-04 21:46:31.332565: predicting val_214
2023-09-04 21:46:31.474860: predicting val_215
2023-09-04 21:46:31.622115: predicting val_216
2023-09-04 21:46:31.767143: predicting val_217
2023-09-04 21:46:31.911830: predicting val_218
2023-09-04 21:46:32.054344: predicting val_219
2023-09-04 21:46:32.194956: predicting val_22
2023-09-04 21:46:32.348139: predicting val_220
2023-09-04 21:46:32.490450: predicting val_221
2023-09-04 21:46:32.635256: predicting val_222
2023-09-04 21:46:32.776716: predicting val_223
2023-09-04 21:46:32.917736: predicting val_224
2023-09-04 21:46:33.059132: predicting val_225
2023-09-04 21:46:33.200222: predicting val_226
2023-09-04 21:46:33.342888: predicting val_227
2023-09-04 21:46:33.487964: predicting val_228
2023-09-04 21:46:33.634318: predicting val_229
2023-09-04 21:46:33.778763: predicting val_23
2023-09-04 21:46:33.923556: predicting val_230
2023-09-04 21:46:34.067788: predicting val_231
2023-09-04 21:46:34.208768: predicting val_232
2023-09-04 21:46:34.355197: predicting val_233
2023-09-04 21:46:34.501361: predicting val_234
2023-09-04 21:46:34.647796: predicting val_235
2023-09-04 21:46:34.789600: predicting val_236
2023-09-04 21:46:34.933543: predicting val_237
2023-09-04 21:46:35.077288: predicting val_238
2023-09-04 21:46:35.227843: predicting val_239
2023-09-04 21:46:35.368094: predicting val_24
2023-09-04 21:46:35.511699: predicting val_240
2023-09-04 21:46:35.655204: predicting val_241
2023-09-04 21:46:35.799926: predicting val_242
2023-09-04 21:46:35.941581: predicting val_243
2023-09-04 21:46:36.083475: predicting val_244
2023-09-04 21:46:36.227749: predicting val_245
2023-09-04 21:46:36.372273: predicting val_246
2023-09-04 21:46:36.522158: predicting val_247
2023-09-04 21:46:36.667079: predicting val_248
2023-09-04 21:46:36.811511: predicting val_249
2023-09-04 21:46:36.956841: predicting val_25
2023-09-04 21:46:37.099876: predicting val_250
2023-09-04 21:46:37.244246: predicting val_251
2023-09-04 21:46:37.385733: predicting val_252
2023-09-04 21:46:37.528050: predicting val_253
2023-09-04 21:46:37.668337: predicting val_254
2023-09-04 21:46:37.810957: predicting val_255
2023-09-04 21:46:37.954419: predicting val_256
2023-09-04 21:46:38.097760: predicting val_257
2023-09-04 21:46:38.239002: predicting val_258
2023-09-04 21:46:38.380679: predicting val_259
2023-09-04 21:46:38.542071: predicting val_26
2023-09-04 21:46:38.690324: predicting val_260
2023-09-04 21:46:38.834590: predicting val_261
2023-09-04 21:46:38.973578: predicting val_262
2023-09-04 21:46:39.114687: predicting val_263
2023-09-04 21:46:39.253244: predicting val_264
2023-09-04 21:46:39.397550: predicting val_265
2023-09-04 21:46:39.538566: predicting val_266
2023-09-04 21:46:39.678590: predicting val_267
2023-09-04 21:46:39.827495: predicting val_268
2023-09-04 21:46:39.969319: predicting val_269
2023-09-04 21:46:40.119400: predicting val_27
2023-09-04 21:46:40.265828: predicting val_270
2023-09-04 21:46:40.407383: predicting val_271
2023-09-04 21:46:40.564342: predicting val_272
2023-09-04 21:46:40.709147: predicting val_273
2023-09-04 21:46:40.853923: predicting val_274
2023-09-04 21:46:40.997859: predicting val_275
2023-09-04 21:46:41.141259: predicting val_276
2023-09-04 21:46:41.287541: predicting val_277
2023-09-04 21:46:41.432466: predicting val_278
2023-09-04 21:46:41.576643: predicting val_279
2023-09-04 21:46:41.727526: predicting val_28
2023-09-04 21:46:41.872069: predicting val_280
2023-09-04 21:46:42.017681: predicting val_281
2023-09-04 21:46:42.163050: predicting val_282
2023-09-04 21:46:42.306463: predicting val_283
2023-09-04 21:46:42.450056: predicting val_284
2023-09-04 21:46:42.599160: predicting val_285
2023-09-04 21:46:42.741570: predicting val_286
2023-09-04 21:46:42.883519: predicting val_287
2023-09-04 21:46:43.023990: predicting val_288
2023-09-04 21:46:43.166615: predicting val_289
2023-09-04 21:46:43.305737: predicting val_29
2023-09-04 21:46:43.445736: predicting val_290
2023-09-04 21:46:43.588165: predicting val_291
2023-09-04 21:46:43.730000: predicting val_292
2023-09-04 21:46:43.870548: predicting val_293
2023-09-04 21:46:44.010395: predicting val_294
2023-09-04 21:46:44.163628: predicting val_295
2023-09-04 21:46:44.302687: predicting val_296
2023-09-04 21:46:44.449549: predicting val_297
2023-09-04 21:46:44.597415: predicting val_298
2023-09-04 21:46:44.746210: predicting val_299
2023-09-04 21:46:44.882862: predicting val_3
2023-09-04 21:46:45.023831: predicting val_30
2023-09-04 21:46:45.165143: predicting val_300
2023-09-04 21:46:45.306987: predicting val_301
2023-09-04 21:46:45.457014: predicting val_302
2023-09-04 21:46:45.606547: predicting val_303
2023-09-04 21:46:45.756783: predicting val_304
2023-09-04 21:46:45.912122: predicting val_305
2023-09-04 21:46:46.054275: predicting val_306
2023-09-04 21:46:46.205514: predicting val_307
2023-09-04 21:46:46.350647: predicting val_308
2023-09-04 21:46:46.498317: predicting val_309
2023-09-04 21:46:46.641253: predicting val_31
2023-09-04 21:46:46.789758: predicting val_310
2023-09-04 21:46:46.935514: predicting val_311
2023-09-04 21:46:47.084916: predicting val_312
2023-09-04 21:46:47.228165: predicting val_313
2023-09-04 21:46:47.368891: predicting val_314
2023-09-04 21:46:47.516494: predicting val_315
2023-09-04 21:46:47.661115: predicting val_316
2023-09-04 21:46:47.808337: predicting val_317
2023-09-04 21:46:47.951077: predicting val_318
2023-09-04 21:46:48.095777: predicting val_319
2023-09-04 21:46:48.240222: predicting val_32
2023-09-04 21:46:48.394318: predicting val_320
2023-09-04 21:46:48.541580: predicting val_321
2023-09-04 21:46:48.689231: predicting val_322
2023-09-04 21:46:48.834727: predicting val_323
2023-09-04 21:46:48.978312: predicting val_324
2023-09-04 21:46:49.117601: predicting val_325
2023-09-04 21:46:49.263447: predicting val_326
2023-09-04 21:46:49.403915: predicting val_327
2023-09-04 21:46:49.545053: predicting val_328
2023-09-04 21:46:49.683515: predicting val_329
2023-09-04 21:46:49.821534: predicting val_33
2023-09-04 21:46:49.960098: predicting val_330
2023-09-04 21:46:50.098703: predicting val_331
2023-09-04 21:46:50.241885: predicting val_332
2023-09-04 21:46:50.383361: predicting val_333
2023-09-04 21:46:50.536407: predicting val_334
2023-09-04 21:46:50.679574: predicting val_335
2023-09-04 21:46:50.832003: predicting val_336
2023-09-04 21:46:50.974821: predicting val_337
2023-09-04 21:46:51.117742: predicting val_338
2023-09-04 21:46:51.263893: predicting val_339
2023-09-04 21:46:51.412996: predicting val_34
2023-09-04 21:46:51.559408: predicting val_340
2023-09-04 21:46:51.789521: predicting val_341
2023-09-04 21:46:51.952054: predicting val_342
2023-09-04 21:46:52.098837: predicting val_343
2023-09-04 21:46:52.257905: predicting val_344
2023-09-04 21:46:52.401022: predicting val_345
2023-09-04 21:46:52.552612: predicting val_346
2023-09-04 21:46:52.708220: predicting val_347
2023-09-04 21:46:52.888081: predicting val_348
2023-09-04 21:46:53.040730: predicting val_349
2023-09-04 21:46:53.277277: predicting val_35
2023-09-04 21:46:53.420693: predicting val_350
2023-09-04 21:46:53.565899: predicting val_351
2023-09-04 21:46:53.713054: predicting val_352
2023-09-04 21:46:53.857074: predicting val_353
2023-09-04 21:46:54.003488: predicting val_354
2023-09-04 21:46:54.146612: predicting val_355
2023-09-04 21:46:54.292370: predicting val_356
2023-09-04 21:46:54.444256: predicting val_357
2023-09-04 21:46:54.588486: predicting val_358
2023-09-04 21:46:54.737226: predicting val_359
2023-09-04 21:46:54.886163: predicting val_36
2023-09-04 21:46:55.035770: predicting val_360
2023-09-04 21:46:55.180075: predicting val_361
2023-09-04 21:46:55.324488: predicting val_362
2023-09-04 21:46:55.467035: predicting val_363
2023-09-04 21:46:55.613398: predicting val_364
2023-09-04 21:46:55.764787: predicting val_365
2023-09-04 21:46:55.909042: predicting val_366
2023-09-04 21:46:56.053775: predicting val_367
2023-09-04 21:46:56.195416: predicting val_368
2023-09-04 21:46:56.337134: predicting val_369
2023-09-04 21:46:56.476638: predicting val_37
2023-09-04 21:46:56.618035: predicting val_370
2023-09-04 21:46:56.759541: predicting val_371
2023-09-04 21:46:56.907128: predicting val_372
2023-09-04 21:46:57.064803: predicting val_373
2023-09-04 21:46:57.212987: predicting val_374
2023-09-04 21:46:57.353017: predicting val_375
2023-09-04 21:46:57.496455: predicting val_376
2023-09-04 21:46:57.641601: predicting val_377
2023-09-04 21:46:57.800406: predicting val_378
2023-09-04 21:46:57.944453: predicting val_379
2023-09-04 21:46:58.086716: predicting val_38
2023-09-04 21:46:58.234057: predicting val_380
2023-09-04 21:46:58.382084: predicting val_381
2023-09-04 21:46:58.523418: predicting val_382
2023-09-04 21:46:58.666312: predicting val_383
2023-09-04 21:46:58.809915: predicting val_384
2023-09-04 21:46:58.961218: predicting val_385
2023-09-04 21:46:59.107104: predicting val_386
2023-09-04 21:46:59.252231: predicting val_387
2023-09-04 21:46:59.392460: predicting val_388
2023-09-04 21:46:59.534993: predicting val_389
2023-09-04 21:46:59.676148: predicting val_39
2023-09-04 21:46:59.818265: predicting val_390
2023-09-04 21:46:59.961594: predicting val_391
2023-09-04 21:47:00.105942: predicting val_392
2023-09-04 21:47:00.253443: predicting val_393
2023-09-04 21:47:00.400175: predicting val_394
2023-09-04 21:47:00.544460: predicting val_395
2023-09-04 21:47:00.695820: predicting val_396
2023-09-04 21:47:00.844950: predicting val_397
2023-09-04 21:47:01.002429: predicting val_398
2023-09-04 21:47:01.153686: predicting val_399
2023-09-04 21:47:01.298295: predicting val_4
2023-09-04 21:47:01.441627: predicting val_40
2023-09-04 21:47:01.587921: predicting val_400
2023-09-04 21:47:01.736270: predicting val_401
2023-09-04 21:47:01.883296: predicting val_402
2023-09-04 21:47:02.033746: predicting val_403
2023-09-04 21:47:02.178386: predicting val_404
2023-09-04 21:47:02.323199: predicting val_405
2023-09-04 21:47:02.467072: predicting val_406
2023-09-04 21:47:02.610825: predicting val_407
2023-09-04 21:47:02.758420: predicting val_408
2023-09-04 21:47:02.902922: predicting val_409
2023-09-04 21:47:03.047037: predicting val_41
2023-09-04 21:47:03.191439: predicting val_410
2023-09-04 21:47:03.335656: predicting val_411
2023-09-04 21:47:03.480117: predicting val_412
2023-09-04 21:47:03.622694: predicting val_413
2023-09-04 21:47:03.772416: predicting val_414
2023-09-04 21:47:03.922469: predicting val_415
2023-09-04 21:47:04.064284: predicting val_416
2023-09-04 21:47:04.207893: predicting val_417
2023-09-04 21:47:04.359207: predicting val_418
2023-09-04 21:47:04.501492: predicting val_419
2023-09-04 21:47:04.644149: predicting val_42
2023-09-04 21:47:04.786290: predicting val_420
2023-09-04 21:47:04.935074: predicting val_421
2023-09-04 21:47:05.083363: predicting val_422
2023-09-04 21:47:05.239026: predicting val_423
2023-09-04 21:47:05.384324: predicting val_424
2023-09-04 21:47:05.524892: predicting val_425
2023-09-04 21:47:05.667704: predicting val_426
2023-09-04 21:47:05.817108: predicting val_427
2023-09-04 21:47:05.955914: predicting val_428
2023-09-04 21:47:06.101092: predicting val_429
2023-09-04 21:47:06.252450: predicting val_43
2023-09-04 21:47:06.396147: predicting val_430
2023-09-04 21:47:06.540565: predicting val_431
2023-09-04 21:47:06.687119: predicting val_432
2023-09-04 21:47:06.840910: predicting val_433
2023-09-04 21:47:06.996274: predicting val_434
2023-09-04 21:47:07.140508: predicting val_435
2023-09-04 21:47:07.292939: predicting val_436
2023-09-04 21:47:07.441380: predicting val_437
2023-09-04 21:47:07.586762: predicting val_438
2023-09-04 21:47:07.736154: predicting val_439
2023-09-04 21:47:07.881050: predicting val_44
2023-09-04 21:47:08.031332: predicting val_440
2023-09-04 21:47:08.177561: predicting val_441
2023-09-04 21:47:08.321334: predicting val_442
2023-09-04 21:47:08.464774: predicting val_443
2023-09-04 21:47:08.608347: predicting val_444
2023-09-04 21:47:08.749692: predicting val_445
2023-09-04 21:47:08.893133: predicting val_446
2023-09-04 21:47:09.033638: predicting val_447
2023-09-04 21:47:09.192005: predicting val_448
2023-09-04 21:47:09.340865: predicting val_449
2023-09-04 21:47:09.478539: predicting val_45
2023-09-04 21:47:09.615464: predicting val_450
2023-09-04 21:47:09.755762: predicting val_451
2023-09-04 21:47:09.894350: predicting val_452
2023-09-04 21:47:10.030428: predicting val_453
2023-09-04 21:47:10.167243: predicting val_454
2023-09-04 21:47:10.304971: predicting val_455
2023-09-04 21:47:10.442610: predicting val_456
2023-09-04 21:47:10.579436: predicting val_457
2023-09-04 21:47:10.716732: predicting val_458
2023-09-04 21:47:10.853001: predicting val_459
2023-09-04 21:47:10.994761: predicting val_46
2023-09-04 21:47:11.140859: predicting val_460
2023-09-04 21:47:11.285365: predicting val_461
2023-09-04 21:47:11.423384: predicting val_462
2023-09-04 21:47:11.561769: predicting val_463
2023-09-04 21:47:11.699259: predicting val_464
2023-09-04 21:47:11.836504: predicting val_465
2023-09-04 21:47:11.972250: predicting val_466
2023-09-04 21:47:12.109078: predicting val_467
2023-09-04 21:47:12.247613: predicting val_468
2023-09-04 21:47:12.384700: predicting val_469
2023-09-04 21:47:12.522023: predicting val_47
2023-09-04 21:47:12.659697: predicting val_470
2023-09-04 21:47:12.796545: predicting val_471
2023-09-04 21:47:12.933692: predicting val_472
2023-09-04 21:47:13.078033: predicting val_473
2023-09-04 21:47:13.215999: predicting val_474
2023-09-04 21:47:13.356454: predicting val_475
2023-09-04 21:47:13.494485: predicting val_476
2023-09-04 21:47:13.633530: predicting val_477
2023-09-04 21:47:13.771900: predicting val_478
2023-09-04 21:47:13.910789: predicting val_479
2023-09-04 21:47:14.051632: predicting val_48
2023-09-04 21:47:14.197467: predicting val_480
2023-09-04 21:47:14.341221: predicting val_481
2023-09-04 21:47:14.481217: predicting val_482
2023-09-04 21:47:14.620345: predicting val_483
2023-09-04 21:47:14.758538: predicting val_484
2023-09-04 21:47:14.899851: predicting val_485
2023-09-04 21:47:15.047634: predicting val_486
2023-09-04 21:47:15.199732: predicting val_487
2023-09-04 21:47:15.344517: predicting val_488
2023-09-04 21:47:15.482372: predicting val_489
2023-09-04 21:47:15.621535: predicting val_49
2023-09-04 21:47:15.759648: predicting val_490
2023-09-04 21:47:15.896976: predicting val_491
2023-09-04 21:47:16.036308: predicting val_492
2023-09-04 21:47:16.173900: predicting val_493
2023-09-04 21:47:16.311939: predicting val_494
2023-09-04 21:47:16.451369: predicting val_495
2023-09-04 21:47:16.591563: predicting val_496
2023-09-04 21:47:16.729445: predicting val_497
2023-09-04 21:47:16.867400: predicting val_498
2023-09-04 21:47:17.004102: predicting val_499
2023-09-04 21:47:17.144052: predicting val_5
2023-09-04 21:47:17.280659: predicting val_50
2023-09-04 21:47:17.418491: predicting val_500
2023-09-04 21:47:17.555971: predicting val_501
2023-09-04 21:47:17.693569: predicting val_502
2023-09-04 21:47:17.830334: predicting val_503
2023-09-04 21:47:17.967178: predicting val_504
2023-09-04 21:47:18.103836: predicting val_505
2023-09-04 21:47:18.239915: predicting val_506
2023-09-04 21:47:18.377222: predicting val_507
2023-09-04 21:47:18.512442: predicting val_508
2023-09-04 21:47:18.649138: predicting val_509
2023-09-04 21:47:18.784489: predicting val_51
2023-09-04 21:47:18.920043: predicting val_510
2023-09-04 21:47:19.055566: predicting val_511
2023-09-04 21:47:19.193281: predicting val_512
2023-09-04 21:47:19.327328: predicting val_513
2023-09-04 21:47:19.465169: predicting val_514
2023-09-04 21:47:19.601403: predicting val_515
2023-09-04 21:47:19.738460: predicting val_516
2023-09-04 21:47:19.873247: predicting val_517
2023-09-04 21:47:20.011990: predicting val_518
2023-09-04 21:47:20.151778: predicting val_519
2023-09-04 21:47:20.287701: predicting val_52
2023-09-04 21:47:20.423383: predicting val_520
2023-09-04 21:47:20.564051: predicting val_521
2023-09-04 21:47:20.699863: predicting val_522
2023-09-04 21:47:20.836529: predicting val_523
2023-09-04 21:47:20.972020: predicting val_524
2023-09-04 21:47:21.109044: predicting val_525
2023-09-04 21:47:21.249300: predicting val_526
2023-09-04 21:47:21.386967: predicting val_527
2023-09-04 21:47:21.530953: predicting val_528
2023-09-04 21:47:21.666890: predicting val_529
2023-09-04 21:47:21.803576: predicting val_53
2023-09-04 21:47:21.942437: predicting val_530
2023-09-04 21:47:22.089183: predicting val_531
2023-09-04 21:47:22.236600: predicting val_532
2023-09-04 21:47:22.378258: predicting val_533
2023-09-04 21:47:22.521632: predicting val_534
2023-09-04 21:47:22.659698: predicting val_535
2023-09-04 21:47:22.798944: predicting val_536
2023-09-04 21:47:22.938640: predicting val_537
2023-09-04 21:47:23.075559: predicting val_538
2023-09-04 21:47:23.215403: predicting val_539
2023-09-04 21:47:23.355844: predicting val_54
2023-09-04 21:47:23.496618: predicting val_540
2023-09-04 21:47:23.637474: predicting val_541
2023-09-04 21:47:23.775952: predicting val_542
2023-09-04 21:47:23.911903: predicting val_543
2023-09-04 21:47:24.049548: predicting val_544
2023-09-04 21:47:24.186328: predicting val_545
2023-09-04 21:47:24.324000: predicting val_546
2023-09-04 21:47:24.463765: predicting val_547
2023-09-04 21:47:24.603172: predicting val_548
2023-09-04 21:47:24.742645: predicting val_549
2023-09-04 21:47:24.883065: predicting val_55
2023-09-04 21:47:25.023792: predicting val_550
2023-09-04 21:47:25.163709: predicting val_551
2023-09-04 21:47:25.304999: predicting val_552
2023-09-04 21:47:25.445654: predicting val_553
2023-09-04 21:47:25.585665: predicting val_554
2023-09-04 21:47:25.730833: predicting val_555
2023-09-04 21:47:25.868616: predicting val_556
2023-09-04 21:47:26.005954: predicting val_557
2023-09-04 21:47:26.143582: predicting val_558
2023-09-04 21:47:26.280787: predicting val_559
2023-09-04 21:47:26.420761: predicting val_56
2023-09-04 21:47:26.559678: predicting val_560
2023-09-04 21:47:26.703895: predicting val_561
2023-09-04 21:47:26.840863: predicting val_562
2023-09-04 21:47:26.980876: predicting val_563
2023-09-04 21:47:27.117977: predicting val_564
2023-09-04 21:47:27.256005: predicting val_565
2023-09-04 21:47:27.393464: predicting val_566
2023-09-04 21:47:27.536233: predicting val_567
2023-09-04 21:47:27.683504: predicting val_568
2023-09-04 21:47:27.820532: predicting val_569
2023-09-04 21:47:27.958741: predicting val_57
2023-09-04 21:47:28.098689: predicting val_570
2023-09-04 21:47:28.236648: predicting val_571
2023-09-04 21:47:28.376115: predicting val_572
2023-09-04 21:47:28.515926: predicting val_573
2023-09-04 21:47:28.654913: predicting val_574
2023-09-04 21:47:28.791521: predicting val_575
2023-09-04 21:47:28.929055: predicting val_576
2023-09-04 21:47:29.066378: predicting val_577
2023-09-04 21:47:29.203558: predicting val_578
2023-09-04 21:47:29.340635: predicting val_579
2023-09-04 21:47:29.489627: predicting val_58
2023-09-04 21:47:29.627482: predicting val_580
2023-09-04 21:47:29.770756: predicting val_581
2023-09-04 21:47:29.908340: predicting val_582
2023-09-04 21:47:30.045342: predicting val_583
2023-09-04 21:47:30.180604: predicting val_584
2023-09-04 21:47:30.317511: predicting val_585
2023-09-04 21:47:30.454000: predicting val_586
2023-09-04 21:47:30.593149: predicting val_587
2023-09-04 21:47:30.731695: predicting val_588
2023-09-04 21:47:30.869947: predicting val_589
2023-09-04 21:47:31.006325: predicting val_59
2023-09-04 21:47:31.143375: predicting val_590
2023-09-04 21:47:31.283449: predicting val_591
2023-09-04 21:47:31.421962: predicting val_592
2023-09-04 21:47:31.560121: predicting val_593
2023-09-04 21:47:31.697192: predicting val_594
2023-09-04 21:47:31.842979: predicting val_595
2023-09-04 21:47:31.985559: predicting val_596
2023-09-04 21:47:32.122911: predicting val_597
2023-09-04 21:47:32.263942: predicting val_598
2023-09-04 21:47:32.413227: predicting val_599
2023-09-04 21:47:32.554064: predicting val_6
2023-09-04 21:47:32.694930: predicting val_60
2023-09-04 21:47:32.835828: predicting val_600
2023-09-04 21:47:32.983055: predicting val_601
2023-09-04 21:47:33.126992: predicting val_602
2023-09-04 21:47:33.266555: predicting val_603
2023-09-04 21:47:33.407265: predicting val_604
2023-09-04 21:47:33.557466: predicting val_605
2023-09-04 21:47:33.695941: predicting val_606
2023-09-04 21:47:33.836428: predicting val_607
2023-09-04 21:47:33.979865: predicting val_608
2023-09-04 21:47:34.122427: predicting val_609
2023-09-04 21:47:34.265300: predicting val_61
2023-09-04 21:47:34.406794: predicting val_610
2023-09-04 21:47:34.547881: predicting val_611
2023-09-04 21:47:34.689332: predicting val_612
2023-09-04 21:47:34.836665: predicting val_613
2023-09-04 21:47:34.972549: predicting val_614
2023-09-04 21:47:35.110066: predicting val_615
2023-09-04 21:47:35.247381: predicting val_616
2023-09-04 21:47:35.383469: predicting val_617
2023-09-04 21:47:35.521243: predicting val_618
2023-09-04 21:47:35.677138: predicting val_619
2023-09-04 21:47:35.816187: predicting val_62
2023-09-04 21:47:35.952943: predicting val_620
2023-09-04 21:47:36.089382: predicting val_621
2023-09-04 21:47:36.228416: predicting val_622
2023-09-04 21:47:36.367788: predicting val_623
2023-09-04 21:47:36.504684: predicting val_624
2023-09-04 21:47:36.650845: predicting val_625
2023-09-04 21:47:36.788058: predicting val_626
2023-09-04 21:47:36.927033: predicting val_627
2023-09-04 21:47:37.063970: predicting val_628
2023-09-04 21:47:37.202860: predicting val_629
2023-09-04 21:47:37.342829: predicting val_63
2023-09-04 21:47:37.488093: predicting val_630
2023-09-04 21:47:37.626569: predicting val_631
2023-09-04 21:47:37.768108: predicting val_632
2023-09-04 21:47:37.918743: predicting val_633
2023-09-04 21:47:38.065027: predicting val_634
2023-09-04 21:47:38.204738: predicting val_635
2023-09-04 21:47:38.344092: predicting val_636
2023-09-04 21:47:38.487560: predicting val_637
2023-09-04 21:47:38.624212: predicting val_638
2023-09-04 21:47:38.765670: predicting val_639
2023-09-04 21:47:38.903023: predicting val_64
2023-09-04 21:47:39.041193: predicting val_640
2023-09-04 21:47:39.184762: predicting val_641
2023-09-04 21:47:39.328388: predicting val_642
2023-09-04 21:47:39.469496: predicting val_643
2023-09-04 21:47:39.610834: predicting val_644
2023-09-04 21:47:39.756339: predicting val_645
2023-09-04 21:47:39.897766: predicting val_646
2023-09-04 21:47:40.037464: predicting val_647
2023-09-04 21:47:40.175092: predicting val_648
2023-09-04 21:47:40.316878: predicting val_649
2023-09-04 21:47:40.453486: predicting val_65
2023-09-04 21:47:40.596888: predicting val_650
2023-09-04 21:47:40.739095: predicting val_651
2023-09-04 21:47:40.878390: predicting val_652
2023-09-04 21:47:41.021769: predicting val_653
2023-09-04 21:47:41.162120: predicting val_654
2023-09-04 21:47:41.300606: predicting val_655
2023-09-04 21:47:41.439657: predicting val_656
2023-09-04 21:47:41.576688: predicting val_657
2023-09-04 21:47:41.718443: predicting val_658
2023-09-04 21:47:41.863849: predicting val_659
2023-09-04 21:47:42.007749: predicting val_66
2023-09-04 21:47:42.148518: predicting val_660
2023-09-04 21:47:42.287086: predicting val_661
2023-09-04 21:47:42.432379: predicting val_662
2023-09-04 21:47:42.575421: predicting val_663
2023-09-04 21:47:42.711376: predicting val_664
2023-09-04 21:47:42.853108: predicting val_665
2023-09-04 21:47:42.991559: predicting val_666
2023-09-04 21:47:43.129865: predicting val_667
2023-09-04 21:47:43.278000: predicting val_668
2023-09-04 21:47:43.417247: predicting val_669
2023-09-04 21:47:43.555557: predicting val_67
2023-09-04 21:47:43.701160: predicting val_670
2023-09-04 21:47:43.839903: predicting val_671
2023-09-04 21:47:43.976993: predicting val_672
2023-09-04 21:47:44.116497: predicting val_673
2023-09-04 21:47:44.254663: predicting val_674
2023-09-04 21:47:44.393481: predicting val_675
2023-09-04 21:47:44.533998: predicting val_676
2023-09-04 21:47:44.674574: predicting val_677
2023-09-04 21:47:44.815049: predicting val_678
2023-09-04 21:47:44.954486: predicting val_679
2023-09-04 21:47:45.092067: predicting val_68
2023-09-04 21:47:45.239934: predicting val_680
2023-09-04 21:47:45.384217: predicting val_681
2023-09-04 21:47:45.530097: predicting val_682
2023-09-04 21:47:45.676334: predicting val_683
2023-09-04 21:47:45.830022: predicting val_684
2023-09-04 21:47:45.988266: predicting val_685
2023-09-04 21:47:46.134579: predicting val_686
2023-09-04 21:47:46.283984: predicting val_687
2023-09-04 21:47:46.430048: predicting val_688
2023-09-04 21:47:46.574296: predicting val_689
2023-09-04 21:47:46.717300: predicting val_69
2023-09-04 21:47:46.867324: predicting val_690
2023-09-04 21:47:47.017195: predicting val_691
2023-09-04 21:47:47.163190: predicting val_692
2023-09-04 21:47:47.307160: predicting val_693
2023-09-04 21:47:47.448648: predicting val_694
2023-09-04 21:47:47.592696: predicting val_695
2023-09-04 21:47:47.741617: predicting val_696
2023-09-04 21:47:47.889357: predicting val_697
2023-09-04 21:47:48.036013: predicting val_698
2023-09-04 21:47:48.184075: predicting val_699
2023-09-04 21:47:48.326280: predicting val_7
2023-09-04 21:47:48.471389: predicting val_70
2023-09-04 21:47:48.620663: predicting val_700
2023-09-04 21:47:48.769626: predicting val_701
2023-09-04 21:47:48.912413: predicting val_702
2023-09-04 21:47:49.057310: predicting val_703
2023-09-04 21:47:49.201877: predicting val_704
2023-09-04 21:47:49.342620: predicting val_705
2023-09-04 21:47:49.486834: predicting val_706
2023-09-04 21:47:49.629884: predicting val_707
2023-09-04 21:47:49.786461: predicting val_708
2023-09-04 21:47:49.943672: predicting val_709
2023-09-04 21:47:50.095462: predicting val_71
2023-09-04 21:47:50.237132: predicting val_710
2023-09-04 21:47:50.378557: predicting val_711
2023-09-04 21:47:50.521871: predicting val_712
2023-09-04 21:47:50.670901: predicting val_713
2023-09-04 21:47:50.819612: predicting val_714
2023-09-04 21:47:50.963642: predicting val_715
2023-09-04 21:47:51.105464: predicting val_716
2023-09-04 21:47:51.253108: predicting val_717
2023-09-04 21:47:51.400842: predicting val_718
2023-09-04 21:47:51.542882: predicting val_719
2023-09-04 21:47:51.683057: predicting val_72
2023-09-04 21:47:51.833111: predicting val_720
2023-09-04 21:47:51.973905: predicting val_721
2023-09-04 21:47:52.118037: predicting val_722
2023-09-04 21:47:52.271789: predicting val_723
2023-09-04 21:47:52.413628: predicting val_724
2023-09-04 21:47:52.555130: predicting val_725
2023-09-04 21:47:52.695509: predicting val_726
2023-09-04 21:47:52.834450: predicting val_727
2023-09-04 21:47:52.969960: predicting val_728
2023-09-04 21:47:53.111333: predicting val_729
2023-09-04 21:47:53.251058: predicting val_73
2023-09-04 21:47:53.389888: predicting val_730
2023-09-04 21:47:53.529245: predicting val_731
2023-09-04 21:47:53.669754: predicting val_732
2023-09-04 21:47:53.813295: predicting val_733
2023-09-04 21:47:53.958536: predicting val_734
2023-09-04 21:47:54.109206: predicting val_735
2023-09-04 21:47:54.268657: predicting val_736
2023-09-04 21:47:54.414789: predicting val_737
2023-09-04 21:47:54.562057: predicting val_738
2023-09-04 21:47:54.708913: predicting val_739
2023-09-04 21:47:54.857002: predicting val_74
2023-09-04 21:47:55.005464: predicting val_740
2023-09-04 21:47:55.147783: predicting val_741
2023-09-04 21:47:55.290845: predicting val_742
2023-09-04 21:47:55.444617: predicting val_743
2023-09-04 21:47:55.593498: predicting val_744
2023-09-04 21:47:55.743308: predicting val_745
2023-09-04 21:47:55.891187: predicting val_746
2023-09-04 21:47:56.047533: predicting val_747
2023-09-04 21:47:56.192858: predicting val_748
2023-09-04 21:47:56.337315: predicting val_749
2023-09-04 21:47:56.477207: predicting val_75
2023-09-04 21:47:56.617232: predicting val_750
2023-09-04 21:47:56.758501: predicting val_751
2023-09-04 21:47:56.898167: predicting val_752
2023-09-04 21:47:57.038942: predicting val_753
2023-09-04 21:47:57.177437: predicting val_754
2023-09-04 21:47:57.318353: predicting val_755
2023-09-04 21:47:57.459539: predicting val_756
2023-09-04 21:47:57.602349: predicting val_757
2023-09-04 21:47:57.750222: predicting val_758
2023-09-04 21:47:57.900227: predicting val_759
2023-09-04 21:47:58.041395: predicting val_76
2023-09-04 21:47:58.186378: predicting val_760
2023-09-04 21:47:58.331448: predicting val_761
2023-09-04 21:47:58.470069: predicting val_762
2023-09-04 21:47:58.617144: predicting val_763
2023-09-04 21:47:58.758204: predicting val_764
2023-09-04 21:47:58.896848: predicting val_765
2023-09-04 21:47:59.036365: predicting val_766
2023-09-04 21:47:59.176324: predicting val_767
2023-09-04 21:47:59.316231: predicting val_768
2023-09-04 21:47:59.456781: predicting val_769
2023-09-04 21:47:59.596648: predicting val_77
2023-09-04 21:47:59.736444: predicting val_770
2023-09-04 21:47:59.875014: predicting val_771
2023-09-04 21:48:00.017593: predicting val_772
2023-09-04 21:48:00.156429: predicting val_773
2023-09-04 21:48:00.296231: predicting val_774
2023-09-04 21:48:00.444515: predicting val_775
2023-09-04 21:48:00.583107: predicting val_776
2023-09-04 21:48:00.721067: predicting val_777
2023-09-04 21:48:00.860450: predicting val_778
2023-09-04 21:48:00.998789: predicting val_779
2023-09-04 21:48:01.138665: predicting val_78
2023-09-04 21:48:01.281933: predicting val_780
2023-09-04 21:48:01.420391: predicting val_781
2023-09-04 21:48:01.561861: predicting val_782
2023-09-04 21:48:01.702561: predicting val_783
2023-09-04 21:48:01.847893: predicting val_784
2023-09-04 21:48:01.991829: predicting val_785
2023-09-04 21:48:02.148648: predicting val_786
2023-09-04 21:48:02.289287: predicting val_787
2023-09-04 21:48:02.427502: predicting val_788
2023-09-04 21:48:02.571596: predicting val_789
2023-09-04 21:48:02.714863: predicting val_79
2023-09-04 21:48:02.851131: predicting val_790
2023-09-04 21:48:02.991508: predicting val_791
2023-09-04 21:48:03.130887: predicting val_792
2023-09-04 21:48:03.273290: predicting val_793
2023-09-04 21:48:03.410803: predicting val_794
2023-09-04 21:48:03.552164: predicting val_795
2023-09-04 21:48:03.690126: predicting val_796
2023-09-04 21:48:03.827117: predicting val_797
2023-09-04 21:48:03.964473: predicting val_798
2023-09-04 21:48:04.108875: predicting val_799
2023-09-04 21:48:04.253342: predicting val_8
2023-09-04 21:48:04.394900: predicting val_80
2023-09-04 21:48:04.530285: predicting val_800
2023-09-04 21:48:04.665664: predicting val_801
2023-09-04 21:48:04.803479: predicting val_802
2023-09-04 21:48:04.988886: predicting val_803
2023-09-04 21:48:05.155200: predicting val_804
2023-09-04 21:48:05.311566: predicting val_805
2023-09-04 21:48:05.452818: predicting val_806
2023-09-04 21:48:05.598587: predicting val_807
2023-09-04 21:48:05.739126: predicting val_81
2023-09-04 21:48:05.878020: predicting val_82
2023-09-04 21:48:06.020899: predicting val_83
2023-09-04 21:48:06.170229: predicting val_84
2023-09-04 21:48:06.318037: predicting val_85
2023-09-04 21:48:06.465037: predicting val_86
2023-09-04 21:48:06.624609: predicting val_87
2023-09-04 21:48:06.778128: predicting val_88
2023-09-04 21:48:06.930072: predicting val_89
2023-09-04 21:48:07.091421: predicting val_9
2023-09-04 21:48:07.236468: predicting val_90
2023-09-04 21:48:07.379335: predicting val_91
2023-09-04 21:48:07.528155: predicting val_92
2023-09-04 21:48:07.675562: predicting val_93
2023-09-04 21:48:07.834200: predicting val_94
2023-09-04 21:48:07.976355: predicting val_95
2023-09-04 21:48:08.119993: predicting val_96
2023-09-04 21:48:08.270276: predicting val_97
2023-09-04 21:48:08.410784: predicting val_98
2023-09-04 21:48:08.550399: predicting val_99
2023-09-04 21:48:16.732654: Validation complete
2023-09-04 21:48:16.735069: Mean Validation Dice:  0.9033195958157891
