OrderedDict([('self', <Parameter "self">), ('plans', <Parameter "plans: dict">), ('configuration', <Parameter "configuration: str">), ('fold', <Parameter "fold: int">), ('dataset_json', <Parameter "dataset_json: dict">), ('unpack_dataset', <Parameter "unpack_dataset: bool = True">), ('device', <Parameter "device: torch.device = device(type='cuda')">), ('debug', <Parameter "debug=True">), ('job_id', <Parameter "job_id=None">)])
Using device: cuda:0
==========================initial_lr: 0.005===========================
2023-09-03 13:12:52.787275: I am training on qa-rtx6k-022.crc.nd.edu
2023-09-03 13:12:52.789474: output folder: /afs/crc.nd.edu/user/y/ypeng4/data/trained_models/Dataset124_ISIC2018/ISICTrainer__nnUNetPlans__2d/458823_my_unet_FusedMBConv_16/fold_0

#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################

WARNING: Cannot continue training because there seems to be no checkpoint available to continue from. Starting a new training...
===============use SpatialAtt + ChannelAtt and My attention layer===============
model: PVTNetwork_1(
  (backbone): pvt_v2_b2(
    (patch_embed1): OverlapPatchEmbed(
      (proj): Conv2d(3, 64, kernel_size=(7, 7), stride=(4, 4), padding=(3, 3))
      (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
    )
    (patch_embed2): OverlapPatchEmbed(
      (proj): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
    )
    (patch_embed3): OverlapPatchEmbed(
      (proj): Conv2d(128, 320, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
    )
    (patch_embed4): OverlapPatchEmbed(
      (proj): Conv2d(320, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    )
    (block1): ModuleList(
      (0): Block(
        (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=64, out_features=64, bias=True)
          (kv): Linear(in_features=64, out_features=128, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=64, out_features=64, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (sr): Conv2d(64, 64, kernel_size=(8, 8), stride=(8, 8))
          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (drop_path): Identity()
        (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=64, out_features=512, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
          )
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=512, out_features=64, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (1): Block(
        (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=64, out_features=64, bias=True)
          (kv): Linear(in_features=64, out_features=128, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=64, out_features=64, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (sr): Conv2d(64, 64, kernel_size=(8, 8), stride=(8, 8))
          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (drop_path): DropPath(drop_prob=0.007)
        (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=64, out_features=512, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
          )
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=512, out_features=64, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (2): Block(
        (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=64, out_features=64, bias=True)
          (kv): Linear(in_features=64, out_features=128, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=64, out_features=64, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (sr): Conv2d(64, 64, kernel_size=(8, 8), stride=(8, 8))
          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (drop_path): DropPath(drop_prob=0.013)
        (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=64, out_features=512, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
          )
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=512, out_features=64, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
    )
    (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
    (block2): ModuleList(
      (0): Block(
        (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=128, out_features=128, bias=True)
          (kv): Linear(in_features=128, out_features=256, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=128, out_features=128, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (sr): Conv2d(128, 128, kernel_size=(4, 4), stride=(4, 4))
          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (drop_path): DropPath(drop_prob=0.020)
        (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=128, out_features=1024, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
          )
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=1024, out_features=128, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (1): Block(
        (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=128, out_features=128, bias=True)
          (kv): Linear(in_features=128, out_features=256, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=128, out_features=128, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (sr): Conv2d(128, 128, kernel_size=(4, 4), stride=(4, 4))
          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (drop_path): DropPath(drop_prob=0.027)
        (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=128, out_features=1024, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
          )
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=1024, out_features=128, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (2): Block(
        (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=128, out_features=128, bias=True)
          (kv): Linear(in_features=128, out_features=256, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=128, out_features=128, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (sr): Conv2d(128, 128, kernel_size=(4, 4), stride=(4, 4))
          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (drop_path): DropPath(drop_prob=0.033)
        (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=128, out_features=1024, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
          )
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=1024, out_features=128, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (3): Block(
        (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=128, out_features=128, bias=True)
          (kv): Linear(in_features=128, out_features=256, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=128, out_features=128, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (sr): Conv2d(128, 128, kernel_size=(4, 4), stride=(4, 4))
          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (drop_path): DropPath(drop_prob=0.040)
        (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=128, out_features=1024, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
          )
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=1024, out_features=128, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
    )
    (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
    (block3): ModuleList(
      (0): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
        )
        (drop_path): DropPath(drop_prob=0.047)
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (1): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
        )
        (drop_path): DropPath(drop_prob=0.053)
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (2): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
        )
        (drop_path): DropPath(drop_prob=0.060)
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (3): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
        )
        (drop_path): DropPath(drop_prob=0.067)
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (4): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
        )
        (drop_path): DropPath(drop_prob=0.073)
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (5): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
        )
        (drop_path): DropPath(drop_prob=0.080)
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
    )
    (norm3): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
    (block4): ModuleList(
      (0): Block(
        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=512, out_features=512, bias=True)
          (kv): Linear(in_features=512, out_features=1024, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (drop_path): DropPath(drop_prob=0.087)
        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)
          )
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (1): Block(
        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=512, out_features=512, bias=True)
          (kv): Linear(in_features=512, out_features=1024, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (drop_path): DropPath(drop_prob=0.093)
        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)
          )
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (2): Block(
        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=512, out_features=512, bias=True)
          (kv): Linear(in_features=512, out_features=1024, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (drop_path): DropPath(drop_prob=0.100)
        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)
          )
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
    )
    (norm4): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
  )
  (ca_1): ChannelAttention(
    (avg_pool): AdaptiveAvgPool2d(output_size=1)
    (max_pool): AdaptiveMaxPool2d(output_size=1)
    (fc1): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (relu1): ReLU()
    (fc2): Conv2d(4, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (sigmoid): Sigmoid()
  )
  (sa_1): SpatialAttention(
    (conv1): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
    (sigmoid): Sigmoid()
  )
  (ca_2): ChannelAttention(
    (avg_pool): AdaptiveAvgPool2d(output_size=1)
    (max_pool): AdaptiveMaxPool2d(output_size=1)
    (fc1): Conv2d(128, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (relu1): ReLU()
    (fc2): Conv2d(8, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (sigmoid): Sigmoid()
  )
  (sa_2): SpatialAttention(
    (conv1): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
    (sigmoid): Sigmoid()
  )
  (ca_3): ChannelAttention(
    (avg_pool): AdaptiveAvgPool2d(output_size=1)
    (max_pool): AdaptiveMaxPool2d(output_size=1)
    (fc1): Conv2d(320, 20, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (relu1): ReLU()
    (fc2): Conv2d(20, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (sigmoid): Sigmoid()
  )
  (sa_3): SpatialAttention(
    (conv1): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
    (sigmoid): Sigmoid()
  )
  (ca_4): ChannelAttention(
    (avg_pool): AdaptiveAvgPool2d(output_size=1)
    (max_pool): AdaptiveMaxPool2d(output_size=1)
    (fc1): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (relu1): ReLU()
    (fc2): Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (sigmoid): Sigmoid()
  )
  (sa_4): SpatialAttention(
    (conv1): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
    (sigmoid): Sigmoid()
  )
  (Translayer_1): BasicConv2d(
    (conv): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (Translayer_2): BasicConv2d(
    (conv): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (Translayer_3): BasicConv2d(
    (conv): Conv2d(320, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (Translayer_4): BasicConv2d(
    (conv): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (attention_1): AttentionLayer(
    (convs): ModuleList(
      (0-3): 4 x Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
  )
  (attention_2): AttentionLayer(
    (convs): ModuleList(
      (0-3): 4 x Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
  )
  (attention_3): AttentionLayer(
    (convs): ModuleList(
      (0-3): 4 x Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
  )
  (attention_4): AttentionLayer(
    (convs): ModuleList(
      (0-3): 4 x Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
  )
  (seg_outs): ModuleList(
    (0-3): 4 x Conv2d(32, 2, kernel_size=(1, 1), stride=(1, 1))
  )
  (deconv2): ConvTranspose2d(32, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
  (deconv3): ConvTranspose2d(32, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
  (deconv4): ConvTranspose2d(32, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
  (deconv5): ConvTranspose2d(32, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
)
===============<class 'nnunetv2.training.network.model.dim2.pvt.pvt_1.PVTNetwork_1'>================
ds wegihts: [0.53333333 0.26666667 0.13333333 0.06666667]

This is the configuration used by this training:
Configuration name: 2d
 {'data_identifier': 'nnUNetPlans_2d', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 49, 'patch_size': [256, 256], 'median_image_size_in_voxels': [256.0, 256.0], 'spacing': [1.0, 1.0], 'normalization_schemes': ['ZScoreNormalization', 'ZScoreNormalization', 'ZScoreNormalization'], 'use_mask_for_norm': [False, False, False], 'UNet_class_name': 'PlainConvUNet', 'nnUNet_UNet': False, 'my_net_class': 'pvt_1', 'UNet_base_num_features': 32, 'n_conv_per_stage_encoder': [2, 2, 2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2, 2, 2], 'num_pool_per_axis': [6, 6], 'pool_op_kernel_sizes': [[1, 1], [2, 2], [2, 2], [2, 2], [2, 2], [2, 2], [2, 2]], 'conv_kernel_sizes': [[3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3]], 'unet_max_num_features': 512, 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'batch_dice': True} 

These are the global plan.json settings:
 {'dataset_name': 'Dataset124_ISIC2018', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [999.0, 1.0, 1.0], 'original_median_shape_after_transp': [1, 256, 256], 'image_reader_writer': 'NaturalImage2DIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 255.0, 'mean': 160.57754516601562, 'median': 164.0, 'min': 0.0, 'percentile_00_5': 29.0, 'percentile_99_5': 253.0, 'std': 42.08180618286133}, '1': {'max': 255.0, 'mean': 111.1130142211914, 'median': 113.0, 'min': 0.0, 'percentile_00_5': 8.0, 'percentile_99_5': 222.0, 'std': 43.864933013916016}, '2': {'max': 255.0, 'mean': 91.45153045654297, 'median': 91.0, 'min': 0.0, 'percentile_00_5': 4.0, 'percentile_99_5': 209.0, 'std': 43.73163604736328}}} 

2023-09-03 13:13:06.621223: unpacking dataset...
2023-09-03 13:13:28.348767: unpacking done...
2023-09-03 13:13:28.350080: do_dummy_2d_data_aug: False
2023-09-03 13:13:28.376994: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 13:13:28.379371: The split file contains 1 splits.
2023-09-03 13:13:28.386214: Desired fold for training: 0
2023-09-03 13:13:28.393781: This split has 1886 training and 808 validation cases.
==================batch size: 49==================
2023-09-03 13:13:28.543442: Unable to plot network architecture:
2023-09-03 13:13:28.550460: No module named 'hiddenlayer'
PVTNetwork_1
===================debug: False===================
2023-09-03 13:13:30.966574: 
2023-09-03 13:13:30.967587: Epoch 0
2023-09-03 13:13:30.974887: Current learning rate: backbone 0.001, others 0.001
2023-09-03 13:13:30.981553: start training, 250
==========num_iterations_per_epoch: 250===========
using pin_memory on device 0
2023-09-03 13:14:51.341444: finished training epoch 0
2023-09-03 13:14:51.367795: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 13:14:51.369085: The split file contains 1 splits.
2023-09-03 13:14:51.369699: Desired fold for training: 0
2023-09-03 13:14:51.370237: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 13:19:32.838002: dsc: 84.56%
2023-09-03 13:19:32.839195: miou: 73.25%
2023-09-03 13:19:32.840196: acc: 93.10%, sen: 75.10%, spe: 99.15%
2023-09-03 13:19:32.841895: current best miou: 0.7324886330629232 at epoch: 0, (0, 0.7324886330629232, 0.8455912715201284)
2023-09-03 13:19:32.842530: current best dsc: 0.8455912715201284 at epoch: 0, (0, 0.7324886330629232, 0.8455912715201284)
2023-09-03 13:19:34.722715: finished real validation
using pin_memory on device 0
2023-09-03 13:19:39.814894: train_loss -0.5411
2023-09-03 13:19:39.815991: val_loss -1.0082
2023-09-03 13:19:39.817537: Pseudo dice [0.8392]
2023-09-03 13:19:39.818333: Epoch time: 368.85 s
2023-09-03 13:19:39.819007: Yayy! New best EMA pseudo Dice: 0.8392
2023-09-03 13:19:42.765439: 
2023-09-03 13:19:42.767934: Epoch 1
2023-09-03 13:19:42.770746: Current learning rate: backbone 0.000997, others 0.000997
2023-09-03 13:19:42.772228: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 13:20:43.683938: finished training epoch 1
2023-09-03 13:20:43.714031: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 13:20:43.715559: The split file contains 1 splits.
2023-09-03 13:20:43.716253: Desired fold for training: 0
2023-09-03 13:20:43.716825: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 13:25:51.742091: dsc: 89.75%
2023-09-03 13:25:51.743487: miou: 81.41%
2023-09-03 13:25:51.744248: acc: 94.98%, sen: 87.39%, spe: 97.53%
2023-09-03 13:25:51.745314: current best miou: 0.8140592655552009 at epoch: 1, (1, 0.8140592655552009, 0.8975001875763463)
2023-09-03 13:25:51.746216: current best dsc: 0.8975001875763463 at epoch: 1, (1, 0.8140592655552009, 0.8975001875763463)
2023-09-03 13:25:53.291512: finished real validation
2023-09-03 13:25:57.664155: train_loss -1.1694
2023-09-03 13:25:57.665847: val_loss -1.1532
2023-09-03 13:25:57.666818: Pseudo dice [0.8961]
2023-09-03 13:25:57.667595: Epoch time: 374.9 s
2023-09-03 13:25:57.668238: Yayy! New best EMA pseudo Dice: 0.8449
2023-09-03 13:26:00.262756: 
2023-09-03 13:26:00.263728: Epoch 2
2023-09-03 13:26:00.264524: Current learning rate: backbone 0.000994, others 0.000994
2023-09-03 13:26:00.265511: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 13:27:01.383073: finished training epoch 2
2023-09-03 13:27:01.418126: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 13:27:01.419925: The split file contains 1 splits.
2023-09-03 13:27:01.420632: Desired fold for training: 0
2023-09-03 13:27:01.425301: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 13:32:09.901947: dsc: 90.23%
2023-09-03 13:32:09.903272: miou: 82.20%
2023-09-03 13:32:09.903964: acc: 95.11%, sen: 89.71%, spe: 96.93%
2023-09-03 13:32:09.904982: current best miou: 0.8220260155271973 at epoch: 2, (2, 0.8220260155271973, 0.9023208324381107)
2023-09-03 13:32:09.905857: current best dsc: 0.9023208324381107 at epoch: 2, (2, 0.8220260155271973, 0.9023208324381107)
2023-09-03 13:32:11.436571: finished real validation
2023-09-03 13:32:15.789224: train_loss -1.2476
2023-09-03 13:32:15.790414: val_loss -1.1685
2023-09-03 13:32:15.792089: Pseudo dice [0.9059]
2023-09-03 13:32:15.793297: Epoch time: 375.53 s
2023-09-03 13:32:15.794161: Yayy! New best EMA pseudo Dice: 0.851
2023-09-03 13:32:18.621361: 
2023-09-03 13:32:18.622516: Epoch 3
2023-09-03 13:32:18.623239: Current learning rate: backbone 0.000991, others 0.000991
2023-09-03 13:32:18.624630: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 13:33:20.165401: finished training epoch 3
2023-09-03 13:33:20.198445: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 13:33:20.200272: The split file contains 1 splits.
2023-09-03 13:33:20.200921: Desired fold for training: 0
2023-09-03 13:33:20.201545: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 13:38:29.613386: dsc: 90.70%
2023-09-03 13:38:29.614594: miou: 82.98%
2023-09-03 13:38:29.615402: acc: 95.37%, sen: 89.83%, spe: 97.23%
2023-09-03 13:38:29.616529: current best miou: 0.8298473384584683 at epoch: 3, (3, 0.8298473384584683, 0.9070126463747108)
2023-09-03 13:38:29.617143: current best dsc: 0.9070126463747108 at epoch: 3, (3, 0.8298473384584683, 0.9070126463747108)
2023-09-03 13:38:31.144799: finished real validation
2023-09-03 13:38:35.501684: train_loss -1.2734
2023-09-03 13:38:35.502796: val_loss -1.1772
2023-09-03 13:38:35.503759: Pseudo dice [0.9055]
2023-09-03 13:38:35.504524: Epoch time: 376.88 s
2023-09-03 13:38:35.505392: Yayy! New best EMA pseudo Dice: 0.8565
2023-09-03 13:38:38.088744: 
2023-09-03 13:38:38.089745: Epoch 4
2023-09-03 13:38:38.090865: Current learning rate: backbone 0.00098799, others 0.00098799
2023-09-03 13:38:38.092508: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 13:39:39.171377: finished training epoch 4
2023-09-03 13:39:39.199033: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 13:39:39.200443: The split file contains 1 splits.
2023-09-03 13:39:39.201143: Desired fold for training: 0
2023-09-03 13:39:39.201688: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 13:44:52.181416: dsc: 90.01%
2023-09-03 13:44:52.182805: miou: 81.83%
2023-09-03 13:44:52.183424: acc: 95.02%, sen: 89.12%, spe: 97.01%
2023-09-03 13:44:52.184602: current best miou: 0.8298473384584683 at epoch: 3, (3, 0.8298473384584683, 0.9070126463747108)
2023-09-03 13:44:52.185200: current best dsc: 0.9070126463747108 at epoch: 3, (3, 0.8298473384584683, 0.9070126463747108)
2023-09-03 13:44:52.185717: finished real validation
2023-09-03 13:44:56.577901: train_loss -1.2948
2023-09-03 13:44:56.579200: val_loss -1.1466
2023-09-03 13:44:56.580372: Pseudo dice [0.9003]
2023-09-03 13:44:56.581784: Epoch time: 378.49 s
2023-09-03 13:44:56.582517: Yayy! New best EMA pseudo Dice: 0.8608
2023-09-03 13:44:59.382733: 
2023-09-03 13:44:59.383773: Epoch 5
2023-09-03 13:44:59.384516: Current learning rate: backbone 0.00098499, others 0.00098499
2023-09-03 13:44:59.385715: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 13:46:01.038207: finished training epoch 5
2023-09-03 13:46:01.065536: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 13:46:01.066971: The split file contains 1 splits.
2023-09-03 13:46:01.067718: Desired fold for training: 0
2023-09-03 13:46:01.068342: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 13:51:53.483594: dsc: 90.93%
2023-09-03 13:51:53.485260: miou: 83.38%
2023-09-03 13:51:53.485917: acc: 95.44%, sen: 90.96%, spe: 96.94%
2023-09-03 13:51:53.487692: current best miou: 0.8337578236146531 at epoch: 5, (5, 0.8337578236146531, 0.9093434398781979)
2023-09-03 13:51:53.488387: current best dsc: 0.9093434398781979 at epoch: 5, (5, 0.8337578236146531, 0.9093434398781979)
2023-09-03 13:51:55.062528: finished real validation
2023-09-03 13:51:59.446319: train_loss -1.3055
2023-09-03 13:51:59.447495: val_loss -1.172
2023-09-03 13:51:59.448532: Pseudo dice [0.9061]
2023-09-03 13:51:59.449413: Epoch time: 420.07 s
2023-09-03 13:51:59.449987: Yayy! New best EMA pseudo Dice: 0.8654
2023-09-03 13:52:02.204967: 
2023-09-03 13:52:02.206023: Epoch 6
2023-09-03 13:52:02.206716: Current learning rate: backbone 0.00098198, others 0.00098198
2023-09-03 13:52:02.207852: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 13:53:03.613320: finished training epoch 6
2023-09-03 13:53:03.638388: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 13:53:03.639923: The split file contains 1 splits.
2023-09-03 13:53:03.640747: Desired fold for training: 0
2023-09-03 13:53:03.641497: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 13:58:37.457854: dsc: 90.80%
2023-09-03 13:58:37.458926: miou: 83.16%
2023-09-03 13:58:37.459632: acc: 95.47%, sen: 88.98%, spe: 97.65%
2023-09-03 13:58:37.460594: current best miou: 0.8337578236146531 at epoch: 5, (5, 0.8337578236146531, 0.9093434398781979)
2023-09-03 13:58:37.461350: current best dsc: 0.9093434398781979 at epoch: 5, (5, 0.8337578236146531, 0.9093434398781979)
2023-09-03 13:58:37.461849: finished real validation
2023-09-03 13:58:41.856006: train_loss -1.3158
2023-09-03 13:58:41.857147: val_loss -1.1921
2023-09-03 13:58:41.858244: Pseudo dice [0.9105]
2023-09-03 13:58:41.859076: Epoch time: 399.65 s
2023-09-03 13:58:41.859813: Yayy! New best EMA pseudo Dice: 0.8699
2023-09-03 13:58:44.595217: 
2023-09-03 13:58:44.596309: Epoch 7
2023-09-03 13:58:44.597138: Current learning rate: backbone 0.00097898, others 0.00097898
2023-09-03 13:58:44.598289: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 13:59:46.179418: finished training epoch 7
2023-09-03 13:59:46.219332: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 13:59:46.220821: The split file contains 1 splits.
2023-09-03 13:59:46.221794: Desired fold for training: 0
2023-09-03 13:59:46.222670: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 14:05:19.532064: dsc: 90.97%
2023-09-03 14:05:19.533325: miou: 83.44%
2023-09-03 14:05:19.534043: acc: 95.52%, sen: 89.71%, spe: 97.47%
2023-09-03 14:05:19.538810: current best miou: 0.8344327376711419 at epoch: 7, (7, 0.8344327376711419, 0.9097447080348937)
2023-09-03 14:05:19.539531: current best dsc: 0.9097447080348937 at epoch: 7, (7, 0.8344327376711419, 0.9097447080348937)
2023-09-03 14:05:21.140146: finished real validation
2023-09-03 14:05:25.506017: train_loss -1.3235
2023-09-03 14:05:25.511833: val_loss -1.192
2023-09-03 14:05:25.513527: Pseudo dice [0.9106]
2023-09-03 14:05:25.514848: Epoch time: 400.91 s
2023-09-03 14:05:25.516118: Yayy! New best EMA pseudo Dice: 0.874
2023-09-03 14:05:28.519010: 
2023-09-03 14:05:28.520287: Epoch 8
2023-09-03 14:05:28.521167: Current learning rate: backbone 0.00097597, others 0.00097597
2023-09-03 14:05:28.522779: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 14:06:30.232152: finished training epoch 8
2023-09-03 14:06:30.261210: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 14:06:30.263172: The split file contains 1 splits.
2023-09-03 14:06:30.264039: Desired fold for training: 0
2023-09-03 14:06:30.265254: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 14:12:28.431215: dsc: 90.56%
2023-09-03 14:12:28.432622: miou: 82.75%
2023-09-03 14:12:28.433405: acc: 95.20%, sen: 91.49%, spe: 96.45%
2023-09-03 14:12:28.435052: current best miou: 0.8344327376711419 at epoch: 7, (7, 0.8344327376711419, 0.9097447080348937)
2023-09-03 14:12:28.435706: current best dsc: 0.9097447080348937 at epoch: 7, (7, 0.8344327376711419, 0.9097447080348937)
2023-09-03 14:12:28.436309: finished real validation
2023-09-03 14:12:32.841842: train_loss -1.3302
2023-09-03 14:12:32.843250: val_loss -1.1544
2023-09-03 14:12:32.844476: Pseudo dice [0.903]
2023-09-03 14:12:32.845250: Epoch time: 424.32 s
2023-09-03 14:12:32.845942: Yayy! New best EMA pseudo Dice: 0.8769
2023-09-03 14:12:35.709747: 
2023-09-03 14:12:35.710767: Epoch 9
2023-09-03 14:12:35.711518: Current learning rate: backbone 0.00097296, others 0.00097296
2023-09-03 14:12:35.713294: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 14:13:37.162635: finished training epoch 9
2023-09-03 14:13:37.189203: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 14:13:37.190789: The split file contains 1 splits.
2023-09-03 14:13:37.191556: Desired fold for training: 0
2023-09-03 14:13:37.192343: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 14:19:21.959244: dsc: 91.03%
2023-09-03 14:19:21.960690: miou: 83.53%
2023-09-03 14:19:21.961638: acc: 95.42%, sen: 92.28%, spe: 96.48%
2023-09-03 14:19:21.964107: current best miou: 0.8352866858454322 at epoch: 9, (9, 0.8352866858454322, 0.9102519974536338)
2023-09-03 14:19:21.965223: current best dsc: 0.9102519974536338 at epoch: 9, (9, 0.8352866858454322, 0.9102519974536338)
2023-09-03 14:19:23.673951: finished real validation
2023-09-03 14:19:28.019963: train_loss -1.3347
2023-09-03 14:19:28.021120: val_loss -1.1854
2023-09-03 14:19:28.022202: Pseudo dice [0.9097]
2023-09-03 14:19:28.022975: Epoch time: 412.31 s
2023-09-03 14:19:29.685222: Yayy! New best EMA pseudo Dice: 0.8801
2023-09-03 14:19:32.476278: 
2023-09-03 14:19:32.477219: Epoch 10
2023-09-03 14:19:32.477959: Current learning rate: backbone 0.00096995, others 0.00096995
2023-09-03 14:19:32.479189: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 14:20:33.942757: finished training epoch 10
2023-09-03 14:20:33.973318: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 14:20:33.975140: The split file contains 1 splits.
2023-09-03 14:20:33.975920: Desired fold for training: 0
2023-09-03 14:20:33.976593: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 14:26:01.036588: dsc: 90.72%
2023-09-03 14:26:01.037855: miou: 83.01%
2023-09-03 14:26:01.038625: acc: 95.36%, sen: 90.17%, spe: 97.10%
2023-09-03 14:26:01.039832: current best miou: 0.8352866858454322 at epoch: 9, (9, 0.8352866858454322, 0.9102519974536338)
2023-09-03 14:26:01.040564: current best dsc: 0.9102519974536338 at epoch: 9, (9, 0.8352866858454322, 0.9102519974536338)
2023-09-03 14:26:01.041205: finished real validation
2023-09-03 14:26:05.450982: train_loss -1.341
2023-09-03 14:26:05.452172: val_loss -1.146
2023-09-03 14:26:05.453327: Pseudo dice [0.9031]
2023-09-03 14:26:05.454306: Epoch time: 392.98 s
2023-09-03 14:26:05.455004: Yayy! New best EMA pseudo Dice: 0.8824
2023-09-03 14:26:08.236052: 
2023-09-03 14:26:08.237139: Epoch 11
2023-09-03 14:26:08.237906: Current learning rate: backbone 0.00096694, others 0.00096694
2023-09-03 14:26:08.239160: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 14:27:09.640298: finished training epoch 11
2023-09-03 14:27:09.669672: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 14:27:09.672778: The split file contains 1 splits.
2023-09-03 14:27:09.674248: Desired fold for training: 0
2023-09-03 14:27:09.675364: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 14:32:33.286043: dsc: 91.28%
2023-09-03 14:32:33.287392: miou: 83.96%
2023-09-03 14:32:33.288335: acc: 95.58%, sen: 91.97%, spe: 96.79%
2023-09-03 14:32:33.289748: current best miou: 0.839577289195163 at epoch: 11, (11, 0.839577289195163, 0.9127937098663443)
2023-09-03 14:32:33.290837: current best dsc: 0.9127937098663443 at epoch: 11, (11, 0.839577289195163, 0.9127937098663443)
2023-09-03 14:32:34.844094: finished real validation
2023-09-03 14:32:39.273724: train_loss -1.3446
2023-09-03 14:32:39.274804: val_loss -1.1684
2023-09-03 14:32:39.275981: Pseudo dice [0.9095]
2023-09-03 14:32:39.276920: Epoch time: 391.04 s
2023-09-03 14:32:39.277776: Yayy! New best EMA pseudo Dice: 0.8851
2023-09-03 14:32:41.889952: 
2023-09-03 14:32:41.891015: Epoch 12
2023-09-03 14:32:41.891870: Current learning rate: backbone 0.00096393, others 0.00096393
2023-09-03 14:32:41.893091: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 14:33:43.414602: finished training epoch 12
2023-09-03 14:33:43.441899: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 14:33:43.443376: The split file contains 1 splits.
2023-09-03 14:33:43.444077: Desired fold for training: 0
2023-09-03 14:33:43.444708: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 14:39:17.717768: dsc: 91.03%
2023-09-03 14:39:17.718765: miou: 83.54%
2023-09-03 14:39:17.719512: acc: 95.50%, sen: 90.92%, spe: 97.03%
2023-09-03 14:39:17.720553: current best miou: 0.839577289195163 at epoch: 11, (11, 0.839577289195163, 0.9127937098663443)
2023-09-03 14:39:17.721250: current best dsc: 0.9127937098663443 at epoch: 11, (11, 0.839577289195163, 0.9127937098663443)
2023-09-03 14:39:17.721810: finished real validation
2023-09-03 14:39:22.136774: train_loss -1.3521
2023-09-03 14:39:22.137921: val_loss -1.1883
2023-09-03 14:39:22.138866: Pseudo dice [0.9118]
2023-09-03 14:39:22.139737: Epoch time: 400.25 s
2023-09-03 14:39:22.140388: Yayy! New best EMA pseudo Dice: 0.8878
2023-09-03 14:39:24.821301: 
2023-09-03 14:39:24.822225: Epoch 13
2023-09-03 14:39:24.822958: Current learning rate: backbone 0.00096091, others 0.00096091
2023-09-03 14:39:24.824004: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 14:40:26.201254: finished training epoch 13
2023-09-03 14:40:26.230295: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 14:40:26.233136: The split file contains 1 splits.
2023-09-03 14:40:26.234402: Desired fold for training: 0
2023-09-03 14:40:26.235165: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 14:45:50.035828: dsc: 90.69%
2023-09-03 14:45:50.037046: miou: 82.96%
2023-09-03 14:45:50.037780: acc: 95.23%, sen: 92.26%, spe: 96.23%
2023-09-03 14:45:50.038790: current best miou: 0.839577289195163 at epoch: 11, (11, 0.839577289195163, 0.9127937098663443)
2023-09-03 14:45:50.039483: current best dsc: 0.9127937098663443 at epoch: 11, (11, 0.839577289195163, 0.9127937098663443)
2023-09-03 14:45:50.040120: finished real validation
2023-09-03 14:45:54.465237: train_loss -1.3552
2023-09-03 14:45:54.466474: val_loss -1.1237
2023-09-03 14:45:54.467478: Pseudo dice [0.903]
2023-09-03 14:45:54.468686: Epoch time: 389.65 s
2023-09-03 14:45:54.469841: Yayy! New best EMA pseudo Dice: 0.8893
2023-09-03 14:45:57.185456: 
2023-09-03 14:45:57.186759: Epoch 14
2023-09-03 14:45:57.187565: Current learning rate: backbone 0.0009579, others 0.0009579
2023-09-03 14:45:57.188688: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 14:46:58.685225: finished training epoch 14
2023-09-03 14:46:58.713934: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 14:46:58.717094: The split file contains 1 splits.
2023-09-03 14:46:58.717897: Desired fold for training: 0
2023-09-03 14:46:58.718613: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 14:52:28.470467: dsc: 91.07%
2023-09-03 14:52:28.471604: miou: 83.60%
2023-09-03 14:52:28.472345: acc: 95.57%, sen: 89.84%, spe: 97.49%
2023-09-03 14:52:28.473438: current best miou: 0.839577289195163 at epoch: 11, (11, 0.839577289195163, 0.9127937098663443)
2023-09-03 14:52:28.474250: current best dsc: 0.9127937098663443 at epoch: 11, (11, 0.839577289195163, 0.9127937098663443)
2023-09-03 14:52:28.474906: finished real validation
2023-09-03 14:52:32.873945: train_loss -1.3603
2023-09-03 14:52:32.875295: val_loss -1.171
2023-09-03 14:52:32.876325: Pseudo dice [0.9092]
2023-09-03 14:52:32.877104: Epoch time: 395.69 s
2023-09-03 14:52:32.877853: Yayy! New best EMA pseudo Dice: 0.8913
2023-09-03 14:52:36.155542: 
2023-09-03 14:52:36.156777: Epoch 15
2023-09-03 14:52:36.157861: Current learning rate: backbone 0.00095489, others 0.00095489
2023-09-03 14:52:36.159188: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 14:53:37.764002: finished training epoch 15
2023-09-03 14:53:37.809994: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 14:53:37.811827: The split file contains 1 splits.
2023-09-03 14:53:37.813010: Desired fold for training: 0
2023-09-03 14:53:37.814305: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 14:59:12.218076: dsc: 90.83%
2023-09-03 14:59:12.219654: miou: 83.19%
2023-09-03 14:59:12.220431: acc: 95.42%, sen: 90.13%, spe: 97.20%
2023-09-03 14:59:12.221934: current best miou: 0.839577289195163 at epoch: 11, (11, 0.839577289195163, 0.9127937098663443)
2023-09-03 14:59:12.222945: current best dsc: 0.9127937098663443 at epoch: 11, (11, 0.839577289195163, 0.9127937098663443)
2023-09-03 14:59:12.223738: finished real validation
2023-09-03 14:59:16.639578: train_loss -1.3597
2023-09-03 14:59:16.641331: val_loss -1.1686
2023-09-03 14:59:16.642795: Pseudo dice [0.9095]
2023-09-03 14:59:16.643661: Epoch time: 400.49 s
2023-09-03 14:59:16.644331: Yayy! New best EMA pseudo Dice: 0.8931
2023-09-03 14:59:19.367437: 
2023-09-03 14:59:19.368734: Epoch 16
2023-09-03 14:59:19.369545: Current learning rate: backbone 0.00095187, others 0.00095187
2023-09-03 14:59:19.370779: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 15:00:20.778045: finished training epoch 16
2023-09-03 15:00:20.832787: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 15:00:20.834693: The split file contains 1 splits.
2023-09-03 15:00:20.835752: Desired fold for training: 0
2023-09-03 15:00:20.836674: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 15:05:39.777778: dsc: 91.04%
2023-09-03 15:05:39.779148: miou: 83.55%
2023-09-03 15:05:39.779906: acc: 95.44%, sen: 92.07%, spe: 96.57%
2023-09-03 15:05:39.780960: current best miou: 0.839577289195163 at epoch: 11, (11, 0.839577289195163, 0.9127937098663443)
2023-09-03 15:05:39.781897: current best dsc: 0.9127937098663443 at epoch: 11, (11, 0.839577289195163, 0.9127937098663443)
2023-09-03 15:05:39.782660: finished real validation
2023-09-03 15:05:44.190889: train_loss -1.3651
2023-09-03 15:05:44.192138: val_loss -1.162
2023-09-03 15:05:44.193138: Pseudo dice [0.9121]
2023-09-03 15:05:44.193946: Epoch time: 384.82 s
2023-09-03 15:05:44.194632: Yayy! New best EMA pseudo Dice: 0.895
2023-09-03 15:05:46.913220: 
2023-09-03 15:05:46.914640: Epoch 17
2023-09-03 15:05:46.915451: Current learning rate: backbone 0.00094885, others 0.00094885
2023-09-03 15:05:46.916576: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 15:06:48.227005: finished training epoch 17
2023-09-03 15:06:48.254603: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 15:06:48.256163: The split file contains 1 splits.
2023-09-03 15:06:48.256930: Desired fold for training: 0
2023-09-03 15:06:48.257565: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 15:11:56.949577: dsc: 91.03%
2023-09-03 15:11:56.950735: miou: 83.54%
2023-09-03 15:11:56.951525: acc: 95.46%, sen: 91.59%, spe: 96.76%
2023-09-03 15:11:56.953282: current best miou: 0.839577289195163 at epoch: 11, (11, 0.839577289195163, 0.9127937098663443)
2023-09-03 15:11:56.953980: current best dsc: 0.9127937098663443 at epoch: 11, (11, 0.839577289195163, 0.9127937098663443)
2023-09-03 15:11:56.954603: finished real validation
2023-09-03 15:12:01.365477: train_loss -1.3708
2023-09-03 15:12:01.366807: val_loss -1.16
2023-09-03 15:12:01.367857: Pseudo dice [0.9099]
2023-09-03 15:12:01.368691: Epoch time: 374.45 s
2023-09-03 15:12:01.369539: Yayy! New best EMA pseudo Dice: 0.8965
2023-09-03 15:12:04.085531: 
2023-09-03 15:12:04.086939: Epoch 18
2023-09-03 15:12:04.087783: Current learning rate: backbone 0.00094583, others 0.00094583
2023-09-03 15:12:04.088909: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 15:13:05.383636: finished training epoch 18
2023-09-03 15:13:05.423055: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 15:13:05.425154: The split file contains 1 splits.
2023-09-03 15:13:05.425952: Desired fold for training: 0
2023-09-03 15:13:05.426689: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 15:18:16.473034: dsc: 91.08%
2023-09-03 15:18:16.474493: miou: 83.62%
2023-09-03 15:18:16.475366: acc: 95.46%, sen: 92.13%, spe: 96.58%
2023-09-03 15:18:16.476662: current best miou: 0.839577289195163 at epoch: 11, (11, 0.839577289195163, 0.9127937098663443)
2023-09-03 15:18:16.477670: current best dsc: 0.9127937098663443 at epoch: 11, (11, 0.839577289195163, 0.9127937098663443)
2023-09-03 15:18:16.478466: finished real validation
2023-09-03 15:18:20.890261: train_loss -1.3744
2023-09-03 15:18:20.891601: val_loss -1.1606
2023-09-03 15:18:20.893847: Pseudo dice [0.912]
2023-09-03 15:18:20.895257: Epoch time: 376.81 s
2023-09-03 15:18:20.896409: Yayy! New best EMA pseudo Dice: 0.8981
2023-09-03 15:18:23.642033: 
2023-09-03 15:18:23.643826: Epoch 19
2023-09-03 15:18:23.644678: Current learning rate: backbone 0.00094282, others 0.00094282
2023-09-03 15:18:23.645984: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 15:19:25.095183: finished training epoch 19
2023-09-03 15:19:25.136379: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 15:19:25.138235: The split file contains 1 splits.
2023-09-03 15:19:25.139095: Desired fold for training: 0
2023-09-03 15:19:25.140051: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 15:24:35.975051: dsc: 91.04%
2023-09-03 15:24:35.976387: miou: 83.55%
2023-09-03 15:24:35.977331: acc: 95.55%, sen: 89.90%, spe: 97.44%
2023-09-03 15:24:35.978440: current best miou: 0.839577289195163 at epoch: 11, (11, 0.839577289195163, 0.9127937098663443)
2023-09-03 15:24:35.979416: current best dsc: 0.9127937098663443 at epoch: 11, (11, 0.839577289195163, 0.9127937098663443)
2023-09-03 15:24:35.980360: finished real validation
2023-09-03 15:24:40.380517: train_loss -1.3754
2023-09-03 15:24:40.381779: val_loss -1.1695
2023-09-03 15:24:40.382807: Pseudo dice [0.9116]
2023-09-03 15:24:40.383587: Epoch time: 376.74 s
2023-09-03 15:24:41.962001: Yayy! New best EMA pseudo Dice: 0.8994
2023-09-03 15:24:44.647932: 
2023-09-03 15:24:44.649098: Epoch 20
2023-09-03 15:24:44.649946: Current learning rate: backbone 0.00093979, others 0.00093979
2023-09-03 15:24:44.651124: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 15:25:45.920423: finished training epoch 20
2023-09-03 15:25:45.964916: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 15:25:45.966909: The split file contains 1 splits.
2023-09-03 15:25:45.967702: Desired fold for training: 0
2023-09-03 15:25:45.968431: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 15:31:02.545614: dsc: 91.03%
2023-09-03 15:31:02.546944: miou: 83.54%
2023-09-03 15:31:02.547774: acc: 95.44%, sen: 92.05%, spe: 96.58%
2023-09-03 15:31:02.549160: current best miou: 0.839577289195163 at epoch: 11, (11, 0.839577289195163, 0.9127937098663443)
2023-09-03 15:31:02.550174: current best dsc: 0.9127937098663443 at epoch: 11, (11, 0.839577289195163, 0.9127937098663443)
2023-09-03 15:31:02.551204: finished real validation
2023-09-03 15:31:06.952240: train_loss -1.3799
2023-09-03 15:31:06.953528: val_loss -1.1505
2023-09-03 15:31:06.954762: Pseudo dice [0.9122]
2023-09-03 15:31:06.955588: Epoch time: 382.31 s
2023-09-03 15:31:06.956330: Yayy! New best EMA pseudo Dice: 0.9007
2023-09-03 15:31:09.639433: 
2023-09-03 15:31:09.640748: Epoch 21
2023-09-03 15:31:09.641607: Current learning rate: backbone 0.00093677, others 0.00093677
2023-09-03 15:31:09.643377: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 15:32:10.830539: finished training epoch 21
2023-09-03 15:32:10.867807: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 15:32:10.869737: The split file contains 1 splits.
2023-09-03 15:32:10.870762: Desired fold for training: 0
2023-09-03 15:32:10.872368: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 15:37:25.603714: dsc: 90.99%
2023-09-03 15:37:25.604936: miou: 83.47%
2023-09-03 15:37:25.605729: acc: 95.47%, sen: 90.90%, spe: 97.01%
2023-09-03 15:37:25.607515: current best miou: 0.839577289195163 at epoch: 11, (11, 0.839577289195163, 0.9127937098663443)
2023-09-03 15:37:25.608312: current best dsc: 0.9127937098663443 at epoch: 11, (11, 0.839577289195163, 0.9127937098663443)
2023-09-03 15:37:25.609191: finished real validation
2023-09-03 15:37:30.018896: train_loss -1.3796
2023-09-03 15:37:30.020191: val_loss -1.1353
2023-09-03 15:37:30.021284: Pseudo dice [0.9088]
2023-09-03 15:37:30.022145: Epoch time: 380.38 s
2023-09-03 15:37:30.022918: Yayy! New best EMA pseudo Dice: 0.9015
2023-09-03 15:37:33.214902: 
2023-09-03 15:37:33.216169: Epoch 22
2023-09-03 15:37:33.217032: Current learning rate: backbone 0.00093375, others 0.00093375
2023-09-03 15:37:33.218571: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 15:38:34.470416: finished training epoch 22
2023-09-03 15:38:34.509793: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 15:38:34.511924: The split file contains 1 splits.
2023-09-03 15:38:34.512757: Desired fold for training: 0
2023-09-03 15:38:34.513515: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 15:43:57.639146: dsc: 91.02%
2023-09-03 15:43:57.640334: miou: 83.52%
2023-09-03 15:43:57.641046: acc: 95.44%, sen: 91.80%, spe: 96.67%
2023-09-03 15:43:57.642190: current best miou: 0.839577289195163 at epoch: 11, (11, 0.839577289195163, 0.9127937098663443)
2023-09-03 15:43:57.642864: current best dsc: 0.9127937098663443 at epoch: 11, (11, 0.839577289195163, 0.9127937098663443)
2023-09-03 15:43:57.643539: finished real validation
2023-09-03 15:44:02.043170: train_loss -1.3799
2023-09-03 15:44:02.044432: val_loss -1.1322
2023-09-03 15:44:02.045544: Pseudo dice [0.9098]
2023-09-03 15:44:02.046407: Epoch time: 388.83 s
2023-09-03 15:44:02.047193: Yayy! New best EMA pseudo Dice: 0.9023
2023-09-03 15:44:04.750828: 
2023-09-03 15:44:04.751986: Epoch 23
2023-09-03 15:44:04.752860: Current learning rate: backbone 0.00093073, others 0.00093073
2023-09-03 15:44:04.754100: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 15:45:06.030713: finished training epoch 23
2023-09-03 15:45:06.070020: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 15:45:06.071925: The split file contains 1 splits.
2023-09-03 15:45:06.072774: Desired fold for training: 0
2023-09-03 15:45:06.073531: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 15:50:20.575321: dsc: 91.26%
2023-09-03 15:50:20.576367: miou: 83.92%
2023-09-03 15:50:20.577104: acc: 95.61%, sen: 91.17%, spe: 97.10%
2023-09-03 15:50:20.578176: current best miou: 0.839577289195163 at epoch: 11, (11, 0.839577289195163, 0.9127937098663443)
2023-09-03 15:50:20.578916: current best dsc: 0.9127937098663443 at epoch: 11, (11, 0.839577289195163, 0.9127937098663443)
2023-09-03 15:50:20.579568: finished real validation
2023-09-03 15:50:24.963786: train_loss -1.3835
2023-09-03 15:50:24.965222: val_loss -1.1505
2023-09-03 15:50:24.966327: Pseudo dice [0.9083]
2023-09-03 15:50:24.967208: Epoch time: 380.21 s
2023-09-03 15:50:24.967975: Yayy! New best EMA pseudo Dice: 0.9029
2023-09-03 15:50:27.670091: 
2023-09-03 15:50:27.671200: Epoch 24
2023-09-03 15:50:27.672290: Current learning rate: backbone 0.0009277, others 0.0009277
2023-09-03 15:50:27.673890: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 15:51:28.887035: finished training epoch 24
2023-09-03 15:51:28.916419: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 15:51:28.918075: The split file contains 1 splits.
2023-09-03 15:51:28.919255: Desired fold for training: 0
2023-09-03 15:51:28.919986: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 15:56:41.102478: dsc: 91.03%
2023-09-03 15:56:41.103671: miou: 83.54%
2023-09-03 15:56:41.104568: acc: 95.52%, sen: 90.47%, spe: 97.21%
2023-09-03 15:56:41.106276: current best miou: 0.839577289195163 at epoch: 11, (11, 0.839577289195163, 0.9127937098663443)
2023-09-03 15:56:41.107195: current best dsc: 0.9127937098663443 at epoch: 11, (11, 0.839577289195163, 0.9127937098663443)
2023-09-03 15:56:41.108196: finished real validation
2023-09-03 15:56:45.502470: train_loss -1.385
2023-09-03 15:56:45.503884: val_loss -1.1322
2023-09-03 15:56:45.504982: Pseudo dice [0.9066]
2023-09-03 15:56:45.505845: Epoch time: 377.83 s
2023-09-03 15:56:45.506617: Yayy! New best EMA pseudo Dice: 0.9033
2023-09-03 15:56:48.208532: 
2023-09-03 15:56:48.211677: Epoch 25
2023-09-03 15:56:48.213047: Current learning rate: backbone 0.00092468, others 0.00092468
2023-09-03 15:56:48.214490: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 15:57:49.596055: finished training epoch 25
2023-09-03 15:57:49.634750: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 15:57:49.636610: The split file contains 1 splits.
2023-09-03 15:57:49.637426: Desired fold for training: 0
2023-09-03 15:57:49.638136: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 16:03:00.458430: dsc: 90.99%
2023-09-03 16:03:00.459585: miou: 83.47%
2023-09-03 16:03:00.460326: acc: 95.45%, sen: 91.36%, spe: 96.83%
2023-09-03 16:03:00.461461: current best miou: 0.839577289195163 at epoch: 11, (11, 0.839577289195163, 0.9127937098663443)
2023-09-03 16:03:00.462224: current best dsc: 0.9127937098663443 at epoch: 11, (11, 0.839577289195163, 0.9127937098663443)
2023-09-03 16:03:00.462907: finished real validation
2023-09-03 16:03:04.858605: train_loss -1.3868
2023-09-03 16:03:04.859996: val_loss -1.1268
2023-09-03 16:03:04.861119: Pseudo dice [0.9089]
2023-09-03 16:03:04.861991: Epoch time: 376.65 s
2023-09-03 16:03:04.862800: Yayy! New best EMA pseudo Dice: 0.9039
2023-09-03 16:03:07.466456: 
2023-09-03 16:03:07.467745: Epoch 26
2023-09-03 16:03:07.468806: Current learning rate: backbone 0.00092165, others 0.00092165
2023-09-03 16:03:07.470366: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 16:04:08.708377: finished training epoch 26
2023-09-03 16:04:08.736957: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 16:04:08.738572: The split file contains 1 splits.
2023-09-03 16:04:08.739379: Desired fold for training: 0
2023-09-03 16:04:08.740131: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 16:09:26.798025: dsc: 91.09%
2023-09-03 16:09:26.799339: miou: 83.64%
2023-09-03 16:09:26.800148: acc: 95.52%, sen: 91.08%, spe: 97.01%
2023-09-03 16:09:26.801245: current best miou: 0.839577289195163 at epoch: 11, (11, 0.839577289195163, 0.9127937098663443)
2023-09-03 16:09:26.802070: current best dsc: 0.9127937098663443 at epoch: 11, (11, 0.839577289195163, 0.9127937098663443)
2023-09-03 16:09:26.802807: finished real validation
2023-09-03 16:09:31.201128: train_loss -1.3888
2023-09-03 16:09:31.202491: val_loss -1.1249
2023-09-03 16:09:31.203772: Pseudo dice [0.9082]
2023-09-03 16:09:31.204634: Epoch time: 383.74 s
2023-09-03 16:09:31.205421: Yayy! New best EMA pseudo Dice: 0.9043
2023-09-03 16:09:33.908753: 
2023-09-03 16:09:33.910048: Epoch 27
2023-09-03 16:09:33.911419: Current learning rate: backbone 0.00091862, others 0.00091862
2023-09-03 16:09:33.913366: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 16:10:35.483839: finished training epoch 27
2023-09-03 16:10:35.538337: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 16:10:35.540104: The split file contains 1 splits.
2023-09-03 16:10:35.544491: Desired fold for training: 0
2023-09-03 16:10:35.552088: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 16:17:20.690464: dsc: 90.92%
2023-09-03 16:17:20.691876: miou: 83.35%
2023-09-03 16:17:20.692682: acc: 95.44%, sen: 90.82%, spe: 96.99%
2023-09-03 16:17:20.693747: current best miou: 0.839577289195163 at epoch: 11, (11, 0.839577289195163, 0.9127937098663443)
2023-09-03 16:17:20.694630: current best dsc: 0.9127937098663443 at epoch: 11, (11, 0.839577289195163, 0.9127937098663443)
2023-09-03 16:17:20.695321: finished real validation
2023-09-03 16:17:25.093198: train_loss -1.3908
2023-09-03 16:17:25.094352: val_loss -1.1003
2023-09-03 16:17:25.095450: Pseudo dice [0.9027]
2023-09-03 16:17:25.096292: Epoch time: 471.19 s
2023-09-03 16:17:26.213575: 
2023-09-03 16:17:26.214686: Epoch 28
2023-09-03 16:17:26.215533: Current learning rate: backbone 0.00091559, others 0.00091559
2023-09-03 16:17:26.216763: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 16:18:27.547362: finished training epoch 28
2023-09-03 16:18:27.590958: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 16:18:27.592853: The split file contains 1 splits.
2023-09-03 16:18:27.593943: Desired fold for training: 0
2023-09-03 16:18:27.594735: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 16:23:39.793084: dsc: 91.15%
2023-09-03 16:23:39.794634: miou: 83.73%
2023-09-03 16:23:39.795455: acc: 95.55%, sen: 91.00%, spe: 97.08%
2023-09-03 16:23:39.797129: current best miou: 0.839577289195163 at epoch: 11, (11, 0.839577289195163, 0.9127937098663443)
2023-09-03 16:23:39.798097: current best dsc: 0.9127937098663443 at epoch: 11, (11, 0.839577289195163, 0.9127937098663443)
2023-09-03 16:23:39.798823: finished real validation
2023-09-03 16:23:44.208868: train_loss -1.3917
2023-09-03 16:23:44.210189: val_loss -1.1598
2023-09-03 16:23:44.211996: Pseudo dice [0.9131]
2023-09-03 16:23:44.213054: Epoch time: 378.0 s
2023-09-03 16:23:44.213879: Yayy! New best EMA pseudo Dice: 0.905
2023-09-03 16:23:46.850591: 
2023-09-03 16:23:46.851975: Epoch 29
2023-09-03 16:23:46.852968: Current learning rate: backbone 0.00091256, others 0.00091256
2023-09-03 16:23:46.854235: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 16:24:48.184618: finished training epoch 29
2023-09-03 16:24:48.212902: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 16:24:48.214734: The split file contains 1 splits.
2023-09-03 16:24:48.215845: Desired fold for training: 0
2023-09-03 16:24:48.216992: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 16:29:55.529144: dsc: 91.22%
2023-09-03 16:29:55.530568: miou: 83.86%
2023-09-03 16:29:55.531616: acc: 95.56%, sen: 91.64%, spe: 96.88%
2023-09-03 16:29:55.533410: current best miou: 0.839577289195163 at epoch: 11, (11, 0.839577289195163, 0.9127937098663443)
2023-09-03 16:29:55.534428: current best dsc: 0.9127937098663443 at epoch: 11, (11, 0.839577289195163, 0.9127937098663443)
2023-09-03 16:29:55.535373: finished real validation
2023-09-03 16:29:59.932797: train_loss -1.3928
2023-09-03 16:29:59.934155: val_loss -1.1261
2023-09-03 16:29:59.935251: Pseudo dice [0.9096]
2023-09-03 16:29:59.936188: Epoch time: 373.08 s
2023-09-03 16:30:01.477845: Yayy! New best EMA pseudo Dice: 0.9055
2023-09-03 16:30:04.193938: 
2023-09-03 16:30:04.195129: Epoch 30
2023-09-03 16:30:04.196023: Current learning rate: backbone 0.00090953, others 0.00090953
2023-09-03 16:30:04.197231: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 16:31:05.566000: finished training epoch 30
2023-09-03 16:31:05.594327: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 16:31:05.595984: The split file contains 1 splits.
2023-09-03 16:31:05.596890: Desired fold for training: 0
2023-09-03 16:31:05.597692: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 16:36:19.145570: dsc: 90.96%
2023-09-03 16:36:19.147086: miou: 83.42%
2023-09-03 16:36:19.147917: acc: 95.48%, sen: 90.36%, spe: 97.21%
2023-09-03 16:36:19.149023: current best miou: 0.839577289195163 at epoch: 11, (11, 0.839577289195163, 0.9127937098663443)
2023-09-03 16:36:19.149864: current best dsc: 0.9127937098663443 at epoch: 11, (11, 0.839577289195163, 0.9127937098663443)
2023-09-03 16:36:19.150647: finished real validation
2023-09-03 16:36:23.554716: train_loss -1.3945
2023-09-03 16:36:23.556285: val_loss -1.1309
2023-09-03 16:36:23.557661: Pseudo dice [0.9106]
2023-09-03 16:36:23.558590: Epoch time: 379.36 s
2023-09-03 16:36:23.559460: Yayy! New best EMA pseudo Dice: 0.906
2023-09-03 16:36:26.288626: 
2023-09-03 16:36:26.289867: Epoch 31
2023-09-03 16:36:26.290750: Current learning rate: backbone 0.0009065, others 0.0009065
2023-09-03 16:36:26.292014: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 16:37:27.958526: finished training epoch 31
2023-09-03 16:37:27.988052: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 16:37:27.990150: The split file contains 1 splits.
2023-09-03 16:37:27.990991: Desired fold for training: 0
2023-09-03 16:37:27.992229: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 16:42:41.540979: dsc: 91.44%
2023-09-03 16:42:41.542542: miou: 84.22%
2023-09-03 16:42:41.543453: acc: 95.71%, sen: 91.05%, spe: 97.28%
2023-09-03 16:42:41.544886: current best miou: 0.8422144348184231 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-03 16:42:41.546029: current best dsc: 0.9143500549125113 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-03 16:42:43.216622: finished real validation
2023-09-03 16:42:47.633977: train_loss -1.3957
2023-09-03 16:42:47.635342: val_loss -1.1294
2023-09-03 16:42:47.636469: Pseudo dice [0.9131]
2023-09-03 16:42:47.637356: Epoch time: 381.35 s
2023-09-03 16:42:47.638151: Yayy! New best EMA pseudo Dice: 0.9067
2023-09-03 16:42:50.322106: 
2023-09-03 16:42:50.323474: Epoch 32
2023-09-03 16:42:50.324404: Current learning rate: backbone 0.00090347, others 0.00090347
2023-09-03 16:42:50.325671: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 16:43:51.924201: finished training epoch 32
2023-09-03 16:43:51.953227: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 16:43:51.954785: The split file contains 1 splits.
2023-09-03 16:43:51.955661: Desired fold for training: 0
2023-09-03 16:43:51.956483: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 16:49:03.829152: dsc: 91.13%
2023-09-03 16:49:03.830522: miou: 83.71%
2023-09-03 16:49:03.831298: acc: 95.56%, sen: 90.77%, spe: 97.17%
2023-09-03 16:49:03.832418: current best miou: 0.8422144348184231 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-03 16:49:03.833214: current best dsc: 0.9143500549125113 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-03 16:49:03.833929: finished real validation
2023-09-03 16:49:08.244540: train_loss -1.3959
2023-09-03 16:49:08.246154: val_loss -1.1452
2023-09-03 16:49:08.247409: Pseudo dice [0.9125]
2023-09-03 16:49:08.248320: Epoch time: 377.92 s
2023-09-03 16:49:08.249165: Yayy! New best EMA pseudo Dice: 0.9073
2023-09-03 16:49:11.087620: 
2023-09-03 16:49:11.089074: Epoch 33
2023-09-03 16:49:11.089999: Current learning rate: backbone 0.00090043, others 0.00090043
2023-09-03 16:49:11.091348: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 16:50:12.522547: finished training epoch 33
2023-09-03 16:50:12.552285: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 16:50:12.554067: The split file contains 1 splits.
2023-09-03 16:50:12.554917: Desired fold for training: 0
2023-09-03 16:50:12.555676: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 16:55:30.813155: dsc: 91.03%
2023-09-03 16:55:30.814442: miou: 83.53%
2023-09-03 16:55:30.815239: acc: 95.47%, sen: 91.42%, spe: 96.83%
2023-09-03 16:55:30.816312: current best miou: 0.8422144348184231 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-03 16:55:30.817115: current best dsc: 0.9143500549125113 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-03 16:55:30.817843: finished real validation
2023-09-03 16:55:35.207136: train_loss -1.3988
2023-09-03 16:55:35.208621: val_loss -1.0895
2023-09-03 16:55:35.209920: Pseudo dice [0.9071]
2023-09-03 16:55:35.210856: Epoch time: 384.12 s
2023-09-03 16:55:36.339958: 
2023-09-03 16:55:36.341179: Epoch 34
2023-09-03 16:55:36.342085: Current learning rate: backbone 0.0008974, others 0.0008974
2023-09-03 16:55:36.343395: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 16:56:37.787297: finished training epoch 34
2023-09-03 16:56:37.828176: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 16:56:37.830254: The split file contains 1 splits.
2023-09-03 16:56:37.831254: Desired fold for training: 0
2023-09-03 16:56:37.832258: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 17:02:51.393318: dsc: 91.24%
2023-09-03 17:02:51.394484: miou: 83.89%
2023-09-03 17:02:51.395307: acc: 95.61%, sen: 90.88%, spe: 97.20%
2023-09-03 17:02:51.396354: current best miou: 0.8422144348184231 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-03 17:02:51.397183: current best dsc: 0.9143500549125113 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-03 17:02:51.397958: finished real validation
2023-09-03 17:02:55.778151: train_loss -1.4006
2023-09-03 17:02:55.779452: val_loss -1.1193
2023-09-03 17:02:55.780544: Pseudo dice [0.9109]
2023-09-03 17:02:55.781397: Epoch time: 439.44 s
2023-09-03 17:02:55.782255: Yayy! New best EMA pseudo Dice: 0.9076
2023-09-03 17:02:58.444918: 
2023-09-03 17:02:58.446171: Epoch 35
2023-09-03 17:02:58.447160: Current learning rate: backbone 0.00089436, others 0.00089436
2023-09-03 17:02:58.448420: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 17:03:59.755271: finished training epoch 35
2023-09-03 17:03:59.783008: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 17:03:59.784647: The split file contains 1 splits.
2023-09-03 17:03:59.785595: Desired fold for training: 0
2023-09-03 17:03:59.786395: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 17:09:16.037493: dsc: 91.16%
2023-09-03 17:09:16.038988: miou: 83.75%
2023-09-03 17:09:16.039869: acc: 95.56%, sen: 91.02%, spe: 97.08%
2023-09-03 17:09:16.041301: current best miou: 0.8422144348184231 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-03 17:09:16.042167: current best dsc: 0.9143500549125113 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-03 17:09:16.042960: finished real validation
2023-09-03 17:09:20.424187: train_loss -1.3997
2023-09-03 17:09:20.425678: val_loss -1.1275
2023-09-03 17:09:20.426898: Pseudo dice [0.9122]
2023-09-03 17:09:20.427747: Epoch time: 381.98 s
2023-09-03 17:09:20.428543: Yayy! New best EMA pseudo Dice: 0.9081
2023-09-03 17:09:23.174589: 
2023-09-03 17:09:23.175953: Epoch 36
2023-09-03 17:09:23.177329: Current learning rate: backbone 0.00089132, others 0.00089132
2023-09-03 17:09:23.179389: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 17:10:24.629895: finished training epoch 36
2023-09-03 17:10:24.696560: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 17:10:24.698309: The split file contains 1 splits.
2023-09-03 17:10:24.699144: Desired fold for training: 0
2023-09-03 17:10:24.699973: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 17:15:45.709672: dsc: 91.22%
2023-09-03 17:15:45.712272: miou: 83.85%
2023-09-03 17:15:45.713393: acc: 95.64%, sen: 90.09%, spe: 97.50%
2023-09-03 17:15:45.714958: current best miou: 0.8422144348184231 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-03 17:15:45.716089: current best dsc: 0.9143500549125113 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-03 17:15:45.717015: finished real validation
2023-09-03 17:15:50.090514: train_loss -1.4
2023-09-03 17:15:50.091880: val_loss -1.1374
2023-09-03 17:15:50.093046: Pseudo dice [0.9142]
2023-09-03 17:15:50.101280: Epoch time: 386.92 s
2023-09-03 17:15:50.106771: Yayy! New best EMA pseudo Dice: 0.9087
2023-09-03 17:15:52.988004: 
2023-09-03 17:15:52.989459: Epoch 37
2023-09-03 17:15:52.990523: Current learning rate: backbone 0.00088828, others 0.00088828
2023-09-03 17:15:52.991914: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 17:16:54.856733: finished training epoch 37
2023-09-03 17:16:54.886793: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 17:16:54.888556: The split file contains 1 splits.
2023-09-03 17:16:54.889447: Desired fold for training: 0
2023-09-03 17:16:54.890354: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 17:22:04.275207: dsc: 91.22%
2023-09-03 17:22:04.277234: miou: 83.85%
2023-09-03 17:22:04.278159: acc: 95.61%, sen: 90.68%, spe: 97.26%
2023-09-03 17:22:04.279878: current best miou: 0.8422144348184231 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-03 17:22:04.280996: current best dsc: 0.9143500549125113 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-03 17:22:04.281770: finished real validation
2023-09-03 17:22:08.699576: train_loss -1.401
2023-09-03 17:22:08.700929: val_loss -1.1302
2023-09-03 17:22:08.702916: Pseudo dice [0.9114]
2023-09-03 17:22:08.704445: Epoch time: 375.71 s
2023-09-03 17:22:08.705814: Yayy! New best EMA pseudo Dice: 0.909
2023-09-03 17:22:11.445466: 
2023-09-03 17:22:11.447108: Epoch 38
2023-09-03 17:22:11.448056: Current learning rate: backbone 0.00088524, others 0.00088524
2023-09-03 17:22:11.449808: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 17:23:12.830255: finished training epoch 38
2023-09-03 17:23:12.871451: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 17:23:12.874511: The split file contains 1 splits.
2023-09-03 17:23:12.875917: Desired fold for training: 0
2023-09-03 17:23:12.877265: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 17:28:49.655664: dsc: 91.02%
2023-09-03 17:28:49.656803: miou: 83.52%
2023-09-03 17:28:49.657582: acc: 95.48%, sen: 91.04%, spe: 96.98%
2023-09-03 17:28:49.658609: current best miou: 0.8422144348184231 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-03 17:28:49.659394: current best dsc: 0.9143500549125113 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-03 17:28:49.660106: finished real validation
2023-09-03 17:28:54.030013: train_loss -1.4014
2023-09-03 17:28:54.031382: val_loss -1.0996
2023-09-03 17:28:54.032564: Pseudo dice [0.9054]
2023-09-03 17:28:54.036160: Epoch time: 402.59 s
2023-09-03 17:28:55.154118: 
2023-09-03 17:28:55.155615: Epoch 39
2023-09-03 17:28:55.156559: Current learning rate: backbone 0.0008822, others 0.0008822
2023-09-03 17:28:55.157835: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 17:29:56.561426: finished training epoch 39
2023-09-03 17:29:56.612411: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 17:29:56.614160: The split file contains 1 splits.
2023-09-03 17:29:56.615484: Desired fold for training: 0
2023-09-03 17:29:56.616507: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 17:35:03.617247: dsc: 91.19%
2023-09-03 17:35:03.618738: miou: 83.81%
2023-09-03 17:35:03.619624: acc: 95.58%, sen: 91.02%, spe: 97.11%
2023-09-03 17:35:03.620956: current best miou: 0.8422144348184231 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-03 17:35:03.621869: current best dsc: 0.9143500549125113 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-03 17:35:03.622681: finished real validation
2023-09-03 17:35:08.015853: train_loss -1.4047
2023-09-03 17:35:08.017483: val_loss -1.138
2023-09-03 17:35:08.018758: Pseudo dice [0.9142]
2023-09-03 17:35:08.019745: Epoch time: 372.86 s
2023-09-03 17:35:09.560461: Yayy! New best EMA pseudo Dice: 0.9092
2023-09-03 17:35:12.270811: 
2023-09-03 17:35:12.272126: Epoch 40
2023-09-03 17:35:12.273103: Current learning rate: backbone 0.00087916, others 0.00087916
2023-09-03 17:35:12.274629: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 17:36:13.452501: finished training epoch 40
2023-09-03 17:36:13.486647: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 17:36:13.488432: The split file contains 1 splits.
2023-09-03 17:36:13.489322: Desired fold for training: 0
2023-09-03 17:36:13.490108: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 17:41:48.108157: dsc: 91.10%
2023-09-03 17:41:48.109870: miou: 83.66%
2023-09-03 17:41:48.110791: acc: 95.55%, sen: 90.55%, spe: 97.23%
2023-09-03 17:41:48.112292: current best miou: 0.8422144348184231 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-03 17:41:48.113158: current best dsc: 0.9143500549125113 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-03 17:41:48.113952: finished real validation
2023-09-03 17:41:52.495777: train_loss -1.4048
2023-09-03 17:41:52.497236: val_loss -1.1125
2023-09-03 17:41:52.498518: Pseudo dice [0.912]
2023-09-03 17:41:52.499551: Epoch time: 400.23 s
2023-09-03 17:41:52.500527: Yayy! New best EMA pseudo Dice: 0.9094
2023-09-03 17:41:55.197866: 
2023-09-03 17:41:55.199146: Epoch 41
2023-09-03 17:41:55.200033: Current learning rate: backbone 0.00087611, others 0.00087611
2023-09-03 17:41:55.201305: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 17:42:56.632640: finished training epoch 41
2023-09-03 17:42:56.678093: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 17:42:56.686589: The split file contains 1 splits.
2023-09-03 17:42:56.691678: Desired fold for training: 0
2023-09-03 17:42:56.692856: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 17:48:25.401760: dsc: 91.11%
2023-09-03 17:48:25.403247: miou: 83.67%
2023-09-03 17:48:25.404108: acc: 95.54%, sen: 90.89%, spe: 97.10%
2023-09-03 17:48:25.405277: current best miou: 0.8422144348184231 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-03 17:48:25.406177: current best dsc: 0.9143500549125113 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-03 17:48:25.406990: finished real validation
2023-09-03 17:48:29.778910: train_loss -1.4062
2023-09-03 17:48:29.780281: val_loss -1.1033
2023-09-03 17:48:29.781514: Pseudo dice [0.9105]
2023-09-03 17:48:29.782541: Epoch time: 394.58 s
2023-09-03 17:48:29.783447: Yayy! New best EMA pseudo Dice: 0.9096
2023-09-03 17:48:32.396276: 
2023-09-03 17:48:32.397790: Epoch 42
2023-09-03 17:48:32.398691: Current learning rate: backbone 0.00087307, others 0.00087307
2023-09-03 17:48:32.399995: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 17:49:33.713649: finished training epoch 42
2023-09-03 17:49:33.760700: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 17:49:33.767543: The split file contains 1 splits.
2023-09-03 17:49:33.768601: Desired fold for training: 0
2023-09-03 17:49:33.769487: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 17:54:48.569131: dsc: 91.12%
2023-09-03 17:54:48.570549: miou: 83.69%
2023-09-03 17:54:48.571410: acc: 95.53%, sen: 91.26%, spe: 96.96%
2023-09-03 17:54:48.572587: current best miou: 0.8422144348184231 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-03 17:54:48.573491: current best dsc: 0.9143500549125113 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-03 17:54:48.574319: finished real validation
2023-09-03 17:54:52.947135: train_loss -1.4065
2023-09-03 17:54:52.948497: val_loss -1.105
2023-09-03 17:54:52.949678: Pseudo dice [0.9085]
2023-09-03 17:54:52.950613: Epoch time: 380.55 s
2023-09-03 17:54:54.043204: 
2023-09-03 17:54:54.044626: Epoch 43
2023-09-03 17:54:54.045676: Current learning rate: backbone 0.00087002, others 0.00087002
2023-09-03 17:54:54.047050: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 17:55:55.362007: finished training epoch 43
2023-09-03 17:55:55.397678: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 17:55:55.399638: The split file contains 1 splits.
2023-09-03 17:55:55.400532: Desired fold for training: 0
2023-09-03 17:55:55.401295: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 18:01:15.077342: dsc: 91.33%
2023-09-03 18:01:15.078696: miou: 84.05%
2023-09-03 18:01:15.079636: acc: 95.65%, sen: 91.04%, spe: 97.21%
2023-09-03 18:01:15.080839: current best miou: 0.8422144348184231 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-03 18:01:15.081719: current best dsc: 0.9143500549125113 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-03 18:01:15.082528: finished real validation
2023-09-03 18:01:19.474662: train_loss -1.4077
2023-09-03 18:01:19.476096: val_loss -1.1288
2023-09-03 18:01:19.477262: Pseudo dice [0.9116]
2023-09-03 18:01:19.478340: Epoch time: 385.43 s
2023-09-03 18:01:19.479347: Yayy! New best EMA pseudo Dice: 0.9097
2023-09-03 18:01:22.143615: 
2023-09-03 18:01:22.144975: Epoch 44
2023-09-03 18:01:22.145995: Current learning rate: backbone 0.00086698, others 0.00086698
2023-09-03 18:01:22.147630: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 18:02:23.864736: finished training epoch 44
2023-09-03 18:02:23.916870: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 18:02:23.919021: The split file contains 1 splits.
2023-09-03 18:02:23.923326: Desired fold for training: 0
2023-09-03 18:02:23.927350: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 18:08:47.940367: dsc: 91.18%
2023-09-03 18:08:47.942562: miou: 83.78%
2023-09-03 18:08:47.943956: acc: 95.57%, sen: 91.00%, spe: 97.11%
2023-09-03 18:08:47.945965: current best miou: 0.8422144348184231 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-03 18:08:47.946957: current best dsc: 0.9143500549125113 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-03 18:08:47.948297: finished real validation
2023-09-03 18:08:52.359728: train_loss -1.4082
2023-09-03 18:08:52.361108: val_loss -1.1078
2023-09-03 18:08:52.362357: Pseudo dice [0.9112]
2023-09-03 18:08:52.363342: Epoch time: 450.22 s
2023-09-03 18:08:52.364243: Yayy! New best EMA pseudo Dice: 0.9098
2023-09-03 18:08:54.957268: 
2023-09-03 18:08:54.958410: Epoch 45
2023-09-03 18:08:54.959301: Current learning rate: backbone 0.00086393, others 0.00086393
2023-09-03 18:08:54.960611: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 18:09:56.393346: finished training epoch 45
2023-09-03 18:09:56.423106: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 18:09:56.425029: The split file contains 1 splits.
2023-09-03 18:09:56.425954: Desired fold for training: 0
2023-09-03 18:09:56.426749: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 18:15:06.305704: dsc: 91.20%
2023-09-03 18:15:06.307171: miou: 83.83%
2023-09-03 18:15:06.308119: acc: 95.64%, sen: 89.82%, spe: 97.60%
2023-09-03 18:15:06.309438: current best miou: 0.8422144348184231 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-03 18:15:06.310334: current best dsc: 0.9143500549125113 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-03 18:15:06.311148: finished real validation
2023-09-03 18:15:10.702458: train_loss -1.4093
2023-09-03 18:15:10.703939: val_loss -1.1091
2023-09-03 18:15:10.705227: Pseudo dice [0.9083]
2023-09-03 18:15:10.706284: Epoch time: 375.75 s
2023-09-03 18:15:11.807259: 
2023-09-03 18:15:11.808627: Epoch 46
2023-09-03 18:15:11.809628: Current learning rate: backbone 0.00086088, others 0.00086088
2023-09-03 18:15:11.811017: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 18:16:13.278941: finished training epoch 46
2023-09-03 18:16:13.323095: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 18:16:13.324952: The split file contains 1 splits.
2023-09-03 18:16:13.325940: Desired fold for training: 0
2023-09-03 18:16:13.326878: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 18:21:20.748114: dsc: 91.01%
2023-09-03 18:21:20.749750: miou: 83.51%
2023-09-03 18:21:20.750674: acc: 95.46%, sen: 91.45%, spe: 96.80%
2023-09-03 18:21:20.751992: current best miou: 0.8422144348184231 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-03 18:21:20.752975: current best dsc: 0.9143500549125113 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-03 18:21:20.753828: finished real validation
2023-09-03 18:21:25.138664: train_loss -1.4089
2023-09-03 18:21:25.140239: val_loss -1.1201
2023-09-03 18:21:25.141530: Pseudo dice [0.9109]
2023-09-03 18:21:25.142570: Epoch time: 373.33 s
2023-09-03 18:21:26.241976: 
2023-09-03 18:21:26.243583: Epoch 47
2023-09-03 18:21:26.244595: Current learning rate: backbone 0.00085783, others 0.00085783
2023-09-03 18:21:26.245927: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 18:22:27.757292: finished training epoch 47
2023-09-03 18:22:27.789969: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 18:22:27.791805: The split file contains 1 splits.
2023-09-03 18:22:27.792779: Desired fold for training: 0
2023-09-03 18:22:27.793733: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 18:28:36.081332: dsc: 90.92%
2023-09-03 18:28:36.082623: miou: 83.36%
2023-09-03 18:28:36.083571: acc: 95.43%, sen: 91.06%, spe: 96.89%
2023-09-03 18:28:36.084937: current best miou: 0.8422144348184231 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-03 18:28:36.086074: current best dsc: 0.9143500549125113 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-03 18:28:36.087210: finished real validation
2023-09-03 18:28:40.457948: train_loss -1.4099
2023-09-03 18:28:40.459474: val_loss -1.1277
2023-09-03 18:28:40.461019: Pseudo dice [0.9133]
2023-09-03 18:28:40.462047: Epoch time: 434.22 s
2023-09-03 18:28:40.463079: Yayy! New best EMA pseudo Dice: 0.9101
2023-09-03 18:28:43.098128: 
2023-09-03 18:28:43.099476: Epoch 48
2023-09-03 18:28:43.100477: Current learning rate: backbone 0.00085477, others 0.00085477
2023-09-03 18:28:43.101873: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 18:29:44.470471: finished training epoch 48
2023-09-03 18:29:44.499552: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 18:29:44.501228: The split file contains 1 splits.
2023-09-03 18:29:44.502158: Desired fold for training: 0
2023-09-03 18:29:44.503017: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 18:34:55.055949: dsc: 91.11%
2023-09-03 18:34:55.057337: miou: 83.67%
2023-09-03 18:34:55.058209: acc: 95.55%, sen: 90.65%, spe: 97.20%
2023-09-03 18:34:55.059375: current best miou: 0.8422144348184231 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-03 18:34:55.060249: current best dsc: 0.9143500549125113 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-03 18:34:55.061050: finished real validation
2023-09-03 18:34:59.430578: train_loss -1.4103
2023-09-03 18:34:59.432044: val_loss -1.1318
2023-09-03 18:34:59.433278: Pseudo dice [0.914]
2023-09-03 18:34:59.434303: Epoch time: 376.33 s
2023-09-03 18:34:59.435194: Yayy! New best EMA pseudo Dice: 0.9105
2023-09-03 18:35:02.049042: 
2023-09-03 18:35:02.050400: Epoch 49
2023-09-03 18:35:02.051471: Current learning rate: backbone 0.00085172, others 0.00085172
2023-09-03 18:35:02.052808: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 18:36:12.430552: finished training epoch 49
2023-09-03 18:36:12.469783: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 18:36:12.472343: The split file contains 1 splits.
2023-09-03 18:36:12.473869: Desired fold for training: 0
2023-09-03 18:36:12.475185: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 18:43:12.575487: dsc: 91.26%
2023-09-03 18:43:12.576969: miou: 83.93%
2023-09-03 18:43:12.577923: acc: 95.61%, sen: 91.24%, spe: 97.07%
2023-09-03 18:43:12.579215: current best miou: 0.8422144348184231 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-03 18:43:12.580506: current best dsc: 0.9143500549125113 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-03 18:43:12.581373: finished real validation
2023-09-03 18:43:16.959591: train_loss -1.4106
2023-09-03 18:43:16.961171: val_loss -1.1059
2023-09-03 18:43:16.962472: Pseudo dice [0.91]
2023-09-03 18:43:16.963471: Epoch time: 494.91 s
2023-09-03 18:43:19.611122: 
2023-09-03 18:43:19.612585: Epoch 50
2023-09-03 18:43:19.613655: Current learning rate: backbone 0.00084867, others 0.00084867
2023-09-03 18:43:19.615140: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 18:44:20.896312: finished training epoch 50
2023-09-03 18:44:20.929337: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 18:44:20.931617: The split file contains 1 splits.
2023-09-03 18:44:20.932651: Desired fold for training: 0
2023-09-03 18:44:20.933619: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 18:49:31.057775: dsc: 91.17%
2023-09-03 18:49:31.059269: miou: 83.77%
2023-09-03 18:49:31.060246: acc: 95.54%, sen: 91.52%, spe: 96.89%
2023-09-03 18:49:31.061518: current best miou: 0.8422144348184231 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-03 18:49:31.062501: current best dsc: 0.9143500549125113 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-03 18:49:31.063355: finished real validation
2023-09-03 18:49:35.451328: train_loss -1.4129
2023-09-03 18:49:35.452937: val_loss -1.0916
2023-09-03 18:49:35.454057: Pseudo dice [0.9096]
2023-09-03 18:49:35.454960: Epoch time: 375.84 s
2023-09-03 18:49:36.605142: 
2023-09-03 18:49:36.606400: Epoch 51
2023-09-03 18:49:36.607489: Current learning rate: backbone 0.00084561, others 0.00084561
2023-09-03 18:49:36.609198: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 18:50:37.839707: finished training epoch 51
2023-09-03 18:50:37.868661: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 18:50:37.870356: The split file contains 1 splits.
2023-09-03 18:50:37.871319: Desired fold for training: 0
2023-09-03 18:50:37.872166: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 18:56:24.638510: dsc: 91.23%
2023-09-03 18:56:24.640072: miou: 83.88%
2023-09-03 18:56:24.640938: acc: 95.62%, sen: 90.62%, spe: 97.30%
2023-09-03 18:56:24.642113: current best miou: 0.8422144348184231 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-03 18:56:24.643033: current best dsc: 0.9143500549125113 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-03 18:56:24.643994: finished real validation
2023-09-03 18:56:29.048213: train_loss -1.4131
2023-09-03 18:56:29.049848: val_loss -1.12
2023-09-03 18:56:29.051287: Pseudo dice [0.9146]
2023-09-03 18:56:29.052510: Epoch time: 412.44 s
2023-09-03 18:56:29.053442: Yayy! New best EMA pseudo Dice: 0.9108
2023-09-03 18:56:31.733845: 
2023-09-03 18:56:31.735361: Epoch 52
2023-09-03 18:56:31.736379: Current learning rate: backbone 0.00084255, others 0.00084255
2023-09-03 18:56:31.737774: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 18:57:33.083336: finished training epoch 52
2023-09-03 18:57:33.113584: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 18:57:33.116758: The split file contains 1 splits.
2023-09-03 18:57:33.118296: Desired fold for training: 0
2023-09-03 18:57:33.119580: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 19:03:02.387713: dsc: 91.22%
2023-09-03 19:03:02.389264: miou: 83.86%
2023-09-03 19:03:02.390805: acc: 95.62%, sen: 90.41%, spe: 97.37%
2023-09-03 19:03:02.392164: current best miou: 0.8422144348184231 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-03 19:03:02.393627: current best dsc: 0.9143500549125113 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-03 19:03:02.394563: finished real validation
2023-09-03 19:03:06.790001: train_loss -1.4133
2023-09-03 19:03:06.791535: val_loss -1.126
2023-09-03 19:03:06.792717: Pseudo dice [0.9135]
2023-09-03 19:03:06.793726: Epoch time: 395.06 s
2023-09-03 19:03:06.794635: Yayy! New best EMA pseudo Dice: 0.9111
2023-09-03 19:03:09.505032: 
2023-09-03 19:03:09.506550: Epoch 53
2023-09-03 19:03:09.507529: Current learning rate: backbone 0.0008395, others 0.0008395
2023-09-03 19:03:09.509127: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 19:04:10.831378: finished training epoch 53
2023-09-03 19:04:10.860735: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 19:04:10.862418: The split file contains 1 splits.
2023-09-03 19:04:10.863308: Desired fold for training: 0
2023-09-03 19:04:10.864146: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 19:09:40.187797: dsc: 91.33%
2023-09-03 19:09:40.189447: miou: 84.05%
2023-09-03 19:09:40.190438: acc: 95.63%, sen: 91.55%, spe: 97.00%
2023-09-03 19:09:40.191916: current best miou: 0.8422144348184231 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-03 19:09:40.192948: current best dsc: 0.9143500549125113 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-03 19:09:40.193881: finished real validation
2023-09-03 19:09:44.576791: train_loss -1.4128
2023-09-03 19:09:44.578164: val_loss -1.0926
2023-09-03 19:09:44.579341: Pseudo dice [0.9102]
2023-09-03 19:09:44.580326: Epoch time: 395.07 s
2023-09-03 19:09:45.715118: 
2023-09-03 19:09:45.716382: Epoch 54
2023-09-03 19:09:45.717453: Current learning rate: backbone 0.00083644, others 0.00083644
2023-09-03 19:09:45.719644: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 19:10:46.860019: finished training epoch 54
2023-09-03 19:10:46.905694: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 19:10:46.907830: The split file contains 1 splits.
2023-09-03 19:10:46.911387: Desired fold for training: 0
2023-09-03 19:10:46.914383: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 19:16:56.198209: dsc: 91.20%
2023-09-03 19:16:56.199682: miou: 83.83%
2023-09-03 19:16:56.200858: acc: 95.61%, sen: 90.42%, spe: 97.36%
2023-09-03 19:16:56.202547: current best miou: 0.8422144348184231 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-03 19:16:56.203832: current best dsc: 0.9143500549125113 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-03 19:16:56.204983: finished real validation
2023-09-03 19:17:00.591309: train_loss -1.4145
2023-09-03 19:17:00.592834: val_loss -1.1198
2023-09-03 19:17:00.594187: Pseudo dice [0.9134]
2023-09-03 19:17:00.595240: Epoch time: 434.88 s
2023-09-03 19:17:00.596321: Yayy! New best EMA pseudo Dice: 0.9112
2023-09-03 19:17:03.275352: 
2023-09-03 19:17:03.276632: Epoch 55
2023-09-03 19:17:03.277608: Current learning rate: backbone 0.00083337, others 0.00083337
2023-09-03 19:17:03.279016: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 19:18:04.724620: finished training epoch 55
2023-09-03 19:18:04.773807: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 19:18:04.775854: The split file contains 1 splits.
2023-09-03 19:18:04.776833: Desired fold for training: 0
2023-09-03 19:18:04.777716: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 19:23:45.064451: dsc: 91.04%
2023-09-03 19:23:45.065716: miou: 83.56%
2023-09-03 19:23:45.066656: acc: 95.49%, sen: 91.07%, spe: 96.98%
2023-09-03 19:23:45.067853: current best miou: 0.8422144348184231 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-03 19:23:45.068807: current best dsc: 0.9143500549125113 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-03 19:23:45.069676: finished real validation
2023-09-03 19:23:49.436805: train_loss -1.4153
2023-09-03 19:23:49.438252: val_loss -1.1067
2023-09-03 19:23:49.439520: Pseudo dice [0.9132]
2023-09-03 19:23:49.440539: Epoch time: 406.16 s
2023-09-03 19:23:49.441678: Yayy! New best EMA pseudo Dice: 0.9114
2023-09-03 19:23:52.154454: 
2023-09-03 19:23:52.155668: Epoch 56
2023-09-03 19:23:52.156591: Current learning rate: backbone 0.00083031, others 0.00083031
2023-09-03 19:23:52.158116: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 19:24:53.579617: finished training epoch 56
2023-09-03 19:24:53.611539: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 19:24:53.613470: The split file contains 1 splits.
2023-09-03 19:24:53.614424: Desired fold for training: 0
2023-09-03 19:24:53.618307: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 19:30:04.279578: dsc: 91.00%
2023-09-03 19:30:04.281154: miou: 83.48%
2023-09-03 19:30:04.282161: acc: 95.52%, sen: 90.02%, spe: 97.37%
2023-09-03 19:30:04.283508: current best miou: 0.8422144348184231 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-03 19:30:04.284754: current best dsc: 0.9143500549125113 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-03 19:30:04.285661: finished real validation
2023-09-03 19:30:08.663973: train_loss -1.4163
2023-09-03 19:30:08.665458: val_loss -1.1078
2023-09-03 19:30:08.666789: Pseudo dice [0.9093]
2023-09-03 19:30:08.668326: Epoch time: 376.51 s
2023-09-03 19:30:09.788396: 
2023-09-03 19:30:09.789721: Epoch 57
2023-09-03 19:30:09.790757: Current learning rate: backbone 0.00082725, others 0.00082725
2023-09-03 19:30:09.792137: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 19:31:11.167747: finished training epoch 57
2023-09-03 19:31:11.218019: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 19:31:11.219938: The split file contains 1 splits.
2023-09-03 19:31:11.220934: Desired fold for training: 0
2023-09-03 19:31:11.221880: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 19:36:33.837600: dsc: 91.21%
2023-09-03 19:36:33.839347: miou: 83.84%
2023-09-03 19:36:33.840725: acc: 95.57%, sen: 91.43%, spe: 96.96%
2023-09-03 19:36:33.842298: current best miou: 0.8422144348184231 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-03 19:36:33.843581: current best dsc: 0.9143500549125113 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-03 19:36:33.844836: finished real validation
2023-09-03 19:36:38.225656: train_loss -1.4163
2023-09-03 19:36:38.227132: val_loss -1.0984
2023-09-03 19:36:38.228405: Pseudo dice [0.9103]
2023-09-03 19:36:38.229457: Epoch time: 388.44 s
2023-09-03 19:36:39.379984: 
2023-09-03 19:36:39.381622: Epoch 58
2023-09-03 19:36:39.382716: Current learning rate: backbone 0.00082418, others 0.00082418
2023-09-03 19:36:39.384223: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 19:37:40.861162: finished training epoch 58
2023-09-03 19:37:40.891174: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 19:37:40.893127: The split file contains 1 splits.
2023-09-03 19:37:40.894101: Desired fold for training: 0
2023-09-03 19:37:40.895034: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 19:42:54.654767: dsc: 91.29%
2023-09-03 19:42:54.656527: miou: 83.98%
2023-09-03 19:42:54.657654: acc: 95.62%, sen: 91.38%, spe: 97.04%
2023-09-03 19:42:54.658846: current best miou: 0.8422144348184231 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-03 19:42:54.659786: current best dsc: 0.9143500549125113 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-03 19:42:54.660661: finished real validation
2023-09-03 19:42:59.045371: train_loss -1.4156
2023-09-03 19:42:59.047018: val_loss -1.088
2023-09-03 19:42:59.048386: Pseudo dice [0.9105]
2023-09-03 19:42:59.049530: Epoch time: 379.67 s
2023-09-03 19:43:00.180699: 
2023-09-03 19:43:00.182272: Epoch 59
2023-09-03 19:43:00.183353: Current learning rate: backbone 0.00082112, others 0.00082112
2023-09-03 19:43:00.184820: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 19:44:01.724136: finished training epoch 59
2023-09-03 19:44:01.751666: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 19:44:01.753755: The split file contains 1 splits.
2023-09-03 19:44:01.754818: Desired fold for training: 0
2023-09-03 19:44:01.755801: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 19:50:35.444794: dsc: 91.09%
2023-09-03 19:50:35.446187: miou: 83.63%
2023-09-03 19:50:35.447200: acc: 95.53%, sen: 90.88%, spe: 97.09%
2023-09-03 19:50:35.448557: current best miou: 0.8422144348184231 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-03 19:50:35.449584: current best dsc: 0.9143500549125113 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-03 19:50:35.450521: finished real validation
2023-09-03 19:50:39.837148: train_loss -1.4162
2023-09-03 19:50:39.839028: val_loss -1.0669
2023-09-03 19:50:39.840755: Pseudo dice [0.9082]
2023-09-03 19:50:39.841886: Epoch time: 459.66 s
2023-09-03 19:50:42.602738: 
2023-09-03 19:50:42.603925: Epoch 60
2023-09-03 19:50:42.604966: Current learning rate: backbone 0.00081805, others 0.00081805
2023-09-03 19:50:42.606474: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 19:51:43.926310: finished training epoch 60
2023-09-03 19:51:43.967018: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 19:51:43.969022: The split file contains 1 splits.
2023-09-03 19:51:43.969929: Desired fold for training: 0
2023-09-03 19:51:43.970745: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 19:57:01.560156: dsc: 91.05%
2023-09-03 19:57:01.561903: miou: 83.57%
2023-09-03 19:57:01.562953: acc: 95.50%, sen: 91.06%, spe: 96.99%
2023-09-03 19:57:01.564325: current best miou: 0.8422144348184231 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-03 19:57:01.565322: current best dsc: 0.9143500549125113 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-03 19:57:01.566291: finished real validation
2023-09-03 19:57:05.955397: train_loss -1.417
2023-09-03 19:57:05.956893: val_loss -1.0978
2023-09-03 19:57:05.958136: Pseudo dice [0.9105]
2023-09-03 19:57:05.959167: Epoch time: 383.35 s
2023-09-03 19:57:07.091353: 
2023-09-03 19:57:07.092653: Epoch 61
2023-09-03 19:57:07.093783: Current learning rate: backbone 0.00081498, others 0.00081498
2023-09-03 19:57:07.095214: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 19:58:08.511106: finished training epoch 61
2023-09-03 19:58:08.537771: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 19:58:08.539669: The split file contains 1 splits.
2023-09-03 19:58:08.540727: Desired fold for training: 0
2023-09-03 19:58:08.541696: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 20:03:18.335637: dsc: 90.89%
2023-09-03 20:03:18.337315: miou: 83.30%
2023-09-03 20:03:18.338565: acc: 95.41%, sen: 91.01%, spe: 96.89%
2023-09-03 20:03:18.340203: current best miou: 0.8422144348184231 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-03 20:03:18.341544: current best dsc: 0.9143500549125113 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-03 20:03:18.342754: finished real validation
2023-09-03 20:03:22.723133: train_loss -1.4181
2023-09-03 20:03:22.724992: val_loss -1.0758
2023-09-03 20:03:22.726479: Pseudo dice [0.9117]
2023-09-03 20:03:22.727624: Epoch time: 375.63 s
2023-09-03 20:03:23.862806: 
2023-09-03 20:03:23.864372: Epoch 62
2023-09-03 20:03:23.865523: Current learning rate: backbone 0.00081191, others 0.00081191
2023-09-03 20:03:23.867118: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 20:04:25.320849: finished training epoch 62
2023-09-03 20:04:25.362725: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 20:04:25.364469: The split file contains 1 splits.
2023-09-03 20:04:25.365472: Desired fold for training: 0
2023-09-03 20:04:25.366356: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 20:09:50.654001: dsc: 91.00%
2023-09-03 20:09:50.656320: miou: 83.48%
2023-09-03 20:09:50.657551: acc: 95.46%, sen: 91.18%, spe: 96.90%
2023-09-03 20:09:50.659141: current best miou: 0.8422144348184231 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-03 20:09:50.660099: current best dsc: 0.9143500549125113 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-03 20:09:50.661114: finished real validation
2023-09-03 20:09:55.061260: train_loss -1.4183
2023-09-03 20:09:55.062676: val_loss -1.0596
2023-09-03 20:09:55.064082: Pseudo dice [0.9099]
2023-09-03 20:09:55.065168: Epoch time: 391.2 s
2023-09-03 20:09:56.213526: 
2023-09-03 20:09:56.215148: Epoch 63
2023-09-03 20:09:56.216228: Current learning rate: backbone 0.00080884, others 0.00080884
2023-09-03 20:09:56.217638: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 20:10:57.781653: finished training epoch 63
2023-09-03 20:10:57.811636: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 20:10:57.813579: The split file contains 1 splits.
2023-09-03 20:10:57.822306: Desired fold for training: 0
2023-09-03 20:10:57.829583: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 20:16:15.117997: dsc: 91.16%
2023-09-03 20:16:15.119572: miou: 83.75%
2023-09-03 20:16:15.120666: acc: 95.57%, sen: 90.82%, spe: 97.16%
2023-09-03 20:16:15.122000: current best miou: 0.8422144348184231 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-03 20:16:15.123083: current best dsc: 0.9143500549125113 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-03 20:16:15.124080: finished real validation
2023-09-03 20:16:19.511076: train_loss -1.4196
2023-09-03 20:16:19.512686: val_loss -1.121
2023-09-03 20:16:19.514080: Pseudo dice [0.9171]
2023-09-03 20:16:19.515247: Epoch time: 383.3 s
2023-09-03 20:16:20.659982: 
2023-09-03 20:16:20.661463: Epoch 64
2023-09-03 20:16:20.662505: Current learning rate: backbone 0.00080577, others 0.00080577
2023-09-03 20:16:20.663940: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 20:17:22.284194: finished training epoch 64
2023-09-03 20:17:22.313782: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 20:17:22.316549: The split file contains 1 splits.
2023-09-03 20:17:22.317984: Desired fold for training: 0
2023-09-03 20:17:22.319374: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 20:22:45.562234: dsc: 90.83%
2023-09-03 20:22:45.563637: miou: 83.21%
2023-09-03 20:22:45.564637: acc: 95.40%, sen: 90.65%, spe: 96.99%
2023-09-03 20:22:45.565884: current best miou: 0.8422144348184231 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-03 20:22:45.566845: current best dsc: 0.9143500549125113 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-03 20:22:45.567758: finished real validation
2023-09-03 20:22:49.951760: train_loss -1.4197
2023-09-03 20:22:49.953550: val_loss -1.0454
2023-09-03 20:22:49.955075: Pseudo dice [0.9051]
2023-09-03 20:22:49.956269: Epoch time: 389.29 s
2023-09-03 20:22:51.114909: 
2023-09-03 20:22:51.117122: Epoch 65
2023-09-03 20:22:51.118593: Current learning rate: backbone 0.0008027, others 0.0008027
2023-09-03 20:22:51.120438: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 20:23:52.579053: finished training epoch 65
2023-09-03 20:23:52.606685: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 20:23:52.608651: The split file contains 1 splits.
2023-09-03 20:23:52.609738: Desired fold for training: 0
2023-09-03 20:23:52.610706: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 20:29:17.504544: dsc: 91.00%
2023-09-03 20:29:17.505949: miou: 83.49%
2023-09-03 20:29:17.506968: acc: 95.52%, sen: 90.12%, spe: 97.33%
2023-09-03 20:29:17.508245: current best miou: 0.8422144348184231 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-03 20:29:17.509326: current best dsc: 0.9143500549125113 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-03 20:29:17.510250: finished real validation
2023-09-03 20:29:21.918650: train_loss -1.4188
2023-09-03 20:29:21.920182: val_loss -1.0729
2023-09-03 20:29:21.921449: Pseudo dice [0.9086]
2023-09-03 20:29:21.922498: Epoch time: 390.81 s
2023-09-03 20:29:23.077260: 
2023-09-03 20:29:23.078858: Epoch 66
2023-09-03 20:29:23.079956: Current learning rate: backbone 0.00079962, others 0.00079962
2023-09-03 20:29:23.081427: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 20:30:24.544593: finished training epoch 66
2023-09-03 20:30:24.590147: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 20:30:24.592043: The split file contains 1 splits.
2023-09-03 20:30:24.593102: Desired fold for training: 0
2023-09-03 20:30:24.594092: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 20:37:00.395539: dsc: 91.10%
2023-09-03 20:37:00.417853: miou: 83.66%
2023-09-03 20:37:00.419423: acc: 95.56%, sen: 90.36%, spe: 97.31%
2023-09-03 20:37:00.422167: current best miou: 0.8422144348184231 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-03 20:37:00.423610: current best dsc: 0.9143500549125113 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-03 20:37:00.425121: finished real validation
2023-09-03 20:37:04.799896: train_loss -1.4181
2023-09-03 20:37:04.801432: val_loss -1.1171
2023-09-03 20:37:04.802776: Pseudo dice [0.9158]
2023-09-03 20:37:04.803850: Epoch time: 461.72 s
2023-09-03 20:37:05.927978: 
2023-09-03 20:37:05.929651: Epoch 67
2023-09-03 20:37:05.930842: Current learning rate: backbone 0.00079655, others 0.00079655
2023-09-03 20:37:05.932583: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 20:38:07.220598: finished training epoch 67
2023-09-03 20:38:07.250714: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 20:38:07.252819: The split file contains 1 splits.
2023-09-03 20:38:07.253894: Desired fold for training: 0
2023-09-03 20:38:07.254919: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 20:43:36.449056: dsc: 91.10%
2023-09-03 20:43:36.450841: miou: 83.66%
2023-09-03 20:43:36.452373: acc: 95.53%, sen: 90.88%, spe: 97.10%
2023-09-03 20:43:36.454283: current best miou: 0.8422144348184231 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-03 20:43:36.455722: current best dsc: 0.9143500549125113 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-03 20:43:36.456712: finished real validation
2023-09-03 20:43:40.843661: train_loss -1.4205
2023-09-03 20:43:40.845244: val_loss -1.1083
2023-09-03 20:43:40.846670: Pseudo dice [0.915]
2023-09-03 20:43:40.847782: Epoch time: 394.92 s
2023-09-03 20:43:40.848812: Yayy! New best EMA pseudo Dice: 0.9115
2023-09-03 20:43:43.526886: 
2023-09-03 20:43:43.528322: Epoch 68
2023-09-03 20:43:43.529485: Current learning rate: backbone 0.00079347, others 0.00079347
2023-09-03 20:43:43.531106: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 20:44:44.894351: finished training epoch 68
2023-09-03 20:44:44.923722: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 20:44:44.925904: The split file contains 1 splits.
2023-09-03 20:44:44.927072: Desired fold for training: 0
2023-09-03 20:44:44.928218: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 20:50:00.020507: dsc: 91.00%
2023-09-03 20:50:00.022182: miou: 83.48%
2023-09-03 20:50:00.023269: acc: 95.48%, sen: 90.80%, spe: 97.05%
2023-09-03 20:50:00.024773: current best miou: 0.8422144348184231 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-03 20:50:00.025778: current best dsc: 0.9143500549125113 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-03 20:50:00.026704: finished real validation
2023-09-03 20:50:04.423471: train_loss -1.4217
2023-09-03 20:50:04.425297: val_loss -1.0893
2023-09-03 20:50:04.426924: Pseudo dice [0.9128]
2023-09-03 20:50:04.428120: Epoch time: 380.9 s
2023-09-03 20:50:04.429189: Yayy! New best EMA pseudo Dice: 0.9116
2023-09-03 20:50:07.154131: 
2023-09-03 20:50:07.155663: Epoch 69
2023-09-03 20:50:07.156744: Current learning rate: backbone 0.00079039, others 0.00079039
2023-09-03 20:50:07.158304: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 20:51:08.495444: finished training epoch 69
2023-09-03 20:51:08.562488: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 20:51:08.564407: The split file contains 1 splits.
2023-09-03 20:51:08.565716: Desired fold for training: 0
2023-09-03 20:51:08.566860: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 20:56:24.810927: dsc: 90.97%
2023-09-03 20:56:24.812461: miou: 83.44%
2023-09-03 20:56:24.813802: acc: 95.47%, sen: 90.84%, spe: 97.02%
2023-09-03 20:56:24.816068: current best miou: 0.8422144348184231 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-03 20:56:24.817497: current best dsc: 0.9143500549125113 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-03 20:56:24.818780: finished real validation
2023-09-03 20:56:29.223149: train_loss -1.42
2023-09-03 20:56:29.224847: val_loss -1.0772
2023-09-03 20:56:29.226314: Pseudo dice [0.9111]
2023-09-03 20:56:29.227462: Epoch time: 382.07 s
2023-09-03 20:56:31.938787: 
2023-09-03 20:56:31.940284: Epoch 70
2023-09-03 20:56:31.941506: Current learning rate: backbone 0.00078731, others 0.00078731
2023-09-03 20:56:31.943116: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 20:57:33.400832: finished training epoch 70
2023-09-03 20:57:33.428644: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 20:57:33.430668: The split file contains 1 splits.
2023-09-03 20:57:33.431695: Desired fold for training: 0
2023-09-03 20:57:33.432698: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 21:02:47.737373: dsc: 91.02%
2023-09-03 21:02:47.738907: miou: 83.52%
2023-09-03 21:02:47.739886: acc: 95.52%, sen: 90.29%, spe: 97.28%
2023-09-03 21:02:47.741157: current best miou: 0.8422144348184231 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-03 21:02:47.742200: current best dsc: 0.9143500549125113 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-03 21:02:47.743151: finished real validation
2023-09-03 21:02:52.139917: train_loss -1.4208
2023-09-03 21:02:52.141428: val_loss -1.0731
2023-09-03 21:02:52.142762: Pseudo dice [0.911]
2023-09-03 21:02:52.143865: Epoch time: 380.2 s
2023-09-03 21:02:53.283795: 
2023-09-03 21:02:53.285406: Epoch 71
2023-09-03 21:02:53.286630: Current learning rate: backbone 0.00078423, others 0.00078423
2023-09-03 21:02:53.288042: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 21:03:54.701699: finished training epoch 71
2023-09-03 21:03:54.757677: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 21:03:54.759784: The split file contains 1 splits.
2023-09-03 21:03:54.762335: Desired fold for training: 0
2023-09-03 21:03:54.763594: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 21:10:27.909020: dsc: 91.12%
2023-09-03 21:10:27.910610: miou: 83.69%
2023-09-03 21:10:27.911662: acc: 95.54%, sen: 90.96%, spe: 97.08%
2023-09-03 21:10:27.913105: current best miou: 0.8422144348184231 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-03 21:10:27.914138: current best dsc: 0.9143500549125113 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-03 21:10:27.915121: finished real validation
2023-09-03 21:10:32.325264: train_loss -1.4222
2023-09-03 21:10:32.326721: val_loss -1.1124
2023-09-03 21:10:32.327990: Pseudo dice [0.915]
2023-09-03 21:10:32.329773: Epoch time: 459.04 s
2023-09-03 21:10:32.330947: Yayy! New best EMA pseudo Dice: 0.9118
2023-09-03 21:10:35.028456: 
2023-09-03 21:10:35.030096: Epoch 72
2023-09-03 21:10:35.031325: Current learning rate: backbone 0.00078115, others 0.00078115
2023-09-03 21:10:35.032912: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 21:11:36.260263: finished training epoch 72
2023-09-03 21:11:36.291517: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 21:11:36.293677: The split file contains 1 splits.
2023-09-03 21:11:36.294886: Desired fold for training: 0
2023-09-03 21:11:36.295987: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 21:16:56.341451: dsc: 91.03%
2023-09-03 21:16:56.343171: miou: 83.54%
2023-09-03 21:16:56.344849: acc: 95.49%, sen: 90.91%, spe: 97.04%
2023-09-03 21:16:56.346182: current best miou: 0.8422144348184231 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-03 21:16:56.347220: current best dsc: 0.9143500549125113 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-03 21:16:56.348226: finished real validation
2023-09-03 21:17:00.750634: train_loss -1.4214
2023-09-03 21:17:00.752392: val_loss -1.0548
2023-09-03 21:17:00.753730: Pseudo dice [0.91]
2023-09-03 21:17:00.755337: Epoch time: 385.72 s
2023-09-03 21:17:01.908469: 
2023-09-03 21:17:01.910096: Epoch 73
2023-09-03 21:17:01.911330: Current learning rate: backbone 0.00077806, others 0.00077806
2023-09-03 21:17:01.912959: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 21:52:41.901957: finished training epoch 73
2023-09-03 21:52:41.939616: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 21:52:41.941635: The split file contains 1 splits.
2023-09-03 21:52:41.942684: Desired fold for training: 0
2023-09-03 21:52:41.943683: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 21:58:47.266923: dsc: 91.16%
2023-09-03 21:58:47.268582: miou: 83.76%
2023-09-03 21:58:47.269670: acc: 95.56%, sen: 90.95%, spe: 97.11%
2023-09-03 21:58:47.271236: current best miou: 0.8422144348184231 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-03 21:58:47.272293: current best dsc: 0.9143500549125113 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-03 21:58:47.273269: finished real validation
2023-09-03 21:58:51.657841: train_loss -1.4222
2023-09-03 21:58:51.659684: val_loss -1.0712
2023-09-03 21:58:51.661184: Pseudo dice [0.9102]
2023-09-03 21:58:51.662325: Epoch time: 2509.75 s
2023-09-03 21:58:53.100040: 
2023-09-03 21:58:53.101883: Epoch 74
2023-09-03 21:58:53.103009: Current learning rate: backbone 0.00077498, others 0.00077498
2023-09-03 21:58:53.104876: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 21:59:55.197091: finished training epoch 74
2023-09-03 21:59:55.238387: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 21:59:55.240540: The split file contains 1 splits.
2023-09-03 21:59:55.241878: Desired fold for training: 0
2023-09-03 21:59:55.242918: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 22:05:07.840665: dsc: 91.10%
2023-09-03 22:05:07.842267: miou: 83.66%
2023-09-03 22:05:07.843575: acc: 95.52%, sen: 91.14%, spe: 96.99%
2023-09-03 22:05:07.845525: current best miou: 0.8422144348184231 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-03 22:05:07.847088: current best dsc: 0.9143500549125113 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-03 22:05:07.848685: finished real validation
2023-09-03 22:05:12.237381: train_loss -1.4223
2023-09-03 22:05:12.239035: val_loss -1.0792
2023-09-03 22:05:12.240446: Pseudo dice [0.9116]
2023-09-03 22:05:12.241841: Epoch time: 379.14 s
2023-09-03 22:05:13.389237: 
2023-09-03 22:05:13.390584: Epoch 75
2023-09-03 22:05:13.392115: Current learning rate: backbone 0.00077189, others 0.00077189
2023-09-03 22:05:13.393895: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 22:06:14.608646: finished training epoch 75
2023-09-03 22:06:14.650719: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 22:06:14.653596: The split file contains 1 splits.
2023-09-03 22:06:14.655539: Desired fold for training: 0
2023-09-03 22:06:14.657166: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 22:11:50.191200: dsc: 91.14%
2023-09-03 22:11:50.192914: miou: 83.72%
2023-09-03 22:11:50.194220: acc: 95.53%, sen: 91.32%, spe: 96.95%
2023-09-03 22:11:50.195992: current best miou: 0.8422144348184231 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-03 22:11:50.197556: current best dsc: 0.9143500549125113 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-03 22:11:50.199135: finished real validation
2023-09-03 22:11:54.585679: train_loss -1.4224
2023-09-03 22:11:54.587211: val_loss -1.0775
2023-09-03 22:11:54.588578: Pseudo dice [0.9117]
2023-09-03 22:11:54.589911: Epoch time: 401.2 s
2023-09-03 22:11:55.746998: 
2023-09-03 22:11:55.748690: Epoch 76
2023-09-03 22:11:55.749823: Current learning rate: backbone 0.0007688, others 0.0007688
2023-09-03 22:11:55.751325: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 22:12:56.970096: finished training epoch 76
2023-09-03 22:12:57.013434: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 22:12:57.015638: The split file contains 1 splits.
2023-09-03 22:12:57.016824: Desired fold for training: 0
2023-09-03 22:12:57.017816: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 22:18:10.935164: dsc: 91.06%
2023-09-03 22:18:10.936923: miou: 83.59%
2023-09-03 22:18:10.938286: acc: 95.53%, sen: 90.43%, spe: 97.25%
2023-09-03 22:18:10.940243: current best miou: 0.8422144348184231 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-03 22:18:10.941837: current best dsc: 0.9143500549125113 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-03 22:18:10.942993: finished real validation
2023-09-03 22:18:15.334565: train_loss -1.4236
2023-09-03 22:18:15.336365: val_loss -1.0824
2023-09-03 22:18:15.337719: Pseudo dice [0.9099]
2023-09-03 22:18:15.338900: Epoch time: 379.59 s
2023-09-03 22:18:16.497555: 
2023-09-03 22:18:16.500799: Epoch 77
2023-09-03 22:18:16.503451: Current learning rate: backbone 0.00076571, others 0.00076571
2023-09-03 22:18:16.507344: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 22:19:17.796666: finished training epoch 77
2023-09-03 22:19:17.849387: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 22:19:17.851574: The split file contains 1 splits.
2023-09-03 22:19:17.853516: Desired fold for training: 0
2023-09-03 22:19:17.855139: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 22:24:24.708541: dsc: 91.21%
2023-09-03 22:24:24.710364: miou: 83.83%
2023-09-03 22:24:24.711725: acc: 95.62%, sen: 90.39%, spe: 97.37%
2023-09-03 22:24:24.713483: current best miou: 0.8422144348184231 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-03 22:24:24.714813: current best dsc: 0.9143500549125113 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-03 22:24:24.716144: finished real validation
2023-09-03 22:24:29.106370: train_loss -1.4245
2023-09-03 22:24:29.107996: val_loss -1.0953
2023-09-03 22:24:29.109402: Pseudo dice [0.9144]
2023-09-03 22:24:29.110567: Epoch time: 372.61 s
2023-09-03 22:24:30.270813: 
2023-09-03 22:24:30.272931: Epoch 78
2023-09-03 22:24:30.274241: Current learning rate: backbone 0.00076262, others 0.00076262
2023-09-03 22:24:30.275720: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 22:25:31.345025: finished training epoch 78
2023-09-03 22:25:31.373895: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 22:25:31.375901: The split file contains 1 splits.
2023-09-03 22:25:31.377656: Desired fold for training: 0
2023-09-03 22:25:31.379148: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 22:30:42.731760: dsc: 90.94%
2023-09-03 22:30:42.733330: miou: 83.39%
2023-09-03 22:30:42.734425: acc: 95.48%, sen: 90.23%, spe: 97.24%
2023-09-03 22:30:42.736283: current best miou: 0.8422144348184231 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-03 22:30:42.737475: current best dsc: 0.9143500549125113 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-03 22:30:42.738699: finished real validation
2023-09-03 22:30:47.129050: train_loss -1.4225
2023-09-03 22:30:47.130739: val_loss -1.0802
2023-09-03 22:30:47.132136: Pseudo dice [0.9121]
2023-09-03 22:30:47.133317: Epoch time: 376.86 s
2023-09-03 22:30:48.258662: 
2023-09-03 22:30:48.260470: Epoch 79
2023-09-03 22:30:48.261898: Current learning rate: backbone 0.00075953, others 0.00075953
2023-09-03 22:30:48.264051: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 22:31:49.400799: finished training epoch 79
2023-09-03 22:31:49.447486: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 22:31:49.449652: The split file contains 1 splits.
2023-09-03 22:31:49.450824: Desired fold for training: 0
2023-09-03 22:31:49.451930: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 22:37:00.445609: dsc: 91.12%
2023-09-03 22:37:00.447108: miou: 83.70%
2023-09-03 22:37:00.448240: acc: 95.55%, sen: 90.73%, spe: 97.18%
2023-09-03 22:37:00.449828: current best miou: 0.8422144348184231 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-03 22:37:00.451101: current best dsc: 0.9143500549125113 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-03 22:37:00.452139: finished real validation
2023-09-03 22:37:04.848548: train_loss -1.4247
2023-09-03 22:37:04.850369: val_loss -1.0657
2023-09-03 22:37:04.851856: Pseudo dice [0.9118]
2023-09-03 22:37:04.854800: Epoch time: 376.59 s
2023-09-03 22:37:07.663056: 
2023-09-03 22:37:07.664579: Epoch 80
2023-09-03 22:37:07.665781: Current learning rate: backbone 0.00075643, others 0.00075643
2023-09-03 22:37:07.667293: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 22:38:08.777127: finished training epoch 80
2023-09-03 22:38:08.806078: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 22:38:08.808054: The split file contains 1 splits.
2023-09-03 22:38:08.809424: Desired fold for training: 0
2023-09-03 22:38:08.810523: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 22:43:16.435856: dsc: 91.04%
2023-09-03 22:43:16.437795: miou: 83.56%
2023-09-03 22:43:16.438914: acc: 95.48%, sen: 91.26%, spe: 96.90%
2023-09-03 22:43:16.440933: current best miou: 0.8422144348184231 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-03 22:43:16.442674: current best dsc: 0.9143500549125113 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-03 22:43:16.444149: finished real validation
2023-09-03 22:43:20.840434: train_loss -1.4252
2023-09-03 22:43:20.842352: val_loss -1.0554
2023-09-03 22:43:20.843884: Pseudo dice [0.9103]
2023-09-03 22:43:20.845221: Epoch time: 373.18 s
2023-09-03 22:43:22.021064: 
2023-09-03 22:43:22.022750: Epoch 81
2023-09-03 22:43:22.024214: Current learning rate: backbone 0.00075334, others 0.00075334
2023-09-03 22:43:22.026016: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 22:44:23.184553: finished training epoch 81
2023-09-03 22:44:23.232020: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 22:44:23.234442: The split file contains 1 splits.
2023-09-03 22:44:23.235540: Desired fold for training: 0
2023-09-03 22:44:23.236645: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 22:49:32.224074: dsc: 91.12%
2023-09-03 22:49:32.225785: miou: 83.69%
2023-09-03 22:49:32.227168: acc: 95.55%, sen: 90.68%, spe: 97.19%
2023-09-03 22:49:32.229594: current best miou: 0.8422144348184231 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-03 22:49:32.230961: current best dsc: 0.9143500549125113 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-03 22:49:32.232112: finished real validation
2023-09-03 22:49:36.614710: train_loss -1.4247
2023-09-03 22:49:36.616418: val_loss -1.0628
2023-09-03 22:49:36.617782: Pseudo dice [0.9069]
2023-09-03 22:49:36.618939: Epoch time: 374.6 s
2023-09-03 22:49:37.791204: 
2023-09-03 22:49:37.792794: Epoch 82
2023-09-03 22:49:37.794219: Current learning rate: backbone 0.00075024, others 0.00075024
2023-09-03 22:49:37.795876: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 22:50:38.993581: finished training epoch 82
2023-09-03 22:50:39.035379: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 22:50:39.037691: The split file contains 1 splits.
2023-09-03 22:50:39.038939: Desired fold for training: 0
2023-09-03 22:50:39.040031: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 22:55:47.941751: dsc: 91.02%
2023-09-03 22:55:47.943399: miou: 83.51%
2023-09-03 22:55:47.944746: acc: 95.51%, sen: 90.37%, spe: 97.24%
2023-09-03 22:55:47.946915: current best miou: 0.8422144348184231 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-03 22:55:47.948184: current best dsc: 0.9143500549125113 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-03 22:55:47.949513: finished real validation
2023-09-03 22:55:52.342319: train_loss -1.4261
2023-09-03 22:55:52.344135: val_loss -1.0801
2023-09-03 22:55:52.345842: Pseudo dice [0.912]
2023-09-03 22:55:52.347054: Epoch time: 374.55 s
2023-09-03 22:55:53.472619: 
2023-09-03 22:55:53.474480: Epoch 83
2023-09-03 22:55:53.476100: Current learning rate: backbone 0.00074714, others 0.00074714
2023-09-03 22:55:53.477851: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 22:56:54.529965: finished training epoch 83
2023-09-03 22:56:54.559525: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 22:56:54.561712: The split file contains 1 splits.
2023-09-03 22:56:54.562871: Desired fold for training: 0
2023-09-03 22:56:54.563930: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 23:02:02.111844: dsc: 90.96%
2023-09-03 23:02:02.113536: miou: 83.41%
2023-09-03 23:02:02.114851: acc: 95.45%, sen: 90.91%, spe: 96.98%
2023-09-03 23:02:02.116416: current best miou: 0.8422144348184231 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-03 23:02:02.117923: current best dsc: 0.9143500549125113 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-03 23:02:02.119309: finished real validation
2023-09-03 23:02:06.508989: train_loss -1.4256
2023-09-03 23:02:06.511004: val_loss -1.0374
2023-09-03 23:02:06.512547: Pseudo dice [0.9101]
2023-09-03 23:02:06.513757: Epoch time: 373.04 s
2023-09-03 23:02:07.656550: 
2023-09-03 23:02:07.658462: Epoch 84
2023-09-03 23:02:07.660058: Current learning rate: backbone 0.00074405, others 0.00074405
2023-09-03 23:02:07.662046: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 23:03:09.170526: finished training epoch 84
2023-09-03 23:03:09.200154: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 23:03:09.202661: The split file contains 1 splits.
2023-09-03 23:03:09.204003: Desired fold for training: 0
2023-09-03 23:03:09.205261: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 23:08:17.501669: dsc: 90.94%
2023-09-03 23:08:17.531576: miou: 83.38%
2023-09-03 23:08:17.533411: acc: 95.46%, sen: 90.61%, spe: 97.09%
2023-09-03 23:08:17.536001: current best miou: 0.8422144348184231 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-03 23:08:17.537684: current best dsc: 0.9143500549125113 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-03 23:08:17.539236: finished real validation
2023-09-03 23:08:21.934964: train_loss -1.4261
2023-09-03 23:08:21.936592: val_loss -1.0437
2023-09-03 23:08:21.938046: Pseudo dice [0.9076]
2023-09-03 23:08:21.939265: Epoch time: 374.28 s
2023-09-03 23:08:23.053121: 
2023-09-03 23:08:23.057123: Epoch 85
2023-09-03 23:08:23.060261: Current learning rate: backbone 0.00074094, others 0.00074094
2023-09-03 23:08:23.064976: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 23:09:25.297870: finished training epoch 85
2023-09-03 23:09:25.336965: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 23:09:25.339221: The split file contains 1 splits.
2023-09-03 23:09:25.340374: Desired fold for training: 0
2023-09-03 23:09:25.341427: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 23:14:32.132295: dsc: 90.75%
2023-09-03 23:14:32.134618: miou: 83.06%
2023-09-03 23:14:32.136930: acc: 95.36%, sen: 90.46%, spe: 97.01%
2023-09-03 23:14:32.140162: current best miou: 0.8422144348184231 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-03 23:14:32.143448: current best dsc: 0.9143500549125113 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-03 23:14:32.145104: finished real validation
2023-09-03 23:14:36.533922: train_loss -1.4273
2023-09-03 23:14:36.535701: val_loss -1.0595
2023-09-03 23:14:36.537252: Pseudo dice [0.9094]
2023-09-03 23:14:36.538461: Epoch time: 373.48 s
2023-09-03 23:14:37.641401: 
2023-09-03 23:14:37.643231: Epoch 86
2023-09-03 23:14:37.644761: Current learning rate: backbone 0.00073784, others 0.00073784
2023-09-03 23:14:37.646687: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 23:15:38.794517: finished training epoch 86
2023-09-03 23:15:38.823602: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 23:15:38.827183: The split file contains 1 splits.
2023-09-03 23:15:38.828440: Desired fold for training: 0
2023-09-03 23:15:38.829535: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 23:20:50.253755: dsc: 90.97%
2023-09-03 23:20:50.255428: miou: 83.44%
2023-09-03 23:20:50.256585: acc: 95.46%, sen: 91.02%, spe: 96.95%
2023-09-03 23:20:50.258069: current best miou: 0.8422144348184231 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-03 23:20:50.259211: current best dsc: 0.9143500549125113 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-03 23:20:50.260265: finished real validation
2023-09-03 23:20:54.644872: train_loss -1.4261
2023-09-03 23:20:54.646667: val_loss -1.0369
2023-09-03 23:20:54.648124: Pseudo dice [0.9067]
2023-09-03 23:20:54.649408: Epoch time: 377.0 s
2023-09-03 23:20:55.768271: 
2023-09-03 23:20:55.769969: Epoch 87
2023-09-03 23:20:55.771220: Current learning rate: backbone 0.00073474, others 0.00073474
2023-09-03 23:20:55.772799: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 23:21:56.937743: finished training epoch 87
2023-09-03 23:21:56.966908: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 23:21:56.970481: The split file contains 1 splits.
2023-09-03 23:21:56.972320: Desired fold for training: 0
2023-09-03 23:21:56.973969: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 23:27:09.470371: dsc: 91.16%
2023-09-03 23:27:09.472616: miou: 83.76%
2023-09-03 23:27:09.474736: acc: 95.57%, sen: 90.89%, spe: 97.14%
2023-09-03 23:27:09.477767: current best miou: 0.8422144348184231 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-03 23:27:09.479867: current best dsc: 0.9143500549125113 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-03 23:27:09.481940: finished real validation
2023-09-03 23:27:13.875644: train_loss -1.4265
2023-09-03 23:27:13.877546: val_loss -1.0657
2023-09-03 23:27:13.879108: Pseudo dice [0.9113]
2023-09-03 23:27:13.880464: Epoch time: 378.11 s
2023-09-03 23:27:14.974138: 
2023-09-03 23:27:14.975886: Epoch 88
2023-09-03 23:27:14.977496: Current learning rate: backbone 0.00073163, others 0.00073163
2023-09-03 23:27:14.979170: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 23:28:16.023769: finished training epoch 88
2023-09-03 23:28:16.053670: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 23:28:16.055792: The split file contains 1 splits.
2023-09-03 23:28:16.057026: Desired fold for training: 0
2023-09-03 23:28:16.058153: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 23:33:27.531573: dsc: 91.09%
2023-09-03 23:33:27.533300: miou: 83.64%
2023-09-03 23:33:27.534760: acc: 95.52%, sen: 91.08%, spe: 97.01%
2023-09-03 23:33:27.536431: current best miou: 0.8422144348184231 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-03 23:33:27.537855: current best dsc: 0.9143500549125113 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-03 23:33:27.539045: finished real validation
2023-09-03 23:33:31.935528: train_loss -1.4263
2023-09-03 23:33:31.937380: val_loss -1.0891
2023-09-03 23:33:31.938854: Pseudo dice [0.9131]
2023-09-03 23:33:31.940074: Epoch time: 376.96 s
2023-09-03 23:33:33.039235: 
2023-09-03 23:33:33.040979: Epoch 89
2023-09-03 23:33:33.042639: Current learning rate: backbone 0.00072853, others 0.00072853
2023-09-03 23:33:33.044487: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 23:34:34.145993: finished training epoch 89
2023-09-03 23:34:34.176252: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 23:34:34.178323: The split file contains 1 splits.
2023-09-03 23:34:34.179490: Desired fold for training: 0
2023-09-03 23:34:34.180608: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 23:39:45.776016: dsc: 90.94%
2023-09-03 23:39:45.777985: miou: 83.39%
2023-09-03 23:39:45.779502: acc: 95.44%, sen: 91.00%, spe: 96.93%
2023-09-03 23:39:45.781766: current best miou: 0.8422144348184231 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-03 23:39:45.783445: current best dsc: 0.9143500549125113 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-03 23:39:45.785009: finished real validation
2023-09-03 23:39:50.166445: train_loss -1.4271
2023-09-03 23:39:50.168227: val_loss -1.0324
2023-09-03 23:39:50.170212: Pseudo dice [0.9066]
2023-09-03 23:39:50.171536: Epoch time: 377.13 s
2023-09-03 23:39:53.203834: 
2023-09-03 23:39:53.205818: Epoch 90
2023-09-03 23:39:53.207757: Current learning rate: backbone 0.00072542, others 0.00072542
2023-09-03 23:39:53.210250: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 23:40:54.270087: finished training epoch 90
2023-09-03 23:40:54.304077: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 23:40:54.308221: The split file contains 1 splits.
2023-09-03 23:40:54.310408: Desired fold for training: 0
2023-09-03 23:40:54.312174: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 23:46:07.706774: dsc: 90.99%
2023-09-03 23:46:07.708557: miou: 83.48%
2023-09-03 23:46:07.709737: acc: 95.48%, sen: 90.81%, spe: 97.05%
2023-09-03 23:46:07.711221: current best miou: 0.8422144348184231 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-03 23:46:07.712359: current best dsc: 0.9143500549125113 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-03 23:46:07.713422: finished real validation
2023-09-03 23:46:12.112997: train_loss -1.4272
2023-09-03 23:46:12.114712: val_loss -1.0653
2023-09-03 23:46:12.116178: Pseudo dice [0.9123]
2023-09-03 23:46:12.117888: Epoch time: 378.91 s
2023-09-03 23:46:13.211124: 
2023-09-03 23:46:13.213044: Epoch 91
2023-09-03 23:46:13.214296: Current learning rate: backbone 0.00072231, others 0.00072231
2023-09-03 23:46:13.216543: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 23:47:14.350263: finished training epoch 91
2023-09-03 23:47:14.382197: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 23:47:14.384400: The split file contains 1 splits.
2023-09-03 23:47:14.385643: Desired fold for training: 0
2023-09-03 23:47:14.387191: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 23:52:32.316896: dsc: 91.02%
2023-09-03 23:52:32.319016: miou: 83.52%
2023-09-03 23:52:32.320394: acc: 95.51%, sen: 90.51%, spe: 97.19%
2023-09-03 23:52:32.322558: current best miou: 0.8422144348184231 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-03 23:52:32.323998: current best dsc: 0.9143500549125113 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-03 23:52:32.325396: finished real validation
2023-09-03 23:52:36.711758: train_loss -1.4275
2023-09-03 23:52:36.713529: val_loss -1.0976
2023-09-03 23:52:36.714949: Pseudo dice [0.9153]
2023-09-03 23:52:36.716180: Epoch time: 383.5 s
2023-09-03 23:52:37.825930: 
2023-09-03 23:52:37.827754: Epoch 92
2023-09-03 23:52:37.829202: Current learning rate: backbone 0.0007192, others 0.0007192
2023-09-03 23:52:37.831462: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 23:53:38.932427: finished training epoch 92
2023-09-03 23:53:38.973846: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 23:53:38.976347: The split file contains 1 splits.
2023-09-03 23:53:38.977560: Desired fold for training: 0
2023-09-03 23:53:38.978762: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 23:58:48.575859: dsc: 91.07%
2023-09-03 23:58:48.577482: miou: 83.61%
2023-09-03 23:58:48.578644: acc: 95.50%, sen: 91.21%, spe: 96.95%
2023-09-03 23:58:48.580388: current best miou: 0.8422144348184231 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-03 23:58:48.581576: current best dsc: 0.9143500549125113 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-03 23:58:48.582684: finished real validation
2023-09-03 23:58:52.961187: train_loss -1.4286
2023-09-03 23:58:52.962892: val_loss -1.081
2023-09-03 23:58:52.964333: Pseudo dice [0.9125]
2023-09-03 23:58:52.965564: Epoch time: 375.14 s
2023-09-03 23:58:54.066718: 
2023-09-03 23:58:54.068380: Epoch 93
2023-09-03 23:58:54.069824: Current learning rate: backbone 0.00071608, others 0.00071608
2023-09-03 23:58:54.071626: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 23:59:55.123574: finished training epoch 93
2023-09-03 23:59:55.162535: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 23:59:55.164964: The split file contains 1 splits.
2023-09-03 23:59:55.166359: Desired fold for training: 0
2023-09-03 23:59:55.167522: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 00:05:05.568598: dsc: 90.91%
2023-09-04 00:05:05.570425: miou: 83.33%
2023-09-04 00:05:05.571744: acc: 95.42%, sen: 91.02%, spe: 96.90%
2023-09-04 00:05:05.573514: current best miou: 0.8422144348184231 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 00:05:05.574880: current best dsc: 0.9143500549125113 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 00:05:05.576078: finished real validation
2023-09-04 00:05:09.990081: train_loss -1.4288
2023-09-04 00:05:10.001056: val_loss -1.0375
2023-09-04 00:05:10.002682: Pseudo dice [0.9112]
2023-09-04 00:05:10.003959: Epoch time: 375.92 s
2023-09-04 00:05:11.124998: 
2023-09-04 00:05:11.126536: Epoch 94
2023-09-04 00:05:11.127938: Current learning rate: backbone 0.00071297, others 0.00071297
2023-09-04 00:05:11.130197: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 00:06:12.282840: finished training epoch 94
2023-09-04 00:06:12.312935: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 00:06:12.314929: The split file contains 1 splits.
2023-09-04 00:06:12.316089: Desired fold for training: 0
2023-09-04 00:06:12.317270: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 00:11:23.461126: dsc: 90.99%
2023-09-04 00:11:23.462795: miou: 83.46%
2023-09-04 00:11:23.464290: acc: 95.47%, sen: 90.90%, spe: 97.00%
2023-09-04 00:11:23.465848: current best miou: 0.8422144348184231 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 00:11:23.467038: current best dsc: 0.9143500549125113 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 00:11:23.468183: finished real validation
2023-09-04 00:11:27.855477: train_loss -1.4279
2023-09-04 00:11:27.857347: val_loss -1.041
2023-09-04 00:11:27.859109: Pseudo dice [0.9098]
2023-09-04 00:11:27.860381: Epoch time: 376.73 s
2023-09-04 00:11:28.970103: 
2023-09-04 00:11:28.971772: Epoch 95
2023-09-04 00:11:28.973040: Current learning rate: backbone 0.00070985, others 0.00070985
2023-09-04 00:11:28.974662: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 00:12:30.092305: finished training epoch 95
2023-09-04 00:12:30.121500: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 00:12:30.123730: The split file contains 1 splits.
2023-09-04 00:12:30.125019: Desired fold for training: 0
2023-09-04 00:12:30.126313: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 00:17:40.728437: dsc: 90.96%
2023-09-04 00:17:40.730769: miou: 83.42%
2023-09-04 00:17:40.732036: acc: 95.46%, sen: 90.80%, spe: 97.03%
2023-09-04 00:17:40.733791: current best miou: 0.8422144348184231 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 00:17:40.735109: current best dsc: 0.9143500549125113 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 00:17:40.736588: finished real validation
2023-09-04 00:17:45.132430: train_loss -1.4284
2023-09-04 00:17:45.134492: val_loss -1.062
2023-09-04 00:17:45.136285: Pseudo dice [0.9088]
2023-09-04 00:17:45.137700: Epoch time: 376.16 s
2023-09-04 00:17:46.244280: 
2023-09-04 00:17:46.246130: Epoch 96
2023-09-04 00:17:46.247487: Current learning rate: backbone 0.00070674, others 0.00070674
2023-09-04 00:17:46.249449: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 00:18:47.427006: finished training epoch 96
2023-09-04 00:18:47.470569: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 00:18:47.473857: The split file contains 1 splits.
2023-09-04 00:18:47.476187: Desired fold for training: 0
2023-09-04 00:18:47.478046: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 00:24:01.073051: dsc: 90.89%
2023-09-04 00:24:01.075070: miou: 83.29%
2023-09-04 00:24:01.076429: acc: 95.42%, sen: 90.86%, spe: 96.95%
2023-09-04 00:24:01.078374: current best miou: 0.8422144348184231 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 00:24:01.079885: current best dsc: 0.9143500549125113 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 00:24:01.081254: finished real validation
2023-09-04 00:24:05.459347: train_loss -1.4286
2023-09-04 00:24:05.461202: val_loss -1.0314
2023-09-04 00:24:05.462788: Pseudo dice [0.9071]
2023-09-04 00:24:05.464123: Epoch time: 379.22 s
2023-09-04 00:24:06.582918: 
2023-09-04 00:24:06.584869: Epoch 97
2023-09-04 00:24:06.586675: Current learning rate: backbone 0.00070362, others 0.00070362
2023-09-04 00:24:06.588885: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 00:25:07.652270: finished training epoch 97
2023-09-04 00:25:07.693652: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 00:25:07.695855: The split file contains 1 splits.
2023-09-04 00:25:07.697037: Desired fold for training: 0
2023-09-04 00:25:07.698731: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 00:30:22.748313: dsc: 90.96%
2023-09-04 00:30:22.750132: miou: 83.41%
2023-09-04 00:30:22.751546: acc: 95.45%, sen: 90.98%, spe: 96.95%
2023-09-04 00:30:22.753606: current best miou: 0.8422144348184231 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 00:30:22.754972: current best dsc: 0.9143500549125113 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 00:30:22.756500: finished real validation
2023-09-04 00:30:27.137911: train_loss -1.429
2023-09-04 00:30:27.139756: val_loss -1.0526
2023-09-04 00:30:27.141394: Pseudo dice [0.9115]
2023-09-04 00:30:27.142800: Epoch time: 380.56 s
2023-09-04 00:30:28.253446: 
2023-09-04 00:30:28.255391: Epoch 98
2023-09-04 00:30:28.256780: Current learning rate: backbone 0.0007005, others 0.0007005
2023-09-04 00:30:28.258760: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 00:31:29.359749: finished training epoch 98
2023-09-04 00:31:29.396081: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 00:31:29.398661: The split file contains 1 splits.
2023-09-04 00:31:29.400057: Desired fold for training: 0
2023-09-04 00:31:29.401345: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 00:36:40.627847: dsc: 90.97%
2023-09-04 00:36:40.629354: miou: 83.43%
2023-09-04 00:36:40.630560: acc: 95.46%, sen: 90.86%, spe: 97.01%
2023-09-04 00:36:40.632284: current best miou: 0.8422144348184231 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 00:36:40.633498: current best dsc: 0.9143500549125113 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 00:36:40.634619: finished real validation
2023-09-04 00:36:45.019288: train_loss -1.429
2023-09-04 00:36:45.020839: val_loss -1.0729
2023-09-04 00:36:45.022291: Pseudo dice [0.9112]
2023-09-04 00:36:45.023514: Epoch time: 376.77 s
2023-09-04 00:36:46.164824: 
2023-09-04 00:36:46.166293: Epoch 99
2023-09-04 00:36:46.168199: Current learning rate: backbone 0.00069738, others 0.00069738
2023-09-04 00:36:46.169684: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 00:37:47.244635: finished training epoch 99
2023-09-04 00:37:47.274582: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 00:37:47.277813: The split file contains 1 splits.
2023-09-04 00:37:47.279378: Desired fold for training: 0
2023-09-04 00:37:47.280786: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 00:43:08.451955: dsc: 91.02%
2023-09-04 00:43:08.453791: miou: 83.51%
2023-09-04 00:43:08.455346: acc: 95.52%, sen: 90.31%, spe: 97.27%
2023-09-04 00:43:08.457887: current best miou: 0.8422144348184231 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 00:43:08.459640: current best dsc: 0.9143500549125113 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 00:43:08.461327: finished real validation
2023-09-04 00:43:12.826298: train_loss -1.4292
2023-09-04 00:43:12.827933: val_loss -1.0571
2023-09-04 00:43:12.829373: Pseudo dice [0.9112]
2023-09-04 00:43:12.830662: Epoch time: 386.66 s
2023-09-04 00:43:15.541944: 
2023-09-04 00:43:15.543680: Epoch 100
2023-09-04 00:43:15.545026: Current learning rate: backbone 0.00069425, others 0.00069425
2023-09-04 00:43:15.546854: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 00:44:16.861466: finished training epoch 100
2023-09-04 00:44:16.892094: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 00:44:16.894170: The split file contains 1 splits.
2023-09-04 00:44:16.895395: Desired fold for training: 0
2023-09-04 00:44:16.896581: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 00:49:31.937429: dsc: 91.12%
2023-09-04 00:49:31.939082: miou: 83.69%
2023-09-04 00:49:31.940422: acc: 95.53%, sen: 91.13%, spe: 97.01%
2023-09-04 00:49:31.941984: current best miou: 0.8422144348184231 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 00:49:31.943432: current best dsc: 0.9143500549125113 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 00:49:31.944836: finished real validation
2023-09-04 00:49:36.319476: train_loss -1.4294
2023-09-04 00:49:36.321240: val_loss -1.0697
2023-09-04 00:49:36.322679: Pseudo dice [0.9147]
2023-09-04 00:49:36.323904: Epoch time: 380.78 s
2023-09-04 00:49:37.473969: 
2023-09-04 00:49:37.475407: Epoch 101
2023-09-04 00:49:37.476716: Current learning rate: backbone 0.00069113, others 0.00069113
2023-09-04 00:49:37.478519: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 00:50:38.691616: finished training epoch 101
2023-09-04 00:50:38.723933: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 00:50:38.726369: The split file contains 1 splits.
2023-09-04 00:50:38.727675: Desired fold for training: 0
2023-09-04 00:50:38.728972: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 00:55:57.444639: dsc: 90.83%
2023-09-04 00:55:57.446289: miou: 83.21%
2023-09-04 00:55:57.447504: acc: 95.41%, sen: 90.38%, spe: 97.10%
2023-09-04 00:55:57.448997: current best miou: 0.8422144348184231 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 00:55:57.450214: current best dsc: 0.9143500549125113 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 00:55:57.451318: finished real validation
2023-09-04 00:56:01.822503: train_loss -1.4306
2023-09-04 00:56:01.824281: val_loss -1.0612
2023-09-04 00:56:01.825818: Pseudo dice [0.9132]
2023-09-04 00:56:01.827460: Epoch time: 384.35 s
2023-09-04 00:56:02.962755: 
2023-09-04 00:56:02.964346: Epoch 102
2023-09-04 00:56:02.965827: Current learning rate: backbone 0.000688, others 0.000688
2023-09-04 00:56:02.967583: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 00:57:04.133774: finished training epoch 102
2023-09-04 00:57:04.169761: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 00:57:04.176056: The split file contains 1 splits.
2023-09-04 00:57:04.177552: Desired fold for training: 0
2023-09-04 00:57:04.178961: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 01:02:33.977407: dsc: 91.10%
2023-09-04 01:02:33.979223: miou: 83.66%
2023-09-04 01:02:33.980761: acc: 95.54%, sen: 90.68%, spe: 97.18%
2023-09-04 01:02:33.982577: current best miou: 0.8422144348184231 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 01:02:33.983945: current best dsc: 0.9143500549125113 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 01:02:33.985507: finished real validation
2023-09-04 01:02:38.358380: train_loss -1.4309
2023-09-04 01:02:38.360189: val_loss -1.0515
2023-09-04 01:02:38.361642: Pseudo dice [0.9109]
2023-09-04 01:02:38.362921: Epoch time: 395.4 s
2023-09-04 01:02:39.506086: 
2023-09-04 01:02:39.507693: Epoch 103
2023-09-04 01:02:39.508944: Current learning rate: backbone 0.00068487, others 0.00068487
2023-09-04 01:02:39.510608: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 01:03:40.701863: finished training epoch 103
2023-09-04 01:03:40.732396: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 01:03:40.734543: The split file contains 1 splits.
2023-09-04 01:03:40.735848: Desired fold for training: 0
2023-09-04 01:03:40.737090: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 01:08:51.028820: dsc: 91.06%
2023-09-04 01:08:51.030493: miou: 83.59%
2023-09-04 01:08:51.031985: acc: 95.51%, sen: 90.87%, spe: 97.07%
2023-09-04 01:08:51.034473: current best miou: 0.8422144348184231 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 01:08:51.036020: current best dsc: 0.9143500549125113 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 01:08:51.037373: finished real validation
2023-09-04 01:08:55.408807: train_loss -1.431
2023-09-04 01:08:55.410719: val_loss -1.0331
2023-09-04 01:08:55.412347: Pseudo dice [0.9084]
2023-09-04 01:08:55.413816: Epoch time: 375.9 s
2023-09-04 01:08:56.548784: 
2023-09-04 01:08:56.550548: Epoch 104
2023-09-04 01:08:56.551841: Current learning rate: backbone 0.00068174, others 0.00068174
2023-09-04 01:08:56.553618: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 01:09:57.745253: finished training epoch 104
2023-09-04 01:09:57.786454: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 01:09:57.788740: The split file contains 1 splits.
2023-09-04 01:09:57.790134: Desired fold for training: 0
2023-09-04 01:09:57.791388: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 01:15:12.011749: dsc: 91.00%
2023-09-04 01:15:12.013488: miou: 83.49%
2023-09-04 01:15:12.014873: acc: 95.49%, sen: 90.66%, spe: 97.11%
2023-09-04 01:15:12.016762: current best miou: 0.8422144348184231 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 01:15:12.018207: current best dsc: 0.9143500549125113 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 01:15:12.019419: finished real validation
2023-09-04 01:15:16.405835: train_loss -1.4309
2023-09-04 01:15:16.407669: val_loss -1.0373
2023-09-04 01:15:16.409142: Pseudo dice [0.9099]
2023-09-04 01:15:16.410439: Epoch time: 379.86 s
2023-09-04 01:15:17.554465: 
2023-09-04 01:15:17.556256: Epoch 105
2023-09-04 01:15:17.557878: Current learning rate: backbone 0.00067861, others 0.00067861
2023-09-04 01:15:17.559873: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 01:16:18.803661: finished training epoch 105
2023-09-04 01:16:18.833309: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 01:16:18.835583: The split file contains 1 splits.
2023-09-04 01:16:18.837002: Desired fold for training: 0
2023-09-04 01:16:18.838508: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 01:21:32.129866: dsc: 90.88%
2023-09-04 01:21:32.132166: miou: 83.29%
2023-09-04 01:21:32.133730: acc: 95.44%, sen: 90.35%, spe: 97.15%
2023-09-04 01:21:32.135363: current best miou: 0.8422144348184231 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 01:21:32.137530: current best dsc: 0.9143500549125113 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 01:21:32.138914: finished real validation
2023-09-04 01:21:36.527089: train_loss -1.4308
2023-09-04 01:21:36.528993: val_loss -1.0241
2023-09-04 01:21:36.530616: Pseudo dice [0.9065]
2023-09-04 01:21:36.532011: Epoch time: 378.97 s
2023-09-04 01:21:37.670000: 
2023-09-04 01:21:37.671692: Epoch 106
2023-09-04 01:21:37.673411: Current learning rate: backbone 0.00067548, others 0.00067548
2023-09-04 01:21:37.675249: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 01:22:38.886099: finished training epoch 106
2023-09-04 01:22:38.929458: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 01:22:38.932691: The split file contains 1 splits.
2023-09-04 01:22:38.934238: Desired fold for training: 0
2023-09-04 01:22:38.935651: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 01:27:53.831070: dsc: 91.05%
2023-09-04 01:27:53.835158: miou: 83.57%
2023-09-04 01:27:53.837110: acc: 95.53%, sen: 90.40%, spe: 97.26%
2023-09-04 01:27:53.838789: current best miou: 0.8422144348184231 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 01:27:53.840346: current best dsc: 0.9143500549125113 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 01:27:53.841840: finished real validation
2023-09-04 01:27:58.213955: train_loss -1.4309
2023-09-04 01:27:58.215877: val_loss -1.0361
2023-09-04 01:27:58.217841: Pseudo dice [0.9084]
2023-09-04 01:27:58.220205: Epoch time: 380.55 s
2023-09-04 01:27:59.392708: 
2023-09-04 01:27:59.394500: Epoch 107
2023-09-04 01:27:59.395792: Current learning rate: backbone 0.00067235, others 0.00067235
2023-09-04 01:27:59.397369: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 01:29:00.592926: finished training epoch 107
2023-09-04 01:29:00.630701: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 01:29:00.633153: The split file contains 1 splits.
2023-09-04 01:29:00.634484: Desired fold for training: 0
2023-09-04 01:29:00.635735: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 01:34:32.831529: dsc: 91.07%
2023-09-04 01:34:32.832897: miou: 83.61%
2023-09-04 01:34:32.834118: acc: 95.52%, sen: 90.80%, spe: 97.11%
2023-09-04 01:34:32.835512: current best miou: 0.8422144348184231 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 01:34:32.836673: current best dsc: 0.9143500549125113 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 01:34:32.837771: finished real validation
2023-09-04 01:34:37.219942: train_loss -1.4308
2023-09-04 01:34:37.221699: val_loss -1.0474
2023-09-04 01:34:37.223410: Pseudo dice [0.9109]
2023-09-04 01:34:37.224793: Epoch time: 397.83 s
2023-09-04 01:34:38.344103: 
2023-09-04 01:34:38.345607: Epoch 108
2023-09-04 01:34:38.347439: Current learning rate: backbone 0.00066921, others 0.00066921
2023-09-04 01:34:38.349222: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 01:35:39.543600: finished training epoch 108
2023-09-04 01:35:39.573486: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 01:35:39.577051: The split file contains 1 splits.
2023-09-04 01:35:39.578923: Desired fold for training: 0
2023-09-04 01:35:39.580532: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 01:41:08.347705: dsc: 91.08%
2023-09-04 01:41:08.349402: miou: 83.63%
2023-09-04 01:41:08.350637: acc: 95.51%, sen: 91.19%, spe: 96.96%
2023-09-04 01:41:08.352401: current best miou: 0.8422144348184231 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 01:41:08.353881: current best dsc: 0.9143500549125113 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 01:41:08.355120: finished real validation
2023-09-04 01:41:12.743560: train_loss -1.4314
2023-09-04 01:41:12.745393: val_loss -1.0466
2023-09-04 01:41:12.747063: Pseudo dice [0.912]
2023-09-04 01:41:12.748547: Epoch time: 394.4 s
2023-09-04 01:41:13.878802: 
2023-09-04 01:41:13.880808: Epoch 109
2023-09-04 01:41:13.882242: Current learning rate: backbone 0.00066607, others 0.00066607
2023-09-04 01:41:13.884066: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 01:42:15.057738: finished training epoch 109
2023-09-04 01:42:15.099422: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 01:42:15.101721: The split file contains 1 splits.
2023-09-04 01:42:15.103181: Desired fold for training: 0
2023-09-04 01:42:15.104553: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 01:47:34.209469: dsc: 91.07%
2023-09-04 01:47:34.211251: miou: 83.60%
2023-09-04 01:47:34.212805: acc: 95.52%, sen: 90.70%, spe: 97.15%
2023-09-04 01:47:34.214653: current best miou: 0.8422144348184231 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 01:47:34.215907: current best dsc: 0.9143500549125113 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 01:47:34.217137: finished real validation
2023-09-04 01:47:38.602961: train_loss -1.4311
2023-09-04 01:47:38.604984: val_loss -1.0343
2023-09-04 01:47:38.606676: Pseudo dice [0.9093]
2023-09-04 01:47:38.608003: Epoch time: 384.73 s
2023-09-04 01:47:41.330734: 
2023-09-04 01:47:41.332360: Epoch 110
2023-09-04 01:47:41.333759: Current learning rate: backbone 0.00066293, others 0.00066293
2023-09-04 01:47:41.335520: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 01:48:42.481614: finished training epoch 110
2023-09-04 01:48:42.519324: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 01:48:42.521752: The split file contains 1 splits.
2023-09-04 01:48:42.523193: Desired fold for training: 0
2023-09-04 01:48:42.524443: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 01:54:06.953408: dsc: 91.05%
2023-09-04 01:54:06.955297: miou: 83.58%
2023-09-04 01:54:06.958693: acc: 95.51%, sen: 90.90%, spe: 97.06%
2023-09-04 01:54:06.960464: current best miou: 0.8422144348184231 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 01:54:06.961702: current best dsc: 0.9143500549125113 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 01:54:06.962867: finished real validation
2023-09-04 01:54:11.346074: train_loss -1.4308
2023-09-04 01:54:11.347921: val_loss -1.0659
2023-09-04 01:54:11.349624: Pseudo dice [0.9121]
2023-09-04 01:54:11.351130: Epoch time: 390.02 s
2023-09-04 01:54:12.485125: 
2023-09-04 01:54:12.486806: Epoch 111
2023-09-04 01:54:12.488232: Current learning rate: backbone 0.00065979, others 0.00065979
2023-09-04 01:54:12.490053: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 01:55:13.678293: finished training epoch 111
2023-09-04 01:55:13.726700: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 01:55:13.728867: The split file contains 1 splits.
2023-09-04 01:55:13.730561: Desired fold for training: 0
2023-09-04 01:55:13.732092: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 02:00:37.559146: dsc: 91.05%
2023-09-04 02:00:37.560993: miou: 83.57%
2023-09-04 02:00:37.562309: acc: 95.51%, sen: 90.88%, spe: 97.06%
2023-09-04 02:00:37.563922: current best miou: 0.8422144348184231 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 02:00:37.565145: current best dsc: 0.9143500549125113 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 02:00:37.566605: finished real validation
2023-09-04 02:00:41.936255: train_loss -1.4322
2023-09-04 02:00:41.938009: val_loss -1.0134
2023-09-04 02:00:41.939508: Pseudo dice [0.9088]
2023-09-04 02:00:41.940748: Epoch time: 389.45 s
2023-09-04 02:00:43.058891: 
2023-09-04 02:00:43.060590: Epoch 112
2023-09-04 02:00:43.062086: Current learning rate: backbone 0.00065665, others 0.00065665
2023-09-04 02:00:43.063884: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 02:01:44.072364: finished training epoch 112
2023-09-04 02:01:44.146018: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 02:01:44.148782: The split file contains 1 splits.
2023-09-04 02:01:44.150612: Desired fold for training: 0
2023-09-04 02:01:44.151828: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 02:07:03.036408: dsc: 91.13%
2023-09-04 02:07:03.038274: miou: 83.71%
2023-09-04 02:07:03.039706: acc: 95.52%, sen: 91.53%, spe: 96.86%
2023-09-04 02:07:03.041357: current best miou: 0.8422144348184231 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 02:07:03.042617: current best dsc: 0.9143500549125113 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 02:07:03.043816: finished real validation
2023-09-04 02:07:07.426334: train_loss -1.433
2023-09-04 02:07:07.428204: val_loss -1.0364
2023-09-04 02:07:07.429895: Pseudo dice [0.9123]
2023-09-04 02:07:07.431332: Epoch time: 384.37 s
2023-09-04 02:07:08.554687: 
2023-09-04 02:07:08.556712: Epoch 113
2023-09-04 02:07:08.558207: Current learning rate: backbone 0.0006535, others 0.0006535
2023-09-04 02:07:08.560304: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 02:08:09.723270: finished training epoch 113
2023-09-04 02:08:09.787834: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 02:08:09.790175: The split file contains 1 splits.
2023-09-04 02:08:09.791673: Desired fold for training: 0
2023-09-04 02:08:09.793020: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 02:13:20.751580: dsc: 90.98%
2023-09-04 02:13:20.753767: miou: 83.45%
2023-09-04 02:13:20.755080: acc: 95.49%, sen: 90.42%, spe: 97.20%
2023-09-04 02:13:20.756694: current best miou: 0.8422144348184231 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 02:13:20.757994: current best dsc: 0.9143500549125113 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 02:13:20.759212: finished real validation
2023-09-04 02:13:25.151591: train_loss -1.4327
2023-09-04 02:13:25.153640: val_loss -1.0371
2023-09-04 02:13:25.155383: Pseudo dice [0.912]
2023-09-04 02:13:25.156898: Epoch time: 376.6 s
2023-09-04 02:13:26.287096: 
2023-09-04 02:13:26.288740: Epoch 114
2023-09-04 02:13:26.290104: Current learning rate: backbone 0.00065036, others 0.00065036
2023-09-04 02:13:26.291740: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 02:14:27.427163: finished training epoch 114
2023-09-04 02:14:27.458640: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 02:14:27.461394: The split file contains 1 splits.
2023-09-04 02:14:27.463068: Desired fold for training: 0
2023-09-04 02:14:27.464711: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 02:19:41.826263: dsc: 91.16%
2023-09-04 02:19:41.828254: miou: 83.76%
2023-09-04 02:19:41.829966: acc: 95.54%, sen: 91.46%, spe: 96.91%
2023-09-04 02:19:41.832019: current best miou: 0.8422144348184231 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 02:19:41.833402: current best dsc: 0.9143500549125113 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 02:19:41.834596: finished real validation
2023-09-04 02:19:46.204862: train_loss -1.4333
2023-09-04 02:19:46.206837: val_loss -1.0313
2023-09-04 02:19:46.208410: Pseudo dice [0.9123]
2023-09-04 02:19:46.209765: Epoch time: 379.92 s
2023-09-04 02:19:47.336784: 
2023-09-04 02:19:47.338394: Epoch 115
2023-09-04 02:19:47.340110: Current learning rate: backbone 0.00064721, others 0.00064721
2023-09-04 02:19:47.342241: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 02:20:48.461092: finished training epoch 115
2023-09-04 02:20:48.492205: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 02:20:48.494538: The split file contains 1 splits.
2023-09-04 02:20:48.495937: Desired fold for training: 0
2023-09-04 02:20:48.497276: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 02:26:03.402000: dsc: 90.84%
2023-09-04 02:26:03.404020: miou: 83.22%
2023-09-04 02:26:03.405344: acc: 95.38%, sen: 91.10%, spe: 96.82%
2023-09-04 02:26:03.407155: current best miou: 0.8422144348184231 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 02:26:03.408589: current best dsc: 0.9143500549125113 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 02:26:03.409914: finished real validation
2023-09-04 02:26:07.785336: train_loss -1.4328
2023-09-04 02:26:07.787422: val_loss -1.051
2023-09-04 02:26:07.789189: Pseudo dice [0.9096]
2023-09-04 02:26:07.790713: Epoch time: 380.45 s
2023-09-04 02:26:08.925625: 
2023-09-04 02:26:08.927549: Epoch 116
2023-09-04 02:26:08.928886: Current learning rate: backbone 0.00064406, others 0.00064406
2023-09-04 02:26:08.930754: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 02:27:10.079629: finished training epoch 116
2023-09-04 02:27:10.109499: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 02:27:10.111653: The split file contains 1 splits.
2023-09-04 02:27:10.112936: Desired fold for training: 0
2023-09-04 02:27:10.114632: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 02:32:34.343684: dsc: 91.14%
2023-09-04 02:32:34.345701: miou: 83.73%
2023-09-04 02:32:34.347244: acc: 95.55%, sen: 91.05%, spe: 97.06%
2023-09-04 02:32:34.348914: current best miou: 0.8422144348184231 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 02:32:34.350509: current best dsc: 0.9143500549125113 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 02:32:34.352049: finished real validation
2023-09-04 02:32:38.728984: train_loss -1.4325
2023-09-04 02:32:38.731135: val_loss -1.0456
2023-09-04 02:32:38.732862: Pseudo dice [0.9104]
2023-09-04 02:32:38.734407: Epoch time: 389.8 s
2023-09-04 02:32:39.860411: 
2023-09-04 02:32:39.862551: Epoch 117
2023-09-04 02:32:39.864051: Current learning rate: backbone 0.00064091, others 0.00064091
2023-09-04 02:32:39.866163: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 02:33:41.166374: finished training epoch 117
2023-09-04 02:33:41.195579: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 02:33:41.198071: The split file contains 1 splits.
2023-09-04 02:33:41.199553: Desired fold for training: 0
2023-09-04 02:33:41.200922: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 02:39:01.623022: dsc: 91.04%
2023-09-04 02:39:01.625562: miou: 83.56%
2023-09-04 02:39:01.627491: acc: 95.51%, sen: 90.67%, spe: 97.14%
2023-09-04 02:39:01.630006: current best miou: 0.8422144348184231 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 02:39:01.631599: current best dsc: 0.9143500549125113 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 02:39:01.633092: finished real validation
2023-09-04 02:39:06.030119: train_loss -1.4332
2023-09-04 02:39:06.032295: val_loss -1.047
2023-09-04 02:39:06.034192: Pseudo dice [0.9125]
2023-09-04 02:39:06.035747: Epoch time: 386.17 s
2023-09-04 02:39:07.181598: 
2023-09-04 02:39:07.183657: Epoch 118
2023-09-04 02:39:07.185169: Current learning rate: backbone 0.00063776, others 0.00063776
2023-09-04 02:39:07.187038: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 02:40:08.621717: finished training epoch 118
2023-09-04 02:40:08.669247: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 02:40:08.672142: The split file contains 1 splits.
2023-09-04 02:40:08.673486: Desired fold for training: 0
2023-09-04 02:40:08.674828: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 02:45:25.150547: dsc: 91.27%
2023-09-04 02:45:25.152614: miou: 83.94%
2023-09-04 02:45:25.154148: acc: 95.61%, sen: 91.26%, spe: 97.07%
2023-09-04 02:45:25.155926: current best miou: 0.8422144348184231 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 02:45:25.157282: current best dsc: 0.9143500549125113 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 02:45:25.158762: finished real validation
2023-09-04 02:45:29.534117: train_loss -1.4337
2023-09-04 02:45:29.535998: val_loss -1.0166
2023-09-04 02:45:29.537578: Pseudo dice [0.9093]
2023-09-04 02:45:29.538965: Epoch time: 382.35 s
2023-09-04 02:45:30.681573: 
2023-09-04 02:45:30.683681: Epoch 119
2023-09-04 02:45:30.685234: Current learning rate: backbone 0.0006346, others 0.0006346
2023-09-04 02:45:30.687274: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 02:46:31.837005: finished training epoch 119
2023-09-04 02:46:31.866540: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 02:46:31.868860: The split file contains 1 splits.
2023-09-04 02:46:31.870313: Desired fold for training: 0
2023-09-04 02:46:31.871628: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 02:51:48.147786: dsc: 91.11%
2023-09-04 02:51:48.149508: miou: 83.67%
2023-09-04 02:51:48.150987: acc: 95.57%, sen: 90.24%, spe: 97.36%
2023-09-04 02:51:48.152869: current best miou: 0.8422144348184231 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 02:51:48.154165: current best dsc: 0.9143500549125113 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 02:51:48.155361: finished real validation
2023-09-04 02:51:52.526263: train_loss -1.4327
2023-09-04 02:51:52.528026: val_loss -1.0351
2023-09-04 02:51:52.529562: Pseudo dice [0.9083]
2023-09-04 02:51:52.530910: Epoch time: 381.85 s
2023-09-04 02:51:55.373067: 
2023-09-04 02:51:55.375255: Epoch 120
2023-09-04 02:51:55.376832: Current learning rate: backbone 0.00063145, others 0.00063145
2023-09-04 02:51:55.379281: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 02:52:56.460595: finished training epoch 120
2023-09-04 02:52:56.506424: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 02:52:56.509007: The split file contains 1 splits.
2023-09-04 02:52:56.510300: Desired fold for training: 0
2023-09-04 02:52:56.511979: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 02:58:16.246963: dsc: 91.04%
2023-09-04 02:58:16.248885: miou: 83.56%
2023-09-04 02:58:16.250218: acc: 95.50%, sen: 91.00%, spe: 97.01%
2023-09-04 02:58:16.251881: current best miou: 0.8422144348184231 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 02:58:16.253233: current best dsc: 0.9143500549125113 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 02:58:16.254478: finished real validation
2023-09-04 02:58:20.635066: train_loss -1.4328
2023-09-04 02:58:20.637182: val_loss -1.0486
2023-09-04 02:58:20.638946: Pseudo dice [0.911]
2023-09-04 02:58:20.640378: Epoch time: 385.26 s
2023-09-04 02:58:21.797566: 
2023-09-04 02:58:21.799280: Epoch 121
2023-09-04 02:58:21.800699: Current learning rate: backbone 0.00062829, others 0.00062829
2023-09-04 02:58:21.802666: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 02:59:22.870952: finished training epoch 121
2023-09-04 02:59:22.912482: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 02:59:22.915030: The split file contains 1 splits.
2023-09-04 02:59:22.916437: Desired fold for training: 0
2023-09-04 02:59:22.917703: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 03:05:02.472744: dsc: 91.01%
2023-09-04 03:05:02.474763: miou: 83.51%
2023-09-04 03:05:02.476205: acc: 95.50%, sen: 90.66%, spe: 97.12%
2023-09-04 03:05:02.477973: current best miou: 0.8422144348184231 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 03:05:02.479309: current best dsc: 0.9143500549125113 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 03:05:02.480635: finished real validation
2023-09-04 03:05:06.863230: train_loss -1.4331
2023-09-04 03:05:06.865279: val_loss -1.0565
2023-09-04 03:05:06.866874: Pseudo dice [0.913]
2023-09-04 03:05:06.868297: Epoch time: 405.07 s
2023-09-04 03:05:08.027497: 
2023-09-04 03:05:08.029256: Epoch 122
2023-09-04 03:05:08.030620: Current learning rate: backbone 0.00062513, others 0.00062513
2023-09-04 03:05:08.032446: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 03:06:09.795953: finished training epoch 122
2023-09-04 03:06:09.874374: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 03:06:09.878043: The split file contains 1 splits.
2023-09-04 03:06:09.879973: Desired fold for training: 0
2023-09-04 03:06:09.881739: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 03:11:37.080981: dsc: 90.96%
2023-09-04 03:11:37.083107: miou: 83.42%
2023-09-04 03:11:37.084479: acc: 95.46%, sen: 90.72%, spe: 97.06%
2023-09-04 03:11:37.086355: current best miou: 0.8422144348184231 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 03:11:37.087752: current best dsc: 0.9143500549125113 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 03:11:37.089008: finished real validation
2023-09-04 03:11:41.471109: train_loss -1.4343
2023-09-04 03:11:41.473131: val_loss -1.0279
2023-09-04 03:11:41.474776: Pseudo dice [0.907]
2023-09-04 03:11:41.476240: Epoch time: 393.44 s
2023-09-04 03:11:42.622240: 
2023-09-04 03:11:42.624075: Epoch 123
2023-09-04 03:11:42.625440: Current learning rate: backbone 0.00062197, others 0.00062197
2023-09-04 03:11:42.627291: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 03:12:43.919247: finished training epoch 123
2023-09-04 03:12:43.992523: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 03:12:43.994966: The split file contains 1 splits.
2023-09-04 03:12:43.996250: Desired fold for training: 0
2023-09-04 03:12:43.997792: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 03:17:58.198447: dsc: 91.10%
2023-09-04 03:17:58.200298: miou: 83.66%
2023-09-04 03:17:58.201695: acc: 95.54%, sen: 90.86%, spe: 97.11%
2023-09-04 03:17:58.203928: current best miou: 0.8422144348184231 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 03:17:58.205274: current best dsc: 0.9143500549125113 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 03:17:58.206668: finished real validation
2023-09-04 03:18:02.601011: train_loss -1.4335
2023-09-04 03:18:02.602859: val_loss -1.0307
2023-09-04 03:18:02.604491: Pseudo dice [0.9101]
2023-09-04 03:18:02.605907: Epoch time: 379.98 s
2023-09-04 03:18:03.770557: 
2023-09-04 03:18:03.772147: Epoch 124
2023-09-04 03:18:03.773543: Current learning rate: backbone 0.0006188, others 0.0006188
2023-09-04 03:18:03.775513: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 03:19:04.917439: finished training epoch 124
2023-09-04 03:19:04.947768: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 03:19:04.950399: The split file contains 1 splits.
2023-09-04 03:19:04.951884: Desired fold for training: 0
2023-09-04 03:19:04.953390: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 03:24:24.145687: dsc: 91.06%
2023-09-04 03:24:24.147691: miou: 83.58%
2023-09-04 03:24:24.149369: acc: 95.55%, sen: 90.16%, spe: 97.36%
2023-09-04 03:24:24.151570: current best miou: 0.8422144348184231 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 03:24:24.153038: current best dsc: 0.9143500549125113 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 03:24:24.154426: finished real validation
2023-09-04 03:24:28.572930: train_loss -1.4339
2023-09-04 03:24:28.575050: val_loss -1.0675
2023-09-04 03:24:28.576905: Pseudo dice [0.9137]
2023-09-04 03:24:28.578583: Epoch time: 384.8 s
2023-09-04 03:24:29.755149: 
2023-09-04 03:24:29.756992: Epoch 125
2023-09-04 03:24:29.758423: Current learning rate: backbone 0.00061564, others 0.00061564
2023-09-04 03:24:29.760166: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 03:25:30.967957: finished training epoch 125
2023-09-04 03:25:31.001754: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 03:25:31.008358: The split file contains 1 splits.
2023-09-04 03:25:31.010170: Desired fold for training: 0
2023-09-04 03:25:31.011810: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 03:30:45.211834: dsc: 91.03%
2023-09-04 03:30:45.213675: miou: 83.53%
2023-09-04 03:30:45.215410: acc: 95.49%, sen: 90.94%, spe: 97.02%
2023-09-04 03:30:45.217610: current best miou: 0.8422144348184231 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 03:30:45.219196: current best dsc: 0.9143500549125113 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 03:30:45.220791: finished real validation
2023-09-04 03:30:49.590616: train_loss -1.4343
2023-09-04 03:30:49.592491: val_loss -1.0255
2023-09-04 03:30:49.594141: Pseudo dice [0.9087]
2023-09-04 03:30:49.595543: Epoch time: 379.84 s
2023-09-04 03:30:50.753292: 
2023-09-04 03:30:50.755172: Epoch 126
2023-09-04 03:30:50.756666: Current learning rate: backbone 0.00061247, others 0.00061247
2023-09-04 03:30:50.758555: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 03:31:52.033712: finished training epoch 126
2023-09-04 03:31:52.071448: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 03:31:52.074388: The split file contains 1 splits.
2023-09-04 03:31:52.076157: Desired fold for training: 0
2023-09-04 03:31:52.077701: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 03:37:17.550068: dsc: 90.89%
2023-09-04 03:37:17.551942: miou: 83.30%
2023-09-04 03:37:17.555761: acc: 95.45%, sen: 90.22%, spe: 97.21%
2023-09-04 03:37:17.558900: current best miou: 0.8422144348184231 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 03:37:17.560970: current best dsc: 0.9143500549125113 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 03:37:17.562590: finished real validation
2023-09-04 03:37:21.955645: train_loss -1.4345
2023-09-04 03:37:21.957483: val_loss -1.0462
2023-09-04 03:37:21.959367: Pseudo dice [0.9104]
2023-09-04 03:37:21.960866: Epoch time: 391.2 s
2023-09-04 03:37:23.118960: 
2023-09-04 03:37:23.120888: Epoch 127
2023-09-04 03:37:23.122841: Current learning rate: backbone 0.0006093, others 0.0006093
2023-09-04 03:37:23.125371: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 03:38:24.622168: finished training epoch 127
2023-09-04 03:38:24.665674: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 03:38:24.668469: The split file contains 1 splits.
2023-09-04 03:38:24.670047: Desired fold for training: 0
2023-09-04 03:38:24.671581: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 03:43:35.867656: dsc: 91.02%
2023-09-04 03:44:02.799929: miou: 83.52%
2023-09-04 03:44:02.802269: acc: 95.49%, sen: 90.89%, spe: 97.04%
2023-09-04 03:44:02.805318: current best miou: 0.8422144348184231 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 03:44:02.807255: current best dsc: 0.9143500549125113 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 03:44:02.809123: finished real validation
2023-09-04 03:44:07.196931: train_loss -1.4342
2023-09-04 03:44:07.198695: val_loss -1.0274
2023-09-04 03:44:07.200322: Pseudo dice [0.9093]
2023-09-04 03:44:07.201688: Epoch time: 404.08 s
2023-09-04 03:44:08.385561: 
2023-09-04 03:44:08.387636: Epoch 128
2023-09-04 03:44:08.389475: Current learning rate: backbone 0.00060613, others 0.00060613
2023-09-04 03:44:08.391882: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 03:45:09.646313: finished training epoch 128
2023-09-04 03:45:09.688160: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 03:45:09.691247: The split file contains 1 splits.
2023-09-04 03:45:09.692470: Desired fold for training: 0
2023-09-04 03:45:09.693674: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 03:50:38.651578: dsc: 90.90%
2023-09-04 03:50:38.653294: miou: 83.32%
2023-09-04 03:50:38.654748: acc: 95.43%, sen: 90.83%, spe: 96.97%
2023-09-04 03:50:38.656414: current best miou: 0.8422144348184231 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 03:50:38.657777: current best dsc: 0.9143500549125113 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 03:50:38.659026: finished real validation
2023-09-04 03:50:43.048685: train_loss -1.4348
2023-09-04 03:50:43.050652: val_loss -1.0247
2023-09-04 03:50:43.052380: Pseudo dice [0.9089]
2023-09-04 03:50:43.053769: Epoch time: 394.66 s
2023-09-04 03:50:44.226125: 
2023-09-04 03:50:44.228200: Epoch 129
2023-09-04 03:50:44.229749: Current learning rate: backbone 0.00060296, others 0.00060296
2023-09-04 03:50:44.231643: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 03:51:45.431155: finished training epoch 129
2023-09-04 03:51:45.472878: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 03:51:45.475531: The split file contains 1 splits.
2023-09-04 03:51:45.476984: Desired fold for training: 0
2023-09-04 03:51:45.478412: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 03:57:29.252174: dsc: 90.98%
2023-09-04 03:57:29.254118: miou: 83.45%
2023-09-04 03:57:29.255624: acc: 95.47%, sen: 90.73%, spe: 97.07%
2023-09-04 03:57:29.258333: current best miou: 0.8422144348184231 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 03:57:29.259801: current best dsc: 0.9143500549125113 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 03:57:29.261675: finished real validation
2023-09-04 03:57:33.662536: train_loss -1.4352
2023-09-04 03:57:33.664392: val_loss -1.0191
2023-09-04 03:57:33.666229: Pseudo dice [0.9116]
2023-09-04 03:57:33.667657: Epoch time: 409.44 s
2023-09-04 03:57:36.368019: 
2023-09-04 03:57:36.369661: Epoch 130
2023-09-04 03:57:36.371130: Current learning rate: backbone 0.00059978, others 0.00059978
2023-09-04 03:57:36.373580: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 03:58:37.664633: finished training epoch 130
2023-09-04 03:58:37.728057: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 03:58:37.730414: The split file contains 1 splits.
2023-09-04 03:58:37.731857: Desired fold for training: 0
2023-09-04 03:58:37.733773: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 04:03:52.312308: dsc: 90.97%
2023-09-04 04:03:52.314032: miou: 83.43%
2023-09-04 04:03:52.315508: acc: 95.47%, sen: 90.71%, spe: 97.07%
2023-09-04 04:03:52.317300: current best miou: 0.8422144348184231 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 04:03:52.318686: current best dsc: 0.9143500549125113 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 04:03:52.320366: finished real validation
2023-09-04 04:03:56.708012: train_loss -1.4356
2023-09-04 04:03:56.709708: val_loss -1.0034
2023-09-04 04:03:56.711272: Pseudo dice [0.9084]
2023-09-04 04:03:56.712603: Epoch time: 380.34 s
2023-09-04 04:03:57.866036: 
2023-09-04 04:03:57.867591: Epoch 131
2023-09-04 04:03:57.868888: Current learning rate: backbone 0.00059661, others 0.00059661
2023-09-04 04:03:57.870517: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 04:04:59.057853: finished training epoch 131
2023-09-04 04:04:59.102516: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 04:04:59.105142: The split file contains 1 splits.
2023-09-04 04:04:59.106595: Desired fold for training: 0
2023-09-04 04:04:59.107911: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 04:10:22.989598: dsc: 91.09%
2023-09-04 04:10:22.991414: miou: 83.65%
2023-09-04 04:10:22.992844: acc: 95.53%, sen: 90.94%, spe: 97.07%
2023-09-04 04:10:22.994600: current best miou: 0.8422144348184231 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 04:10:22.996137: current best dsc: 0.9143500549125113 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 04:10:22.997887: finished real validation
2023-09-04 04:10:27.376015: train_loss -1.435
2023-09-04 04:10:27.377821: val_loss -1.0563
2023-09-04 04:10:27.379444: Pseudo dice [0.912]
2023-09-04 04:10:27.381092: Epoch time: 389.51 s
2023-09-04 04:10:28.550834: 
2023-09-04 04:10:28.552435: Epoch 132
2023-09-04 04:10:28.553843: Current learning rate: backbone 0.00059343, others 0.00059343
2023-09-04 04:10:28.555652: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 04:11:29.677763: finished training epoch 132
2023-09-04 04:11:29.707710: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 04:11:29.714851: The split file contains 1 splits.
2023-09-04 04:11:29.716699: Desired fold for training: 0
2023-09-04 04:11:29.718380: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 04:16:53.785389: dsc: 91.11%
2023-09-04 04:16:53.787102: miou: 83.68%
2023-09-04 04:16:53.788473: acc: 95.54%, sen: 90.83%, spe: 97.13%
2023-09-04 04:16:53.790185: current best miou: 0.8422144348184231 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 04:16:53.791501: current best dsc: 0.9143500549125113 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 04:16:53.792772: finished real validation
2023-09-04 04:16:58.176086: train_loss -1.4355
2023-09-04 04:16:58.178076: val_loss -1.0588
2023-09-04 04:16:58.179701: Pseudo dice [0.9143]
2023-09-04 04:16:58.181129: Epoch time: 389.63 s
2023-09-04 04:16:59.340117: 
2023-09-04 04:16:59.342056: Epoch 133
2023-09-04 04:16:59.343554: Current learning rate: backbone 0.00059025, others 0.00059025
2023-09-04 04:16:59.345342: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 04:18:00.478833: finished training epoch 133
2023-09-04 04:18:00.519156: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 04:18:00.522434: The split file contains 1 splits.
2023-09-04 04:18:00.524189: Desired fold for training: 0
2023-09-04 04:18:00.525995: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 04:23:22.503014: dsc: 90.99%
2023-09-04 04:23:22.504977: miou: 83.47%
2023-09-04 04:23:22.506544: acc: 95.48%, sen: 90.82%, spe: 97.04%
2023-09-04 04:23:22.508460: current best miou: 0.8422144348184231 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 04:23:22.509999: current best dsc: 0.9143500549125113 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 04:23:22.511436: finished real validation
2023-09-04 04:23:26.912235: train_loss -1.4351
2023-09-04 04:23:26.914688: val_loss -1.0357
2023-09-04 04:23:26.916702: Pseudo dice [0.9122]
2023-09-04 04:23:26.918321: Epoch time: 387.57 s
2023-09-04 04:23:28.053826: 
2023-09-04 04:23:28.055688: Epoch 134
2023-09-04 04:23:28.057355: Current learning rate: backbone 0.00058707, others 0.00058707
2023-09-04 04:23:28.059179: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 04:24:29.173003: finished training epoch 134
2023-09-04 04:24:29.212741: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 04:24:29.214983: The split file contains 1 splits.
2023-09-04 04:24:29.216303: Desired fold for training: 0
2023-09-04 04:24:29.217777: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 04:29:58.610215: dsc: 91.08%
2023-09-04 04:29:58.612605: miou: 83.63%
2023-09-04 04:29:58.614206: acc: 95.53%, sen: 90.76%, spe: 97.13%
2023-09-04 04:29:58.616123: current best miou: 0.8422144348184231 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 04:29:58.617656: current best dsc: 0.9143500549125113 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 04:29:58.619529: finished real validation
2023-09-04 04:30:03.021334: train_loss -1.4355
2023-09-04 04:30:03.023262: val_loss -1.0584
2023-09-04 04:30:03.024930: Pseudo dice [0.9171]
2023-09-04 04:30:03.026393: Epoch time: 394.97 s
2023-09-04 04:30:04.154695: 
2023-09-04 04:30:04.156476: Epoch 135
2023-09-04 04:30:04.157918: Current learning rate: backbone 0.00058388, others 0.00058388
2023-09-04 04:30:04.160036: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 04:31:05.605966: finished training epoch 135
2023-09-04 04:31:05.637079: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 04:31:05.640020: The split file contains 1 splits.
2023-09-04 04:31:05.641636: Desired fold for training: 0
2023-09-04 04:31:05.643200: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 04:36:27.159301: dsc: 90.93%
2023-09-04 04:36:27.161502: miou: 83.36%
2023-09-04 04:36:27.163455: acc: 95.45%, sen: 90.63%, spe: 97.07%
2023-09-04 04:36:27.165662: current best miou: 0.8422144348184231 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 04:36:27.167228: current best dsc: 0.9143500549125113 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 04:36:27.168667: finished real validation
2023-09-04 04:36:31.560482: train_loss -1.4359
2023-09-04 04:36:31.562411: val_loss -1.0348
2023-09-04 04:36:31.564106: Pseudo dice [0.913]
2023-09-04 04:36:31.565634: Epoch time: 387.41 s
2023-09-04 04:36:32.706831: 
2023-09-04 04:36:32.708672: Epoch 136
2023-09-04 04:36:32.710133: Current learning rate: backbone 0.0005807, others 0.0005807
2023-09-04 04:36:32.712002: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 04:37:33.898373: finished training epoch 136
2023-09-04 04:37:33.928509: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 04:37:33.931103: The split file contains 1 splits.
2023-09-04 04:37:33.932633: Desired fold for training: 0
2023-09-04 04:37:33.934057: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 04:42:49.830241: dsc: 91.04%
2023-09-04 04:42:49.832078: miou: 83.56%
2023-09-04 04:42:49.833726: acc: 95.50%, sen: 90.99%, spe: 97.01%
2023-09-04 04:42:49.835621: current best miou: 0.8422144348184231 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 04:42:49.837309: current best dsc: 0.9143500549125113 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 04:42:49.839226: finished real validation
2023-09-04 04:42:54.223812: train_loss -1.4354
2023-09-04 04:42:54.225718: val_loss -1.0293
2023-09-04 04:42:54.227491: Pseudo dice [0.9098]
2023-09-04 04:42:54.229076: Epoch time: 381.52 s
2023-09-04 04:42:55.385441: 
2023-09-04 04:42:55.387386: Epoch 137
2023-09-04 04:42:55.389591: Current learning rate: backbone 0.00057751, others 0.00057751
2023-09-04 04:42:55.391974: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 04:43:56.554845: finished training epoch 137
2023-09-04 04:43:56.596013: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 04:43:56.598541: The split file contains 1 splits.
2023-09-04 04:43:56.599971: Desired fold for training: 0
2023-09-04 04:43:56.601718: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 04:49:07.599928: dsc: 91.09%
2023-09-04 04:49:07.601969: miou: 83.64%
2023-09-04 04:49:07.603654: acc: 95.53%, sen: 90.80%, spe: 97.12%
2023-09-04 04:49:07.605626: current best miou: 0.8422144348184231 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 04:49:07.607390: current best dsc: 0.9143500549125113 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 04:49:07.609036: finished real validation
2023-09-04 04:49:12.005901: train_loss -1.4364
2023-09-04 04:49:12.007940: val_loss -1.0128
2023-09-04 04:49:12.009629: Pseudo dice [0.909]
2023-09-04 04:49:12.011096: Epoch time: 376.62 s
2023-09-04 04:49:13.160695: 
2023-09-04 04:49:13.162596: Epoch 138
2023-09-04 04:49:13.164017: Current learning rate: backbone 0.00057432, others 0.00057432
2023-09-04 04:49:13.165806: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 04:50:14.340039: finished training epoch 138
2023-09-04 04:50:14.369536: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 04:50:14.372004: The split file contains 1 splits.
2023-09-04 04:50:14.373833: Desired fold for training: 0
2023-09-04 04:50:14.375526: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 04:55:41.568828: dsc: 91.01%
2023-09-04 04:55:41.570960: miou: 83.50%
2023-09-04 04:55:41.572459: acc: 95.49%, sen: 90.66%, spe: 97.12%
2023-09-04 04:55:41.574497: current best miou: 0.8422144348184231 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 04:55:41.575860: current best dsc: 0.9143500549125113 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 04:55:41.577286: finished real validation
2023-09-04 04:55:45.970026: train_loss -1.437
2023-09-04 04:55:45.972079: val_loss -1.0445
2023-09-04 04:55:45.974026: Pseudo dice [0.912]
2023-09-04 04:55:45.975677: Epoch time: 392.81 s
2023-09-04 04:55:47.121356: 
2023-09-04 04:55:47.123527: Epoch 139
2023-09-04 04:55:47.125316: Current learning rate: backbone 0.00057113, others 0.00057113
2023-09-04 04:55:47.127342: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 04:56:48.337779: finished training epoch 139
2023-09-04 04:56:48.384197: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 04:56:48.386882: The split file contains 1 splits.
2023-09-04 04:56:48.388352: Desired fold for training: 0
2023-09-04 04:56:48.389775: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 05:02:05.579905: dsc: 91.08%
2023-09-04 05:02:05.581731: miou: 83.63%
2023-09-04 05:02:05.583323: acc: 95.52%, sen: 91.04%, spe: 97.02%
2023-09-04 05:02:05.585080: current best miou: 0.8422144348184231 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 05:02:05.586493: current best dsc: 0.9143500549125113 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 05:02:05.588250: finished real validation
2023-09-04 05:02:09.991856: train_loss -1.436
2023-09-04 05:02:09.993843: val_loss -1.0402
2023-09-04 05:02:09.995536: Pseudo dice [0.9124]
2023-09-04 05:02:09.997001: Epoch time: 382.87 s
2023-09-04 05:02:12.737138: 
2023-09-04 05:02:12.739265: Epoch 140
2023-09-04 05:02:12.740962: Current learning rate: backbone 0.00056794, others 0.00056794
2023-09-04 05:02:12.742955: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 05:03:14.467509: finished training epoch 140
2023-09-04 05:03:14.508325: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 05:03:14.511882: The split file contains 1 splits.
2023-09-04 05:03:14.513830: Desired fold for training: 0
2023-09-04 05:03:14.515652: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 05:08:35.789887: dsc: 91.00%
2023-09-04 05:08:35.791878: miou: 83.48%
2023-09-04 05:08:35.793496: acc: 95.47%, sen: 91.12%, spe: 96.93%
2023-09-04 05:08:35.796148: current best miou: 0.8422144348184231 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 05:08:35.798908: current best dsc: 0.9143500549125113 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 05:08:35.801225: finished real validation
2023-09-04 05:08:40.195880: train_loss -1.4364
2023-09-04 05:08:40.198040: val_loss -1.0167
2023-09-04 05:08:40.199981: Pseudo dice [0.9095]
2023-09-04 05:08:40.201710: Epoch time: 387.46 s
2023-09-04 05:08:41.346995: 
2023-09-04 05:08:41.348966: Epoch 141
2023-09-04 05:08:41.350584: Current learning rate: backbone 0.00056474, others 0.00056474
2023-09-04 05:08:41.352761: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 05:09:42.422529: finished training epoch 141
2023-09-04 05:09:42.458688: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 05:09:42.461466: The split file contains 1 splits.
2023-09-04 05:09:42.463114: Desired fold for training: 0
2023-09-04 05:09:42.464587: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 05:14:55.280104: dsc: 90.99%
2023-09-04 05:14:55.282256: miou: 83.47%
2023-09-04 05:14:55.284401: acc: 95.47%, sen: 91.03%, spe: 96.96%
2023-09-04 05:14:55.287920: current best miou: 0.8422144348184231 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 05:14:55.289711: current best dsc: 0.9143500549125113 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 05:14:55.291077: finished real validation
2023-09-04 05:14:59.675073: train_loss -1.4366
2023-09-04 05:14:59.676977: val_loss -1.0376
2023-09-04 05:14:59.678700: Pseudo dice [0.9133]
2023-09-04 05:14:59.680167: Epoch time: 378.33 s
2023-09-04 05:15:00.818294: 
2023-09-04 05:15:00.820297: Epoch 142
2023-09-04 05:15:00.822003: Current learning rate: backbone 0.00056154, others 0.00056154
2023-09-04 05:15:00.824350: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 05:16:02.130074: finished training epoch 142
2023-09-04 05:16:02.171813: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 05:16:02.174622: The split file contains 1 splits.
2023-09-04 05:16:02.176095: Desired fold for training: 0
2023-09-04 05:16:02.177475: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 05:21:20.729506: dsc: 90.97%
2023-09-04 05:21:20.731425: miou: 83.44%
2023-09-04 05:21:20.733082: acc: 95.47%, sen: 90.74%, spe: 97.06%
2023-09-04 05:21:20.734999: current best miou: 0.8422144348184231 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 05:21:20.736601: current best dsc: 0.9143500549125113 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 05:21:20.738135: finished real validation
2023-09-04 05:21:25.149549: train_loss -1.4364
2023-09-04 05:21:25.151638: val_loss -1.0123
2023-09-04 05:21:25.153496: Pseudo dice [0.9105]
2023-09-04 05:21:25.154991: Epoch time: 384.33 s
2023-09-04 05:21:26.328385: 
2023-09-04 05:21:26.330605: Epoch 143
2023-09-04 05:21:26.332454: Current learning rate: backbone 0.00055834, others 0.00055834
2023-09-04 05:21:26.335118: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 05:22:27.466042: finished training epoch 143
2023-09-04 05:22:27.505117: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 05:22:27.507707: The split file contains 1 splits.
2023-09-04 05:22:27.509286: Desired fold for training: 0
2023-09-04 05:22:27.510677: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 05:27:46.631691: dsc: 91.05%
2023-09-04 05:27:46.633898: miou: 83.56%
2023-09-04 05:27:46.635524: acc: 95.50%, sen: 90.96%, spe: 97.02%
2023-09-04 05:27:46.637582: current best miou: 0.8422144348184231 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 05:27:46.639300: current best dsc: 0.9143500549125113 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 05:27:46.641193: finished real validation
2023-09-04 05:27:51.026763: train_loss -1.4369
2023-09-04 05:27:51.028728: val_loss -1.0506
2023-09-04 05:27:51.030467: Pseudo dice [0.9133]
2023-09-04 05:27:51.032009: Epoch time: 384.7 s
2023-09-04 05:27:52.184775: 
2023-09-04 05:27:52.186694: Epoch 144
2023-09-04 05:27:52.188350: Current learning rate: backbone 0.00055514, others 0.00055514
2023-09-04 05:27:52.190335: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 05:28:53.357851: finished training epoch 144
2023-09-04 05:28:53.388560: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 05:28:53.390991: The split file contains 1 splits.
2023-09-04 05:28:53.392462: Desired fold for training: 0
2023-09-04 05:28:53.393857: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 05:34:07.349766: dsc: 91.00%
2023-09-04 05:34:07.351737: miou: 83.49%
2023-09-04 05:34:07.353220: acc: 95.49%, sen: 90.76%, spe: 97.07%
2023-09-04 05:34:07.355044: current best miou: 0.8422144348184231 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 05:34:07.356555: current best dsc: 0.9143500549125113 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 05:34:07.357933: finished real validation
2023-09-04 05:34:11.751213: train_loss -1.4368
2023-09-04 05:34:11.753340: val_loss -1.0219
2023-09-04 05:34:11.755129: Pseudo dice [0.9103]
2023-09-04 05:34:11.756678: Epoch time: 379.57 s
2023-09-04 05:34:12.905289: 
2023-09-04 05:34:12.907135: Epoch 145
2023-09-04 05:34:12.908931: Current learning rate: backbone 0.00055194, others 0.00055194
2023-09-04 05:34:12.911385: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 05:35:13.985617: finished training epoch 145
2023-09-04 05:35:14.016711: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 05:35:14.019436: The split file contains 1 splits.
2023-09-04 05:35:14.021042: Desired fold for training: 0
2023-09-04 05:35:14.022563: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 05:40:41.877910: dsc: 91.07%
2023-09-04 05:40:41.879862: miou: 83.61%
2023-09-04 05:40:41.881320: acc: 95.51%, sen: 91.03%, spe: 97.02%
2023-09-04 05:40:41.883138: current best miou: 0.8422144348184231 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 05:40:41.884571: current best dsc: 0.9143500549125113 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 05:40:41.885922: finished real validation
2023-09-04 05:40:46.289829: train_loss -1.4373
2023-09-04 05:40:46.291824: val_loss -1.0428
2023-09-04 05:40:46.293564: Pseudo dice [0.9123]
2023-09-04 05:40:46.295086: Epoch time: 393.39 s
2023-09-04 05:40:47.437396: 
2023-09-04 05:40:47.439557: Epoch 146
2023-09-04 05:40:47.441516: Current learning rate: backbone 0.00054873, others 0.00054873
2023-09-04 05:40:47.443898: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 05:41:48.571213: finished training epoch 146
2023-09-04 05:41:48.647679: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 05:41:48.650506: The split file contains 1 splits.
2023-09-04 05:41:48.652057: Desired fold for training: 0
2023-09-04 05:41:48.653498: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 05:47:10.999131: dsc: 91.04%
2023-09-04 05:47:11.001355: miou: 83.55%
2023-09-04 05:47:11.002849: acc: 95.49%, sen: 91.06%, spe: 96.98%
2023-09-04 05:47:11.004818: current best miou: 0.8422144348184231 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 05:47:11.006492: current best dsc: 0.9143500549125113 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 05:47:11.008124: finished real validation
2023-09-04 05:47:15.402340: train_loss -1.4369
2023-09-04 05:47:15.404366: val_loss -1.0394
2023-09-04 05:47:15.406357: Pseudo dice [0.9117]
2023-09-04 05:47:15.408270: Epoch time: 387.97 s
2023-09-04 05:47:16.557856: 
2023-09-04 05:47:16.559818: Epoch 147
2023-09-04 05:47:16.561697: Current learning rate: backbone 0.00054552, others 0.00054552
2023-09-04 05:47:16.564089: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 05:48:17.724520: finished training epoch 147
2023-09-04 05:48:17.756437: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 05:48:17.759433: The split file contains 1 splits.
2023-09-04 05:48:17.761229: Desired fold for training: 0
2023-09-04 05:48:17.762702: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 05:53:35.288962: dsc: 91.05%
2023-09-04 05:53:35.291096: miou: 83.57%
2023-09-04 05:53:35.292882: acc: 95.50%, sen: 91.11%, spe: 96.97%
2023-09-04 05:53:35.295148: current best miou: 0.8422144348184231 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 05:53:35.296777: current best dsc: 0.9143500549125113 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 05:53:35.298635: finished real validation
2023-09-04 05:53:39.684740: train_loss -1.4371
2023-09-04 05:53:39.686771: val_loss -1.0244
2023-09-04 05:53:39.688493: Pseudo dice [0.9112]
2023-09-04 05:53:39.690064: Epoch time: 383.13 s
2023-09-04 05:53:40.850744: 
2023-09-04 05:53:40.852457: Epoch 148
2023-09-04 05:53:40.854412: Current learning rate: backbone 0.00054231, others 0.00054231
2023-09-04 05:53:40.856862: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 05:54:45.129185: finished training epoch 148
2023-09-04 05:54:45.159703: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 05:54:45.162303: The split file contains 1 splits.
2023-09-04 05:54:45.164047: Desired fold for training: 0
2023-09-04 05:54:45.165637: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 06:00:14.200824: dsc: 90.76%
2023-09-04 06:00:14.203025: miou: 83.09%
2023-09-04 06:00:14.204679: acc: 95.40%, sen: 89.83%, spe: 97.27%
2023-09-04 06:00:14.206838: current best miou: 0.8422144348184231 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 06:00:14.208330: current best dsc: 0.9143500549125113 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 06:00:14.209750: finished real validation
2023-09-04 06:00:18.597991: train_loss -1.4377
2023-09-04 06:00:18.600189: val_loss -1.0322
2023-09-04 06:00:18.602394: Pseudo dice [0.9103]
2023-09-04 06:00:18.604870: Epoch time: 397.75 s
2023-09-04 06:00:19.744432: 
2023-09-04 06:00:19.746608: Epoch 149
2023-09-04 06:00:19.748315: Current learning rate: backbone 0.0005391, others 0.0005391
2023-09-04 06:00:19.750391: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 06:01:20.902776: finished training epoch 149
2023-09-04 06:01:20.932755: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 06:01:20.935262: The split file contains 1 splits.
2023-09-04 06:01:20.936992: Desired fold for training: 0
2023-09-04 06:01:20.938569: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 06:06:41.243765: dsc: 90.96%
2023-09-04 06:06:41.245745: miou: 83.43%
2023-09-04 06:06:41.247324: acc: 95.47%, sen: 90.58%, spe: 97.12%
2023-09-04 06:06:41.249471: current best miou: 0.8422144348184231 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 06:06:41.250981: current best dsc: 0.9143500549125113 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 06:06:41.252455: finished real validation
2023-09-04 06:06:45.635458: train_loss -1.4353
2023-09-04 06:06:45.637423: val_loss -1.0159
2023-09-04 06:06:45.639204: Pseudo dice [0.9088]
2023-09-04 06:06:45.640777: Epoch time: 385.89 s
2023-09-04 06:06:48.292509: 
2023-09-04 06:06:48.294487: Epoch 150
2023-09-04 06:06:48.296084: Current learning rate: backbone 0.00053589, others 0.00053589
2023-09-04 06:06:48.298085: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 06:07:49.479121: finished training epoch 150
2023-09-04 06:07:49.508819: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 06:07:49.511869: The split file contains 1 splits.
2023-09-04 06:07:49.513674: Desired fold for training: 0
2023-09-04 06:07:49.515218: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 06:13:06.774866: dsc: 91.03%
2023-09-04 06:13:06.776837: miou: 83.53%
2023-09-04 06:13:06.778305: acc: 95.50%, sen: 90.64%, spe: 97.14%
2023-09-04 06:13:06.780252: current best miou: 0.8422144348184231 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 06:13:06.781893: current best dsc: 0.9143500549125113 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 06:13:06.783309: finished real validation
2023-09-04 06:13:11.171892: train_loss -1.4371
2023-09-04 06:13:11.173748: val_loss -1.0777
2023-09-04 06:13:11.175440: Pseudo dice [0.9164]
2023-09-04 06:13:11.176936: Epoch time: 382.88 s
2023-09-04 06:13:12.335157: 
2023-09-04 06:13:12.337085: Epoch 151
2023-09-04 06:13:12.338953: Current learning rate: backbone 0.00053267, others 0.00053267
2023-09-04 06:13:12.340764: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 06:14:13.538452: finished training epoch 151
2023-09-04 06:14:13.589150: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 06:14:13.591532: The split file contains 1 splits.
2023-09-04 06:14:13.593041: Desired fold for training: 0
2023-09-04 06:14:13.594536: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 06:19:33.660169: dsc: 91.08%
2023-09-04 06:19:33.662174: miou: 83.63%
2023-09-04 06:19:33.663859: acc: 95.54%, sen: 90.63%, spe: 97.19%
2023-09-04 06:19:33.666602: current best miou: 0.8422144348184231 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 06:19:33.668571: current best dsc: 0.9143500549125113 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 06:19:33.670392: finished real validation
2023-09-04 06:19:38.063175: train_loss -1.4375
2023-09-04 06:19:38.065222: val_loss -1.0382
2023-09-04 06:19:38.066994: Pseudo dice [0.912]
2023-09-04 06:19:38.068534: Epoch time: 385.73 s
2023-09-04 06:19:39.224537: 
2023-09-04 06:19:39.226583: Epoch 152
2023-09-04 06:19:39.228243: Current learning rate: backbone 0.00052945, others 0.00052945
2023-09-04 06:19:39.230171: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 06:20:40.296103: finished training epoch 152
2023-09-04 06:20:40.326335: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 06:20:40.328956: The split file contains 1 splits.
2023-09-04 06:20:40.330973: Desired fold for training: 0
2023-09-04 06:20:40.334141: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 06:25:52.992772: dsc: 91.01%
2023-09-04 06:25:52.995004: miou: 83.51%
2023-09-04 06:25:52.996711: acc: 95.49%, sen: 90.85%, spe: 97.05%
2023-09-04 06:25:52.998585: current best miou: 0.8422144348184231 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 06:25:53.000089: current best dsc: 0.9143500549125113 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 06:25:53.001528: finished real validation
2023-09-04 06:25:57.403282: train_loss -1.4382
2023-09-04 06:25:57.405345: val_loss -1.0257
2023-09-04 06:25:57.407090: Pseudo dice [0.9121]
2023-09-04 06:25:57.408637: Epoch time: 378.18 s
2023-09-04 06:25:58.554323: 
2023-09-04 06:25:58.556197: Epoch 153
2023-09-04 06:25:58.557884: Current learning rate: backbone 0.00052623, others 0.00052623
2023-09-04 06:25:58.559826: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 06:26:59.924001: finished training epoch 153
2023-09-04 06:26:59.962428: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 06:26:59.965557: The split file contains 1 splits.
2023-09-04 06:26:59.967610: Desired fold for training: 0
2023-09-04 06:26:59.969476: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 06:32:08.165238: dsc: 90.84%
2023-09-04 06:32:08.167185: miou: 83.22%
2023-09-04 06:32:08.168969: acc: 95.41%, sen: 90.61%, spe: 97.02%
2023-09-04 06:32:08.171160: current best miou: 0.8422144348184231 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 06:32:08.172585: current best dsc: 0.9143500549125113 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 06:32:08.173978: finished real validation
2023-09-04 06:32:12.562970: train_loss -1.4372
2023-09-04 06:32:12.565346: val_loss -1.034
2023-09-04 06:32:12.567323: Pseudo dice [0.911]
2023-09-04 06:32:12.569088: Epoch time: 374.01 s
2023-09-04 06:32:13.728088: 
2023-09-04 06:32:13.730393: Epoch 154
2023-09-04 06:32:13.732475: Current learning rate: backbone 0.00052301, others 0.00052301
2023-09-04 06:32:13.734750: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 06:33:14.845973: finished training epoch 154
2023-09-04 06:33:14.885107: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 06:33:14.887847: The split file contains 1 splits.
2023-09-04 06:33:14.889637: Desired fold for training: 0
2023-09-04 06:33:14.891147: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 06:38:32.598973: dsc: 91.10%
2023-09-04 06:38:32.601002: miou: 83.65%
2023-09-04 06:38:32.602802: acc: 95.53%, sen: 90.97%, spe: 97.06%
2023-09-04 06:38:32.604708: current best miou: 0.8422144348184231 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 06:38:32.606553: current best dsc: 0.9143500549125113 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 06:38:32.608327: finished real validation
2023-09-04 06:38:36.994524: train_loss -1.4376
2023-09-04 06:38:36.996742: val_loss -1.0403
2023-09-04 06:38:36.998757: Pseudo dice [0.9146]
2023-09-04 06:38:37.000567: Epoch time: 383.27 s
2023-09-04 06:38:37.002301: Yayy! New best EMA pseudo Dice: 0.9119
2023-09-04 06:38:40.062624: 
2023-09-04 06:38:40.064490: Epoch 155
2023-09-04 06:38:40.066095: Current learning rate: backbone 0.00051978, others 0.00051978
2023-09-04 06:38:40.068170: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 06:39:41.209993: finished training epoch 155
2023-09-04 06:39:41.257026: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 06:39:41.259574: The split file contains 1 splits.
2023-09-04 06:39:41.261308: Desired fold for training: 0
2023-09-04 06:39:41.262929: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 06:45:00.714851: dsc: 90.97%
2023-09-04 06:45:00.716905: miou: 83.43%
2023-09-04 06:45:00.718551: acc: 95.48%, sen: 90.48%, spe: 97.16%
2023-09-04 06:45:00.720571: current best miou: 0.8422144348184231 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 06:45:00.722057: current best dsc: 0.9143500549125113 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 06:45:00.723848: finished real validation
2023-09-04 06:45:05.114297: train_loss -1.4382
2023-09-04 06:45:05.116406: val_loss -1.0167
2023-09-04 06:45:05.118287: Pseudo dice [0.909]
2023-09-04 06:45:05.119985: Epoch time: 385.05 s
2023-09-04 06:45:06.273144: 
2023-09-04 06:45:06.275152: Epoch 156
2023-09-04 06:45:06.277157: Current learning rate: backbone 0.00051656, others 0.00051656
2023-09-04 06:45:06.279431: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 06:46:07.399940: finished training epoch 156
2023-09-04 06:46:07.444064: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 06:46:07.446767: The split file contains 1 splits.
2023-09-04 06:46:07.448406: Desired fold for training: 0
2023-09-04 06:46:07.449948: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 06:51:15.979455: dsc: 91.09%
2023-09-04 06:51:15.981739: miou: 83.63%
2023-09-04 06:51:15.983848: acc: 95.51%, sen: 91.12%, spe: 96.99%
2023-09-04 06:51:15.986086: current best miou: 0.8422144348184231 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 06:51:15.987787: current best dsc: 0.9143500549125113 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 06:51:15.989332: finished real validation
2023-09-04 06:51:20.382392: train_loss -1.439
2023-09-04 06:51:20.384660: val_loss -1.0187
2023-09-04 06:51:20.386426: Pseudo dice [0.9131]
2023-09-04 06:51:20.387961: Epoch time: 374.11 s
2023-09-04 06:51:21.549827: 
2023-09-04 06:51:21.551826: Epoch 157
2023-09-04 06:51:21.553759: Current learning rate: backbone 0.00051333, others 0.00051333
2023-09-04 06:51:21.555897: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 06:52:22.787063: finished training epoch 157
2023-09-04 06:52:22.820937: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 06:52:22.823940: The split file contains 1 splits.
2023-09-04 06:52:22.825488: Desired fold for training: 0
2023-09-04 06:52:22.827394: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 06:57:31.087668: dsc: 90.93%
2023-09-04 06:57:31.089691: miou: 83.37%
2023-09-04 06:57:31.091303: acc: 95.43%, sen: 91.03%, spe: 96.91%
2023-09-04 06:57:31.093165: current best miou: 0.8422144348184231 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 06:57:31.094682: current best dsc: 0.9143500549125113 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 06:57:31.096144: finished real validation
2023-09-04 06:57:35.482388: train_loss -1.4386
2023-09-04 06:57:35.484554: val_loss -1.0314
2023-09-04 06:57:35.486528: Pseudo dice [0.913]
2023-09-04 06:57:35.488322: Epoch time: 373.93 s
2023-09-04 06:57:36.665445: 
2023-09-04 06:57:36.667612: Epoch 158
2023-09-04 06:57:36.669373: Current learning rate: backbone 0.00051009, others 0.00051009
2023-09-04 06:57:36.671628: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 06:58:37.793350: finished training epoch 158
2023-09-04 06:58:37.835968: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 06:58:37.839427: The split file contains 1 splits.
2023-09-04 06:58:37.841299: Desired fold for training: 0
2023-09-04 06:58:37.843086: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 07:03:44.916331: dsc: 91.02%
2023-09-04 07:03:44.918833: miou: 83.52%
2023-09-04 07:03:44.920738: acc: 95.49%, sen: 90.95%, spe: 97.01%
2023-09-04 07:03:44.922865: current best miou: 0.8422144348184231 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 07:03:44.924856: current best dsc: 0.9143500549125113 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 07:03:44.926491: finished real validation
2023-09-04 07:03:49.314142: train_loss -1.4384
2023-09-04 07:03:49.316171: val_loss -1.0404
2023-09-04 07:03:49.318105: Pseudo dice [0.912]
2023-09-04 07:03:49.319895: Epoch time: 372.65 s
2023-09-04 07:03:50.472923: 
2023-09-04 07:03:50.475058: Epoch 159
2023-09-04 07:03:50.476643: Current learning rate: backbone 0.00050686, others 0.00050686
2023-09-04 07:03:50.478623: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 07:04:51.535771: finished training epoch 159
2023-09-04 07:04:51.567505: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 07:04:51.570086: The split file contains 1 splits.
2023-09-04 07:04:51.571718: Desired fold for training: 0
2023-09-04 07:04:51.573273: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 07:10:24.541719: dsc: 91.12%
2023-09-04 07:10:24.543906: miou: 83.69%
2023-09-04 07:10:24.545959: acc: 95.54%, sen: 90.94%, spe: 97.09%
2023-09-04 07:10:24.548859: current best miou: 0.8422144348184231 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 07:10:24.550655: current best dsc: 0.9143500549125113 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 07:10:24.552334: finished real validation
2023-09-04 07:10:28.932631: train_loss -1.4389
2023-09-04 07:10:28.934935: val_loss -1.0628
2023-09-04 07:10:28.936868: Pseudo dice [0.9148]
2023-09-04 07:10:28.939595: Epoch time: 398.46 s
2023-09-04 07:10:30.578855: Yayy! New best EMA pseudo Dice: 0.9122
2023-09-04 07:10:33.370139: 
2023-09-04 07:10:33.372177: Epoch 160
2023-09-04 07:10:33.373866: Current learning rate: backbone 0.00050362, others 0.00050362
2023-09-04 07:10:33.376051: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 07:11:34.545768: finished training epoch 160
2023-09-04 07:11:34.586460: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 07:11:34.589151: The split file contains 1 splits.
2023-09-04 07:11:34.590644: Desired fold for training: 0
2023-09-04 07:11:34.592128: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 07:17:04.639117: dsc: 90.98%
2023-09-04 07:17:04.641354: miou: 83.46%
2023-09-04 07:17:04.643238: acc: 95.46%, sen: 91.03%, spe: 96.95%
2023-09-04 07:17:04.645480: current best miou: 0.8422144348184231 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 07:17:04.647449: current best dsc: 0.9143500549125113 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 07:17:04.648938: finished real validation
2023-09-04 07:17:09.040932: train_loss -1.4389
2023-09-04 07:17:09.042984: val_loss -1.0158
2023-09-04 07:17:09.044794: Pseudo dice [0.9118]
2023-09-04 07:17:09.046391: Epoch time: 395.67 s
2023-09-04 07:17:10.227123: 
2023-09-04 07:17:10.229187: Epoch 161
2023-09-04 07:17:10.231197: Current learning rate: backbone 0.00050038, others 0.00050038
2023-09-04 07:17:10.233477: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 07:18:11.482273: finished training epoch 161
2023-09-04 07:18:11.511798: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 07:18:11.514236: The split file contains 1 splits.
2023-09-04 07:18:11.516079: Desired fold for training: 0
2023-09-04 07:18:11.517833: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 07:23:26.885748: dsc: 91.04%
2023-09-04 07:23:26.887844: miou: 83.56%
2023-09-04 07:23:26.889784: acc: 95.51%, sen: 90.78%, spe: 97.10%
2023-09-04 07:23:26.891876: current best miou: 0.8422144348184231 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 07:23:26.893507: current best dsc: 0.9143500549125113 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 07:23:26.895256: finished real validation
2023-09-04 07:23:31.288834: train_loss -1.4391
2023-09-04 07:23:31.291087: val_loss -1.0253
2023-09-04 07:23:31.293113: Pseudo dice [0.913]
2023-09-04 07:23:31.294914: Epoch time: 381.06 s
2023-09-04 07:23:31.296625: Yayy! New best EMA pseudo Dice: 0.9123
2023-09-04 07:23:34.078100: 
2023-09-04 07:23:34.080081: Epoch 162
2023-09-04 07:23:34.081956: Current learning rate: backbone 0.00049714, others 0.00049714
2023-09-04 07:23:34.084067: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 07:24:35.238607: finished training epoch 162
2023-09-04 07:24:35.268491: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 07:24:35.270908: The split file contains 1 splits.
2023-09-04 07:24:35.272506: Desired fold for training: 0
2023-09-04 07:24:35.274005: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 07:29:46.953707: dsc: 90.99%
2023-09-04 07:29:46.955835: miou: 83.47%
2023-09-04 07:29:46.957536: acc: 95.46%, sen: 91.03%, spe: 96.96%
2023-09-04 07:29:46.959600: current best miou: 0.8422144348184231 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 07:29:46.961125: current best dsc: 0.9143500549125113 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 07:29:46.962622: finished real validation
2023-09-04 07:29:51.349447: train_loss -1.4388
2023-09-04 07:29:51.351691: val_loss -0.9933
2023-09-04 07:29:51.353717: Pseudo dice [0.9078]
2023-09-04 07:29:51.355545: Epoch time: 377.27 s
2023-09-04 07:29:52.507725: 
2023-09-04 07:29:52.509842: Epoch 163
2023-09-04 07:29:52.511936: Current learning rate: backbone 0.0004939, others 0.0004939
2023-09-04 07:29:52.514318: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 07:30:53.512000: finished training epoch 163
2023-09-04 07:30:53.549027: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 07:30:53.551757: The split file contains 1 splits.
2023-09-04 07:30:53.553411: Desired fold for training: 0
2023-09-04 07:30:53.554977: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 07:36:03.297676: dsc: 90.96%
2023-09-04 07:36:03.299679: miou: 83.42%
2023-09-04 07:36:03.301565: acc: 95.48%, sen: 90.47%, spe: 97.16%
2023-09-04 07:36:03.303781: current best miou: 0.8422144348184231 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 07:36:03.305503: current best dsc: 0.9143500549125113 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 07:36:03.307443: finished real validation
2023-09-04 07:36:07.699804: train_loss -1.4396
2023-09-04 07:36:07.701860: val_loss -1.0148
2023-09-04 07:36:07.703666: Pseudo dice [0.9122]
2023-09-04 07:36:07.705288: Epoch time: 375.19 s
2023-09-04 07:36:08.875170: 
2023-09-04 07:36:08.877053: Epoch 164
2023-09-04 07:36:08.878686: Current learning rate: backbone 0.00049065, others 0.00049065
2023-09-04 07:36:08.881097: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 07:37:10.498669: finished training epoch 164
2023-09-04 07:37:10.528265: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 07:37:10.530849: The split file contains 1 splits.
2023-09-04 07:37:10.532487: Desired fold for training: 0
2023-09-04 07:37:10.534311: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 07:42:21.550952: dsc: 90.95%
2023-09-04 07:42:21.553192: miou: 83.40%
2023-09-04 07:42:21.555191: acc: 95.44%, sen: 91.02%, spe: 96.93%
2023-09-04 07:42:21.557640: current best miou: 0.8422144348184231 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 07:42:21.559498: current best dsc: 0.9143500549125113 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 07:42:21.561265: finished real validation
2023-09-04 07:42:25.942741: train_loss -1.4393
2023-09-04 07:42:25.945015: val_loss -1.0002
2023-09-04 07:42:25.946852: Pseudo dice [0.9074]
2023-09-04 07:42:25.948474: Epoch time: 377.07 s
2023-09-04 07:42:27.109025: 
2023-09-04 07:42:27.111171: Epoch 165
2023-09-04 07:42:27.113284: Current learning rate: backbone 0.00048741, others 0.00048741
2023-09-04 07:42:27.115836: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 07:43:28.109010: finished training epoch 165
2023-09-04 07:43:28.138479: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 07:43:28.140956: The split file contains 1 splits.
2023-09-04 07:43:28.142626: Desired fold for training: 0
2023-09-04 07:43:28.144586: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 07:48:47.733544: dsc: 91.04%
2023-09-04 07:48:47.735559: miou: 83.56%
2023-09-04 07:48:47.737293: acc: 95.50%, sen: 90.85%, spe: 97.07%
2023-09-04 07:48:47.739159: current best miou: 0.8422144348184231 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 07:48:47.740696: current best dsc: 0.9143500549125113 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 07:48:47.742329: finished real validation
2023-09-04 07:48:52.137781: train_loss -1.4392
2023-09-04 07:48:52.139760: val_loss -1.0086
2023-09-04 07:48:52.141484: Pseudo dice [0.9111]
2023-09-04 07:48:52.143040: Epoch time: 385.03 s
2023-09-04 07:48:53.270561: 
2023-09-04 07:48:53.272962: Epoch 166
2023-09-04 07:48:53.274850: Current learning rate: backbone 0.00048416, others 0.00048416
2023-09-04 07:48:53.277323: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 07:49:54.311191: finished training epoch 166
2023-09-04 07:49:54.351635: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 07:49:54.354487: The split file contains 1 splits.
2023-09-04 07:49:54.356065: Desired fold for training: 0
2023-09-04 07:49:54.357546: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 07:55:32.056205: dsc: 91.10%
2023-09-04 07:55:32.058544: miou: 83.65%
2023-09-04 07:55:32.060546: acc: 95.53%, sen: 90.86%, spe: 97.10%
2023-09-04 07:55:32.062690: current best miou: 0.8422144348184231 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 07:55:32.064620: current best dsc: 0.9143500549125113 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 07:55:32.066573: finished real validation
2023-09-04 07:55:36.437641: train_loss -1.4399
2023-09-04 07:55:36.440004: val_loss -1.0163
2023-09-04 07:55:36.441986: Pseudo dice [0.9125]
2023-09-04 07:55:36.443754: Epoch time: 403.17 s
2023-09-04 07:55:37.554742: 
2023-09-04 07:55:37.556895: Epoch 167
2023-09-04 07:55:37.558688: Current learning rate: backbone 0.0004809, others 0.0004809
2023-09-04 07:55:37.560928: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 07:56:38.572236: finished training epoch 167
2023-09-04 07:56:38.602105: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 07:56:38.605148: The split file contains 1 splits.
2023-09-04 07:56:38.607348: Desired fold for training: 0
2023-09-04 07:56:38.609352: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 08:02:29.543466: dsc: 91.04%
2023-09-04 08:02:29.545746: miou: 83.56%
2023-09-04 08:02:29.547582: acc: 95.50%, sen: 90.87%, spe: 97.06%
2023-09-04 08:02:29.549847: current best miou: 0.8422144348184231 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 08:02:29.551822: current best dsc: 0.9143500549125113 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 08:02:29.553571: finished real validation
2023-09-04 08:02:33.934218: train_loss -1.4394
2023-09-04 08:02:33.936278: val_loss -1.0043
2023-09-04 08:02:33.938095: Pseudo dice [0.91]
2023-09-04 08:02:33.939759: Epoch time: 416.38 s
2023-09-04 08:02:35.089399: 
2023-09-04 08:02:35.091515: Epoch 168
2023-09-04 08:02:35.093594: Current learning rate: backbone 0.00047765, others 0.00047765
2023-09-04 08:02:35.095979: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 08:03:36.206398: finished training epoch 168
2023-09-04 08:03:36.245382: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 08:03:36.248256: The split file contains 1 splits.
2023-09-04 08:03:36.250197: Desired fold for training: 0
2023-09-04 08:03:36.252056: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 08:08:53.503660: dsc: 91.07%
2023-09-04 08:08:53.505818: miou: 83.61%
2023-09-04 08:08:53.507380: acc: 95.52%, sen: 90.85%, spe: 97.09%
2023-09-04 08:08:53.509248: current best miou: 0.8422144348184231 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 08:08:53.510947: current best dsc: 0.9143500549125113 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 08:08:53.512630: finished real validation
2023-09-04 08:08:57.892768: train_loss -1.4398
2023-09-04 08:08:57.895437: val_loss -1.0322
2023-09-04 08:08:57.897756: Pseudo dice [0.9133]
2023-09-04 08:08:57.899707: Epoch time: 382.8 s
2023-09-04 08:08:59.044447: 
2023-09-04 08:08:59.046894: Epoch 169
2023-09-04 08:08:59.049006: Current learning rate: backbone 0.00047439, others 0.00047439
2023-09-04 08:08:59.051266: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 08:10:00.050941: finished training epoch 169
2023-09-04 08:10:00.094590: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 08:10:00.098976: The split file contains 1 splits.
2023-09-04 08:10:00.101089: Desired fold for training: 0
2023-09-04 08:10:00.103261: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 08:15:11.450918: dsc: 90.99%
2023-09-04 08:15:11.453030: miou: 83.48%
2023-09-04 08:15:11.454588: acc: 95.47%, sen: 90.98%, spe: 96.98%
2023-09-04 08:15:11.456714: current best miou: 0.8422144348184231 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 08:15:11.458481: current best dsc: 0.9143500549125113 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 08:15:11.460371: finished real validation
2023-09-04 08:15:15.841175: train_loss -1.4394
2023-09-04 08:15:15.844307: val_loss -0.9934
2023-09-04 08:15:15.847055: Pseudo dice [0.9084]
2023-09-04 08:15:15.849595: Epoch time: 376.8 s
2023-09-04 08:15:18.661761: 
2023-09-04 08:15:18.663657: Epoch 170
2023-09-04 08:15:18.665305: Current learning rate: backbone 0.00047113, others 0.00047113
2023-09-04 08:15:18.667603: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 08:16:19.702557: finished training epoch 170
2023-09-04 08:16:19.732381: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 08:16:19.736181: The split file contains 1 splits.
2023-09-04 08:16:19.738574: Desired fold for training: 0
2023-09-04 08:16:19.740680: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 08:21:34.624625: dsc: 90.92%
2023-09-04 08:21:34.627136: miou: 83.35%
2023-09-04 08:21:34.628814: acc: 95.46%, sen: 90.42%, spe: 97.15%
2023-09-04 08:21:34.630930: current best miou: 0.8422144348184231 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 08:21:34.632515: current best dsc: 0.9143500549125113 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 08:21:34.634451: finished real validation
2023-09-04 08:21:39.003138: train_loss -1.4397
2023-09-04 08:21:39.005246: val_loss -1.0044
2023-09-04 08:21:39.007092: Pseudo dice [0.9104]
2023-09-04 08:21:39.008755: Epoch time: 380.34 s
2023-09-04 08:21:40.155864: 
2023-09-04 08:21:40.158139: Epoch 171
2023-09-04 08:21:40.159802: Current learning rate: backbone 0.00046787, others 0.00046787
2023-09-04 08:21:40.161758: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 08:22:41.300941: finished training epoch 171
2023-09-04 08:22:41.331201: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 08:22:41.333812: The split file contains 1 splits.
2023-09-04 08:22:41.335505: Desired fold for training: 0
2023-09-04 08:22:41.337106: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 08:28:10.341439: dsc: 90.98%
2023-09-04 08:28:10.343785: miou: 83.46%
2023-09-04 08:28:10.345556: acc: 95.49%, sen: 90.50%, spe: 97.17%
2023-09-04 08:28:10.347674: current best miou: 0.8422144348184231 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 08:28:10.349818: current best dsc: 0.9143500549125113 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 08:28:10.351890: finished real validation
2023-09-04 08:28:14.738302: train_loss -1.4398
2023-09-04 08:28:14.740454: val_loss -1.0273
2023-09-04 08:28:14.742716: Pseudo dice [0.9131]
2023-09-04 08:28:14.744680: Epoch time: 394.58 s
2023-09-04 08:28:15.882591: 
2023-09-04 08:28:15.884583: Epoch 172
2023-09-04 08:28:15.886258: Current learning rate: backbone 0.0004646, others 0.0004646
2023-09-04 08:28:15.888293: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 08:29:16.969802: finished training epoch 172
2023-09-04 08:29:17.000159: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 08:29:17.002948: The split file contains 1 splits.
2023-09-04 08:29:17.004650: Desired fold for training: 0
2023-09-04 08:29:17.006354: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 08:34:30.376928: dsc: 90.98%
2023-09-04 08:34:30.379036: miou: 83.45%
2023-09-04 08:34:30.380656: acc: 95.46%, sen: 90.95%, spe: 96.98%
2023-09-04 08:34:30.382540: current best miou: 0.8422144348184231 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 08:34:30.384444: current best dsc: 0.9143500549125113 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 08:34:30.386327: finished real validation
2023-09-04 08:34:34.779647: train_loss -1.4393
2023-09-04 08:34:34.781847: val_loss -1.0333
2023-09-04 08:34:34.783753: Pseudo dice [0.9134]
2023-09-04 08:34:34.785434: Epoch time: 378.9 s
2023-09-04 08:34:35.941812: 
2023-09-04 08:34:35.944101: Epoch 173
2023-09-04 08:34:35.946014: Current learning rate: backbone 0.00046133, others 0.00046133
2023-09-04 08:34:35.948210: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 08:35:37.476707: finished training epoch 173
2023-09-04 08:35:37.506021: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 08:35:37.509453: The split file contains 1 splits.
2023-09-04 08:35:37.511801: Desired fold for training: 0
2023-09-04 08:35:37.513957: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 08:40:44.118523: dsc: 90.98%
2023-09-04 08:40:44.121085: miou: 83.45%
2023-09-04 08:40:44.122908: acc: 95.46%, sen: 90.96%, spe: 96.97%
2023-09-04 08:40:44.125046: current best miou: 0.8422144348184231 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 08:40:44.126696: current best dsc: 0.9143500549125113 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 08:40:44.128566: finished real validation
2023-09-04 08:40:48.518507: train_loss -1.4399
2023-09-04 08:40:48.520709: val_loss -1.0025
2023-09-04 08:40:48.522729: Pseudo dice [0.9104]
2023-09-04 08:40:48.524419: Epoch time: 372.58 s
2023-09-04 08:40:49.714248: 
2023-09-04 08:40:49.716213: Epoch 174
2023-09-04 08:40:49.717908: Current learning rate: backbone 0.00045806, others 0.00045806
2023-09-04 08:40:49.720103: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 08:41:51.036406: finished training epoch 174
2023-09-04 08:41:51.065325: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 08:41:51.067961: The split file contains 1 splits.
2023-09-04 08:41:51.070065: Desired fold for training: 0
2023-09-04 08:41:51.071747: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 08:47:08.296725: dsc: 90.93%
2023-09-04 08:47:08.298960: miou: 83.36%
2023-09-04 08:47:08.300990: acc: 95.45%, sen: 90.59%, spe: 97.09%
2023-09-04 08:47:08.303214: current best miou: 0.8422144348184231 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 08:47:08.305073: current best dsc: 0.9143500549125113 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 08:47:08.306858: finished real validation
2023-09-04 08:47:12.687185: train_loss -1.4398
2023-09-04 08:47:12.689581: val_loss -0.9988
2023-09-04 08:47:12.691729: Pseudo dice [0.9103]
2023-09-04 08:47:12.693473: Epoch time: 382.97 s
2023-09-04 08:47:13.826029: 
2023-09-04 08:47:13.828322: Epoch 175
2023-09-04 08:47:13.830565: Current learning rate: backbone 0.00045479, others 0.00045479
2023-09-04 08:47:13.833065: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 08:48:15.424267: finished training epoch 175
2023-09-04 08:48:15.454773: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 08:48:15.458491: The split file contains 1 splits.
2023-09-04 08:48:15.460782: Desired fold for training: 0
2023-09-04 08:48:15.462889: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 08:53:24.614945: dsc: 91.00%
2023-09-04 08:53:24.617088: miou: 83.49%
2023-09-04 08:53:24.618689: acc: 95.50%, sen: 90.52%, spe: 97.17%
2023-09-04 08:53:24.620828: current best miou: 0.8422144348184231 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 08:53:24.622440: current best dsc: 0.9143500549125113 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 08:53:24.623987: finished real validation
2023-09-04 08:53:29.005573: train_loss -1.4395
2023-09-04 08:53:29.007844: val_loss -1.0111
2023-09-04 08:53:29.009848: Pseudo dice [0.9114]
2023-09-04 08:53:29.011662: Epoch time: 375.18 s
2023-09-04 08:53:30.170594: 
2023-09-04 08:53:30.172647: Epoch 176
2023-09-04 08:53:30.174263: Current learning rate: backbone 0.00045151, others 0.00045151
2023-09-04 08:53:30.176221: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 08:54:31.257840: finished training epoch 176
2023-09-04 08:54:31.287594: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 08:54:31.290191: The split file contains 1 splits.
2023-09-04 08:54:31.292448: Desired fold for training: 0
2023-09-04 08:54:31.294311: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 08:59:42.194397: dsc: 90.98%
2023-09-04 08:59:42.196670: miou: 83.45%
2023-09-04 08:59:42.198362: acc: 95.49%, sen: 90.45%, spe: 97.18%
2023-09-04 08:59:42.200347: current best miou: 0.8422144348184231 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 08:59:42.202134: current best dsc: 0.9143500549125113 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 08:59:42.203762: finished real validation
2023-09-04 08:59:46.596263: train_loss -1.4404
2023-09-04 08:59:46.598463: val_loss -1.0305
2023-09-04 08:59:46.600497: Pseudo dice [0.9152]
2023-09-04 08:59:46.602222: Epoch time: 376.43 s
2023-09-04 08:59:47.750313: 
2023-09-04 08:59:47.752580: Epoch 177
2023-09-04 08:59:47.754657: Current learning rate: backbone 0.00044823, others 0.00044823
2023-09-04 08:59:47.757284: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 09:00:48.840784: finished training epoch 177
2023-09-04 09:00:48.870140: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 09:00:48.872818: The split file contains 1 splits.
2023-09-04 09:00:48.874675: Desired fold for training: 0
2023-09-04 09:00:48.876300: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 09:06:15.638469: dsc: 90.98%
2023-09-04 09:06:15.640671: miou: 83.45%
2023-09-04 09:06:15.642379: acc: 95.48%, sen: 90.60%, spe: 97.12%
2023-09-04 09:06:15.644304: current best miou: 0.8422144348184231 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 09:06:15.646093: current best dsc: 0.9143500549125113 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 09:06:15.647818: finished real validation
2023-09-04 09:06:20.034281: train_loss -1.4399
2023-09-04 09:06:20.036428: val_loss -1.0211
2023-09-04 09:06:20.038303: Pseudo dice [0.9131]
2023-09-04 09:06:20.039985: Epoch time: 392.29 s
2023-09-04 09:06:21.186928: 
2023-09-04 09:06:21.189041: Epoch 178
2023-09-04 09:06:21.190807: Current learning rate: backbone 0.00044495, others 0.00044495
2023-09-04 09:06:21.192911: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 09:07:22.268115: finished training epoch 178
2023-09-04 09:07:22.297421: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 09:07:22.300009: The split file contains 1 splits.
2023-09-04 09:07:22.301718: Desired fold for training: 0
2023-09-04 09:07:22.303346: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 09:12:32.335387: dsc: 91.04%
2023-09-04 09:12:32.337415: miou: 83.55%
2023-09-04 09:12:32.339362: acc: 95.50%, sen: 90.84%, spe: 97.07%
2023-09-04 09:12:32.341594: current best miou: 0.8422144348184231 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 09:12:32.343471: current best dsc: 0.9143500549125113 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 09:12:32.345310: finished real validation
2023-09-04 09:12:36.731333: train_loss -1.4396
2023-09-04 09:12:36.733713: val_loss -1.0021
2023-09-04 09:12:36.735805: Pseudo dice [0.9101]
2023-09-04 09:12:36.737822: Epoch time: 375.55 s
2023-09-04 09:12:37.879277: 
2023-09-04 09:12:37.881410: Epoch 179
2023-09-04 09:12:37.883273: Current learning rate: backbone 0.00044167, others 0.00044167
2023-09-04 09:12:37.885503: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 09:13:38.911645: finished training epoch 179
2023-09-04 09:13:38.940474: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 09:13:38.943756: The split file contains 1 splits.
2023-09-04 09:13:38.945391: Desired fold for training: 0
2023-09-04 09:13:38.946931: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 09:18:52.864011: dsc: 90.97%
2023-09-04 09:18:52.865973: miou: 83.44%
2023-09-04 09:18:52.867532: acc: 95.47%, sen: 90.68%, spe: 97.08%
2023-09-04 09:18:52.869472: current best miou: 0.8422144348184231 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 09:18:52.871029: current best dsc: 0.9143500549125113 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 09:18:52.872510: finished real validation
2023-09-04 09:18:57.262824: train_loss -1.4406
2023-09-04 09:18:57.264989: val_loss -0.9986
2023-09-04 09:18:57.266829: Pseudo dice [0.9085]
2023-09-04 09:18:57.268722: Epoch time: 379.38 s
2023-09-04 09:18:59.946959: 
2023-09-04 09:18:59.948853: Epoch 180
2023-09-04 09:18:59.950559: Current learning rate: backbone 0.00043838, others 0.00043838
2023-09-04 09:18:59.952658: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 09:20:01.037364: finished training epoch 180
2023-09-04 09:20:01.067425: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 09:20:01.069826: The split file contains 1 splits.
2023-09-04 09:20:01.071481: Desired fold for training: 0
2023-09-04 09:20:01.073089: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 09:25:14.677888: dsc: 91.08%
2023-09-04 09:25:14.680865: miou: 83.61%
2023-09-04 09:25:14.682766: acc: 95.55%, sen: 90.35%, spe: 97.29%
2023-09-04 09:25:14.684944: current best miou: 0.8422144348184231 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 09:25:14.686687: current best dsc: 0.9143500549125113 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 09:25:14.688630: finished real validation
2023-09-04 09:25:19.071605: train_loss -1.44
2023-09-04 09:25:19.073902: val_loss -0.993
2023-09-04 09:25:19.075989: Pseudo dice [0.9088]
2023-09-04 09:25:19.077899: Epoch time: 379.13 s
2023-09-04 09:25:20.237253: 
2023-09-04 09:25:20.239392: Epoch 181
2023-09-04 09:25:20.241146: Current learning rate: backbone 0.00043509, others 0.00043509
2023-09-04 09:25:20.243144: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 09:26:21.363761: finished training epoch 181
2023-09-04 09:26:21.394626: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 09:26:21.397281: The split file contains 1 splits.
2023-09-04 09:26:21.399022: Desired fold for training: 0
2023-09-04 09:26:21.400911: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 09:31:45.831403: dsc: 91.17%
2023-09-04 09:31:45.833526: miou: 83.77%
2023-09-04 09:31:45.835695: acc: 95.58%, sen: 90.77%, spe: 97.19%
2023-09-04 09:31:45.838587: current best miou: 0.8422144348184231 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 09:31:45.840598: current best dsc: 0.9143500549125113 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 09:31:45.842262: finished real validation
2023-09-04 09:31:50.228139: train_loss -1.4406
2023-09-04 09:31:50.230428: val_loss -1.0081
2023-09-04 09:31:50.232449: Pseudo dice [0.9098]
2023-09-04 09:31:50.234115: Epoch time: 389.99 s
2023-09-04 09:31:51.358925: 
2023-09-04 09:31:51.360991: Epoch 182
2023-09-04 09:31:51.362660: Current learning rate: backbone 0.0004318, others 0.0004318
2023-09-04 09:31:51.365030: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 09:32:52.496857: finished training epoch 182
2023-09-04 09:32:52.526378: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 09:32:52.529952: The split file contains 1 splits.
2023-09-04 09:32:52.532116: Desired fold for training: 0
2023-09-04 09:32:52.534178: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 09:38:03.785995: dsc: 90.97%
2023-09-04 09:38:03.788065: miou: 83.43%
2023-09-04 09:38:03.789901: acc: 95.47%, sen: 90.80%, spe: 97.03%
2023-09-04 09:38:03.792230: current best miou: 0.8422144348184231 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 09:38:03.794225: current best dsc: 0.9143500549125113 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 09:38:03.796223: finished real validation
2023-09-04 09:38:08.183501: train_loss -1.4411
2023-09-04 09:38:08.185820: val_loss -0.9746
2023-09-04 09:38:08.187905: Pseudo dice [0.9083]
2023-09-04 09:38:08.189766: Epoch time: 376.83 s
2023-09-04 09:38:09.334658: 
2023-09-04 09:38:09.336704: Epoch 183
2023-09-04 09:38:09.338731: Current learning rate: backbone 0.00042851, others 0.00042851
2023-09-04 09:38:09.341029: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 09:39:10.348274: finished training epoch 183
2023-09-04 09:39:10.381696: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 09:39:10.384552: The split file contains 1 splits.
2023-09-04 09:39:10.386420: Desired fold for training: 0
2023-09-04 09:39:10.388084: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 09:44:36.461656: dsc: 91.12%
2023-09-04 09:44:36.463901: miou: 83.69%
2023-09-04 09:44:36.465680: acc: 95.53%, sen: 91.23%, spe: 96.97%
2023-09-04 09:44:36.467860: current best miou: 0.8422144348184231 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 09:44:36.469817: current best dsc: 0.9143500549125113 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 09:44:36.471552: finished real validation
2023-09-04 09:44:40.859944: train_loss -1.4407
2023-09-04 09:44:40.862189: val_loss -1.0091
2023-09-04 09:44:40.864111: Pseudo dice [0.9129]
2023-09-04 09:44:40.865911: Epoch time: 391.53 s
2023-09-04 09:44:41.999659: 
2023-09-04 09:44:42.002300: Epoch 184
2023-09-04 09:44:42.004255: Current learning rate: backbone 0.00042521, others 0.00042521
2023-09-04 09:44:42.006518: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 09:45:43.046869: finished training epoch 184
2023-09-04 09:45:43.075773: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 09:45:43.078456: The split file contains 1 splits.
2023-09-04 09:45:43.080142: Desired fold for training: 0
2023-09-04 09:45:43.081719: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 09:50:54.997720: dsc: 91.10%
2023-09-04 09:50:54.999789: miou: 83.65%
2023-09-04 09:50:55.001519: acc: 95.52%, sen: 91.10%, spe: 97.01%
2023-09-04 09:50:55.004315: current best miou: 0.8422144348184231 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 09:50:55.006451: current best dsc: 0.9143500549125113 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 09:50:55.008428: finished real validation
2023-09-04 09:50:59.402430: train_loss -1.4401
2023-09-04 09:50:59.404838: val_loss -0.9927
2023-09-04 09:50:59.407129: Pseudo dice [0.9101]
2023-09-04 09:50:59.409236: Epoch time: 377.4 s
2023-09-04 09:51:00.550721: 
2023-09-04 09:51:00.552707: Epoch 185
2023-09-04 09:51:00.554291: Current learning rate: backbone 0.00042191, others 0.00042191
2023-09-04 09:51:00.556269: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 09:52:01.544671: finished training epoch 185
2023-09-04 09:52:01.585029: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 09:52:01.588118: The split file contains 1 splits.
2023-09-04 09:52:01.589790: Desired fold for training: 0
2023-09-04 09:52:01.591531: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 09:57:16.748609: dsc: 91.07%
2023-09-04 09:57:16.751021: miou: 83.61%
2023-09-04 09:57:16.752800: acc: 95.54%, sen: 90.51%, spe: 97.23%
2023-09-04 09:57:16.754920: current best miou: 0.8422144348184231 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 09:57:16.756743: current best dsc: 0.9143500549125113 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 09:57:16.758888: finished real validation
2023-09-04 09:57:21.149466: train_loss -1.4409
2023-09-04 09:57:21.151659: val_loss -0.9326
2023-09-04 09:57:21.153770: Pseudo dice [0.9028]
2023-09-04 09:57:21.155732: Epoch time: 380.6 s
2023-09-04 09:57:22.303707: 
2023-09-04 09:57:22.306054: Epoch 186
2023-09-04 09:57:22.308270: Current learning rate: backbone 0.00041861, others 0.00041861
2023-09-04 09:57:22.310432: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 09:58:23.619220: finished training epoch 186
2023-09-04 09:58:23.665964: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 09:58:23.668607: The split file contains 1 splits.
2023-09-04 09:58:23.670443: Desired fold for training: 0
2023-09-04 09:58:23.672481: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 10:03:33.483631: dsc: 91.06%
2023-09-04 10:03:33.485898: miou: 83.59%
2023-09-04 10:03:33.487602: acc: 95.51%, sen: 91.01%, spe: 97.02%
2023-09-04 10:03:33.489764: current best miou: 0.8422144348184231 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 10:03:33.491502: current best dsc: 0.9143500549125113 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 10:03:33.493117: finished real validation
2023-09-04 10:03:37.874170: train_loss -1.4408
2023-09-04 10:03:37.876541: val_loss -1.0214
2023-09-04 10:03:37.878664: Pseudo dice [0.9136]
2023-09-04 10:03:37.880651: Epoch time: 375.57 s
2023-09-04 10:03:39.036233: 
2023-09-04 10:03:39.038509: Epoch 187
2023-09-04 10:03:39.040369: Current learning rate: backbone 0.0004153, others 0.0004153
2023-09-04 10:03:39.042627: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 10:04:40.019603: finished training epoch 187
2023-09-04 10:04:40.070026: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 10:04:40.077685: The split file contains 1 splits.
2023-09-04 10:04:40.079685: Desired fold for training: 0
2023-09-04 10:04:40.081492: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 10:09:49.948414: dsc: 90.93%
2023-09-04 10:09:49.950871: miou: 83.37%
2023-09-04 10:09:49.952961: acc: 95.45%, sen: 90.69%, spe: 97.05%
2023-09-04 10:09:49.955237: current best miou: 0.8422144348184231 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 10:09:49.957176: current best dsc: 0.9143500549125113 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 10:09:49.958840: finished real validation
2023-09-04 10:09:54.325410: train_loss -1.441
2023-09-04 10:09:54.327703: val_loss -1.0142
2023-09-04 10:09:54.329769: Pseudo dice [0.9111]
2023-09-04 10:09:54.331567: Epoch time: 375.29 s
2023-09-04 10:09:55.474611: 
2023-09-04 10:09:55.476991: Epoch 188
2023-09-04 10:09:55.478914: Current learning rate: backbone 0.00041199, others 0.00041199
2023-09-04 10:09:55.481204: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 10:10:56.555303: finished training epoch 188
2023-09-04 10:10:56.610839: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 10:10:56.613820: The split file contains 1 splits.
2023-09-04 10:10:56.615562: Desired fold for training: 0
2023-09-04 10:10:56.617235: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 10:16:06.001693: dsc: 91.07%
2023-09-04 10:16:06.004090: miou: 83.60%
2023-09-04 10:16:06.006147: acc: 95.51%, sen: 91.10%, spe: 96.98%
2023-09-04 10:16:06.008530: current best miou: 0.8422144348184231 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 10:16:06.010376: current best dsc: 0.9143500549125113 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 10:16:06.012177: finished real validation
2023-09-04 10:16:10.398695: train_loss -1.4411
2023-09-04 10:16:10.401230: val_loss -0.987
2023-09-04 10:16:10.403407: Pseudo dice [0.9092]
2023-09-04 10:16:10.405473: Epoch time: 374.93 s
2023-09-04 10:16:11.553755: 
2023-09-04 10:16:11.555763: Epoch 189
2023-09-04 10:16:11.557682: Current learning rate: backbone 0.00040868, others 0.00040868
2023-09-04 10:16:11.559642: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 10:17:12.542222: finished training epoch 189
2023-09-04 10:17:12.571945: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 10:17:12.574545: The split file contains 1 splits.
2023-09-04 10:17:12.576266: Desired fold for training: 0
2023-09-04 10:17:12.577933: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 10:22:20.045897: dsc: 91.02%
2023-09-04 10:22:20.048385: miou: 83.53%
2023-09-04 10:22:20.050715: acc: 95.48%, sen: 91.14%, spe: 96.94%
2023-09-04 10:22:20.053290: current best miou: 0.8422144348184231 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 10:22:20.055242: current best dsc: 0.9143500549125113 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 10:22:20.057406: finished real validation
2023-09-04 10:22:24.451982: train_loss -1.4414
2023-09-04 10:22:24.454446: val_loss -0.979
2023-09-04 10:22:24.456585: Pseudo dice [0.9092]
2023-09-04 10:22:24.458552: Epoch time: 372.9 s
2023-09-04 10:22:27.135548: 
2023-09-04 10:22:27.137703: Epoch 190
2023-09-04 10:22:27.139544: Current learning rate: backbone 0.00040536, others 0.00040536
2023-09-04 10:22:27.141665: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 10:23:28.249615: finished training epoch 190
2023-09-04 10:23:28.293056: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 10:23:28.295954: The split file contains 1 splits.
2023-09-04 10:23:28.298729: Desired fold for training: 0
2023-09-04 10:23:28.300542: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 10:28:47.813906: dsc: 91.08%
2023-09-04 10:28:47.816229: miou: 83.61%
2023-09-04 10:28:47.818120: acc: 95.52%, sen: 90.91%, spe: 97.07%
2023-09-04 10:28:47.820246: current best miou: 0.8422144348184231 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 10:28:47.822098: current best dsc: 0.9143500549125113 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 10:28:47.823850: finished real validation
2023-09-04 10:28:52.248432: train_loss -1.441
2023-09-04 10:28:52.250708: val_loss -1.035
2023-09-04 10:28:52.252650: Pseudo dice [0.9122]
2023-09-04 10:28:52.254421: Epoch time: 385.11 s
2023-09-04 10:28:53.389084: 
2023-09-04 10:28:53.391605: Epoch 191
2023-09-04 10:28:53.393405: Current learning rate: backbone 0.00040205, others 0.00040205
2023-09-04 10:28:53.395394: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 10:29:55.214551: finished training epoch 191
2023-09-04 10:29:55.246670: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 10:29:55.249518: The split file contains 1 splits.
2023-09-04 10:29:55.251312: Desired fold for training: 0
2023-09-04 10:29:55.253057: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 10:35:41.948707: dsc: 91.07%
2023-09-04 10:35:41.951014: miou: 83.61%
2023-09-04 10:35:41.952866: acc: 95.52%, sen: 90.92%, spe: 97.06%
2023-09-04 10:35:41.954800: current best miou: 0.8422144348184231 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 10:35:41.956644: current best dsc: 0.9143500549125113 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 10:35:41.958376: finished real validation
2023-09-04 10:35:46.359423: train_loss -1.4412
2023-09-04 10:35:46.361933: val_loss -1.0165
2023-09-04 10:35:46.364043: Pseudo dice [0.9121]
2023-09-04 10:35:46.365782: Epoch time: 412.97 s
2023-09-04 10:35:47.521686: 
2023-09-04 10:35:47.523828: Epoch 192
2023-09-04 10:35:47.525921: Current learning rate: backbone 0.00039872, others 0.00039872
2023-09-04 10:35:47.528339: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 10:36:48.625941: finished training epoch 192
2023-09-04 10:36:48.676970: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 10:36:48.679893: The split file contains 1 splits.
2023-09-04 10:36:48.681941: Desired fold for training: 0
2023-09-04 10:36:48.683883: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 10:42:06.455775: dsc: 91.14%
2023-09-04 10:42:06.457945: miou: 83.72%
2023-09-04 10:42:06.459746: acc: 95.53%, sen: 91.30%, spe: 96.96%
2023-09-04 10:42:06.461866: current best miou: 0.8422144348184231 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 10:42:06.463893: current best dsc: 0.9143500549125113 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 10:42:06.465631: finished real validation
2023-09-04 10:42:10.857839: train_loss -1.4414
2023-09-04 10:42:10.860032: val_loss -1.0217
2023-09-04 10:42:10.862002: Pseudo dice [0.9157]
2023-09-04 10:42:10.863801: Epoch time: 383.34 s
2023-09-04 10:42:12.028115: 
2023-09-04 10:42:12.030456: Epoch 193
2023-09-04 10:42:12.032450: Current learning rate: backbone 0.0003954, others 0.0003954
2023-09-04 10:42:12.034824: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 10:43:13.168712: finished training epoch 193
2023-09-04 10:43:13.211006: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 10:43:13.213822: The split file contains 1 splits.
2023-09-04 10:43:13.215837: Desired fold for training: 0
2023-09-04 10:43:13.217912: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 10:48:26.712021: dsc: 91.00%
2023-09-04 10:48:26.714385: miou: 83.48%
2023-09-04 10:48:26.716598: acc: 95.50%, sen: 90.46%, spe: 97.19%
2023-09-04 10:48:26.718779: current best miou: 0.8422144348184231 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 10:48:26.720723: current best dsc: 0.9143500549125113 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 10:48:26.722525: finished real validation
2023-09-04 10:48:31.107376: train_loss -1.4417
2023-09-04 10:48:31.109896: val_loss -0.964
2023-09-04 10:48:31.111946: Pseudo dice [0.9085]
2023-09-04 10:48:31.113739: Epoch time: 379.08 s
2023-09-04 10:48:32.278434: 
2023-09-04 10:48:32.280553: Epoch 194
2023-09-04 10:48:32.282363: Current learning rate: backbone 0.00039207, others 0.00039207
2023-09-04 10:48:32.284441: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 10:49:33.276117: finished training epoch 194
2023-09-04 10:49:33.315655: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 10:49:33.318503: The split file contains 1 splits.
2023-09-04 10:49:33.320248: Desired fold for training: 0
2023-09-04 10:49:33.321932: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 10:54:43.529949: dsc: 91.06%
2023-09-04 10:54:43.532989: miou: 83.59%
2023-09-04 10:54:43.535300: acc: 95.52%, sen: 90.70%, spe: 97.14%
2023-09-04 10:54:43.537722: current best miou: 0.8422144348184231 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 10:54:43.539576: current best dsc: 0.9143500549125113 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 10:54:43.541635: finished real validation
2023-09-04 10:54:47.926789: train_loss -1.4413
2023-09-04 10:54:47.929361: val_loss -0.9987
2023-09-04 10:54:47.931572: Pseudo dice [0.9105]
2023-09-04 10:54:47.933596: Epoch time: 375.65 s
2023-09-04 10:54:49.157252: 
2023-09-04 10:54:49.159562: Epoch 195
2023-09-04 10:54:49.161418: Current learning rate: backbone 0.00038874, others 0.00038874
2023-09-04 10:54:49.163456: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 10:55:50.317475: finished training epoch 195
2023-09-04 10:55:50.355212: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 10:55:50.358179: The split file contains 1 splits.
2023-09-04 10:55:50.360046: Desired fold for training: 0
2023-09-04 10:55:50.361756: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 11:01:00.570172: dsc: 91.06%
2023-09-04 11:01:00.572392: miou: 83.58%
2023-09-04 11:01:00.574385: acc: 95.52%, sen: 90.67%, spe: 97.15%
2023-09-04 11:01:00.576576: current best miou: 0.8422144348184231 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 11:01:00.578395: current best dsc: 0.9143500549125113 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 11:01:00.580017: finished real validation
2023-09-04 11:01:04.963652: train_loss -1.4415
2023-09-04 11:01:04.965940: val_loss -0.983
2023-09-04 11:01:04.968192: Pseudo dice [0.9106]
2023-09-04 11:01:04.970220: Epoch time: 375.81 s
2023-09-04 11:01:06.126302: 
2023-09-04 11:01:06.128475: Epoch 196
2023-09-04 11:01:06.130256: Current learning rate: backbone 0.00038541, others 0.00038541
2023-09-04 11:01:06.132762: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 11:02:07.107793: finished training epoch 196
2023-09-04 11:02:07.137078: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 11:02:07.139932: The split file contains 1 splits.
2023-09-04 11:02:07.141848: Desired fold for training: 0
2023-09-04 11:02:07.144124: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 11:07:34.086880: dsc: 91.08%
2023-09-04 11:07:34.089018: miou: 83.62%
2023-09-04 11:07:34.090922: acc: 95.51%, sen: 91.08%, spe: 97.00%
2023-09-04 11:07:34.093491: current best miou: 0.8422144348184231 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 11:07:34.095284: current best dsc: 0.9143500549125113 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 11:07:34.097010: finished real validation
2023-09-04 11:07:38.484514: train_loss -1.4417
2023-09-04 11:07:38.486808: val_loss -1.018
2023-09-04 11:07:38.488950: Pseudo dice [0.9146]
2023-09-04 11:07:38.490727: Epoch time: 392.36 s
2023-09-04 11:07:39.650020: 
2023-09-04 11:07:39.652411: Epoch 197
2023-09-04 11:07:39.654268: Current learning rate: backbone 0.00038207, others 0.00038207
2023-09-04 11:07:39.656698: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 11:08:40.623983: finished training epoch 197
2023-09-04 11:08:40.700759: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 11:08:40.703674: The split file contains 1 splits.
2023-09-04 11:08:40.705384: Desired fold for training: 0
2023-09-04 11:08:40.707267: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 11:14:19.640073: dsc: 91.00%
2023-09-04 11:14:19.642462: miou: 83.49%
2023-09-04 11:14:19.644313: acc: 95.45%, sen: 91.37%, spe: 96.83%
2023-09-04 11:14:19.646508: current best miou: 0.8422144348184231 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 11:14:19.648584: current best dsc: 0.9143500549125113 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 11:14:19.650285: finished real validation
2023-09-04 11:14:24.040066: train_loss -1.4411
2023-09-04 11:14:24.042387: val_loss -0.9702
2023-09-04 11:14:24.044631: Pseudo dice [0.908]
2023-09-04 11:14:24.046521: Epoch time: 404.39 s
2023-09-04 11:14:25.205380: 
2023-09-04 11:14:25.207477: Epoch 198
2023-09-04 11:14:25.209356: Current learning rate: backbone 0.00037873, others 0.00037873
2023-09-04 11:14:25.211501: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 11:15:26.238151: finished training epoch 198
2023-09-04 11:15:26.267346: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 11:15:26.269957: The split file contains 1 splits.
2023-09-04 11:15:26.271776: Desired fold for training: 0
2023-09-04 11:15:26.273516: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 11:20:44.818646: dsc: 91.11%
2023-09-04 11:20:44.821111: miou: 83.68%
2023-09-04 11:20:44.822878: acc: 95.55%, sen: 90.64%, spe: 97.20%
2023-09-04 11:20:44.824915: current best miou: 0.8422144348184231 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 11:20:44.826840: current best dsc: 0.9143500549125113 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 11:20:44.828753: finished real validation
2023-09-04 11:20:49.218046: train_loss -1.4413
2023-09-04 11:20:49.220301: val_loss -1.0166
2023-09-04 11:20:49.222542: Pseudo dice [0.9113]
2023-09-04 11:20:49.224466: Epoch time: 384.01 s
2023-09-04 11:20:50.374097: 
2023-09-04 11:20:50.376330: Epoch 199
2023-09-04 11:20:50.378158: Current learning rate: backbone 0.00037539, others 0.00037539
2023-09-04 11:20:50.380491: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 11:21:51.397833: finished training epoch 199
2023-09-04 11:21:51.444695: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 11:21:51.447486: The split file contains 1 splits.
2023-09-04 11:21:51.449301: Desired fold for training: 0
2023-09-04 11:21:51.451206: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 11:27:13.152353: dsc: 90.97%
2023-09-04 11:27:13.154738: miou: 83.43%
2023-09-04 11:27:13.156777: acc: 95.45%, sen: 91.01%, spe: 96.95%
2023-09-04 11:27:13.159225: current best miou: 0.8422144348184231 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 11:27:13.160936: current best dsc: 0.9143500549125113 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 11:27:13.162622: finished real validation
2023-09-04 11:27:17.556623: train_loss -1.4421
2023-09-04 11:27:17.559193: val_loss -0.991
2023-09-04 11:27:17.561242: Pseudo dice [0.9095]
2023-09-04 11:27:17.563127: Epoch time: 387.18 s
2023-09-04 11:27:20.268704: 
2023-09-04 11:27:20.271158: Epoch 200
2023-09-04 11:27:20.273036: Current learning rate: backbone 0.00037204, others 0.00037204
2023-09-04 11:27:20.275200: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 11:28:21.229908: finished training epoch 200
2023-09-04 11:28:21.270130: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 11:28:21.273875: The split file contains 1 splits.
2023-09-04 11:28:21.275840: Desired fold for training: 0
2023-09-04 11:28:21.277579: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 11:33:33.575895: dsc: 91.16%
2023-09-04 11:33:33.578469: miou: 83.76%
2023-09-04 11:33:33.580431: acc: 95.58%, sen: 90.68%, spe: 97.22%
2023-09-04 11:33:33.583534: current best miou: 0.8422144348184231 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 11:33:33.585675: current best dsc: 0.9143500549125113 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 11:33:33.587556: finished real validation
2023-09-04 11:33:37.981157: train_loss -1.4417
2023-09-04 11:33:37.983643: val_loss -1.0065
2023-09-04 11:33:37.985829: Pseudo dice [0.9112]
2023-09-04 11:33:37.987808: Epoch time: 377.71 s
2023-09-04 11:33:39.154907: 
2023-09-04 11:33:39.157368: Epoch 201
2023-09-04 11:33:39.159459: Current learning rate: backbone 0.00036869, others 0.00036869
2023-09-04 11:33:39.162104: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 11:34:40.177803: finished training epoch 201
2023-09-04 11:34:40.208319: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 11:34:40.210970: The split file contains 1 splits.
2023-09-04 11:34:40.212848: Desired fold for training: 0
2023-09-04 11:34:40.214619: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 11:40:10.879137: dsc: 91.05%
2023-09-04 11:40:10.881671: miou: 83.57%
2023-09-04 11:40:10.883999: acc: 95.51%, sen: 90.77%, spe: 97.11%
2023-09-04 11:40:10.887033: current best miou: 0.8422144348184231 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 11:40:10.889212: current best dsc: 0.9143500549125113 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 11:40:10.891272: finished real validation
2023-09-04 11:40:15.284682: train_loss -1.4416
2023-09-04 11:40:15.287251: val_loss -0.9725
2023-09-04 11:40:15.289589: Pseudo dice [0.9088]
2023-09-04 11:40:15.291701: Epoch time: 396.13 s
2023-09-04 11:40:16.456882: 
2023-09-04 11:40:16.459201: Epoch 202
2023-09-04 11:40:16.461596: Current learning rate: backbone 0.00036534, others 0.00036534
2023-09-04 11:40:16.464331: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 11:41:17.808720: finished training epoch 202
2023-09-04 11:41:17.840751: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 11:41:17.844129: The split file contains 1 splits.
2023-09-04 11:41:17.846352: Desired fold for training: 0
2023-09-04 11:41:17.848237: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 11:46:28.319412: dsc: 91.17%
2023-09-04 11:46:28.322399: miou: 83.77%
2023-09-04 11:46:28.324320: acc: 95.55%, sen: 91.32%, spe: 96.97%
2023-09-04 11:46:28.326380: current best miou: 0.8422144348184231 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 11:46:28.328083: current best dsc: 0.9143500549125113 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 11:46:28.329819: finished real validation
2023-09-04 11:46:32.714355: train_loss -1.4422
2023-09-04 11:46:32.716477: val_loss -0.9905
2023-09-04 11:46:32.718429: Pseudo dice [0.9122]
2023-09-04 11:46:32.720206: Epoch time: 376.26 s
2023-09-04 11:46:33.867856: 
2023-09-04 11:46:33.870280: Epoch 203
2023-09-04 11:46:33.872490: Current learning rate: backbone 0.00036198, others 0.00036198
2023-09-04 11:46:33.874752: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 11:47:34.991612: finished training epoch 203
2023-09-04 11:47:35.021401: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 11:47:35.023972: The split file contains 1 splits.
2023-09-04 11:47:35.025794: Desired fold for training: 0
2023-09-04 11:47:35.027756: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 11:52:40.780917: dsc: 91.01%
2023-09-04 11:52:40.783472: miou: 83.50%
2023-09-04 11:52:40.785612: acc: 95.47%, sen: 91.07%, spe: 96.95%
2023-09-04 11:52:40.788327: current best miou: 0.8422144348184231 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 11:52:40.790474: current best dsc: 0.9143500549125113 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 11:52:40.792505: finished real validation
2023-09-04 11:52:45.182133: train_loss -1.4426
2023-09-04 11:52:45.184361: val_loss -0.9509
2023-09-04 11:52:45.186416: Pseudo dice [0.9084]
2023-09-04 11:52:45.188278: Epoch time: 371.32 s
2023-09-04 11:52:46.357336: 
2023-09-04 11:52:46.359930: Epoch 204
2023-09-04 11:52:46.361944: Current learning rate: backbone 0.00035862, others 0.00035862
2023-09-04 11:52:46.364052: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 11:53:47.322265: finished training epoch 204
2023-09-04 11:53:47.351258: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 11:53:47.356862: The split file contains 1 splits.
2023-09-04 11:53:47.359364: Desired fold for training: 0
2023-09-04 11:53:47.361578: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 11:59:00.223842: dsc: 91.09%
2023-09-04 11:59:00.226113: miou: 83.64%
2023-09-04 11:59:00.227932: acc: 95.53%, sen: 90.80%, spe: 97.12%
2023-09-04 11:59:00.229968: current best miou: 0.8422144348184231 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 11:59:00.231702: current best dsc: 0.9143500549125113 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 11:59:00.233529: finished real validation
2023-09-04 11:59:04.624352: train_loss -1.4426
2023-09-04 11:59:04.626687: val_loss -1.0103
2023-09-04 11:59:04.628741: Pseudo dice [0.9121]
2023-09-04 11:59:04.630607: Epoch time: 378.27 s
2023-09-04 11:59:05.785539: 
2023-09-04 11:59:05.788120: Epoch 205
2023-09-04 11:59:05.790154: Current learning rate: backbone 0.00035526, others 0.00035526
2023-09-04 11:59:05.792477: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 12:00:06.803427: finished training epoch 205
2023-09-04 12:00:06.834176: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 12:00:06.837165: The split file contains 1 splits.
2023-09-04 12:00:06.839100: Desired fold for training: 0
2023-09-04 12:00:06.840902: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 12:05:24.236940: dsc: 91.05%
2023-09-04 12:05:24.239286: miou: 83.57%
2023-09-04 12:05:24.241080: acc: 95.51%, sen: 90.78%, spe: 97.10%
2023-09-04 12:05:24.243287: current best miou: 0.8422144348184231 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 12:05:24.245204: current best dsc: 0.9143500549125113 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 12:05:24.247341: finished real validation
2023-09-04 12:05:28.630960: train_loss -1.4422
2023-09-04 12:05:28.633232: val_loss -0.9606
2023-09-04 12:05:28.635323: Pseudo dice [0.9098]
2023-09-04 12:05:28.637344: Epoch time: 382.85 s
2023-09-04 12:05:29.742886: 
2023-09-04 12:05:29.744881: Epoch 206
2023-09-04 12:05:29.747187: Current learning rate: backbone 0.00035189, others 0.00035189
2023-09-04 12:05:29.749558: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 12:06:30.894030: finished training epoch 206
2023-09-04 12:06:30.934647: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 12:06:30.937473: The split file contains 1 splits.
2023-09-04 12:06:30.939306: Desired fold for training: 0
2023-09-04 12:06:30.941107: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 12:11:35.943556: dsc: 91.06%
2023-09-04 12:11:35.945940: miou: 83.59%
2023-09-04 12:11:35.948187: acc: 95.51%, sen: 90.86%, spe: 97.08%
2023-09-04 12:11:35.950577: current best miou: 0.8422144348184231 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 12:11:35.952537: current best dsc: 0.9143500549125113 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 12:11:35.954511: finished real validation
2023-09-04 12:11:40.347645: train_loss -1.4426
2023-09-04 12:11:40.350040: val_loss -0.9947
2023-09-04 12:11:40.352104: Pseudo dice [0.911]
2023-09-04 12:11:40.354000: Epoch time: 370.61 s
2023-09-04 12:11:41.469526: 
2023-09-04 12:11:41.471734: Epoch 207
2023-09-04 12:11:41.473564: Current learning rate: backbone 0.00034852, others 0.00034852
2023-09-04 12:11:41.475682: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 12:12:42.545858: finished training epoch 207
2023-09-04 12:12:42.576209: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 12:12:42.579114: The split file contains 1 splits.
2023-09-04 12:12:42.581092: Desired fold for training: 0
2023-09-04 12:12:42.582952: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 12:17:50.068986: dsc: 91.05%
2023-09-04 12:17:50.071621: miou: 83.58%
2023-09-04 12:17:50.073936: acc: 95.51%, sen: 90.88%, spe: 97.06%
2023-09-04 12:17:50.076440: current best miou: 0.8422144348184231 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 12:17:50.078693: current best dsc: 0.9143500549125113 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 12:17:50.080859: finished real validation
2023-09-04 12:17:54.473695: train_loss -1.4425
2023-09-04 12:17:54.476214: val_loss -1.01
2023-09-04 12:17:54.478523: Pseudo dice [0.9144]
2023-09-04 12:17:54.480383: Epoch time: 373.01 s
2023-09-04 12:17:55.630236: 
2023-09-04 12:17:55.632492: Epoch 208
2023-09-04 12:17:55.634378: Current learning rate: backbone 0.00034514, others 0.00034514
2023-09-04 12:17:55.636516: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 12:18:56.676914: finished training epoch 208
2023-09-04 12:18:56.706217: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 12:18:56.709044: The split file contains 1 splits.
2023-09-04 12:18:56.711049: Desired fold for training: 0
2023-09-04 12:18:56.712985: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 12:24:29.198215: dsc: 91.09%
2023-09-04 12:24:29.200748: miou: 83.64%
2023-09-04 12:24:29.203067: acc: 95.52%, sen: 90.95%, spe: 97.06%
2023-09-04 12:24:29.205457: current best miou: 0.8422144348184231 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 12:24:29.207646: current best dsc: 0.9143500549125113 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 12:24:29.209935: finished real validation
2023-09-04 12:24:33.605631: train_loss -1.4428
2023-09-04 12:24:33.608237: val_loss -0.982
2023-09-04 12:24:33.610662: Pseudo dice [0.9089]
2023-09-04 12:24:33.612770: Epoch time: 397.98 s
2023-09-04 12:24:34.730889: 
2023-09-04 12:24:34.733191: Epoch 209
2023-09-04 12:24:34.735407: Current learning rate: backbone 0.00034177, others 0.00034177
2023-09-04 12:24:34.737852: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 12:25:35.801598: finished training epoch 209
2023-09-04 12:25:35.832268: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 12:25:35.835054: The split file contains 1 splits.
2023-09-04 12:25:35.837189: Desired fold for training: 0
2023-09-04 12:25:35.839108: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 12:31:06.434909: dsc: 90.98%
2023-09-04 12:31:06.437807: miou: 83.46%
2023-09-04 12:31:06.440128: acc: 95.47%, sen: 90.94%, spe: 96.99%
2023-09-04 12:31:06.442935: current best miou: 0.8422144348184231 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 12:31:06.445052: current best dsc: 0.9143500549125113 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 12:31:06.447908: finished real validation
2023-09-04 12:31:10.840807: train_loss -1.4429
2023-09-04 12:31:10.843415: val_loss -0.9848
2023-09-04 12:31:10.845713: Pseudo dice [0.9117]
2023-09-04 12:31:10.847862: Epoch time: 396.11 s
2023-09-04 12:31:13.523763: 
2023-09-04 12:31:13.526105: Epoch 210
2023-09-04 12:31:13.527977: Current learning rate: backbone 0.00033838, others 0.00033838
2023-09-04 12:31:13.530120: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 12:32:14.801405: finished training epoch 210
2023-09-04 12:32:14.841585: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 12:32:14.844816: The split file contains 1 splits.
2023-09-04 12:32:14.846920: Desired fold for training: 0
2023-09-04 12:32:14.848989: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 12:37:44.756893: dsc: 90.99%
2023-09-04 12:37:44.759593: miou: 83.47%
2023-09-04 12:37:44.761862: acc: 95.49%, sen: 90.65%, spe: 97.11%
2023-09-04 12:37:44.764005: current best miou: 0.8422144348184231 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 12:37:44.765831: current best dsc: 0.9143500549125113 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 12:37:44.767909: finished real validation
2023-09-04 12:37:49.167049: train_loss -1.4426
2023-09-04 12:37:49.169504: val_loss -0.9901
2023-09-04 12:37:49.171630: Pseudo dice [0.9105]
2023-09-04 12:37:49.173575: Epoch time: 395.64 s
2023-09-04 12:37:50.280903: 
2023-09-04 12:37:50.283030: Epoch 211
2023-09-04 12:37:50.285205: Current learning rate: backbone 0.000335, others 0.000335
2023-09-04 12:37:50.287825: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 12:38:51.302458: finished training epoch 211
2023-09-04 12:38:51.342241: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 12:38:51.345255: The split file contains 1 splits.
2023-09-04 12:38:51.346997: Desired fold for training: 0
2023-09-04 12:38:51.348701: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 12:44:04.366275: dsc: 90.97%
2023-09-04 12:44:04.368555: miou: 83.43%
2023-09-04 12:44:04.370566: acc: 95.46%, sen: 90.82%, spe: 97.02%
2023-09-04 12:44:04.373010: current best miou: 0.8422144348184231 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 12:44:04.374736: current best dsc: 0.9143500549125113 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 12:44:04.376649: finished real validation
2023-09-04 12:44:08.763949: train_loss -1.4431
2023-09-04 12:44:08.766250: val_loss -0.9797
2023-09-04 12:44:08.768607: Pseudo dice [0.9089]
2023-09-04 12:44:08.770737: Epoch time: 378.48 s
2023-09-04 12:44:09.871419: 
2023-09-04 12:44:09.874208: Epoch 212
2023-09-04 12:44:09.876324: Current learning rate: backbone 0.00033161, others 0.00033161
2023-09-04 12:44:09.878660: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 12:45:10.885065: finished training epoch 212
2023-09-04 12:45:10.916329: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 12:45:10.919302: The split file contains 1 splits.
2023-09-04 12:45:10.921237: Desired fold for training: 0
2023-09-04 12:45:10.923147: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 12:50:46.840824: dsc: 91.05%
2023-09-04 12:50:46.843212: miou: 83.57%
2023-09-04 12:50:46.845035: acc: 95.49%, sen: 91.13%, spe: 96.96%
2023-09-04 12:50:46.847853: current best miou: 0.8422144348184231 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 12:50:46.849769: current best dsc: 0.9143500549125113 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 12:50:46.851619: finished real validation
2023-09-04 12:50:51.244100: train_loss -1.4425
2023-09-04 12:50:51.246340: val_loss -1.0051
2023-09-04 12:50:51.248392: Pseudo dice [0.9134]
2023-09-04 12:50:51.250215: Epoch time: 401.37 s
2023-09-04 12:50:52.348904: 
2023-09-04 12:50:52.351158: Epoch 213
2023-09-04 12:50:52.353035: Current learning rate: backbone 0.00032821, others 0.00032821
2023-09-04 12:50:52.355399: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 12:51:53.678168: finished training epoch 213
2023-09-04 12:51:53.709627: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 12:51:53.712908: The split file contains 1 splits.
2023-09-04 12:51:53.715000: Desired fold for training: 0
2023-09-04 12:51:53.716966: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 12:57:37.045847: dsc: 91.01%
2023-09-04 12:57:37.048164: miou: 83.50%
2023-09-04 12:57:37.050015: acc: 95.47%, sen: 91.11%, spe: 96.94%
2023-09-04 12:57:37.052243: current best miou: 0.8422144348184231 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 12:57:37.054224: current best dsc: 0.9143500549125113 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 12:57:37.056203: finished real validation
2023-09-04 12:57:41.449380: train_loss -1.4427
2023-09-04 12:57:41.452033: val_loss -0.9823
2023-09-04 12:57:41.454162: Pseudo dice [0.9121]
2023-09-04 12:57:41.456254: Epoch time: 409.1 s
2023-09-04 12:57:42.582692: 
2023-09-04 12:57:42.585015: Epoch 214
2023-09-04 12:57:42.586937: Current learning rate: backbone 0.00032482, others 0.00032482
2023-09-04 12:57:42.589264: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 12:58:44.799483: finished training epoch 214
2023-09-04 12:58:44.832203: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 12:58:44.835229: The split file contains 1 splits.
2023-09-04 12:58:44.837126: Desired fold for training: 0
2023-09-04 12:58:44.839004: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 13:03:55.740882: dsc: 91.00%
2023-09-04 13:03:55.743207: miou: 83.49%
2023-09-04 13:03:55.745075: acc: 95.48%, sen: 90.97%, spe: 96.99%
2023-09-04 13:03:55.747220: current best miou: 0.8422144348184231 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 13:03:55.749054: current best dsc: 0.9143500549125113 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 13:03:55.750810: finished real validation
2023-09-04 13:04:00.142440: train_loss -1.4427
2023-09-04 13:04:00.145170: val_loss -1.0145
2023-09-04 13:04:00.147309: Pseudo dice [0.9126]
2023-09-04 13:04:00.149254: Epoch time: 377.56 s
2023-09-04 13:04:01.292158: 
2023-09-04 13:04:01.294529: Epoch 215
2023-09-04 13:04:01.296705: Current learning rate: backbone 0.00032142, others 0.00032142
2023-09-04 13:04:01.299099: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 13:05:02.353093: finished training epoch 215
2023-09-04 13:05:02.383688: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 13:05:02.386640: The split file contains 1 splits.
2023-09-04 13:05:02.388639: Desired fold for training: 0
2023-09-04 13:05:02.390474: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 13:10:32.906457: dsc: 91.07%
2023-09-04 13:10:32.909176: miou: 83.61%
2023-09-04 13:10:32.911278: acc: 95.50%, sen: 91.19%, spe: 96.95%
2023-09-04 13:10:32.913840: current best miou: 0.8422144348184231 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 13:10:32.915997: current best dsc: 0.9143500549125113 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 13:10:32.918033: finished real validation
2023-09-04 13:10:37.298774: train_loss -1.4432
2023-09-04 13:10:37.301275: val_loss -1.0051
2023-09-04 13:10:37.303389: Pseudo dice [0.9128]
2023-09-04 13:10:37.305272: Epoch time: 396.01 s
2023-09-04 13:10:38.415520: 
2023-09-04 13:10:38.418174: Epoch 216
2023-09-04 13:10:38.420702: Current learning rate: backbone 0.00031801, others 0.00031801
2023-09-04 13:10:38.423152: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 13:11:39.486459: finished training epoch 216
2023-09-04 13:11:39.533486: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 13:11:39.536198: The split file contains 1 splits.
2023-09-04 13:11:39.538052: Desired fold for training: 0
2023-09-04 13:11:39.539990: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 13:16:44.062846: dsc: 91.13%
2023-09-04 13:16:44.065500: miou: 83.71%
2023-09-04 13:16:44.067764: acc: 95.53%, sen: 91.22%, spe: 96.99%
2023-09-04 13:16:44.070442: current best miou: 0.8422144348184231 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 13:16:44.072456: current best dsc: 0.9143500549125113 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 13:16:44.074411: finished real validation
2023-09-04 13:16:48.478145: train_loss -1.4433
2023-09-04 13:16:48.480797: val_loss -0.9489
2023-09-04 13:16:48.483188: Pseudo dice [0.9078]
2023-09-04 13:16:48.485512: Epoch time: 370.06 s
2023-09-04 13:16:49.605648: 
2023-09-04 13:16:49.608450: Epoch 217
2023-09-04 13:16:49.610567: Current learning rate: backbone 0.0003146, others 0.0003146
2023-09-04 13:16:49.612841: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 13:17:50.584725: finished training epoch 217
2023-09-04 13:17:50.615261: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 13:17:50.617922: The split file contains 1 splits.
2023-09-04 13:17:50.619859: Desired fold for training: 0
2023-09-04 13:17:50.621804: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 13:22:59.923181: dsc: 91.02%
2023-09-04 13:22:59.925824: miou: 83.52%
2023-09-04 13:22:59.927851: acc: 95.49%, sen: 90.90%, spe: 97.03%
2023-09-04 13:22:59.930212: current best miou: 0.8422144348184231 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 13:22:59.932036: current best dsc: 0.9143500549125113 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 13:22:59.933780: finished real validation
2023-09-04 13:23:04.319696: train_loss -1.443
2023-09-04 13:23:04.321999: val_loss -0.9932
2023-09-04 13:23:04.324126: Pseudo dice [0.9116]
2023-09-04 13:23:04.326008: Epoch time: 374.72 s
2023-09-04 13:23:05.455669: 
2023-09-04 13:23:05.458797: Epoch 218
2023-09-04 13:23:05.462134: Current learning rate: backbone 0.00031119, others 0.00031119
2023-09-04 13:23:05.465303: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 13:24:06.451758: finished training epoch 218
2023-09-04 13:24:06.483459: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 13:24:06.486712: The split file contains 1 splits.
2023-09-04 13:24:06.488727: Desired fold for training: 0
2023-09-04 13:24:06.490641: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 13:29:18.100606: dsc: 91.07%
2023-09-04 13:29:18.103827: miou: 83.61%
2023-09-04 13:29:18.105809: acc: 95.51%, sen: 90.99%, spe: 97.03%
2023-09-04 13:29:18.108106: current best miou: 0.8422144348184231 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 13:29:18.110397: current best dsc: 0.9143500549125113 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 13:29:18.112435: finished real validation
2023-09-04 13:29:22.528764: train_loss -1.4432
2023-09-04 13:29:22.531355: val_loss -0.9603
2023-09-04 13:29:22.533537: Pseudo dice [0.9082]
2023-09-04 13:29:22.535806: Epoch time: 377.07 s
2023-09-04 13:29:23.679798: 
2023-09-04 13:29:23.682295: Epoch 219
2023-09-04 13:29:23.684511: Current learning rate: backbone 0.00030777, others 0.00030777
2023-09-04 13:29:23.687350: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 13:30:24.860171: finished training epoch 219
2023-09-04 13:30:24.890525: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 13:30:24.893724: The split file contains 1 splits.
2023-09-04 13:30:24.895943: Desired fold for training: 0
2023-09-04 13:30:24.897833: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 13:35:34.960703: dsc: 90.97%
2023-09-04 13:35:34.963271: miou: 83.43%
2023-09-04 13:35:34.965222: acc: 95.45%, sen: 91.04%, spe: 96.94%
2023-09-04 13:35:34.968190: current best miou: 0.8422144348184231 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 13:35:34.970160: current best dsc: 0.9143500549125113 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 13:35:34.972123: finished real validation
2023-09-04 13:35:39.360898: train_loss -1.4427
2023-09-04 13:35:39.363600: val_loss -0.9768
2023-09-04 13:35:39.366011: Pseudo dice [0.9105]
2023-09-04 13:35:39.368527: Epoch time: 375.68 s
2023-09-04 13:35:42.000180: 
2023-09-04 13:35:42.002561: Epoch 220
2023-09-04 13:35:42.004760: Current learning rate: backbone 0.00030435, others 0.00030435
2023-09-04 13:35:42.006996: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 13:36:43.066694: finished training epoch 220
2023-09-04 13:36:43.119861: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 13:36:43.122821: The split file contains 1 splits.
2023-09-04 13:36:43.124756: Desired fold for training: 0
2023-09-04 13:36:43.126823: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 13:42:16.803450: dsc: 91.07%
2023-09-04 13:42:16.806002: miou: 83.60%
2023-09-04 13:42:16.808064: acc: 95.50%, sen: 91.17%, spe: 96.96%
2023-09-04 13:42:16.810680: current best miou: 0.8422144348184231 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 13:42:16.812650: current best dsc: 0.9143500549125113 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 13:42:16.814819: finished real validation
2023-09-04 13:42:21.199084: train_loss -1.4433
2023-09-04 13:42:21.201518: val_loss -0.9751
2023-09-04 13:42:21.203608: Pseudo dice [0.9094]
2023-09-04 13:42:21.205516: Epoch time: 399.2 s
2023-09-04 13:42:22.313426: 
2023-09-04 13:42:22.316105: Epoch 221
2023-09-04 13:42:22.318165: Current learning rate: backbone 0.00030092, others 0.00030092
2023-09-04 13:42:22.320400: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 13:43:24.251682: finished training epoch 221
2023-09-04 13:43:24.295011: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 13:43:24.297767: The split file contains 1 splits.
2023-09-04 13:43:24.299746: Desired fold for training: 0
2023-09-04 13:43:24.301542: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 13:48:28.959586: dsc: 91.10%
2023-09-04 13:48:28.962662: miou: 83.65%
2023-09-04 13:48:28.965778: acc: 95.54%, sen: 90.77%, spe: 97.14%
2023-09-04 13:48:28.969020: current best miou: 0.8422144348184231 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 13:48:28.971240: current best dsc: 0.9143500549125113 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 13:48:28.973353: finished real validation
2023-09-04 13:48:33.393295: train_loss -1.4431
2023-09-04 13:48:33.395690: val_loss -1.0075
2023-09-04 13:48:33.397962: Pseudo dice [0.9126]
2023-09-04 13:48:33.399919: Epoch time: 371.08 s
2023-09-04 13:48:34.514030: 
2023-09-04 13:48:34.516319: Epoch 222
2023-09-04 13:48:34.518357: Current learning rate: backbone 0.00029749, others 0.00029749
2023-09-04 13:48:34.520957: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 13:49:35.618340: finished training epoch 222
2023-09-04 13:49:35.649504: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 13:49:35.652481: The split file contains 1 splits.
2023-09-04 13:49:35.654666: Desired fold for training: 0
2023-09-04 13:49:35.656631: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 13:55:15.544804: dsc: 91.00%
2023-09-04 13:55:15.547333: miou: 83.49%
2023-09-04 13:55:15.549437: acc: 95.49%, sen: 90.69%, spe: 97.11%
2023-09-04 13:55:15.552107: current best miou: 0.8422144348184231 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 13:55:15.554043: current best dsc: 0.9143500549125113 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 13:55:15.555981: finished real validation
2023-09-04 13:55:19.961650: train_loss -1.4427
2023-09-04 13:55:19.964073: val_loss -0.9531
2023-09-04 13:55:19.966250: Pseudo dice [0.9104]
2023-09-04 13:55:19.968220: Epoch time: 405.45 s
2023-09-04 13:55:21.086981: 
2023-09-04 13:55:21.089233: Epoch 223
2023-09-04 13:55:21.091430: Current learning rate: backbone 0.00029406, others 0.00029406
2023-09-04 13:55:21.093633: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 13:56:22.884387: finished training epoch 223
2023-09-04 13:56:22.914270: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 13:56:22.917109: The split file contains 1 splits.
2023-09-04 13:56:22.919043: Desired fold for training: 0
2023-09-04 13:56:22.920909: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 14:01:28.296767: dsc: 91.10%
2023-09-04 14:01:28.299141: miou: 83.65%
2023-09-04 14:01:28.301043: acc: 95.55%, sen: 90.60%, spe: 97.21%
2023-09-04 14:01:28.303389: current best miou: 0.8422144348184231 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 14:01:28.305297: current best dsc: 0.9143500549125113 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 14:01:28.307324: finished real validation
2023-09-04 14:01:32.680169: train_loss -1.4435
2023-09-04 14:01:32.682714: val_loss -0.9902
2023-09-04 14:01:32.684908: Pseudo dice [0.9101]
2023-09-04 14:01:32.686870: Epoch time: 371.59 s
2023-09-04 14:01:33.798266: 
2023-09-04 14:01:33.800436: Epoch 224
2023-09-04 14:01:33.802324: Current learning rate: backbone 0.00029062, others 0.00029062
2023-09-04 14:01:33.804470: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 14:02:34.940425: finished training epoch 224
2023-09-04 14:02:34.977349: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 14:02:34.980083: The split file contains 1 splits.
2023-09-04 14:02:34.982034: Desired fold for training: 0
2023-09-04 14:02:34.984589: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 14:07:45.078296: dsc: 91.04%
2023-09-04 14:07:45.080738: miou: 83.55%
2023-09-04 14:07:45.082741: acc: 95.50%, sen: 90.98%, spe: 97.01%
2023-09-04 14:07:45.085120: current best miou: 0.8422144348184231 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 14:07:45.087026: current best dsc: 0.9143500549125113 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 14:07:45.088845: finished real validation
2023-09-04 14:07:49.466631: train_loss -1.4435
2023-09-04 14:07:49.469299: val_loss -1.0028
2023-09-04 14:07:49.471701: Pseudo dice [0.9148]
2023-09-04 14:07:49.473942: Epoch time: 375.67 s
2023-09-04 14:07:50.594506: 
2023-09-04 14:07:50.596979: Epoch 225
2023-09-04 14:07:50.599010: Current learning rate: backbone 0.00028717, others 0.00028717
2023-09-04 14:07:50.601254: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 14:08:51.658230: finished training epoch 225
2023-09-04 14:08:51.687666: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 14:08:51.690503: The split file contains 1 splits.
2023-09-04 14:08:51.692452: Desired fold for training: 0
2023-09-04 14:08:51.694337: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 14:13:56.735101: dsc: 91.04%
2023-09-04 14:13:56.737935: miou: 83.55%
2023-09-04 14:13:56.740444: acc: 95.51%, sen: 90.66%, spe: 97.14%
2023-09-04 14:13:56.742979: current best miou: 0.8422144348184231 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 14:13:56.745234: current best dsc: 0.9143500549125113 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 14:13:56.747269: finished real validation
2023-09-04 14:14:01.123231: train_loss -1.4433
2023-09-04 14:14:01.125889: val_loss -0.9668
2023-09-04 14:14:01.128076: Pseudo dice [0.9101]
2023-09-04 14:14:01.130210: Epoch time: 370.53 s
2023-09-04 14:14:02.239125: 
2023-09-04 14:14:02.241497: Epoch 226
2023-09-04 14:14:02.243490: Current learning rate: backbone 0.00028373, others 0.00028373
2023-09-04 14:14:02.246290: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 14:15:03.336040: finished training epoch 226
2023-09-04 14:15:03.365803: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 14:15:03.368802: The split file contains 1 splits.
2023-09-04 14:15:03.370959: Desired fold for training: 0
2023-09-04 14:15:03.373087: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 14:20:34.551873: dsc: 91.02%
2023-09-04 14:20:35.517252: miou: 83.51%
2023-09-04 14:20:35.520148: acc: 95.48%, sen: 91.07%, spe: 96.96%
2023-09-04 14:20:35.523693: current best miou: 0.8422144348184231 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 14:20:35.526261: current best dsc: 0.9143500549125113 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 14:20:35.528679: finished real validation
2023-09-04 14:20:39.912210: train_loss -1.4428
2023-09-04 14:20:39.914943: val_loss -1.0075
2023-09-04 14:20:39.918375: Pseudo dice [0.9122]
2023-09-04 14:20:39.920555: Epoch time: 397.67 s
2023-09-04 14:20:41.037511: 
2023-09-04 14:20:41.040812: Epoch 227
2023-09-04 14:20:41.043055: Current learning rate: backbone 0.00028027, others 0.00028027
2023-09-04 14:20:41.046461: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 14:21:42.198785: finished training epoch 227
2023-09-04 14:21:42.230751: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 14:21:42.233778: The split file contains 1 splits.
2023-09-04 14:21:42.235693: Desired fold for training: 0
2023-09-04 14:21:42.237726: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 14:26:55.447891: dsc: 91.08%
2023-09-04 14:26:55.524340: miou: 83.63%
2023-09-04 14:26:55.527270: acc: 95.53%, sen: 90.83%, spe: 97.11%
2023-09-04 14:26:55.531003: current best miou: 0.8422144348184231 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 14:26:55.533454: current best dsc: 0.9143500549125113 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 14:26:55.535911: finished real validation
2023-09-04 14:26:59.919273: train_loss -1.4437
2023-09-04 14:26:59.924083: val_loss -1.0376
2023-09-04 14:26:59.927260: Pseudo dice [0.916]
2023-09-04 14:26:59.930962: Epoch time: 378.88 s
2023-09-04 14:27:01.094245: 
2023-09-04 14:27:01.096677: Epoch 228
2023-09-04 14:27:01.099114: Current learning rate: backbone 0.00027682, others 0.00027682
2023-09-04 14:27:01.101795: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 14:28:02.202521: finished training epoch 228
2023-09-04 14:28:02.232228: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 14:28:02.235126: The split file contains 1 splits.
2023-09-04 14:28:02.237309: Desired fold for training: 0
2023-09-04 14:28:02.239253: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 14:33:25.514573: dsc: 90.99%
2023-09-04 14:33:25.517476: miou: 83.47%
2023-09-04 14:33:25.520020: acc: 95.48%, sen: 90.72%, spe: 97.08%
2023-09-04 14:33:25.522881: current best miou: 0.8422144348184231 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 14:33:25.524809: current best dsc: 0.9143500549125113 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 14:33:25.527193: finished real validation
2023-09-04 14:33:29.924476: train_loss -1.4436
2023-09-04 14:33:29.927519: val_loss -1.0
2023-09-04 14:33:29.930788: Pseudo dice [0.912]
2023-09-04 14:33:29.933935: Epoch time: 388.83 s
2023-09-04 14:33:31.053785: 
2023-09-04 14:33:31.056950: Epoch 229
2023-09-04 14:33:31.059841: Current learning rate: backbone 0.00027335, others 0.00027335
2023-09-04 14:33:31.063157: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 14:34:32.096405: finished training epoch 229
2023-09-04 14:34:32.144589: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 14:34:32.147667: The split file contains 1 splits.
2023-09-04 14:34:32.149960: Desired fold for training: 0
2023-09-04 14:34:32.152164: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 14:39:48.341286: dsc: 90.92%
2023-09-04 14:39:48.569206: miou: 83.34%
2023-09-04 14:39:48.572009: acc: 95.44%, sen: 90.69%, spe: 97.04%
2023-09-04 14:39:48.575852: current best miou: 0.8422144348184231 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 14:39:48.578461: current best dsc: 0.9143500549125113 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 14:39:48.580946: finished real validation
2023-09-04 14:39:52.960983: train_loss -1.4433
2023-09-04 14:39:52.963844: val_loss -0.9913
2023-09-04 14:39:52.966351: Pseudo dice [0.9116]
2023-09-04 14:39:52.968673: Epoch time: 381.91 s
2023-09-04 14:39:55.623938: 
2023-09-04 14:39:55.626575: Epoch 230
2023-09-04 14:39:55.628615: Current learning rate: backbone 0.00026989, others 0.00026989
2023-09-04 14:39:55.630899: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 14:40:57.463492: finished training epoch 230
2023-09-04 14:40:57.548953: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 14:40:57.553727: The split file contains 1 splits.
2023-09-04 14:40:57.556098: Desired fold for training: 0
2023-09-04 14:40:57.558246: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 14:46:26.351994: dsc: 90.98%
2023-09-04 14:46:26.354449: miou: 83.46%
2023-09-04 14:46:26.356730: acc: 95.47%, sen: 90.94%, spe: 96.99%
2023-09-04 14:46:26.359107: current best miou: 0.8422144348184231 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 14:46:26.361107: current best dsc: 0.9143500549125113 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 14:46:26.362974: finished real validation
2023-09-04 14:46:30.743543: train_loss -1.4437
2023-09-04 14:46:30.746023: val_loss -0.9817
2023-09-04 14:46:30.748449: Pseudo dice [0.9116]
2023-09-04 14:46:30.750821: Epoch time: 395.12 s
2023-09-04 14:46:31.884285: 
2023-09-04 14:46:31.887152: Epoch 231
2023-09-04 14:46:31.889143: Current learning rate: backbone 0.00026641, others 0.00026641
2023-09-04 14:46:31.891714: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 14:47:33.106344: finished training epoch 231
2023-09-04 14:47:33.146038: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 14:47:33.149147: The split file contains 1 splits.
2023-09-04 14:47:33.151071: Desired fold for training: 0
2023-09-04 14:47:33.153339: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 14:52:46.250761: dsc: 91.07%
2023-09-04 14:52:46.253195: miou: 83.60%
2023-09-04 14:52:46.255394: acc: 95.52%, sen: 90.81%, spe: 97.10%
2023-09-04 14:52:46.257900: current best miou: 0.8422144348184231 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 14:52:46.260160: current best dsc: 0.9143500549125113 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 14:52:46.262263: finished real validation
2023-09-04 14:52:50.655869: train_loss -1.4435
2023-09-04 14:52:50.658513: val_loss -0.9745
2023-09-04 14:52:50.660984: Pseudo dice [0.9093]
2023-09-04 14:52:50.663114: Epoch time: 378.77 s
2023-09-04 14:52:51.766037: 
2023-09-04 14:52:51.768625: Epoch 232
2023-09-04 14:52:51.770897: Current learning rate: backbone 0.00026294, others 0.00026294
2023-09-04 14:52:51.773737: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 14:53:52.824317: finished training epoch 232
2023-09-04 14:53:52.859169: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 14:53:52.862361: The split file contains 1 splits.
2023-09-04 14:53:52.864613: Desired fold for training: 0
2023-09-04 14:53:52.866823: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 14:59:02.420330: dsc: 91.05%
2023-09-04 14:59:02.423056: miou: 83.57%
2023-09-04 14:59:02.425563: acc: 95.50%, sen: 91.04%, spe: 97.00%
2023-09-04 14:59:02.428327: current best miou: 0.8422144348184231 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 14:59:02.430583: current best dsc: 0.9143500549125113 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 14:59:02.432943: finished real validation
2023-09-04 14:59:06.819460: train_loss -1.4436
2023-09-04 14:59:06.822159: val_loss -0.9832
2023-09-04 14:59:06.824327: Pseudo dice [0.911]
2023-09-04 14:59:06.826325: Epoch time: 375.05 s
2023-09-04 14:59:07.941995: 
2023-09-04 14:59:07.944622: Epoch 233
2023-09-04 14:59:07.946901: Current learning rate: backbone 0.00025945, others 0.00025945
2023-09-04 14:59:07.949527: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 15:00:08.995201: finished training epoch 233
2023-09-04 15:00:09.036884: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 15:00:09.039903: The split file contains 1 splits.
2023-09-04 15:00:09.041791: Desired fold for training: 0
2023-09-04 15:00:09.043685: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 15:05:18.665090: dsc: 91.07%
2023-09-04 15:05:18.667691: miou: 83.60%
2023-09-04 15:05:18.669943: acc: 95.52%, sen: 90.87%, spe: 97.08%
2023-09-04 15:05:18.672450: current best miou: 0.8422144348184231 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 15:05:18.674686: current best dsc: 0.9143500549125113 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 15:05:18.676554: finished real validation
2023-09-04 15:05:23.068629: train_loss -1.444
2023-09-04 15:05:23.071046: val_loss -0.9878
2023-09-04 15:05:23.073226: Pseudo dice [0.9132]
2023-09-04 15:05:23.075251: Epoch time: 375.13 s
2023-09-04 15:05:24.190169: 
2023-09-04 15:05:24.192472: Epoch 234
2023-09-04 15:05:24.194405: Current learning rate: backbone 0.00025596, others 0.00025596
2023-09-04 15:05:24.196615: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 15:06:25.355025: finished training epoch 234
2023-09-04 15:06:25.408086: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 15:06:25.411030: The split file contains 1 splits.
2023-09-04 15:06:25.413063: Desired fold for training: 0
2023-09-04 15:06:25.415083: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 15:11:59.314674: dsc: 91.03%
2023-09-04 15:11:59.317468: miou: 83.54%
2023-09-04 15:11:59.319722: acc: 95.49%, sen: 90.96%, spe: 97.02%
2023-09-04 15:11:59.322435: current best miou: 0.8422144348184231 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 15:11:59.324486: current best dsc: 0.9143500549125113 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 15:11:59.326470: finished real validation
2023-09-04 15:12:03.717943: train_loss -1.4442
2023-09-04 15:12:03.720484: val_loss -0.9624
2023-09-04 15:12:03.722711: Pseudo dice [0.9106]
2023-09-04 15:12:03.724709: Epoch time: 399.53 s
2023-09-04 15:12:04.861563: 
2023-09-04 15:12:04.864096: Epoch 235
2023-09-04 15:12:04.866193: Current learning rate: backbone 0.00025247, others 0.00025247
2023-09-04 15:12:04.868773: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 15:13:05.914893: finished training epoch 235
2023-09-04 15:13:05.954126: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 15:13:05.956924: The split file contains 1 splits.
2023-09-04 15:13:05.958931: Desired fold for training: 0
2023-09-04 15:13:05.960891: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 15:18:21.751341: dsc: 91.22%
2023-09-04 15:18:21.753821: miou: 83.85%
2023-09-04 15:18:21.756026: acc: 95.58%, sen: 91.29%, spe: 97.02%
2023-09-04 15:18:21.758573: current best miou: 0.8422144348184231 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 15:18:21.761007: current best dsc: 0.9143500549125113 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 15:18:21.763252: finished real validation
2023-09-04 15:18:26.146375: train_loss -1.4439
2023-09-04 15:18:26.149009: val_loss -0.9843
2023-09-04 15:18:26.151427: Pseudo dice [0.9115]
2023-09-04 15:18:26.153650: Epoch time: 381.29 s
2023-09-04 15:18:27.256024: 
2023-09-04 15:18:27.258539: Epoch 236
2023-09-04 15:18:27.260795: Current learning rate: backbone 0.00024897, others 0.00024897
2023-09-04 15:18:27.263525: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 15:19:28.397691: finished training epoch 236
2023-09-04 15:19:28.437140: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 15:19:28.440814: The split file contains 1 splits.
2023-09-04 15:19:28.442992: Desired fold for training: 0
2023-09-04 15:19:28.446216: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 15:24:53.269310: dsc: 91.17%
2023-09-04 15:24:53.272012: miou: 83.77%
2023-09-04 15:24:53.274004: acc: 95.56%, sen: 91.10%, spe: 97.06%
2023-09-04 15:24:53.276250: current best miou: 0.8422144348184231 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 15:24:53.278178: current best dsc: 0.9143500549125113 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 15:24:53.280100: finished real validation
2023-09-04 15:24:57.666049: train_loss -1.4438
2023-09-04 15:24:57.668649: val_loss -0.9677
2023-09-04 15:24:57.670828: Pseudo dice [0.9113]
2023-09-04 15:24:57.672842: Epoch time: 390.41 s
2023-09-04 15:24:58.809849: 
2023-09-04 15:24:58.812359: Epoch 237
2023-09-04 15:24:58.814718: Current learning rate: backbone 0.00024547, others 0.00024547
2023-09-04 15:24:58.817288: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 15:25:59.871437: finished training epoch 237
2023-09-04 15:25:59.911695: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 15:25:59.914895: The split file contains 1 splits.
2023-09-04 15:25:59.916821: Desired fold for training: 0
2023-09-04 15:25:59.919025: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 15:31:26.892959: dsc: 91.01%
2023-09-04 15:31:26.895879: miou: 83.50%
2023-09-04 15:31:26.898287: acc: 95.46%, sen: 91.29%, spe: 96.87%
2023-09-04 15:31:26.901081: current best miou: 0.8422144348184231 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 15:31:26.903229: current best dsc: 0.9143500549125113 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 15:31:26.905441: finished real validation
2023-09-04 15:31:31.299734: train_loss -1.4434
2023-09-04 15:31:31.302274: val_loss -0.9754
2023-09-04 15:31:31.304720: Pseudo dice [0.911]
2023-09-04 15:31:31.306770: Epoch time: 392.49 s
2023-09-04 15:31:32.433475: 
2023-09-04 15:31:32.435908: Epoch 238
2023-09-04 15:31:32.438047: Current learning rate: backbone 0.00024196, others 0.00024196
2023-09-04 15:31:32.441134: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 15:32:33.790509: finished training epoch 238
2023-09-04 15:32:33.820286: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 15:32:33.823193: The split file contains 1 splits.
2023-09-04 15:32:33.825200: Desired fold for training: 0
2023-09-04 15:32:33.827146: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 15:37:42.676046: dsc: 90.99%
2023-09-04 15:37:42.678744: miou: 83.47%
2023-09-04 15:37:42.680663: acc: 95.47%, sen: 90.88%, spe: 97.02%
2023-09-04 15:37:42.682857: current best miou: 0.8422144348184231 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 15:37:42.684678: current best dsc: 0.9143500549125113 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 15:37:42.686717: finished real validation
2023-09-04 15:37:47.077782: train_loss -1.4442
2023-09-04 15:37:47.080202: val_loss -0.9737
2023-09-04 15:37:47.082402: Pseudo dice [0.9098]
2023-09-04 15:37:47.084370: Epoch time: 374.65 s
2023-09-04 15:37:48.214330: 
2023-09-04 15:37:48.216772: Epoch 239
2023-09-04 15:37:48.219100: Current learning rate: backbone 0.00023844, others 0.00023844
2023-09-04 15:37:48.221461: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 15:38:49.382656: finished training epoch 239
2023-09-04 15:38:49.412399: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 15:38:49.415443: The split file contains 1 splits.
2023-09-04 15:38:49.417706: Desired fold for training: 0
2023-09-04 15:38:49.419817: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 15:44:01.298811: dsc: 91.03%
2023-09-04 15:44:01.301385: miou: 83.53%
2023-09-04 15:44:01.303493: acc: 95.48%, sen: 91.16%, spe: 96.93%
2023-09-04 15:44:01.306124: current best miou: 0.8422144348184231 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 15:44:01.308452: current best dsc: 0.9143500549125113 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 15:44:01.310743: finished real validation
2023-09-04 15:44:05.696871: train_loss -1.4437
2023-09-04 15:44:05.699382: val_loss -0.9856
2023-09-04 15:44:05.701538: Pseudo dice [0.91]
2023-09-04 15:44:05.703673: Epoch time: 377.48 s
2023-09-04 15:44:08.357431: 
2023-09-04 15:44:08.359861: Epoch 240
2023-09-04 15:44:08.362303: Current learning rate: backbone 0.00023492, others 0.00023492
2023-09-04 15:44:08.365105: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 15:45:09.905605: finished training epoch 240
2023-09-04 15:45:09.935043: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 15:45:09.937883: The split file contains 1 splits.
2023-09-04 15:45:09.939941: Desired fold for training: 0
2023-09-04 15:45:09.941871: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 15:50:13.791228: dsc: 91.09%
2023-09-04 15:50:13.794024: miou: 83.63%
2023-09-04 15:50:13.796320: acc: 95.52%, sen: 91.05%, spe: 97.02%
2023-09-04 15:50:13.799489: current best miou: 0.8422144348184231 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 15:50:13.801460: current best dsc: 0.9143500549125113 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 15:50:13.803340: finished real validation
2023-09-04 15:50:18.192459: train_loss -1.4438
2023-09-04 15:50:18.195196: val_loss -0.9809
2023-09-04 15:50:18.197608: Pseudo dice [0.912]
2023-09-04 15:50:18.199943: Epoch time: 369.84 s
2023-09-04 15:50:19.324959: 
2023-09-04 15:50:19.327573: Epoch 241
2023-09-04 15:50:19.329820: Current learning rate: backbone 0.0002314, others 0.0002314
2023-09-04 15:50:19.332355: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 15:51:20.406249: finished training epoch 241
2023-09-04 15:51:20.445502: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 15:51:20.449416: The split file contains 1 splits.
2023-09-04 15:51:20.451816: Desired fold for training: 0
2023-09-04 15:51:20.453992: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 15:56:39.858155: dsc: 91.09%
2023-09-04 15:56:39.860755: miou: 83.63%
2023-09-04 15:56:39.863176: acc: 95.52%, sen: 90.92%, spe: 97.07%
2023-09-04 15:56:39.865784: current best miou: 0.8422144348184231 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 15:56:39.868124: current best dsc: 0.9143500549125113 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 15:56:39.870900: finished real validation
2023-09-04 15:56:44.257871: train_loss -1.4439
2023-09-04 15:56:44.260360: val_loss -0.9908
2023-09-04 15:56:44.262554: Pseudo dice [0.912]
2023-09-04 15:56:44.264580: Epoch time: 384.93 s
2023-09-04 15:56:45.385563: 
2023-09-04 15:56:45.387945: Epoch 242
2023-09-04 15:56:45.390254: Current learning rate: backbone 0.00022786, others 0.00022786
2023-09-04 15:56:45.392795: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 15:57:46.478984: finished training epoch 242
2023-09-04 15:57:46.510550: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 15:57:46.513534: The split file contains 1 splits.
2023-09-04 15:57:46.515618: Desired fold for training: 0
2023-09-04 15:57:46.517546: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 16:03:09.669656: dsc: 91.03%
2023-09-04 16:03:09.672670: miou: 83.54%
2023-09-04 16:03:09.675137: acc: 95.50%, sen: 90.91%, spe: 97.04%
2023-09-04 16:03:09.677595: current best miou: 0.8422144348184231 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 16:03:09.679932: current best dsc: 0.9143500549125113 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 16:03:09.682463: finished real validation
2023-09-04 16:03:14.067494: train_loss -1.4447
2023-09-04 16:03:14.070037: val_loss -0.9556
2023-09-04 16:03:14.072378: Pseudo dice [0.9101]
2023-09-04 16:03:14.074421: Epoch time: 388.68 s
2023-09-04 16:03:15.197191: 
2023-09-04 16:03:15.199988: Epoch 243
2023-09-04 16:03:15.202421: Current learning rate: backbone 0.00022433, others 0.00022433
2023-09-04 16:03:15.205270: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 16:04:16.249762: finished training epoch 243
2023-09-04 16:04:16.285225: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 16:04:16.288530: The split file contains 1 splits.
2023-09-04 16:04:16.290998: Desired fold for training: 0
2023-09-04 16:04:16.293107: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 16:09:23.416441: dsc: 91.10%
2023-09-04 16:09:23.419441: miou: 83.66%
2023-09-04 16:09:23.422076: acc: 95.53%, sen: 90.96%, spe: 97.07%
2023-09-04 16:09:23.424980: current best miou: 0.8422144348184231 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 16:09:23.427231: current best dsc: 0.9143500549125113 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 16:09:23.429718: finished real validation
2023-09-04 16:09:27.808772: train_loss -1.4443
2023-09-04 16:09:27.811533: val_loss -0.9497
2023-09-04 16:09:27.813958: Pseudo dice [0.9095]
2023-09-04 16:09:27.816251: Epoch time: 372.61 s
2023-09-04 16:09:28.942611: 
2023-09-04 16:09:28.945261: Epoch 244
2023-09-04 16:09:28.947555: Current learning rate: backbone 0.00022078, others 0.00022078
2023-09-04 16:09:28.950106: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 16:10:30.138504: finished training epoch 244
2023-09-04 16:10:30.169499: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 16:10:30.172640: The split file contains 1 splits.
2023-09-04 16:10:30.174981: Desired fold for training: 0
2023-09-04 16:10:30.177230: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 16:15:55.833762: dsc: 91.12%
2023-09-04 16:15:55.836448: miou: 83.69%
2023-09-04 16:15:55.838600: acc: 95.53%, sen: 91.21%, spe: 96.98%
2023-09-04 16:15:55.840857: current best miou: 0.8422144348184231 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 16:15:55.842863: current best dsc: 0.9143500549125113 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 16:15:55.845281: finished real validation
2023-09-04 16:16:00.240164: train_loss -1.4442
2023-09-04 16:16:00.242934: val_loss -0.9956
2023-09-04 16:16:00.245435: Pseudo dice [0.9132]
2023-09-04 16:16:00.247488: Epoch time: 391.3 s
2023-09-04 16:16:01.380749: 
2023-09-04 16:16:01.383021: Epoch 245
2023-09-04 16:16:01.385091: Current learning rate: backbone 0.00021723, others 0.00021723
2023-09-04 16:16:01.387408: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 16:17:02.679206: finished training epoch 245
2023-09-04 16:17:02.710172: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 16:17:02.712970: The split file contains 1 splits.
2023-09-04 16:17:02.715230: Desired fold for training: 0
2023-09-04 16:17:02.717226: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 16:22:19.252660: dsc: 91.03%
2023-09-04 16:22:19.255396: miou: 83.53%
2023-09-04 16:22:19.257373: acc: 95.49%, sen: 90.85%, spe: 97.06%
2023-09-04 16:22:19.259654: current best miou: 0.8422144348184231 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 16:22:19.261533: current best dsc: 0.9143500549125113 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 16:22:19.263391: finished real validation
2023-09-04 16:22:23.648627: train_loss -1.4441
2023-09-04 16:22:23.651501: val_loss -0.9692
2023-09-04 16:22:23.653807: Pseudo dice [0.912]
2023-09-04 16:22:23.655837: Epoch time: 382.27 s
2023-09-04 16:22:24.787148: 
2023-09-04 16:22:24.789522: Epoch 246
2023-09-04 16:22:24.791888: Current learning rate: backbone 0.00021367, others 0.00021367
2023-09-04 16:22:24.794257: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 16:23:26.179124: finished training epoch 246
2023-09-04 16:23:26.209492: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 16:23:26.212770: The split file contains 1 splits.
2023-09-04 16:23:26.215053: Desired fold for training: 0
2023-09-04 16:23:26.217346: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 16:28:53.728934: dsc: 90.87%
2023-09-04 16:28:53.731628: miou: 83.27%
2023-09-04 16:28:53.734173: acc: 95.43%, sen: 90.47%, spe: 97.09%
2023-09-04 16:28:53.737660: current best miou: 0.8422144348184231 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 16:28:53.739890: current best dsc: 0.9143500549125113 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 16:28:53.742218: finished real validation
2023-09-04 16:28:58.137963: train_loss -1.444
2023-09-04 16:28:58.140867: val_loss -0.9745
2023-09-04 16:28:58.143442: Pseudo dice [0.9096]
2023-09-04 16:28:58.145790: Epoch time: 393.35 s
2023-09-04 16:28:59.286923: 
2023-09-04 16:28:59.289431: Epoch 247
2023-09-04 16:28:59.291701: Current learning rate: backbone 0.00021011, others 0.00021011
2023-09-04 16:28:59.294114: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 16:30:00.497568: finished training epoch 247
2023-09-04 16:30:00.577434: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 16:30:00.583223: The split file contains 1 splits.
2023-09-04 16:30:00.585643: Desired fold for training: 0
2023-09-04 16:30:00.587808: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 16:35:10.806086: dsc: 90.98%
2023-09-04 16:35:10.808707: miou: 83.45%
2023-09-04 16:35:10.810989: acc: 95.47%, sen: 90.69%, spe: 97.08%
2023-09-04 16:35:10.813531: current best miou: 0.8422144348184231 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 16:35:10.815783: current best dsc: 0.9143500549125113 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 16:35:10.817768: finished real validation
2023-09-04 16:35:15.208569: train_loss -1.4439
2023-09-04 16:35:15.211184: val_loss -0.9681
2023-09-04 16:35:15.213502: Pseudo dice [0.9088]
2023-09-04 16:35:15.215644: Epoch time: 375.92 s
2023-09-04 16:35:16.340786: 
2023-09-04 16:35:16.343401: Epoch 248
2023-09-04 16:35:16.345469: Current learning rate: backbone 0.00020654, others 0.00020654
2023-09-04 16:35:16.347797: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 16:36:17.414530: finished training epoch 248
2023-09-04 16:36:17.444215: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 16:36:17.447225: The split file contains 1 splits.
2023-09-04 16:36:17.449304: Desired fold for training: 0
2023-09-04 16:36:17.451509: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 16:41:32.858436: dsc: 91.04%
2023-09-04 16:41:32.860930: miou: 83.56%
2023-09-04 16:41:32.862902: acc: 95.50%, sen: 90.96%, spe: 97.02%
2023-09-04 16:41:32.865906: current best miou: 0.8422144348184231 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 16:41:32.867866: current best dsc: 0.9143500549125113 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 16:41:32.869879: finished real validation
2023-09-04 16:41:37.248561: train_loss -1.4445
2023-09-04 16:41:37.251396: val_loss -0.9724
2023-09-04 16:41:37.253699: Pseudo dice [0.9103]
2023-09-04 16:41:37.255745: Epoch time: 380.91 s
2023-09-04 16:41:38.370386: 
2023-09-04 16:41:38.372935: Epoch 249
2023-09-04 16:41:38.375008: Current learning rate: backbone 0.00020296, others 0.00020296
2023-09-04 16:41:38.377358: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 16:42:39.757508: finished training epoch 249
2023-09-04 16:42:39.798979: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 16:42:39.802191: The split file contains 1 splits.
2023-09-04 16:42:39.804311: Desired fold for training: 0
2023-09-04 16:42:39.806357: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 16:48:12.340962: dsc: 91.08%
2023-09-04 16:48:12.343731: miou: 83.62%
2023-09-04 16:48:12.345980: acc: 95.52%, sen: 90.93%, spe: 97.06%
2023-09-04 16:48:12.348424: current best miou: 0.8422144348184231 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 16:48:12.350449: current best dsc: 0.9143500549125113 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 16:48:12.352406: finished real validation
2023-09-04 16:48:16.732319: train_loss -1.4441
2023-09-04 16:48:16.734869: val_loss -0.9667
2023-09-04 16:48:16.737302: Pseudo dice [0.9117]
2023-09-04 16:48:16.739343: Epoch time: 398.36 s
2023-09-04 16:48:19.398548: 
2023-09-04 16:48:19.401343: Epoch 250
2023-09-04 16:48:19.403959: Current learning rate: backbone 0.00019937, others 0.00019937
2023-09-04 16:48:19.406693: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 16:49:20.703669: finished training epoch 250
2023-09-04 16:49:20.740029: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 16:49:20.743085: The split file contains 1 splits.
2023-09-04 16:49:20.745398: Desired fold for training: 0
2023-09-04 16:49:20.747698: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 16:54:37.698474: dsc: 91.08%
2023-09-04 16:54:37.701279: miou: 83.62%
2023-09-04 16:54:37.703633: acc: 95.52%, sen: 91.06%, spe: 97.01%
2023-09-04 16:54:37.706273: current best miou: 0.8422144348184231 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 16:54:37.708846: current best dsc: 0.9143500549125113 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 16:54:37.711474: finished real validation
2023-09-04 16:54:42.102484: train_loss -1.4441
2023-09-04 16:54:42.105213: val_loss -0.9959
2023-09-04 16:54:42.107769: Pseudo dice [0.9128]
2023-09-04 16:54:42.110093: Epoch time: 382.71 s
2023-09-04 16:54:43.241355: 
2023-09-04 16:54:43.244075: Epoch 251
2023-09-04 16:54:43.246652: Current learning rate: backbone 0.00019578, others 0.00019578
2023-09-04 16:54:43.249391: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 16:55:44.333978: finished training epoch 251
2023-09-04 16:55:44.375632: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 16:55:44.378503: The split file contains 1 splits.
2023-09-04 16:55:44.380554: Desired fold for training: 0
2023-09-04 16:55:44.382713: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 17:01:12.248867: dsc: 91.11%
2023-09-04 17:01:12.251611: miou: 83.68%
2023-09-04 17:01:12.253726: acc: 95.54%, sen: 90.83%, spe: 97.13%
2023-09-04 17:01:12.256149: current best miou: 0.8422144348184231 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 17:01:12.258334: current best dsc: 0.9143500549125113 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 17:01:12.260324: finished real validation
2023-09-04 17:01:16.650900: train_loss -1.445
2023-09-04 17:01:16.653633: val_loss -0.9631
2023-09-04 17:01:16.656047: Pseudo dice [0.9087]
2023-09-04 17:01:16.658181: Epoch time: 393.41 s
2023-09-04 17:01:17.792112: 
2023-09-04 17:01:17.794534: Epoch 252
2023-09-04 17:01:17.796639: Current learning rate: backbone 0.00019218, others 0.00019218
2023-09-04 17:01:17.799071: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 17:02:18.838090: finished training epoch 252
2023-09-04 17:02:18.868713: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 17:02:18.872009: The split file contains 1 splits.
2023-09-04 17:02:18.874449: Desired fold for training: 0
2023-09-04 17:02:18.876859: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 17:07:31.349938: dsc: 91.08%
2023-09-04 17:07:31.352921: miou: 83.62%
2023-09-04 17:07:31.355298: acc: 95.52%, sen: 91.05%, spe: 97.01%
2023-09-04 17:07:31.358166: current best miou: 0.8422144348184231 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 17:07:31.360390: current best dsc: 0.9143500549125113 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 17:07:31.362817: finished real validation
2023-09-04 17:07:35.763239: train_loss -1.445
2023-09-04 17:07:35.766031: val_loss -1.0098
2023-09-04 17:07:35.768607: Pseudo dice [0.9169]
2023-09-04 17:07:35.770952: Epoch time: 377.97 s
2023-09-04 17:07:36.927124: 
2023-09-04 17:07:36.929615: Epoch 253
2023-09-04 17:07:36.932162: Current learning rate: backbone 0.00018857, others 0.00018857
2023-09-04 17:07:36.935232: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 17:08:38.077051: finished training epoch 253
2023-09-04 17:08:38.115454: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 17:08:38.118471: The split file contains 1 splits.
2023-09-04 17:08:38.120570: Desired fold for training: 0
2023-09-04 17:08:38.122615: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 17:13:56.547298: dsc: 91.00%
2023-09-04 17:13:56.551004: miou: 83.48%
2023-09-04 17:13:56.557240: acc: 95.47%, sen: 91.05%, spe: 96.95%
2023-09-04 17:13:56.560153: current best miou: 0.8422144348184231 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 17:13:56.564798: current best dsc: 0.9143500549125113 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 17:13:56.567328: finished real validation
2023-09-04 17:14:00.958858: train_loss -1.4445
2023-09-04 17:14:00.961619: val_loss -0.9746
2023-09-04 17:14:00.963910: Pseudo dice [0.9113]
2023-09-04 17:14:00.965994: Epoch time: 384.03 s
2023-09-04 17:14:02.082381: 
2023-09-04 17:14:02.085112: Epoch 254
2023-09-04 17:14:02.087376: Current learning rate: backbone 0.00018496, others 0.00018496
2023-09-04 17:14:02.089902: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 17:15:03.291392: finished training epoch 254
2023-09-04 17:15:03.333437: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 17:15:03.336594: The split file contains 1 splits.
2023-09-04 17:15:03.338935: Desired fold for training: 0
2023-09-04 17:15:03.341213: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 17:20:22.288489: dsc: 91.10%
2023-09-04 17:20:22.291432: miou: 83.65%
2023-09-04 17:20:22.293706: acc: 95.54%, sen: 90.72%, spe: 97.16%
2023-09-04 17:20:22.296067: current best miou: 0.8422144348184231 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 17:20:22.298329: current best dsc: 0.9143500549125113 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 17:20:22.300349: finished real validation
2023-09-04 17:20:26.697426: train_loss -1.4445
2023-09-04 17:20:26.700075: val_loss -1.0077
2023-09-04 17:20:26.702356: Pseudo dice [0.9143]
2023-09-04 17:20:26.704531: Epoch time: 384.62 s
2023-09-04 17:20:27.853541: 
2023-09-04 17:20:27.856188: Epoch 255
2023-09-04 17:20:27.858318: Current learning rate: backbone 0.00018134, others 0.00018134
2023-09-04 17:20:27.860994: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 17:21:29.246219: finished training epoch 255
2023-09-04 17:21:29.289208: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 17:21:29.292240: The split file contains 1 splits.
2023-09-04 17:21:29.295154: Desired fold for training: 0
2023-09-04 17:21:29.297430: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 17:26:51.161295: dsc: 91.11%
2023-09-04 17:26:51.164198: miou: 83.68%
2023-09-04 17:26:51.166524: acc: 95.54%, sen: 90.93%, spe: 97.09%
2023-09-04 17:26:51.169186: current best miou: 0.8422144348184231 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 17:26:51.171449: current best dsc: 0.9143500549125113 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 17:26:51.173836: finished real validation
2023-09-04 17:26:55.565631: train_loss -1.4442
2023-09-04 17:26:55.568744: val_loss -0.9712
2023-09-04 17:26:55.571450: Pseudo dice [0.9104]
2023-09-04 17:26:55.573703: Epoch time: 387.71 s
2023-09-04 17:26:56.681253: 
2023-09-04 17:26:56.684016: Epoch 256
2023-09-04 17:26:56.686298: Current learning rate: backbone 0.0001777, others 0.0001777
2023-09-04 17:26:56.688791: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 17:27:57.830236: finished training epoch 256
2023-09-04 17:27:57.870677: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 17:27:57.875712: The split file contains 1 splits.
2023-09-04 17:27:57.878407: Desired fold for training: 0
2023-09-04 17:27:57.880828: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 17:33:24.583906: dsc: 91.08%
2023-09-04 17:33:24.587952: miou: 83.62%
2023-09-04 17:33:24.590415: acc: 95.52%, sen: 90.92%, spe: 97.07%
2023-09-04 17:33:24.592845: current best miou: 0.8422144348184231 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 17:33:24.594845: current best dsc: 0.9143500549125113 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 17:33:24.597030: finished real validation
2023-09-04 17:33:29.003903: train_loss -1.4451
2023-09-04 17:33:29.006862: val_loss -0.9829
2023-09-04 17:33:29.009433: Pseudo dice [0.9103]
2023-09-04 17:33:29.011786: Epoch time: 392.32 s
2023-09-04 17:33:30.165959: 
2023-09-04 17:33:30.168496: Epoch 257
2023-09-04 17:33:30.170573: Current learning rate: backbone 0.00017407, others 0.00017407
2023-09-04 17:33:30.173096: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 17:34:31.372251: finished training epoch 257
2023-09-04 17:34:31.404437: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 17:34:31.407854: The split file contains 1 splits.
2023-09-04 17:34:31.410279: Desired fold for training: 0
2023-09-04 17:34:31.412651: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 17:39:49.239292: dsc: 91.05%
2023-09-04 17:39:49.242403: miou: 83.57%
2023-09-04 17:39:49.244880: acc: 95.51%, sen: 90.75%, spe: 97.11%
2023-09-04 17:39:49.247444: current best miou: 0.8422144348184231 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 17:39:49.249619: current best dsc: 0.9143500549125113 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 17:39:49.251716: finished real validation
2023-09-04 17:39:53.637921: train_loss -1.4449
2023-09-04 17:39:53.640549: val_loss -1.0125
2023-09-04 17:39:53.642933: Pseudo dice [0.9137]
2023-09-04 17:39:53.644983: Epoch time: 383.47 s
2023-09-04 17:39:54.784951: 
2023-09-04 17:39:54.787363: Epoch 258
2023-09-04 17:39:54.790021: Current learning rate: backbone 0.00017042, others 0.00017042
2023-09-04 17:39:54.793466: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 17:40:55.958538: finished training epoch 258
2023-09-04 17:40:55.989513: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 17:40:55.992615: The split file contains 1 splits.
2023-09-04 17:40:55.994698: Desired fold for training: 0
2023-09-04 17:40:55.996802: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 17:46:12.113559: dsc: 91.09%
2023-09-04 17:46:12.116383: miou: 83.63%
2023-09-04 17:46:12.118555: acc: 95.53%, sen: 90.89%, spe: 97.08%
2023-09-04 17:46:12.121023: current best miou: 0.8422144348184231 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 17:46:12.123160: current best dsc: 0.9143500549125113 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 17:46:12.125251: finished real validation
2023-09-04 17:46:16.521867: train_loss -1.445
2023-09-04 17:46:16.524898: val_loss -0.9727
2023-09-04 17:46:16.527310: Pseudo dice [0.9116]
2023-09-04 17:46:16.529640: Epoch time: 381.74 s
2023-09-04 17:46:17.660547: 
2023-09-04 17:46:17.663338: Epoch 259
2023-09-04 17:46:17.666204: Current learning rate: backbone 0.00016676, others 0.00016676
2023-09-04 17:46:17.668969: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 17:47:18.810824: finished training epoch 259
2023-09-04 17:47:18.841128: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 17:47:18.844210: The split file contains 1 splits.
2023-09-04 17:47:18.846469: Desired fold for training: 0
2023-09-04 17:47:18.848878: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 17:52:25.407402: dsc: 91.03%
2023-09-04 17:52:25.410739: miou: 83.54%
2023-09-04 17:52:25.413106: acc: 95.50%, sen: 90.80%, spe: 97.08%
2023-09-04 17:52:25.415773: current best miou: 0.8422144348184231 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 17:52:25.418152: current best dsc: 0.9143500549125113 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 17:52:25.420250: finished real validation
2023-09-04 17:52:29.804305: train_loss -1.4446
2023-09-04 17:52:29.806969: val_loss -0.9839
2023-09-04 17:52:29.809385: Pseudo dice [0.9118]
2023-09-04 17:52:29.811831: Epoch time: 372.15 s
2023-09-04 17:52:32.447667: 
2023-09-04 17:52:32.450094: Epoch 260
2023-09-04 17:52:32.452191: Current learning rate: backbone 0.0001631, others 0.0001631
2023-09-04 17:52:32.454563: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 17:53:33.534593: finished training epoch 260
2023-09-04 17:53:33.563982: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 17:53:33.566892: The split file contains 1 splits.
2023-09-04 17:53:33.568980: Desired fold for training: 0
2023-09-04 17:53:33.570986: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 17:58:45.751487: dsc: 91.08%
2023-09-04 17:58:45.754212: miou: 83.62%
2023-09-04 17:58:45.756608: acc: 95.52%, sen: 90.97%, spe: 97.05%
2023-09-04 17:58:45.758952: current best miou: 0.8422144348184231 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 17:58:45.760955: current best dsc: 0.9143500549125113 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 17:58:45.762904: finished real validation
2023-09-04 17:58:50.164375: train_loss -1.4447
2023-09-04 17:58:50.167186: val_loss -0.9928
2023-09-04 17:58:50.169683: Pseudo dice [0.9133]
2023-09-04 17:58:50.172173: Epoch time: 377.72 s
2023-09-04 17:58:51.304638: 
2023-09-04 17:58:51.307078: Epoch 261
2023-09-04 17:58:51.309162: Current learning rate: backbone 0.00015942, others 0.00015942
2023-09-04 17:58:51.311556: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 17:59:52.398620: finished training epoch 261
2023-09-04 17:59:52.430071: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 17:59:52.433210: The split file contains 1 splits.
2023-09-04 17:59:52.435610: Desired fold for training: 0
2023-09-04 17:59:52.438041: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 18:05:11.203339: dsc: 91.10%
2023-09-04 18:05:11.206242: miou: 83.65%
2023-09-04 18:05:11.208608: acc: 95.52%, sen: 91.24%, spe: 96.95%
2023-09-04 18:05:11.211181: current best miou: 0.8422144348184231 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 18:05:11.213460: current best dsc: 0.9143500549125113 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 18:05:11.216779: finished real validation
2023-09-04 18:05:15.606685: train_loss -1.4449
2023-09-04 18:05:15.609488: val_loss -0.9928
2023-09-04 18:05:15.612119: Pseudo dice [0.915]
2023-09-04 18:05:15.614484: Epoch time: 384.3 s
2023-09-04 18:05:16.727273: 
2023-09-04 18:05:16.729926: Epoch 262
2023-09-04 18:05:16.732029: Current learning rate: backbone 0.00015574, others 0.00015574
2023-09-04 18:05:16.734716: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 18:06:17.782032: finished training epoch 262
2023-09-04 18:06:17.824867: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 18:06:17.828763: The split file contains 1 splits.
2023-09-04 18:06:17.831089: Desired fold for training: 0
2023-09-04 18:06:17.833225: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 18:11:43.618207: dsc: 91.14%
2023-09-04 18:11:43.620753: miou: 83.73%
2023-09-04 18:11:43.623053: acc: 95.54%, sen: 91.18%, spe: 97.01%
2023-09-04 18:11:43.625905: current best miou: 0.8422144348184231 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 18:11:43.628025: current best dsc: 0.9143500549125113 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 18:11:43.630191: finished real validation
2023-09-04 18:11:48.025993: train_loss -1.4453
2023-09-04 18:11:48.029243: val_loss -0.9899
2023-09-04 18:11:48.031909: Pseudo dice [0.9127]
2023-09-04 18:11:48.034423: Epoch time: 391.3 s
2023-09-04 18:11:49.161962: 
2023-09-04 18:11:49.164862: Epoch 263
2023-09-04 18:11:49.167264: Current learning rate: backbone 0.00015205, others 0.00015205
2023-09-04 18:11:49.169765: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 18:12:50.479377: finished training epoch 263
2023-09-04 18:12:50.513390: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 18:12:50.516746: The split file contains 1 splits.
2023-09-04 18:12:50.519041: Desired fold for training: 0
2023-09-04 18:12:50.521433: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 18:18:03.968277: dsc: 91.14%
2023-09-04 18:18:03.972534: miou: 83.72%
2023-09-04 18:18:03.975229: acc: 95.53%, sen: 91.41%, spe: 96.91%
2023-09-04 18:18:03.977677: current best miou: 0.8422144348184231 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 18:18:03.980501: current best dsc: 0.9143500549125113 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 18:18:03.983254: finished real validation
2023-09-04 18:18:08.380758: train_loss -1.4452
2023-09-04 18:18:08.383400: val_loss -0.9756
2023-09-04 18:18:08.385747: Pseudo dice [0.9127]
2023-09-04 18:18:08.387883: Epoch time: 379.22 s
2023-09-04 18:18:08.390104: Yayy! New best EMA pseudo Dice: 0.9123
2023-09-04 18:18:11.039069: 
2023-09-04 18:18:11.041650: Epoch 264
2023-09-04 18:18:11.043895: Current learning rate: backbone 0.00014834, others 0.00014834
2023-09-04 18:18:11.046400: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 18:19:12.269296: finished training epoch 264
2023-09-04 18:19:12.300588: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 18:19:12.303788: The split file contains 1 splits.
2023-09-04 18:19:12.306189: Desired fold for training: 0
2023-09-04 18:19:12.308499: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 18:24:26.521673: dsc: 91.04%
2023-09-04 18:24:35.104851: miou: 83.55%
2023-09-04 18:24:35.107730: acc: 95.49%, sen: 91.04%, spe: 96.99%
2023-09-04 18:24:35.111383: current best miou: 0.8422144348184231 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 18:24:35.114239: current best dsc: 0.9143500549125113 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 18:24:35.116851: finished real validation
2023-09-04 18:24:39.522904: train_loss -1.4451
2023-09-04 18:24:39.525695: val_loss -0.9797
2023-09-04 18:24:39.528461: Pseudo dice [0.9112]
2023-09-04 18:24:39.530650: Epoch time: 388.49 s
2023-09-04 18:24:40.668343: 
2023-09-04 18:24:40.670700: Epoch 265
2023-09-04 18:24:40.672823: Current learning rate: backbone 0.00014463, others 0.00014463
2023-09-04 18:24:40.675589: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 18:25:41.897019: finished training epoch 265
2023-09-04 18:25:41.937441: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 18:25:41.940677: The split file contains 1 splits.
2023-09-04 18:25:41.942736: Desired fold for training: 0
2023-09-04 18:25:41.944715: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 18:31:06.157187: dsc: 91.09%
2023-09-04 18:31:06.160074: miou: 83.63%
2023-09-04 18:31:06.162493: acc: 95.52%, sen: 90.97%, spe: 97.05%
2023-09-04 18:31:06.165948: current best miou: 0.8422144348184231 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 18:31:06.168454: current best dsc: 0.9143500549125113 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 18:31:06.171264: finished real validation
2023-09-04 18:31:10.580276: train_loss -1.445
2023-09-04 18:31:10.583200: val_loss -0.9852
2023-09-04 18:31:10.585912: Pseudo dice [0.9122]
2023-09-04 18:31:10.588388: Epoch time: 389.91 s
2023-09-04 18:31:11.757700: 
2023-09-04 18:31:11.760680: Epoch 266
2023-09-04 18:31:11.763342: Current learning rate: backbone 0.0001409, others 0.0001409
2023-09-04 18:31:11.766243: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 18:32:12.893147: finished training epoch 266
2023-09-04 18:32:12.924337: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 18:32:12.928669: The split file contains 1 splits.
2023-09-04 18:32:12.931286: Desired fold for training: 0
2023-09-04 18:32:12.934400: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 18:37:40.362033: dsc: 91.03%
2023-09-04 18:37:40.364793: miou: 83.54%
2023-09-04 18:37:40.367011: acc: 95.49%, sen: 90.90%, spe: 97.04%
2023-09-04 18:37:40.369735: current best miou: 0.8422144348184231 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 18:37:40.372036: current best dsc: 0.9143500549125113 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 18:37:40.374178: finished real validation
2023-09-04 18:37:44.769693: train_loss -1.4455
2023-09-04 18:37:44.772742: val_loss -0.9745
2023-09-04 18:37:44.775238: Pseudo dice [0.912]
2023-09-04 18:37:44.777465: Epoch time: 393.01 s
2023-09-04 18:37:45.901054: 
2023-09-04 18:37:45.904224: Epoch 267
2023-09-04 18:37:45.906492: Current learning rate: backbone 0.00013717, others 0.00013717
2023-09-04 18:37:45.909079: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 18:38:47.041621: finished training epoch 267
2023-09-04 18:38:47.082391: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 18:38:47.085660: The split file contains 1 splits.
2023-09-04 18:38:47.087666: Desired fold for training: 0
2023-09-04 18:38:47.089662: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 18:44:06.130867: dsc: 91.11%
2023-09-04 18:44:06.133767: miou: 83.67%
2023-09-04 18:44:06.136459: acc: 95.53%, sen: 91.11%, spe: 97.01%
2023-09-04 18:44:06.139575: current best miou: 0.8422144348184231 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 18:44:06.141923: current best dsc: 0.9143500549125113 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 18:44:06.144338: finished real validation
2023-09-04 18:44:10.533497: train_loss -1.4448
2023-09-04 18:44:10.536468: val_loss -1.0447
2023-09-04 18:44:10.539146: Pseudo dice [0.9198]
2023-09-04 18:44:10.541350: Epoch time: 384.63 s
2023-09-04 18:44:10.543487: Yayy! New best EMA pseudo Dice: 0.9129
2023-09-04 18:44:13.188207: 
2023-09-04 18:44:13.191042: Epoch 268
2023-09-04 18:44:13.193908: Current learning rate: backbone 0.00013342, others 0.00013342
2023-09-04 18:44:13.196477: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 18:45:14.445221: finished training epoch 268
2023-09-04 18:45:14.477039: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 18:45:14.480840: The split file contains 1 splits.
2023-09-04 18:45:14.483115: Desired fold for training: 0
2023-09-04 18:45:14.485266: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 18:50:23.285393: dsc: 91.07%
2023-09-04 18:50:23.288002: miou: 83.61%
2023-09-04 18:50:23.290292: acc: 95.52%, sen: 90.82%, spe: 97.10%
2023-09-04 18:50:23.293019: current best miou: 0.8422144348184231 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 18:50:23.295344: current best dsc: 0.9143500549125113 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 18:50:23.297481: finished real validation
2023-09-04 18:50:27.746902: train_loss -1.4452
2023-09-04 18:50:27.749573: val_loss -0.9804
2023-09-04 18:50:27.752308: Pseudo dice [0.9131]
2023-09-04 18:50:27.754940: Epoch time: 374.56 s
2023-09-04 18:50:27.757469: Yayy! New best EMA pseudo Dice: 0.9129
2023-09-04 18:50:30.387183: 
2023-09-04 18:50:30.389903: Epoch 269
2023-09-04 18:50:30.392654: Current learning rate: backbone 0.00012966, others 0.00012966
2023-09-04 18:50:30.395873: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 18:51:32.195257: finished training epoch 269
2023-09-04 18:51:32.236742: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 18:51:32.241070: The split file contains 1 splits.
2023-09-04 18:51:32.243402: Desired fold for training: 0
2023-09-04 18:51:32.245556: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 18:56:59.690615: dsc: 91.08%
2023-09-04 18:56:59.693747: miou: 83.63%
2023-09-04 18:56:59.696442: acc: 95.51%, sen: 91.10%, spe: 97.00%
2023-09-04 18:56:59.699230: current best miou: 0.8422144348184231 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 18:56:59.701608: current best dsc: 0.9143500549125113 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 18:56:59.703879: finished real validation
2023-09-04 18:57:04.109617: train_loss -1.4444
2023-09-04 18:57:04.112338: val_loss -0.9624
2023-09-04 18:57:04.114913: Pseudo dice [0.9106]
2023-09-04 18:57:04.117177: Epoch time: 393.72 s
2023-09-04 18:57:06.763942: 
2023-09-04 18:57:06.766668: Epoch 270
2023-09-04 18:57:06.768885: Current learning rate: backbone 0.00012589, others 0.00012589
2023-09-04 18:57:06.771344: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 18:58:07.957035: finished training epoch 270
2023-09-04 18:58:08.011107: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 18:58:08.015450: The split file contains 1 splits.
2023-09-04 18:58:08.018008: Desired fold for training: 0
2023-09-04 18:58:08.020557: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 19:03:24.732393: dsc: 91.13%
2023-09-04 19:03:24.735526: miou: 83.70%
2023-09-04 19:03:24.738107: acc: 95.53%, sen: 91.17%, spe: 97.00%
2023-09-04 19:03:24.741388: current best miou: 0.8422144348184231 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 19:03:24.743952: current best dsc: 0.9143500549125113 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 19:03:24.746378: finished real validation
2023-09-04 19:03:29.133617: train_loss -1.4451
2023-09-04 19:03:29.136513: val_loss -0.9492
2023-09-04 19:03:29.139244: Pseudo dice [0.9093]
2023-09-04 19:03:29.141724: Epoch time: 382.37 s
2023-09-04 19:03:30.286370: 
2023-09-04 19:03:30.289251: Epoch 271
2023-09-04 19:03:30.291909: Current learning rate: backbone 0.00012211, others 0.00012211
2023-09-04 19:03:30.294865: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 19:04:31.447823: finished training epoch 271
2023-09-04 19:04:31.478328: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 19:04:31.481352: The split file contains 1 splits.
2023-09-04 19:04:31.483563: Desired fold for training: 0
2023-09-04 19:04:31.485644: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 19:09:47.959071: dsc: 91.13%
2023-09-04 19:09:47.962054: miou: 83.71%
2023-09-04 19:09:47.966169: acc: 95.53%, sen: 91.29%, spe: 96.96%
2023-09-04 19:09:47.972609: current best miou: 0.8422144348184231 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 19:09:47.976517: current best dsc: 0.9143500549125113 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 19:09:47.980662: finished real validation
2023-09-04 19:09:52.373896: train_loss -1.4449
2023-09-04 19:09:52.377035: val_loss -0.9703
2023-09-04 19:09:52.379483: Pseudo dice [0.9122]
2023-09-04 19:09:52.381640: Epoch time: 382.09 s
2023-09-04 19:09:53.489088: 
2023-09-04 19:09:53.491461: Epoch 272
2023-09-04 19:09:53.493643: Current learning rate: backbone 0.00011831, others 0.00011831
2023-09-04 19:09:53.496624: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 19:10:55.425687: finished training epoch 272
2023-09-04 19:10:55.457376: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 19:10:55.461047: The split file contains 1 splits.
2023-09-04 19:10:55.463486: Desired fold for training: 0
2023-09-04 19:10:55.465697: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 19:16:08.046293: dsc: 91.08%
2023-09-04 19:16:08.049149: miou: 83.62%
2023-09-04 19:16:08.051261: acc: 95.51%, sen: 91.16%, spe: 96.97%
2023-09-04 19:16:08.054014: current best miou: 0.8422144348184231 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 19:16:08.056421: current best dsc: 0.9143500549125113 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 19:16:08.058724: finished real validation
2023-09-04 19:16:12.460880: train_loss -1.4452
2023-09-04 19:16:12.463722: val_loss -0.9683
2023-09-04 19:16:12.466359: Pseudo dice [0.9118]
2023-09-04 19:16:12.468703: Epoch time: 378.97 s
2023-09-04 19:16:13.600457: 
2023-09-04 19:16:13.603307: Epoch 273
2023-09-04 19:16:13.605682: Current learning rate: backbone 0.0001145, others 0.0001145
2023-09-04 19:16:13.608310: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 19:17:15.260291: finished training epoch 273
2023-09-04 19:17:15.302212: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 19:17:15.306102: The split file contains 1 splits.
2023-09-04 19:17:15.308769: Desired fold for training: 0
2023-09-04 19:17:15.311233: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 19:22:36.738187: dsc: 91.06%
2023-09-04 19:22:36.741197: miou: 83.59%
2023-09-04 19:22:36.744010: acc: 95.51%, sen: 90.97%, spe: 97.04%
2023-09-04 19:22:36.747548: current best miou: 0.8422144348184231 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 19:22:36.750316: current best dsc: 0.9143500549125113 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 19:22:36.753068: finished real validation
2023-09-04 19:22:41.144334: train_loss -1.4454
2023-09-04 19:22:41.147087: val_loss -0.9826
2023-09-04 19:22:41.149517: Pseudo dice [0.9132]
2023-09-04 19:22:41.151705: Epoch time: 387.55 s
2023-09-04 19:22:42.269039: 
2023-09-04 19:22:42.271602: Epoch 274
2023-09-04 19:22:42.273824: Current learning rate: backbone 0.00011068, others 0.00011068
2023-09-04 19:22:42.276382: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 19:23:43.783796: finished training epoch 274
2023-09-04 19:23:43.827799: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 19:23:43.831167: The split file contains 1 splits.
2023-09-04 19:23:43.833799: Desired fold for training: 0
2023-09-04 19:23:43.835810: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 19:28:57.910990: dsc: 91.09%
2023-09-04 19:28:57.913888: miou: 83.63%
2023-09-04 19:28:57.916105: acc: 95.51%, sen: 91.20%, spe: 96.96%
2023-09-04 19:28:57.918610: current best miou: 0.8422144348184231 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 19:28:57.920788: current best dsc: 0.9143500549125113 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 19:28:57.923287: finished real validation
2023-09-04 19:29:02.319357: train_loss -1.445
2023-09-04 19:29:02.322461: val_loss -1.0052
2023-09-04 19:29:02.325537: Pseudo dice [0.916]
2023-09-04 19:29:02.327782: Epoch time: 380.05 s
2023-09-04 19:29:03.455512: 
2023-09-04 19:29:03.459253: Epoch 275
2023-09-04 19:29:03.461909: Current learning rate: backbone 0.00010684, others 0.00010684
2023-09-04 19:29:03.465050: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 19:30:05.143381: finished training epoch 275
2023-09-04 19:30:05.173536: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 19:30:05.176604: The split file contains 1 splits.
2023-09-04 19:30:05.178890: Desired fold for training: 0
2023-09-04 19:30:05.181013: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 19:35:40.372276: dsc: 91.04%
2023-09-04 19:35:40.374928: miou: 83.55%
2023-09-04 19:35:40.377378: acc: 95.50%, sen: 90.89%, spe: 97.05%
2023-09-04 19:35:40.379933: current best miou: 0.8422144348184231 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 19:35:40.382473: current best dsc: 0.9143500549125113 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 19:35:40.385002: finished real validation
2023-09-04 19:35:44.761481: train_loss -1.4446
2023-09-04 19:35:44.764077: val_loss -0.9931
2023-09-04 19:35:44.766543: Pseudo dice [0.9128]
2023-09-04 19:35:44.768789: Epoch time: 401.31 s
2023-09-04 19:35:45.891365: 
2023-09-04 19:35:45.893823: Epoch 276
2023-09-04 19:35:45.896317: Current learning rate: backbone 0.00010299, others 0.00010299
2023-09-04 19:35:45.898985: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 19:36:47.053966: finished training epoch 276
2023-09-04 19:36:47.084420: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 19:36:47.087517: The split file contains 1 splits.
2023-09-04 19:36:47.089768: Desired fold for training: 0
2023-09-04 19:36:47.091898: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 19:42:06.530950: dsc: 91.11%
2023-09-04 19:42:06.534075: miou: 83.67%
2023-09-04 19:42:06.536569: acc: 95.53%, sen: 91.18%, spe: 96.99%
2023-09-04 19:42:06.539330: current best miou: 0.8422144348184231 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 19:42:06.541943: current best dsc: 0.9143500549125113 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 19:42:06.544374: finished real validation
2023-09-04 19:42:10.921266: train_loss -1.4452
2023-09-04 19:42:10.924242: val_loss -0.9563
2023-09-04 19:42:10.926986: Pseudo dice [0.9117]
2023-09-04 19:42:10.929502: Epoch time: 385.03 s
2023-09-04 19:42:12.062675: 
2023-09-04 19:42:12.065351: Epoch 277
2023-09-04 19:42:12.067570: Current learning rate: backbone 9.912e-05, others 9.912e-05
2023-09-04 19:42:12.070872: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 19:43:13.103825: finished training epoch 277
2023-09-04 19:43:13.133865: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 19:43:13.137014: The split file contains 1 splits.
2023-09-04 19:43:13.139265: Desired fold for training: 0
2023-09-04 19:43:13.141411: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 19:48:23.486522: dsc: 91.09%
2023-09-04 19:48:23.489199: miou: 83.64%
2023-09-04 19:48:23.491883: acc: 95.52%, sen: 90.99%, spe: 97.04%
2023-09-04 19:48:23.495022: current best miou: 0.8422144348184231 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 19:48:23.497577: current best dsc: 0.9143500549125113 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 19:48:23.499942: finished real validation
2023-09-04 19:48:27.890326: train_loss -1.4454
2023-09-04 19:48:27.893083: val_loss -0.9657
2023-09-04 19:48:27.895574: Pseudo dice [0.9099]
2023-09-04 19:48:27.897853: Epoch time: 375.83 s
2023-09-04 19:48:29.020015: 
2023-09-04 19:48:29.022774: Epoch 278
2023-09-04 19:48:29.025298: Current learning rate: backbone 9.523e-05, others 9.523e-05
2023-09-04 19:48:29.029084: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 19:49:30.358885: finished training epoch 278
2023-09-04 19:49:30.399672: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 19:49:30.403293: The split file contains 1 splits.
2023-09-04 19:49:30.405441: Desired fold for training: 0
2023-09-04 19:49:30.407509: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 19:54:40.228076: dsc: 91.07%
2023-09-04 19:54:40.231755: miou: 83.61%
2023-09-04 19:54:40.234303: acc: 95.50%, sen: 91.19%, spe: 96.95%
2023-09-04 19:54:40.237514: current best miou: 0.8422144348184231 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 19:54:40.240150: current best dsc: 0.9143500549125113 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 19:54:40.242746: finished real validation
2023-09-04 19:54:44.630264: train_loss -1.4454
2023-09-04 19:54:44.633116: val_loss -1.0042
2023-09-04 19:54:44.635859: Pseudo dice [0.9154]
2023-09-04 19:54:44.638351: Epoch time: 375.61 s
2023-09-04 19:54:45.759474: 
2023-09-04 19:54:45.761926: Epoch 279
2023-09-04 19:54:45.764363: Current learning rate: backbone 9.132e-05, others 9.132e-05
2023-09-04 19:54:45.766969: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 19:55:46.856758: finished training epoch 279
2023-09-04 19:55:46.894371: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 19:55:46.897587: The split file contains 1 splits.
2023-09-04 19:55:46.899818: Desired fold for training: 0
2023-09-04 19:55:46.902082: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 20:00:55.710252: dsc: 91.08%
2023-09-04 20:00:55.713164: miou: 83.63%
2023-09-04 20:00:55.715371: acc: 95.52%, sen: 90.99%, spe: 97.04%
2023-09-04 20:00:55.717915: current best miou: 0.8422144348184231 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 20:00:55.720222: current best dsc: 0.9143500549125113 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 20:00:55.722296: finished real validation
2023-09-04 20:01:00.106581: train_loss -1.4455
2023-09-04 20:01:00.109367: val_loss -0.9457
2023-09-04 20:01:00.111835: Pseudo dice [0.9098]
2023-09-04 20:01:00.114116: Epoch time: 374.35 s
2023-09-04 20:01:02.806370: 
2023-09-04 20:01:02.808973: Epoch 280
2023-09-04 20:01:02.811481: Current learning rate: backbone 8.74e-05, others 8.74e-05
2023-09-04 20:01:02.814354: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 20:02:03.919994: finished training epoch 280
2023-09-04 20:02:03.960926: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 20:02:03.965322: The split file contains 1 splits.
2023-09-04 20:02:03.967910: Desired fold for training: 0
2023-09-04 20:02:03.970144: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 20:07:29.032647: dsc: 91.05%
2023-09-04 20:07:29.035750: miou: 83.57%
2023-09-04 20:07:29.038022: acc: 95.50%, sen: 90.92%, spe: 97.04%
2023-09-04 20:07:29.041456: current best miou: 0.8422144348184231 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 20:07:29.044050: current best dsc: 0.9143500549125113 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 20:07:29.047756: finished real validation
2023-09-04 20:07:33.447048: train_loss -1.4456
2023-09-04 20:07:33.450109: val_loss -0.9652
2023-09-04 20:07:33.452791: Pseudo dice [0.9105]
2023-09-04 20:07:33.455087: Epoch time: 390.64 s
2023-09-04 20:07:34.614673: 
2023-09-04 20:07:34.617555: Epoch 281
2023-09-04 20:07:34.620337: Current learning rate: backbone 8.346e-05, others 8.346e-05
2023-09-04 20:07:34.623097: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 20:08:36.331993: finished training epoch 281
2023-09-04 20:08:36.372948: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 20:08:36.376257: The split file contains 1 splits.
2023-09-04 20:08:36.378367: Desired fold for training: 0
2023-09-04 20:08:36.380961: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 20:14:05.162592: dsc: 91.11%
2023-09-04 20:14:05.165490: miou: 83.66%
2023-09-04 20:14:05.168088: acc: 95.53%, sen: 90.95%, spe: 97.07%
2023-09-04 20:14:05.170771: current best miou: 0.8422144348184231 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 20:14:05.172943: current best dsc: 0.9143500549125113 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 20:14:05.175175: finished real validation
2023-09-04 20:14:09.555279: train_loss -1.4458
2023-09-04 20:14:09.558069: val_loss -0.9919
2023-09-04 20:14:09.560597: Pseudo dice [0.9148]
2023-09-04 20:14:09.562871: Epoch time: 394.94 s
2023-09-04 20:14:10.691663: 
2023-09-04 20:14:10.694705: Epoch 282
2023-09-04 20:14:10.696932: Current learning rate: backbone 7.949e-05, others 7.949e-05
2023-09-04 20:14:10.699809: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 20:15:11.840723: finished training epoch 282
2023-09-04 20:15:11.888625: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 20:15:11.891989: The split file contains 1 splits.
2023-09-04 20:15:11.894425: Desired fold for training: 0
2023-09-04 20:15:11.896813: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 20:20:30.024121: dsc: 91.06%
2023-09-04 20:20:30.026987: miou: 83.58%
2023-09-04 20:20:30.029323: acc: 95.50%, sen: 90.99%, spe: 97.02%
2023-09-04 20:20:30.032071: current best miou: 0.8422144348184231 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 20:20:30.034212: current best dsc: 0.9143500549125113 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 20:20:30.036633: finished real validation
2023-09-04 20:20:34.437279: train_loss -1.4453
2023-09-04 20:20:34.440168: val_loss -0.9545
2023-09-04 20:20:34.442642: Pseudo dice [0.9086]
2023-09-04 20:20:34.444947: Epoch time: 383.75 s
2023-09-04 20:20:35.574292: 
2023-09-04 20:20:35.577140: Epoch 283
2023-09-04 20:20:35.579761: Current learning rate: backbone 7.551e-05, others 7.551e-05
2023-09-04 20:20:35.582690: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 20:21:36.870826: finished training epoch 283
2023-09-04 20:21:36.901712: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 20:21:36.905437: The split file contains 1 splits.
2023-09-04 20:21:36.908303: Desired fold for training: 0
2023-09-04 20:21:36.911168: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 20:26:44.597579: dsc: 91.04%
2023-09-04 20:26:44.600569: miou: 83.55%
2023-09-04 20:26:44.603047: acc: 95.49%, sen: 91.13%, spe: 96.95%
2023-09-04 20:26:44.605847: current best miou: 0.8422144348184231 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 20:26:44.608148: current best dsc: 0.9143500549125113 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 20:26:44.610465: finished real validation
2023-09-04 20:26:49.002962: train_loss -1.4454
2023-09-04 20:26:49.005623: val_loss -0.9503
2023-09-04 20:26:49.008081: Pseudo dice [0.9093]
2023-09-04 20:26:49.010327: Epoch time: 373.43 s
2023-09-04 20:26:50.125446: 
2023-09-04 20:26:50.128237: Epoch 284
2023-09-04 20:26:50.130518: Current learning rate: backbone 7.15e-05, others 7.15e-05
2023-09-04 20:26:50.133386: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 20:27:51.215718: finished training epoch 284
2023-09-04 20:27:51.257099: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 20:27:51.260552: The split file contains 1 splits.
2023-09-04 20:27:51.262962: Desired fold for training: 0
2023-09-04 20:27:51.265136: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 20:33:08.279460: dsc: 91.07%
2023-09-04 20:33:08.282501: miou: 83.61%
2023-09-04 20:33:08.285005: acc: 95.51%, sen: 91.15%, spe: 96.97%
2023-09-04 20:33:08.287743: current best miou: 0.8422144348184231 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 20:33:08.289951: current best dsc: 0.9143500549125113 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 20:33:08.292269: finished real validation
2023-09-04 20:33:12.684855: train_loss -1.4457
2023-09-04 20:33:12.687625: val_loss -0.975
2023-09-04 20:33:12.690218: Pseudo dice [0.9113]
2023-09-04 20:33:12.692583: Epoch time: 382.56 s
2023-09-04 20:33:13.828999: 
2023-09-04 20:33:13.831934: Epoch 285
2023-09-04 20:33:13.834510: Current learning rate: backbone 6.746e-05, others 6.746e-05
2023-09-04 20:33:13.837335: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 20:34:15.100636: finished training epoch 285
2023-09-04 20:34:15.130934: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 20:34:15.134127: The split file contains 1 splits.
2023-09-04 20:34:15.136430: Desired fold for training: 0
2023-09-04 20:34:15.138620: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 20:39:28.355009: dsc: 91.09%
2023-09-04 20:39:28.357746: miou: 83.63%
2023-09-04 20:39:28.359984: acc: 95.52%, sen: 91.09%, spe: 97.00%
2023-09-04 20:39:28.362563: current best miou: 0.8422144348184231 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 20:39:28.364745: current best dsc: 0.9143500549125113 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 20:39:28.366919: finished real validation
2023-09-04 20:39:32.764390: train_loss -1.4456
2023-09-04 20:39:32.767238: val_loss -0.9511
2023-09-04 20:39:32.769725: Pseudo dice [0.9101]
2023-09-04 20:39:32.772177: Epoch time: 378.94 s
2023-09-04 20:39:33.881623: 
2023-09-04 20:39:33.884221: Epoch 286
2023-09-04 20:39:33.886473: Current learning rate: backbone 6.34e-05, others 6.34e-05
2023-09-04 20:39:33.889000: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 20:40:34.953700: finished training epoch 286
2023-09-04 20:40:34.984018: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 20:40:34.987201: The split file contains 1 splits.
2023-09-04 20:40:34.989493: Desired fold for training: 0
2023-09-04 20:40:34.991735: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 20:46:01.687596: dsc: 91.08%
2023-09-04 20:46:01.690589: miou: 83.62%
2023-09-04 20:46:01.692780: acc: 95.52%, sen: 90.96%, spe: 97.05%
2023-09-04 20:46:01.695267: current best miou: 0.8422144348184231 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 20:46:01.697404: current best dsc: 0.9143500549125113 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 20:46:01.699552: finished real validation
2023-09-04 20:46:06.092247: train_loss -1.446
2023-09-04 20:46:06.095360: val_loss -1.0127
2023-09-04 20:46:06.098247: Pseudo dice [0.9155]
2023-09-04 20:46:06.101152: Epoch time: 392.21 s
2023-09-04 20:46:07.248775: 
2023-09-04 20:46:07.251718: Epoch 287
2023-09-04 20:46:07.254201: Current learning rate: backbone 5.931e-05, others 5.931e-05
2023-09-04 20:46:07.257066: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 20:47:08.413424: finished training epoch 287
2023-09-04 20:47:08.443416: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 20:47:08.446941: The split file contains 1 splits.
2023-09-04 20:47:08.449325: Desired fold for training: 0
2023-09-04 20:47:08.451623: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 20:52:16.461636: dsc: 91.07%
2023-09-04 20:52:16.464530: miou: 83.60%
2023-09-04 20:52:16.466906: acc: 95.51%, sen: 90.92%, spe: 97.06%
2023-09-04 20:52:16.469734: current best miou: 0.8422144348184231 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 20:52:16.472281: current best dsc: 0.9143500549125113 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 20:52:16.474420: finished real validation
2023-09-04 20:52:20.862065: train_loss -1.4455
2023-09-04 20:52:20.864953: val_loss -1.0288
2023-09-04 20:52:20.867491: Pseudo dice [0.9175]
2023-09-04 20:52:20.869961: Epoch time: 373.61 s
2023-09-04 20:52:21.996517: 
2023-09-04 20:52:21.999358: Epoch 288
2023-09-04 20:52:22.001874: Current learning rate: backbone 5.519e-05, others 5.519e-05
2023-09-04 20:52:22.004720: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 20:53:23.069532: finished training epoch 288
2023-09-04 20:53:23.101660: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 20:53:23.105148: The split file contains 1 splits.
2023-09-04 20:53:23.107740: Desired fold for training: 0
2023-09-04 20:53:23.110343: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 20:58:43.903366: dsc: 91.04%
2023-09-04 20:58:43.906345: miou: 83.55%
2023-09-04 20:58:43.908940: acc: 95.49%, sen: 91.01%, spe: 97.00%
2023-09-04 20:58:43.912214: current best miou: 0.8422144348184231 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 20:58:43.914699: current best dsc: 0.9143500549125113 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 20:58:43.917387: finished real validation
2023-09-04 20:58:48.306035: train_loss -1.4455
2023-09-04 20:58:48.309024: val_loss -0.9692
2023-09-04 20:58:48.311792: Pseudo dice [0.9118]
2023-09-04 20:58:48.314365: Epoch time: 386.31 s
2023-09-04 20:58:49.440107: 
2023-09-04 20:58:49.442992: Epoch 289
2023-09-04 20:58:49.445527: Current learning rate: backbone 5.103e-05, others 5.103e-05
2023-09-04 20:58:49.448888: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 20:59:50.643359: finished training epoch 289
2023-09-04 20:59:50.676657: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 20:59:50.680171: The split file contains 1 splits.
2023-09-04 20:59:50.682531: Desired fold for training: 0
2023-09-04 20:59:50.684887: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 21:05:08.928415: dsc: 91.08%
2023-09-04 21:05:08.931756: miou: 83.63%
2023-09-04 21:05:08.934438: acc: 95.52%, sen: 90.93%, spe: 97.07%
2023-09-04 21:05:08.937029: current best miou: 0.8422144348184231 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 21:05:08.939191: current best dsc: 0.9143500549125113 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 21:05:08.941343: finished real validation
2023-09-04 21:05:13.316325: train_loss -1.4454
2023-09-04 21:05:13.319116: val_loss -0.9533
2023-09-04 21:05:13.321586: Pseudo dice [0.9094]
2023-09-04 21:05:13.323849: Epoch time: 383.88 s
2023-09-04 21:05:15.986989: 
2023-09-04 21:05:15.989887: Epoch 290
2023-09-04 21:05:15.992179: Current learning rate: backbone 4.684e-05, others 4.684e-05
2023-09-04 21:05:15.994727: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 21:06:17.007188: finished training epoch 290
2023-09-04 21:06:17.038562: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 21:06:17.042027: The split file contains 1 splits.
2023-09-04 21:06:17.044648: Desired fold for training: 0
2023-09-04 21:06:17.047161: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 21:11:34.966157: dsc: 91.09%
2023-09-04 21:11:34.969182: miou: 83.63%
2023-09-04 21:11:34.971458: acc: 95.51%, sen: 91.14%, spe: 96.98%
2023-09-04 21:11:34.974013: current best miou: 0.8422144348184231 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 21:11:34.976235: current best dsc: 0.9143500549125113 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 21:11:34.978371: finished real validation
2023-09-04 21:11:39.360641: train_loss -1.4461
2023-09-04 21:11:39.363690: val_loss -0.9507
2023-09-04 21:11:39.366438: Pseudo dice [0.9098]
2023-09-04 21:11:39.369122: Epoch time: 383.37 s
2023-09-04 21:11:40.498403: 
2023-09-04 21:11:40.501302: Epoch 291
2023-09-04 21:11:40.503831: Current learning rate: backbone 4.26e-05, others 4.26e-05
2023-09-04 21:11:40.506700: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 21:12:41.574504: finished training epoch 291
2023-09-04 21:12:41.604040: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 21:12:41.607409: The split file contains 1 splits.
2023-09-04 21:12:41.609715: Desired fold for training: 0
2023-09-04 21:12:41.611990: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 21:18:30.588650: dsc: 91.06%
2023-09-04 21:18:30.591586: miou: 83.59%
2023-09-04 21:18:30.593911: acc: 95.51%, sen: 91.03%, spe: 97.01%
2023-09-04 21:18:30.596413: current best miou: 0.8422144348184231 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 21:18:30.598613: current best dsc: 0.9143500549125113 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 21:18:30.600898: finished real validation
2023-09-04 21:18:34.991186: train_loss -1.4456
2023-09-04 21:18:34.994123: val_loss -0.9635
2023-09-04 21:18:34.996756: Pseudo dice [0.9107]
2023-09-04 21:18:34.999110: Epoch time: 414.49 s
2023-09-04 21:18:36.141700: 
2023-09-04 21:18:36.145567: Epoch 292
2023-09-04 21:18:36.149743: Current learning rate: backbone 3.832e-05, others 3.832e-05
2023-09-04 21:18:36.153792: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 21:19:37.338593: finished training epoch 292
2023-09-04 21:19:37.369538: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 21:19:37.372972: The split file contains 1 splits.
2023-09-04 21:19:37.375277: Desired fold for training: 0
2023-09-04 21:19:37.377471: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 21:24:57.849491: dsc: 91.09%
2023-09-04 21:24:57.852338: miou: 83.63%
2023-09-04 21:24:57.854573: acc: 95.52%, sen: 90.91%, spe: 97.08%
2023-09-04 21:24:57.857134: current best miou: 0.8422144348184231 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 21:24:57.859481: current best dsc: 0.9143500549125113 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 21:24:57.861688: finished real validation
2023-09-04 21:25:02.234557: train_loss -1.4456
2023-09-04 21:25:02.237358: val_loss -0.9711
2023-09-04 21:25:02.239982: Pseudo dice [0.9111]
2023-09-04 21:25:02.242317: Epoch time: 386.09 s
2023-09-04 21:25:03.402164: 
2023-09-04 21:25:03.408232: Epoch 293
2023-09-04 21:25:03.414294: Current learning rate: backbone 3.398e-05, others 3.398e-05
2023-09-04 21:25:03.420949: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 21:26:04.668820: finished training epoch 293
2023-09-04 21:26:04.713537: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 21:26:04.716844: The split file contains 1 splits.
2023-09-04 21:26:04.719419: Desired fold for training: 0
2023-09-04 21:26:04.721736: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 21:31:20.590891: dsc: 91.11%
2023-09-04 21:31:20.593713: miou: 83.67%
2023-09-04 21:31:20.596567: acc: 95.53%, sen: 91.00%, spe: 97.06%
2023-09-04 21:31:20.599480: current best miou: 0.8422144348184231 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 21:31:20.601987: current best dsc: 0.9143500549125113 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 21:31:20.604168: finished real validation
2023-09-04 21:31:24.982475: train_loss -1.4458
2023-09-04 21:31:24.985202: val_loss -0.9683
2023-09-04 21:31:24.987658: Pseudo dice [0.9125]
2023-09-04 21:31:24.989934: Epoch time: 381.58 s
2023-09-04 21:31:26.138617: 
2023-09-04 21:31:26.141599: Epoch 294
2023-09-04 21:31:26.144154: Current learning rate: backbone 2.958e-05, others 2.958e-05
2023-09-04 21:31:26.147133: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 21:32:27.405421: finished training epoch 294
2023-09-04 21:32:27.447992: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 21:32:27.451638: The split file contains 1 splits.
2023-09-04 21:32:27.454747: Desired fold for training: 0
2023-09-04 21:32:27.459299: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 21:37:46.129310: dsc: 91.11%
2023-09-04 21:37:46.132942: miou: 83.67%
2023-09-04 21:37:46.135787: acc: 95.53%, sen: 90.96%, spe: 97.07%
2023-09-04 21:37:46.139054: current best miou: 0.8422144348184231 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 21:37:46.141310: current best dsc: 0.9143500549125113 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 21:37:46.143550: finished real validation
2023-09-04 21:37:50.537728: train_loss -1.4457
2023-09-04 21:37:50.540603: val_loss -1.0087
2023-09-04 21:37:50.543286: Pseudo dice [0.9164]
2023-09-04 21:37:50.545587: Epoch time: 384.4 s
2023-09-04 21:37:51.672620: 
2023-09-04 21:37:51.675475: Epoch 295
2023-09-04 21:37:51.678181: Current learning rate: backbone 2.51e-05, others 2.51e-05
2023-09-04 21:37:51.681237: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 21:38:52.930439: finished training epoch 295
2023-09-04 21:38:52.962263: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 21:38:52.965593: The split file contains 1 splits.
2023-09-04 21:38:52.968073: Desired fold for training: 0
2023-09-04 21:38:52.970476: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 21:44:07.587040: dsc: 91.08%
2023-09-04 21:44:07.589834: miou: 83.62%
2023-09-04 21:44:07.592117: acc: 95.52%, sen: 91.00%, spe: 97.03%
2023-09-04 21:44:07.594694: current best miou: 0.8422144348184231 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 21:44:07.596925: current best dsc: 0.9143500549125113 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 21:44:07.599120: finished real validation
2023-09-04 21:44:11.990023: train_loss -1.4457
2023-09-04 21:44:11.992990: val_loss -0.9154
2023-09-04 21:44:11.995536: Pseudo dice [0.9046]
2023-09-04 21:44:11.997869: Epoch time: 380.32 s
2023-09-04 21:44:13.130013: 
2023-09-04 21:44:13.133093: Epoch 296
2023-09-04 21:44:13.135853: Current learning rate: backbone 2.053e-05, others 2.053e-05
2023-09-04 21:44:13.139028: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 21:45:14.146859: finished training epoch 296
2023-09-04 21:45:14.178423: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 21:45:14.181994: The split file contains 1 splits.
2023-09-04 21:45:14.184336: Desired fold for training: 0
2023-09-04 21:45:14.186691: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 21:50:30.728722: dsc: 91.08%
2023-09-04 21:50:30.731770: miou: 83.63%
2023-09-04 21:50:30.734263: acc: 95.52%, sen: 90.97%, spe: 97.05%
2023-09-04 21:50:30.737016: current best miou: 0.8422144348184231 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 21:50:30.739271: current best dsc: 0.9143500549125113 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 21:50:30.741432: finished real validation
2023-09-04 21:50:38.614744: train_loss -1.4461
2023-09-04 21:50:38.617458: val_loss -0.956
2023-09-04 21:50:38.619867: Pseudo dice [0.9105]
2023-09-04 21:50:38.622064: Epoch time: 385.49 s
2023-09-04 21:50:39.760770: 
2023-09-04 21:50:39.764204: Epoch 297
2023-09-04 21:50:39.767028: Current learning rate: backbone 1.585e-05, others 1.585e-05
2023-09-04 21:50:39.770709: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 21:51:40.858974: finished training epoch 297
2023-09-04 21:51:40.887223: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 21:51:40.890730: The split file contains 1 splits.
2023-09-04 21:51:40.893198: Desired fold for training: 0
2023-09-04 21:51:40.895525: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 21:57:06.126612: dsc: 91.08%
2023-09-04 21:57:06.129910: miou: 83.62%
2023-09-04 21:57:06.132213: acc: 95.52%, sen: 90.98%, spe: 97.04%
2023-09-04 21:57:06.134847: current best miou: 0.8422144348184231 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 21:57:06.137160: current best dsc: 0.9143500549125113 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 21:57:06.139450: finished real validation
2023-09-04 21:57:10.531137: train_loss -1.4459
2023-09-04 21:57:10.533980: val_loss -0.9404
2023-09-04 21:57:10.536555: Pseudo dice [0.9074]
2023-09-04 21:57:10.539541: Epoch time: 390.77 s
2023-09-04 21:57:11.662283: 
2023-09-04 21:57:11.665147: Epoch 298
2023-09-04 21:57:11.667448: Current learning rate: backbone 1.1e-05, others 1.1e-05
2023-09-04 21:57:11.670017: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 21:58:12.721576: finished training epoch 298
2023-09-04 21:58:12.756116: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 21:58:12.759635: The split file contains 1 splits.
2023-09-04 21:58:12.762429: Desired fold for training: 0
2023-09-04 21:58:12.765100: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 22:03:39.756101: dsc: 91.09%
2023-09-04 22:03:39.759034: miou: 83.64%
2023-09-04 22:03:39.761386: acc: 95.53%, sen: 90.95%, spe: 97.06%
2023-09-04 22:03:39.764204: current best miou: 0.8422144348184231 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 22:03:39.766484: current best dsc: 0.9143500549125113 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 22:03:39.768709: finished real validation
2023-09-04 22:03:44.151485: train_loss -1.4454
2023-09-04 22:03:44.154682: val_loss -0.9978
2023-09-04 22:03:44.157494: Pseudo dice [0.9143]
2023-09-04 22:03:44.160025: Epoch time: 392.49 s
2023-09-04 22:03:45.284140: 
2023-09-04 22:03:45.287127: Epoch 299
2023-09-04 22:03:45.289943: Current learning rate: backbone 5.9e-06, others 5.9e-06
2023-09-04 22:03:45.292902: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 22:04:46.228563: finished training epoch 299
2023-09-04 22:04:46.259097: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 22:04:46.262642: The split file contains 1 splits.
2023-09-04 22:04:46.265354: Desired fold for training: 0
2023-09-04 22:04:46.268264: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 22:10:30.645979: dsc: 91.08%
2023-09-04 22:10:30.649361: miou: 83.62%
2023-09-04 22:10:30.652125: acc: 95.52%, sen: 90.92%, spe: 97.07%
2023-09-04 22:10:30.656160: current best miou: 0.8422144348184231 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 22:10:30.658532: current best dsc: 0.9143500549125113 at epoch: 31, (31, 0.8422144348184231, 0.9143500549125113)
2023-09-04 22:10:30.662714: finished real validation
2023-09-04 22:10:35.054444: train_loss -1.4458
2023-09-04 22:10:35.057586: val_loss -0.9843
2023-09-04 22:10:35.060510: Pseudo dice [0.9125]
2023-09-04 22:10:35.063123: Epoch time: 409.77 s
2023-09-04 22:10:37.841261: Training done.
2023-09-04 22:10:37.928634: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 22:10:37.932651: The split file contains 1 splits.
2023-09-04 22:10:37.936906: Desired fold for training: 0
2023-09-04 22:10:37.941495: This split has 1886 training and 808 validation cases.
2023-09-04 22:10:37.965632: predicting val_0
2023-09-04 22:10:38.135310: predicting val_1
2023-09-04 22:10:38.286189: predicting val_10
2023-09-04 22:10:38.434685: predicting val_100
2023-09-04 22:10:38.663541: predicting val_101
2023-09-04 22:10:38.803635: predicting val_102
2023-09-04 22:10:38.941226: predicting val_103
2023-09-04 22:10:39.076338: predicting val_104
2023-09-04 22:10:39.216638: predicting val_105
2023-09-04 22:10:39.355864: predicting val_106
2023-09-04 22:10:39.498617: predicting val_107
2023-09-04 22:10:39.640464: predicting val_108
2023-09-04 22:10:39.780010: predicting val_109
2023-09-04 22:10:39.916907: predicting val_11
2023-09-04 22:10:40.065328: predicting val_110
2023-09-04 22:10:40.248204: predicting val_111
2023-09-04 22:10:40.414973: predicting val_112
2023-09-04 22:10:40.571030: predicting val_113
2023-09-04 22:10:40.710647: predicting val_114
2023-09-04 22:10:40.844987: predicting val_115
2023-09-04 22:10:40.985772: predicting val_116
2023-09-04 22:10:41.142646: predicting val_117
2023-09-04 22:10:41.295901: predicting val_118
2023-09-04 22:10:41.476728: predicting val_119
2023-09-04 22:10:42.643136: predicting val_12
2023-09-04 22:10:42.831848: predicting val_120
2023-09-04 22:10:43.003613: predicting val_121
2023-09-04 22:10:43.143381: predicting val_122
2023-09-04 22:10:43.277210: predicting val_123
2023-09-04 22:10:43.411184: predicting val_124
2023-09-04 22:10:43.544900: predicting val_125
2023-09-04 22:10:43.678590: predicting val_126
2023-09-04 22:10:43.811989: predicting val_127
2023-09-04 22:10:43.947221: predicting val_128
2023-09-04 22:10:44.083362: predicting val_129
2023-09-04 22:10:44.216922: predicting val_13
2023-09-04 22:10:44.352728: predicting val_130
2023-09-04 22:10:44.487576: predicting val_131
2023-09-04 22:10:44.621977: predicting val_132
2023-09-04 22:10:44.757514: predicting val_133
2023-09-04 22:10:44.890876: predicting val_134
2023-09-04 22:10:45.025054: predicting val_135
2023-09-04 22:10:45.161729: predicting val_136
2023-09-04 22:10:45.299448: predicting val_137
2023-09-04 22:10:45.433189: predicting val_138
2023-09-04 22:10:45.568273: predicting val_139
2023-09-04 22:10:45.702070: predicting val_14
2023-09-04 22:10:45.835304: predicting val_140
2023-09-04 22:10:45.968682: predicting val_141
2023-09-04 22:10:46.102092: predicting val_142
2023-09-04 22:10:46.234885: predicting val_143
2023-09-04 22:10:46.368560: predicting val_144
2023-09-04 22:10:46.501447: predicting val_145
2023-09-04 22:10:46.635412: predicting val_146
2023-09-04 22:10:46.769651: predicting val_147
2023-09-04 22:10:46.903289: predicting val_148
2023-09-04 22:10:47.036597: predicting val_149
2023-09-04 22:10:47.169615: predicting val_15
2023-09-04 22:10:47.306488: predicting val_150
2023-09-04 22:10:47.440223: predicting val_151
2023-09-04 22:10:47.574495: predicting val_152
2023-09-04 22:10:47.708405: predicting val_153
2023-09-04 22:10:47.841840: predicting val_154
2023-09-04 22:10:47.978991: predicting val_155
2023-09-04 22:10:48.115908: predicting val_156
2023-09-04 22:10:48.251385: predicting val_157
2023-09-04 22:10:48.386126: predicting val_158
2023-09-04 22:10:48.520780: predicting val_159
2023-09-04 22:10:48.657378: predicting val_16
2023-09-04 22:10:48.791732: predicting val_160
2023-09-04 22:10:48.925758: predicting val_161
2023-09-04 22:10:49.060444: predicting val_162
2023-09-04 22:10:49.193984: predicting val_163
2023-09-04 22:10:49.330284: predicting val_164
2023-09-04 22:10:49.463604: predicting val_165
2023-09-04 22:10:49.596318: predicting val_166
2023-09-04 22:10:49.731431: predicting val_167
2023-09-04 22:10:49.865202: predicting val_168
2023-09-04 22:10:49.999499: predicting val_169
2023-09-04 22:10:50.133177: predicting val_17
2023-09-04 22:10:50.266239: predicting val_170
2023-09-04 22:10:50.399009: predicting val_171
2023-09-04 22:10:50.530887: predicting val_172
2023-09-04 22:10:50.664722: predicting val_173
2023-09-04 22:10:50.798420: predicting val_174
2023-09-04 22:10:50.932450: predicting val_175
2023-09-04 22:10:51.065305: predicting val_176
2023-09-04 22:10:51.197911: predicting val_177
2023-09-04 22:10:51.329576: predicting val_178
2023-09-04 22:10:51.464849: predicting val_179
2023-09-04 22:10:51.599621: predicting val_18
2023-09-04 22:10:51.734184: predicting val_180
2023-09-04 22:10:51.868522: predicting val_181
2023-09-04 22:10:52.002224: predicting val_182
2023-09-04 22:10:52.137661: predicting val_183
2023-09-04 22:10:52.271184: predicting val_184
2023-09-04 22:10:52.407324: predicting val_185
2023-09-04 22:10:52.540932: predicting val_186
2023-09-04 22:10:52.672748: predicting val_187
2023-09-04 22:10:52.805571: predicting val_188
2023-09-04 22:10:52.937206: predicting val_189
2023-09-04 22:10:53.070084: predicting val_19
2023-09-04 22:10:53.202104: predicting val_190
2023-09-04 22:10:53.337957: predicting val_191
2023-09-04 22:10:53.472366: predicting val_192
2023-09-04 22:10:53.605580: predicting val_193
2023-09-04 22:10:53.738575: predicting val_194
2023-09-04 22:10:53.870699: predicting val_195
2023-09-04 22:10:54.014979: predicting val_196
2023-09-04 22:10:54.171582: predicting val_197
2023-09-04 22:10:54.310736: predicting val_198
2023-09-04 22:10:54.446809: predicting val_199
2023-09-04 22:10:54.590665: predicting val_2
2023-09-04 22:10:54.725260: predicting val_20
2023-09-04 22:10:54.864151: predicting val_200
2023-09-04 22:10:55.002363: predicting val_201
2023-09-04 22:10:55.135802: predicting val_202
2023-09-04 22:10:55.269974: predicting val_203
2023-09-04 22:10:55.403656: predicting val_204
2023-09-04 22:10:55.539282: predicting val_205
2023-09-04 22:10:55.674131: predicting val_206
2023-09-04 22:10:55.807066: predicting val_207
2023-09-04 22:10:55.951779: predicting val_208
2023-09-04 22:10:56.109116: predicting val_209
2023-09-04 22:10:56.259762: predicting val_21
2023-09-04 22:10:56.409183: predicting val_210
2023-09-04 22:10:56.559702: predicting val_211
2023-09-04 22:10:56.694488: predicting val_212
2023-09-04 22:10:56.828663: predicting val_213
2023-09-04 22:10:56.962603: predicting val_214
2023-09-04 22:10:57.096353: predicting val_215
2023-09-04 22:10:57.255214: predicting val_216
2023-09-04 22:10:57.406168: predicting val_217
2023-09-04 22:10:57.559480: predicting val_218
2023-09-04 22:10:57.709750: predicting val_219
2023-09-04 22:10:57.859394: predicting val_22
2023-09-04 22:10:58.007939: predicting val_220
2023-09-04 22:10:58.160848: predicting val_221
2023-09-04 22:10:58.310690: predicting val_222
2023-09-04 22:10:58.460092: predicting val_223
2023-09-04 22:10:58.608567: predicting val_224
2023-09-04 22:10:58.776599: predicting val_225
2023-09-04 22:10:58.928166: predicting val_226
2023-09-04 22:10:59.078318: predicting val_227
2023-09-04 22:10:59.228052: predicting val_228
2023-09-04 22:10:59.377093: predicting val_229
2023-09-04 22:10:59.526385: predicting val_23
2023-09-04 22:10:59.672573: predicting val_230
2023-09-04 22:10:59.807920: predicting val_231
2023-09-04 22:10:59.939881: predicting val_232
2023-09-04 22:11:00.072933: predicting val_233
2023-09-04 22:11:00.214515: predicting val_234
2023-09-04 22:11:00.348297: predicting val_235
2023-09-04 22:11:00.482114: predicting val_236
2023-09-04 22:11:00.617046: predicting val_237
2023-09-04 22:11:00.753096: predicting val_238
2023-09-04 22:11:00.888722: predicting val_239
2023-09-04 22:11:01.022402: predicting val_24
2023-09-04 22:11:01.157206: predicting val_240
2023-09-04 22:11:01.297852: predicting val_241
2023-09-04 22:11:01.432399: predicting val_242
2023-09-04 22:11:01.566368: predicting val_243
2023-09-04 22:11:01.704482: predicting val_244
2023-09-04 22:11:01.838202: predicting val_245
2023-09-04 22:11:01.971418: predicting val_246
2023-09-04 22:11:02.104978: predicting val_247
2023-09-04 22:11:02.238872: predicting val_248
2023-09-04 22:11:02.371966: predicting val_249
2023-09-04 22:11:02.504759: predicting val_25
2023-09-04 22:11:02.664634: predicting val_250
2023-09-04 22:11:02.812893: predicting val_251
2023-09-04 22:11:02.949826: predicting val_252
2023-09-04 22:11:03.105932: predicting val_253
2023-09-04 22:11:03.255965: predicting val_254
2023-09-04 22:11:03.407458: predicting val_255
2023-09-04 22:11:03.566528: predicting val_256
2023-09-04 22:11:03.714644: predicting val_257
2023-09-04 22:11:03.866935: predicting val_258
2023-09-04 22:11:04.016717: predicting val_259
2023-09-04 22:11:04.167070: predicting val_26
2023-09-04 22:11:04.302685: predicting val_260
2023-09-04 22:11:04.441841: predicting val_261
2023-09-04 22:11:04.578007: predicting val_262
2023-09-04 22:11:04.712533: predicting val_263
2023-09-04 22:11:04.846575: predicting val_264
2023-09-04 22:11:04.980415: predicting val_265
2023-09-04 22:11:05.113020: predicting val_266
2023-09-04 22:11:05.246114: predicting val_267
2023-09-04 22:11:05.380216: predicting val_268
2023-09-04 22:11:05.513769: predicting val_269
2023-09-04 22:11:05.648240: predicting val_27
2023-09-04 22:11:05.783628: predicting val_270
2023-09-04 22:11:05.917658: predicting val_271
2023-09-04 22:11:06.050535: predicting val_272
2023-09-04 22:11:06.183244: predicting val_273
2023-09-04 22:11:06.317719: predicting val_274
2023-09-04 22:11:06.453457: predicting val_275
2023-09-04 22:11:06.590132: predicting val_276
2023-09-04 22:11:06.725861: predicting val_277
2023-09-04 22:11:06.860044: predicting val_278
2023-09-04 22:11:06.995520: predicting val_279
2023-09-04 22:11:07.129145: predicting val_28
2023-09-04 22:11:07.264908: predicting val_280
2023-09-04 22:11:07.399529: predicting val_281
2023-09-04 22:11:07.537323: predicting val_282
2023-09-04 22:11:07.671814: predicting val_283
2023-09-04 22:11:07.808750: predicting val_284
2023-09-04 22:11:07.944731: predicting val_285
2023-09-04 22:11:08.078507: predicting val_286
2023-09-04 22:11:08.212743: predicting val_287
2023-09-04 22:11:08.347852: predicting val_288
2023-09-04 22:11:08.481112: predicting val_289
2023-09-04 22:11:08.615413: predicting val_29
2023-09-04 22:11:08.756098: predicting val_290
2023-09-04 22:11:08.887859: predicting val_291
2023-09-04 22:11:09.020233: predicting val_292
2023-09-04 22:11:09.159080: predicting val_293
2023-09-04 22:11:09.294484: predicting val_294
2023-09-04 22:11:09.431508: predicting val_295
2023-09-04 22:11:09.564894: predicting val_296
2023-09-04 22:11:09.703635: predicting val_297
2023-09-04 22:11:09.841018: predicting val_298
2023-09-04 22:11:09.979758: predicting val_299
2023-09-04 22:11:10.114316: predicting val_3
2023-09-04 22:11:10.248537: predicting val_30
2023-09-04 22:11:10.382510: predicting val_300
2023-09-04 22:11:10.516413: predicting val_301
2023-09-04 22:11:10.652684: predicting val_302
2023-09-04 22:11:10.786707: predicting val_303
2023-09-04 22:11:10.921324: predicting val_304
2023-09-04 22:11:11.056092: predicting val_305
2023-09-04 22:11:11.187283: predicting val_306
2023-09-04 22:11:11.323852: predicting val_307
2023-09-04 22:11:11.457155: predicting val_308
2023-09-04 22:11:11.593939: predicting val_309
2023-09-04 22:11:11.726119: predicting val_31
2023-09-04 22:11:11.866769: predicting val_310
2023-09-04 22:11:12.020597: predicting val_311
2023-09-04 22:11:12.169930: predicting val_312
2023-09-04 22:11:12.317736: predicting val_313
2023-09-04 22:11:12.453415: predicting val_314
2023-09-04 22:11:12.584688: predicting val_315
2023-09-04 22:11:12.718209: predicting val_316
2023-09-04 22:11:12.847930: predicting val_317
2023-09-04 22:11:12.980161: predicting val_318
2023-09-04 22:11:13.111697: predicting val_319
2023-09-04 22:11:13.243414: predicting val_32
2023-09-04 22:11:13.373878: predicting val_320
2023-09-04 22:11:13.508193: predicting val_321
2023-09-04 22:11:13.641168: predicting val_322
2023-09-04 22:11:13.775010: predicting val_323
2023-09-04 22:11:13.908350: predicting val_324
2023-09-04 22:11:14.040794: predicting val_325
2023-09-04 22:11:14.172261: predicting val_326
2023-09-04 22:11:14.304532: predicting val_327
2023-09-04 22:11:14.436393: predicting val_328
2023-09-04 22:11:14.588225: predicting val_329
2023-09-04 22:11:14.738570: predicting val_33
2023-09-04 22:11:14.878699: predicting val_330
2023-09-04 22:11:15.009474: predicting val_331
2023-09-04 22:11:15.141327: predicting val_332
2023-09-04 22:11:15.274954: predicting val_333
2023-09-04 22:11:15.407392: predicting val_334
2023-09-04 22:11:15.538414: predicting val_335
2023-09-04 22:11:15.672371: predicting val_336
2023-09-04 22:11:15.806101: predicting val_337
2023-09-04 22:11:15.940760: predicting val_338
2023-09-04 22:11:16.070791: predicting val_339
2023-09-04 22:11:16.205723: predicting val_34
2023-09-04 22:11:16.340636: predicting val_340
2023-09-04 22:11:16.474848: predicting val_341
2023-09-04 22:11:16.607283: predicting val_342
2023-09-04 22:11:16.747286: predicting val_343
2023-09-04 22:11:16.885376: predicting val_344
2023-09-04 22:11:17.023866: predicting val_345
2023-09-04 22:11:17.156339: predicting val_346
2023-09-04 22:11:17.291995: predicting val_347
2023-09-04 22:11:17.427372: predicting val_348
2023-09-04 22:11:17.562111: predicting val_349
2023-09-04 22:11:17.693756: predicting val_35
2023-09-04 22:11:17.828106: predicting val_350
2023-09-04 22:11:17.965005: predicting val_351
2023-09-04 22:11:18.100389: predicting val_352
2023-09-04 22:11:18.232957: predicting val_353
2023-09-04 22:11:18.365614: predicting val_354
2023-09-04 22:11:18.499596: predicting val_355
2023-09-04 22:11:18.638184: predicting val_356
2023-09-04 22:11:18.767427: predicting val_357
2023-09-04 22:11:18.899453: predicting val_358
2023-09-04 22:11:19.032366: predicting val_359
2023-09-04 22:11:19.165118: predicting val_36
2023-09-04 22:11:19.302220: predicting val_360
2023-09-04 22:11:19.435620: predicting val_361
2023-09-04 22:11:19.567852: predicting val_362
2023-09-04 22:11:19.703551: predicting val_363
2023-09-04 22:11:19.833390: predicting val_364
2023-09-04 22:11:19.967635: predicting val_365
2023-09-04 22:11:20.101964: predicting val_366
2023-09-04 22:11:20.235666: predicting val_367
2023-09-04 22:11:20.367805: predicting val_368
2023-09-04 22:11:20.500616: predicting val_369
2023-09-04 22:11:20.634954: predicting val_37
2023-09-04 22:11:20.769319: predicting val_370
2023-09-04 22:11:20.899598: predicting val_371
2023-09-04 22:11:21.034029: predicting val_372
2023-09-04 22:11:21.168355: predicting val_373
2023-09-04 22:11:21.304048: predicting val_374
2023-09-04 22:11:21.436116: predicting val_375
2023-09-04 22:11:21.569963: predicting val_376
2023-09-04 22:11:21.704000: predicting val_377
2023-09-04 22:11:21.837119: predicting val_378
2023-09-04 22:11:21.968658: predicting val_379
2023-09-04 22:11:22.102490: predicting val_38
2023-09-04 22:11:22.234786: predicting val_380
2023-09-04 22:11:22.368865: predicting val_381
2023-09-04 22:11:22.499955: predicting val_382
2023-09-04 22:11:22.634637: predicting val_383
2023-09-04 22:11:22.769301: predicting val_384
2023-09-04 22:11:22.905333: predicting val_385
2023-09-04 22:11:23.036606: predicting val_386
2023-09-04 22:11:23.170997: predicting val_387
2023-09-04 22:11:23.306692: predicting val_388
2023-09-04 22:11:23.441031: predicting val_389
2023-09-04 22:11:23.574013: predicting val_39
2023-09-04 22:11:23.707286: predicting val_390
2023-09-04 22:11:23.841373: predicting val_391
2023-09-04 22:11:23.977258: predicting val_392
2023-09-04 22:11:24.112926: predicting val_393
2023-09-04 22:11:24.247695: predicting val_394
2023-09-04 22:11:24.382830: predicting val_395
2023-09-04 22:11:24.517243: predicting val_396
2023-09-04 22:11:24.650130: predicting val_397
2023-09-04 22:11:24.784273: predicting val_398
2023-09-04 22:11:24.918106: predicting val_399
2023-09-04 22:11:25.051589: predicting val_4
2023-09-04 22:11:25.185703: predicting val_40
2023-09-04 22:11:25.319825: predicting val_400
2023-09-04 22:11:25.452755: predicting val_401
2023-09-04 22:11:25.585755: predicting val_402
2023-09-04 22:11:25.716841: predicting val_403
2023-09-04 22:11:25.850605: predicting val_404
2023-09-04 22:11:25.984991: predicting val_405
2023-09-04 22:11:26.119201: predicting val_406
2023-09-04 22:11:26.250751: predicting val_407
2023-09-04 22:11:26.385178: predicting val_408
2023-09-04 22:11:26.519577: predicting val_409
2023-09-04 22:11:26.655202: predicting val_41
2023-09-04 22:11:26.786510: predicting val_410
2023-09-04 22:11:26.928695: predicting val_411
2023-09-04 22:11:27.084239: predicting val_412
2023-09-04 22:11:27.233732: predicting val_413
2023-09-04 22:11:27.382174: predicting val_414
2023-09-04 22:11:27.519986: predicting val_415
2023-09-04 22:11:27.655831: predicting val_416
2023-09-04 22:11:27.792174: predicting val_417
2023-09-04 22:11:27.924579: predicting val_418
2023-09-04 22:11:28.076210: predicting val_419
2023-09-04 22:11:28.225753: predicting val_42
2023-09-04 22:11:28.374053: predicting val_420
2023-09-04 22:11:28.520951: predicting val_421
2023-09-04 22:11:28.670605: predicting val_422
2023-09-04 22:11:28.806426: predicting val_423
2023-09-04 22:11:28.941201: predicting val_424
2023-09-04 22:11:29.074261: predicting val_425
2023-09-04 22:11:29.208042: predicting val_426
2023-09-04 22:11:29.343718: predicting val_427
2023-09-04 22:11:29.478101: predicting val_428
2023-09-04 22:11:29.609038: predicting val_429
2023-09-04 22:11:29.745461: predicting val_43
2023-09-04 22:11:29.880226: predicting val_430
2023-09-04 22:11:30.034057: predicting val_431
2023-09-04 22:11:30.182369: predicting val_432
2023-09-04 22:11:30.318684: predicting val_433
2023-09-04 22:11:30.452138: predicting val_434
2023-09-04 22:11:30.584665: predicting val_435
2023-09-04 22:11:30.716909: predicting val_436
2023-09-04 22:11:30.850872: predicting val_437
2023-09-04 22:11:30.984505: predicting val_438
2023-09-04 22:11:31.123659: predicting val_439
2023-09-04 22:11:31.257221: predicting val_44
2023-09-04 22:11:31.390770: predicting val_440
2023-09-04 22:11:31.524159: predicting val_441
2023-09-04 22:11:31.658977: predicting val_442
2023-09-04 22:11:31.789143: predicting val_443
2023-09-04 22:11:31.922692: predicting val_444
2023-09-04 22:11:32.055361: predicting val_445
2023-09-04 22:11:32.187732: predicting val_446
2023-09-04 22:11:32.326827: predicting val_447
2023-09-04 22:11:32.462812: predicting val_448
2023-09-04 22:11:32.597826: predicting val_449
2023-09-04 22:11:32.733249: predicting val_45
2023-09-04 22:11:32.873871: predicting val_450
2023-09-04 22:11:33.006698: predicting val_451
2023-09-04 22:11:33.140996: predicting val_452
2023-09-04 22:11:33.274546: predicting val_453
2023-09-04 22:11:33.427518: predicting val_454
2023-09-04 22:11:33.565047: predicting val_455
2023-09-04 22:11:33.700522: predicting val_456
2023-09-04 22:11:33.852803: predicting val_457
2023-09-04 22:11:34.002248: predicting val_458
2023-09-04 22:11:34.153987: predicting val_459
2023-09-04 22:11:34.296980: predicting val_46
2023-09-04 22:11:34.432614: predicting val_460
2023-09-04 22:11:34.565717: predicting val_461
2023-09-04 22:11:34.699455: predicting val_462
2023-09-04 22:11:34.836338: predicting val_463
2023-09-04 22:11:34.969316: predicting val_464
2023-09-04 22:11:35.102351: predicting val_465
2023-09-04 22:11:35.235306: predicting val_466
2023-09-04 22:11:35.369485: predicting val_467
2023-09-04 22:11:35.502649: predicting val_468
2023-09-04 22:11:35.636697: predicting val_469
2023-09-04 22:11:35.771638: predicting val_47
2023-09-04 22:11:35.905560: predicting val_470
2023-09-04 22:11:36.040446: predicting val_471
2023-09-04 22:11:36.173458: predicting val_472
2023-09-04 22:11:36.328588: predicting val_473
2023-09-04 22:11:36.479279: predicting val_474
2023-09-04 22:11:36.616608: predicting val_475
2023-09-04 22:11:36.749336: predicting val_476
2023-09-04 22:11:36.884542: predicting val_477
2023-09-04 22:11:37.019184: predicting val_478
2023-09-04 22:11:37.154309: predicting val_479
2023-09-04 22:11:37.286526: predicting val_48
2023-09-04 22:11:37.421606: predicting val_480
2023-09-04 22:11:37.554451: predicting val_481
2023-09-04 22:11:37.692249: predicting val_482
2023-09-04 22:11:37.831446: predicting val_483
2023-09-04 22:11:37.967253: predicting val_484
2023-09-04 22:11:38.105923: predicting val_485
2023-09-04 22:11:38.238711: predicting val_486
2023-09-04 22:11:38.372354: predicting val_487
2023-09-04 22:11:38.507166: predicting val_488
2023-09-04 22:11:38.640584: predicting val_489
2023-09-04 22:11:38.773556: predicting val_49
2023-09-04 22:11:38.909449: predicting val_490
2023-09-04 22:11:39.045657: predicting val_491
2023-09-04 22:11:39.182348: predicting val_492
2023-09-04 22:11:39.316902: predicting val_493
2023-09-04 22:11:39.448558: predicting val_494
2023-09-04 22:11:39.583445: predicting val_495
2023-09-04 22:11:39.717986: predicting val_496
2023-09-04 22:11:39.852161: predicting val_497
2023-09-04 22:11:39.987391: predicting val_498
2023-09-04 22:11:40.126129: predicting val_499
2023-09-04 22:11:40.266824: predicting val_5
2023-09-04 22:11:40.404036: predicting val_50
2023-09-04 22:11:40.537818: predicting val_500
2023-09-04 22:11:40.674247: predicting val_501
2023-09-04 22:11:40.813188: predicting val_502
2023-09-04 22:11:40.948128: predicting val_503
2023-09-04 22:11:41.082473: predicting val_504
2023-09-04 22:11:41.215977: predicting val_505
2023-09-04 22:11:41.349896: predicting val_506
2023-09-04 22:11:41.510022: predicting val_507
2023-09-04 22:11:41.659794: predicting val_508
2023-09-04 22:11:41.814067: predicting val_509
2023-09-04 22:11:41.964954: predicting val_51
2023-09-04 22:11:42.114171: predicting val_510
2023-09-04 22:11:42.253113: predicting val_511
2023-09-04 22:11:42.397642: predicting val_512
2023-09-04 22:11:42.534954: predicting val_513
2023-09-04 22:11:42.670118: predicting val_514
2023-09-04 22:11:42.805823: predicting val_515
2023-09-04 22:11:42.941738: predicting val_516
2023-09-04 22:11:43.077233: predicting val_517
2023-09-04 22:11:43.217573: predicting val_518
2023-09-04 22:11:43.351239: predicting val_519
2023-09-04 22:11:43.486608: predicting val_52
2023-09-04 22:11:43.624084: predicting val_520
2023-09-04 22:11:43.767683: predicting val_521
2023-09-04 22:11:43.905239: predicting val_522
2023-09-04 22:11:44.039635: predicting val_523
2023-09-04 22:11:44.176793: predicting val_524
2023-09-04 22:11:44.309936: predicting val_525
2023-09-04 22:11:44.450554: predicting val_526
2023-09-04 22:11:44.586471: predicting val_527
2023-09-04 22:11:44.721393: predicting val_528
2023-09-04 22:11:44.857000: predicting val_529
2023-09-04 22:11:44.991664: predicting val_53
2023-09-04 22:11:45.127282: predicting val_530
2023-09-04 22:11:45.267768: predicting val_531
2023-09-04 22:11:45.899803: predicting val_532
2023-09-04 22:11:46.040999: predicting val_533
2023-09-04 22:11:46.175935: predicting val_534
2023-09-04 22:11:46.321254: predicting val_535
2023-09-04 22:11:46.461835: predicting val_536
2023-09-04 22:11:46.596190: predicting val_537
2023-09-04 22:11:46.738228: predicting val_538
2023-09-04 22:11:46.874628: predicting val_539
2023-09-04 22:11:47.017527: predicting val_54
2023-09-04 22:11:47.148988: predicting val_540
2023-09-04 22:11:47.281585: predicting val_541
2023-09-04 22:11:47.414057: predicting val_542
2023-09-04 22:11:47.551755: predicting val_543
2023-09-04 22:11:47.697410: predicting val_544
2023-09-04 22:11:47.830466: predicting val_545
2023-09-04 22:11:47.962994: predicting val_546
2023-09-04 22:11:48.095265: predicting val_547
2023-09-04 22:11:48.226596: predicting val_548
2023-09-04 22:11:48.359979: predicting val_549
2023-09-04 22:11:48.493403: predicting val_55
2023-09-04 22:11:48.625743: predicting val_550
2023-09-04 22:11:48.762106: predicting val_551
2023-09-04 22:11:48.905603: predicting val_552
2023-09-04 22:11:49.039867: predicting val_553
2023-09-04 22:11:49.174263: predicting val_554
2023-09-04 22:11:49.306673: predicting val_555
2023-09-04 22:11:49.438538: predicting val_556
2023-09-04 22:11:49.572633: predicting val_557
2023-09-04 22:11:49.706163: predicting val_558
2023-09-04 22:11:49.835705: predicting val_559
2023-09-04 22:11:49.968269: predicting val_56
2023-09-04 22:11:50.101571: predicting val_560
2023-09-04 22:11:50.236816: predicting val_561
2023-09-04 22:11:50.370627: predicting val_562
2023-09-04 22:11:50.504683: predicting val_563
2023-09-04 22:11:50.639954: predicting val_564
2023-09-04 22:11:50.781574: predicting val_565
2023-09-04 22:11:50.911794: predicting val_566
2023-09-04 22:11:51.046170: predicting val_567
2023-09-04 22:11:51.179194: predicting val_568
2023-09-04 22:11:51.317649: predicting val_569
2023-09-04 22:11:51.451337: predicting val_57
2023-09-04 22:11:51.586140: predicting val_570
2023-09-04 22:11:51.721181: predicting val_571
2023-09-04 22:11:51.855013: predicting val_572
2023-09-04 22:11:51.985720: predicting val_573
2023-09-04 22:11:52.120038: predicting val_574
2023-09-04 22:11:52.253009: predicting val_575
2023-09-04 22:11:52.385768: predicting val_576
2023-09-04 22:11:52.519427: predicting val_577
2023-09-04 22:11:52.655227: predicting val_578
2023-09-04 22:11:52.790890: predicting val_579
2023-09-04 22:11:52.927502: predicting val_58
2023-09-04 22:11:53.059349: predicting val_580
2023-09-04 22:11:53.193902: predicting val_581
2023-09-04 22:11:53.329190: predicting val_582
2023-09-04 22:11:53.463985: predicting val_583
2023-09-04 22:11:53.599044: predicting val_584
2023-09-04 22:11:53.733072: predicting val_585
2023-09-04 22:11:53.867439: predicting val_586
2023-09-04 22:11:54.002979: predicting val_587
2023-09-04 22:11:54.135201: predicting val_588
2023-09-04 22:11:54.270489: predicting val_589
2023-09-04 22:11:54.405799: predicting val_59
2023-09-04 22:11:54.541162: predicting val_590
2023-09-04 22:11:54.677542: predicting val_591
2023-09-04 22:11:54.815342: predicting val_592
2023-09-04 22:11:54.949087: predicting val_593
2023-09-04 22:11:55.085446: predicting val_594
2023-09-04 22:11:55.217692: predicting val_595
2023-09-04 22:11:55.351870: predicting val_596
2023-09-04 22:11:55.487257: predicting val_597
2023-09-04 22:11:55.621706: predicting val_598
2023-09-04 22:11:55.755486: predicting val_599
2023-09-04 22:11:55.892635: predicting val_6
2023-09-04 22:11:56.026949: predicting val_60
2023-09-04 22:11:56.165620: predicting val_600
2023-09-04 22:11:56.298454: predicting val_601
2023-09-04 22:11:56.432853: predicting val_602
2023-09-04 22:11:56.567169: predicting val_603
2023-09-04 22:11:56.707496: predicting val_604
2023-09-04 22:11:56.840984: predicting val_605
2023-09-04 22:11:56.973679: predicting val_606
2023-09-04 22:11:57.109622: predicting val_607
2023-09-04 22:11:57.243808: predicting val_608
2023-09-04 22:11:57.376745: predicting val_609
2023-09-04 22:11:57.510887: predicting val_61
2023-09-04 22:11:57.645937: predicting val_610
2023-09-04 22:11:57.781884: predicting val_611
2023-09-04 22:11:57.916667: predicting val_612
2023-09-04 22:11:58.051952: predicting val_613
2023-09-04 22:11:58.186255: predicting val_614
2023-09-04 22:11:58.320232: predicting val_615
2023-09-04 22:11:58.452573: predicting val_616
2023-09-04 22:11:58.586868: predicting val_617
2023-09-04 22:11:58.722455: predicting val_618
2023-09-04 22:11:58.862904: predicting val_619
2023-09-04 22:11:58.999636: predicting val_62
2023-09-04 22:11:59.134719: predicting val_620
2023-09-04 22:11:59.269789: predicting val_621
2023-09-04 22:11:59.406175: predicting val_622
2023-09-04 22:11:59.540077: predicting val_623
2023-09-04 22:11:59.675542: predicting val_624
2023-09-04 22:11:59.815401: predicting val_625
2023-09-04 22:11:59.948771: predicting val_626
2023-09-04 22:12:00.082565: predicting val_627
2023-09-04 22:12:00.232325: predicting val_628
2023-09-04 22:12:00.382675: predicting val_629
2023-09-04 22:12:00.531856: predicting val_63
2023-09-04 22:12:00.680810: predicting val_630
2023-09-04 22:12:00.831616: predicting val_631
2023-09-04 22:12:00.982660: predicting val_632
2023-09-04 22:12:01.132757: predicting val_633
2023-09-04 22:12:01.283563: predicting val_634
2023-09-04 22:12:01.420049: predicting val_635
2023-09-04 22:12:01.554582: predicting val_636
2023-09-04 22:12:01.688703: predicting val_637
2023-09-04 22:12:01.819712: predicting val_638
2023-09-04 22:12:01.953237: predicting val_639
2023-09-04 22:12:02.086090: predicting val_64
2023-09-04 22:12:02.219174: predicting val_640
2023-09-04 22:12:02.352091: predicting val_641
2023-09-04 22:12:02.490910: predicting val_642
2023-09-04 22:12:02.623629: predicting val_643
2023-09-04 22:12:02.757309: predicting val_644
2023-09-04 22:12:02.887560: predicting val_645
2023-09-04 22:12:03.020763: predicting val_646
2023-09-04 22:12:03.153249: predicting val_647
2023-09-04 22:12:03.292877: predicting val_648
2023-09-04 22:12:03.427203: predicting val_649
2023-09-04 22:12:03.582373: predicting val_65
2023-09-04 22:12:03.730919: predicting val_650
2023-09-04 22:12:03.865294: predicting val_651
2023-09-04 22:12:03.996622: predicting val_652
2023-09-04 22:12:04.129459: predicting val_653
2023-09-04 22:12:04.262067: predicting val_654
2023-09-04 22:12:04.395069: predicting val_655
2023-09-04 22:12:04.528203: predicting val_656
2023-09-04 22:12:04.660895: predicting val_657
2023-09-04 22:12:04.803503: predicting val_658
2023-09-04 22:12:04.938615: predicting val_659
2023-09-04 22:12:05.072966: predicting val_66
2023-09-04 22:12:05.208071: predicting val_660
2023-09-04 22:12:05.342850: predicting val_661
2023-09-04 22:12:05.477769: predicting val_662
2023-09-04 22:12:05.613175: predicting val_663
2023-09-04 22:12:05.751544: predicting val_664
2023-09-04 22:12:05.894770: predicting val_665
2023-09-04 22:12:06.030663: predicting val_666
2023-09-04 22:12:06.166317: predicting val_667
2023-09-04 22:12:06.300280: predicting val_668
2023-09-04 22:12:06.432841: predicting val_669
2023-09-04 22:12:06.565386: predicting val_67
2023-09-04 22:12:06.704161: predicting val_670
2023-09-04 22:12:06.837058: predicting val_671
2023-09-04 22:12:06.970883: predicting val_672
2023-09-04 22:12:07.103999: predicting val_673
2023-09-04 22:12:07.236148: predicting val_674
2023-09-04 22:12:07.375213: predicting val_675
2023-09-04 22:12:07.509485: predicting val_676
2023-09-04 22:12:07.643924: predicting val_677
2023-09-04 22:12:07.778068: predicting val_678
2023-09-04 22:12:07.911929: predicting val_679
2023-09-04 22:12:08.046082: predicting val_68
2023-09-04 22:12:08.179863: predicting val_680
2023-09-04 22:12:08.310477: predicting val_681
2023-09-04 22:12:08.445721: predicting val_682
2023-09-04 22:12:08.581597: predicting val_683
2023-09-04 22:12:08.717455: predicting val_684
2023-09-04 22:12:08.851038: predicting val_685
2023-09-04 22:12:08.986158: predicting val_686
2023-09-04 22:12:09.120669: predicting val_687
2023-09-04 22:12:09.260253: predicting val_688
2023-09-04 22:12:09.392741: predicting val_689
2023-09-04 22:12:09.528212: predicting val_69
2023-09-04 22:12:09.685914: predicting val_690
2023-09-04 22:12:09.861971: predicting val_691
2023-09-04 22:12:10.020747: predicting val_692
2023-09-04 22:12:10.162244: predicting val_693
2023-09-04 22:12:10.296872: predicting val_694
2023-09-04 22:12:10.431879: predicting val_695
2023-09-04 22:12:10.563259: predicting val_696
2023-09-04 22:12:10.699298: predicting val_697
2023-09-04 22:12:10.839394: predicting val_698
2023-09-04 22:12:10.977584: predicting val_699
2023-09-04 22:12:11.115918: predicting val_7
2023-09-04 22:12:11.252053: predicting val_70
2023-09-04 22:12:11.396733: predicting val_700
2023-09-04 22:12:11.530626: predicting val_701
2023-09-04 22:12:11.661386: predicting val_702
2023-09-04 22:12:11.804770: predicting val_703
2023-09-04 22:12:11.938740: predicting val_704
2023-09-04 22:12:12.071757: predicting val_705
2023-09-04 22:12:12.202306: predicting val_706
2023-09-04 22:12:12.335126: predicting val_707
2023-09-04 22:12:12.471829: predicting val_708
2023-09-04 22:12:12.608737: predicting val_709
2023-09-04 22:12:12.746509: predicting val_71
2023-09-04 22:12:12.881889: predicting val_710
2023-09-04 22:12:13.015620: predicting val_711
2023-09-04 22:12:13.149795: predicting val_712
2023-09-04 22:12:13.281318: predicting val_713
2023-09-04 22:12:13.417017: predicting val_714
2023-09-04 22:12:13.551078: predicting val_715
2023-09-04 22:12:13.685736: predicting val_716
2023-09-04 22:12:13.817125: predicting val_717
2023-09-04 22:12:13.950682: predicting val_718
2023-09-04 22:12:14.085045: predicting val_719
2023-09-04 22:12:14.218491: predicting val_72
2023-09-04 22:12:14.349403: predicting val_720
2023-09-04 22:12:14.482889: predicting val_721
2023-09-04 22:12:14.617720: predicting val_722
2023-09-04 22:12:14.752582: predicting val_723
2023-09-04 22:12:14.885928: predicting val_724
2023-09-04 22:12:15.022152: predicting val_725
2023-09-04 22:12:15.156650: predicting val_726
2023-09-04 22:12:15.291655: predicting val_727
2023-09-04 22:12:15.425088: predicting val_728
2023-09-04 22:12:15.559304: predicting val_729
2023-09-04 22:12:15.694690: predicting val_73
2023-09-04 22:12:15.830097: predicting val_730
2023-09-04 22:12:15.969212: predicting val_731
2023-09-04 22:12:16.104371: predicting val_732
2023-09-04 22:12:16.239259: predicting val_733
2023-09-04 22:12:16.376412: predicting val_734
2023-09-04 22:12:16.507621: predicting val_735
2023-09-04 22:12:16.641083: predicting val_736
2023-09-04 22:12:16.775980: predicting val_737
2023-09-04 22:12:16.910057: predicting val_738
2023-09-04 22:12:17.042073: predicting val_739
2023-09-04 22:12:17.177090: predicting val_74
2023-09-04 22:12:17.311809: predicting val_740
2023-09-04 22:12:17.445477: predicting val_741
2023-09-04 22:12:17.577169: predicting val_742
2023-09-04 22:12:17.712583: predicting val_743
2023-09-04 22:12:17.847507: predicting val_744
2023-09-04 22:12:17.980032: predicting val_745
2023-09-04 22:12:18.111785: predicting val_746
2023-09-04 22:12:18.245513: predicting val_747
2023-09-04 22:12:18.379447: predicting val_748
2023-09-04 22:12:18.513996: predicting val_749
2023-09-04 22:12:18.647945: predicting val_75
2023-09-04 22:12:18.788352: predicting val_750
2023-09-04 22:12:18.921569: predicting val_751
2023-09-04 22:12:19.075121: predicting val_752
2023-09-04 22:12:19.221933: predicting val_753
2023-09-04 22:12:19.372223: predicting val_754
2023-09-04 22:12:19.523703: predicting val_755
2023-09-04 22:12:19.669770: predicting val_756
2023-09-04 22:12:19.829458: predicting val_757
2023-09-04 22:12:19.982684: predicting val_758
2023-09-04 22:12:20.135271: predicting val_759
2023-09-04 22:12:20.287744: predicting val_76
2023-09-04 22:12:20.435992: predicting val_760
2023-09-04 22:12:20.587121: predicting val_761
2023-09-04 22:12:20.738450: predicting val_762
2023-09-04 22:12:20.888444: predicting val_763
2023-09-04 22:12:21.034620: predicting val_764
2023-09-04 22:12:21.169906: predicting val_765
2023-09-04 22:12:21.304968: predicting val_766
2023-09-04 22:12:21.454286: predicting val_767
2023-09-04 22:12:21.601219: predicting val_768
2023-09-04 22:12:21.750664: predicting val_769
2023-09-04 22:12:21.900945: predicting val_77
2023-09-04 22:12:22.050192: predicting val_770
2023-09-04 22:12:22.189444: predicting val_771
2023-09-04 22:12:22.326430: predicting val_772
2023-09-04 22:12:22.460970: predicting val_773
2023-09-04 22:12:22.593820: predicting val_774
2023-09-04 22:12:22.725332: predicting val_775
2023-09-04 22:12:22.858531: predicting val_776
2023-09-04 22:12:22.991034: predicting val_777
2023-09-04 22:12:23.123891: predicting val_778
2023-09-04 22:12:23.258615: predicting val_779
2023-09-04 22:12:23.392143: predicting val_78
2023-09-04 22:12:23.525086: predicting val_780
2023-09-04 22:12:23.660784: predicting val_781
2023-09-04 22:12:23.792809: predicting val_782
2023-09-04 22:12:23.926350: predicting val_783
2023-09-04 22:12:24.060138: predicting val_784
2023-09-04 22:12:24.194021: predicting val_785
2023-09-04 22:12:24.324425: predicting val_786
2023-09-04 22:12:24.456755: predicting val_787
2023-09-04 22:12:24.587891: predicting val_788
2023-09-04 22:12:24.720044: predicting val_789
2023-09-04 22:12:24.852223: predicting val_79
2023-09-04 22:12:24.986290: predicting val_790
2023-09-04 22:12:25.124479: predicting val_791
2023-09-04 22:12:25.259796: predicting val_792
2023-09-04 22:12:25.395440: predicting val_793
2023-09-04 22:12:25.532642: predicting val_794
2023-09-04 22:12:25.665281: predicting val_795
2023-09-04 22:12:25.800874: predicting val_796
2023-09-04 22:12:25.935451: predicting val_797
2023-09-04 22:12:26.089094: predicting val_798
2023-09-04 22:12:26.240407: predicting val_799
2023-09-04 22:12:26.390038: predicting val_8
2023-09-04 22:12:26.539490: predicting val_80
2023-09-04 22:12:26.690439: predicting val_800
2023-09-04 22:12:26.837718: predicting val_801
2023-09-04 22:12:26.986928: predicting val_802
2023-09-04 22:12:27.134833: predicting val_803
2023-09-04 22:12:27.284477: predicting val_804
2023-09-04 22:12:27.433731: predicting val_805
2023-09-04 22:12:27.585924: predicting val_806
2023-09-04 22:12:27.733247: predicting val_807
2023-09-04 22:12:27.883464: predicting val_81
2023-09-04 22:12:28.031022: predicting val_82
2023-09-04 22:12:28.181286: predicting val_83
2023-09-04 22:12:28.329535: predicting val_84
2023-09-04 22:12:28.480505: predicting val_85
2023-09-04 22:12:28.630755: predicting val_86
2023-09-04 22:12:28.781202: predicting val_87
2023-09-04 22:12:28.921432: predicting val_88
2023-09-04 22:12:29.055869: predicting val_89
2023-09-04 22:12:29.194351: predicting val_9
2023-09-04 22:12:29.328750: predicting val_90
2023-09-04 22:12:29.483469: predicting val_91
2023-09-04 22:12:29.625266: predicting val_92
2023-09-04 22:12:29.758174: predicting val_93
2023-09-04 22:12:29.892555: predicting val_94
2023-09-04 22:12:30.023515: predicting val_95
2023-09-04 22:12:30.156357: predicting val_96
2023-09-04 22:12:30.287476: predicting val_97
2023-09-04 22:12:30.419761: predicting val_98
2023-09-04 22:12:30.569577: predicting val_99
2023-09-04 22:12:38.219248: Validation complete
2023-09-04 22:12:38.221977: Mean Validation Dice:  0.9025852683436826
