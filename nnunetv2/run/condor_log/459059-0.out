OrderedDict([('self', <Parameter "self">), ('plans', <Parameter "plans: dict">), ('configuration', <Parameter "configuration: str">), ('fold', <Parameter "fold: int">), ('dataset_json', <Parameter "dataset_json: dict">), ('unpack_dataset', <Parameter "unpack_dataset: bool = True">), ('device', <Parameter "device: torch.device = device(type='cuda')">), ('debug', <Parameter "debug=True">), ('job_id', <Parameter "job_id=None">)])
Using device: cuda:0
==========================initial_lr: 0.005===========================
2023-09-05 23:42:27.420809: I am training on qa-rtx6k-022.crc.nd.edu
2023-09-05 23:42:27.422411: output folder: /afs/crc.nd.edu/user/y/ypeng4/data/trained_models/Dataset122_ISIC2017/ISICTrainer__nnUNetPlans__2d/458835_my_unet_FusedMBConv_16/fold_0

#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################

===============use SpatialAtt + ChannelAtt and My attention layer===============
model: PVTNetwork_5(
  (backbone): pvt_v2_b2(
    (patch_embed1): OverlapPatchEmbed(
      (proj): Conv2d(3, 64, kernel_size=(7, 7), stride=(4, 4), padding=(3, 3))
      (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
    )
    (patch_embed2): OverlapPatchEmbed(
      (proj): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
    )
    (patch_embed3): OverlapPatchEmbed(
      (proj): Conv2d(128, 320, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
    )
    (patch_embed4): OverlapPatchEmbed(
      (proj): Conv2d(320, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    )
    (block1): ModuleList(
      (0): Block(
        (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=64, out_features=64, bias=True)
          (kv): Linear(in_features=64, out_features=128, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=64, out_features=64, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (sr): Conv2d(64, 64, kernel_size=(8, 8), stride=(8, 8))
          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (drop_path): Identity()
        (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=64, out_features=512, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
          )
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=512, out_features=64, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (1): Block(
        (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=64, out_features=64, bias=True)
          (kv): Linear(in_features=64, out_features=128, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=64, out_features=64, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (sr): Conv2d(64, 64, kernel_size=(8, 8), stride=(8, 8))
          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (drop_path): DropPath(drop_prob=0.007)
        (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=64, out_features=512, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
          )
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=512, out_features=64, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (2): Block(
        (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=64, out_features=64, bias=True)
          (kv): Linear(in_features=64, out_features=128, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=64, out_features=64, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (sr): Conv2d(64, 64, kernel_size=(8, 8), stride=(8, 8))
          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (drop_path): DropPath(drop_prob=0.013)
        (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=64, out_features=512, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
          )
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=512, out_features=64, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
    )
    (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
    (block2): ModuleList(
      (0): Block(
        (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=128, out_features=128, bias=True)
          (kv): Linear(in_features=128, out_features=256, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=128, out_features=128, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (sr): Conv2d(128, 128, kernel_size=(4, 4), stride=(4, 4))
          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (drop_path): DropPath(drop_prob=0.020)
        (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=128, out_features=1024, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
          )
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=1024, out_features=128, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (1): Block(
        (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=128, out_features=128, bias=True)
          (kv): Linear(in_features=128, out_features=256, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=128, out_features=128, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (sr): Conv2d(128, 128, kernel_size=(4, 4), stride=(4, 4))
          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (drop_path): DropPath(drop_prob=0.027)
        (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=128, out_features=1024, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
          )
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=1024, out_features=128, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (2): Block(
        (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=128, out_features=128, bias=True)
          (kv): Linear(in_features=128, out_features=256, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=128, out_features=128, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (sr): Conv2d(128, 128, kernel_size=(4, 4), stride=(4, 4))
          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (drop_path): DropPath(drop_prob=0.033)
        (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=128, out_features=1024, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
          )
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=1024, out_features=128, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (3): Block(
        (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=128, out_features=128, bias=True)
          (kv): Linear(in_features=128, out_features=256, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=128, out_features=128, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (sr): Conv2d(128, 128, kernel_size=(4, 4), stride=(4, 4))
          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (drop_path): DropPath(drop_prob=0.040)
        (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=128, out_features=1024, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
          )
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=1024, out_features=128, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
    )
    (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
    (block3): ModuleList(
      (0): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
        )
        (drop_path): DropPath(drop_prob=0.047)
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (1): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
        )
        (drop_path): DropPath(drop_prob=0.053)
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (2): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
        )
        (drop_path): DropPath(drop_prob=0.060)
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (3): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
        )
        (drop_path): DropPath(drop_prob=0.067)
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (4): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
        )
        (drop_path): DropPath(drop_prob=0.073)
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (5): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
        )
        (drop_path): DropPath(drop_prob=0.080)
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
    )
    (norm3): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
    (block4): ModuleList(
      (0): Block(
        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=512, out_features=512, bias=True)
          (kv): Linear(in_features=512, out_features=1024, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (drop_path): DropPath(drop_prob=0.087)
        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)
          )
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (1): Block(
        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=512, out_features=512, bias=True)
          (kv): Linear(in_features=512, out_features=1024, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (drop_path): DropPath(drop_prob=0.093)
        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)
          )
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (2): Block(
        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=512, out_features=512, bias=True)
          (kv): Linear(in_features=512, out_features=1024, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (drop_path): DropPath(drop_prob=0.100)
        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)
          )
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
    )
    (norm4): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
  )
  (Translayer_1): BasicConv2d(
    (conv): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (Translayer_2): BasicConv2d(
    (conv): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (Translayer_3): BasicConv2d(
    (conv): Conv2d(320, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (Translayer_4): BasicConv2d(
    (conv): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (attention_1): AttentionLayer(
    (convs): ModuleList(
      (0-3): 4 x Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
  )
  (attention_2): AttentionLayer(
    (convs): ModuleList(
      (0-3): 4 x Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
  )
  (attention_3): AttentionLayer(
    (convs): ModuleList(
      (0-3): 4 x Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
  )
  (attention_4): AttentionLayer(
    (convs): ModuleList(
      (0-3): 4 x Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
  )
  (seg_outs): ModuleList(
    (0-3): 4 x Conv2d(32, 2, kernel_size=(1, 1), stride=(1, 1))
  )
  (deconv2): ConvTranspose2d(32, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
  (deconv3): ConvTranspose2d(32, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
  (deconv4): ConvTranspose2d(32, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
  (deconv5): ConvTranspose2d(32, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
)
===============<class 'nnunetv2.training.network.model.dim2.pvt.pvt_5.PVTNetwork_5'>================
ds wegihts: [0.53333333 0.26666667 0.13333333 0.06666667]
loading from : /afs/crc.nd.edu/user/y/ypeng4/data/trained_models/Dataset122_ISIC2017/ISICTrainer__nnUNetPlans__2d/458835_my_unet_FusedMBConv_16/fold_0/checkpoint_latest.pth

This is the configuration used by this training:
Configuration name: 2d
 {'data_identifier': 'nnUNetPlans_2d', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 49, 'patch_size': [256, 256], 'median_image_size_in_voxels': [256.0, 256.0], 'spacing': [1.0, 1.0], 'normalization_schemes': ['ZScoreNormalization', 'ZScoreNormalization', 'ZScoreNormalization'], 'use_mask_for_norm': [False, False, False], 'UNet_class_name': 'ResidualEncoderUNet', 'nnUNet_UNet': False, 'UNet_base_num_features': 32, 'my_net_class': 'pvt_5', 'n_conv_per_stage_encoder': [2, 2, 2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2, 2, 2], 'num_pool_per_axis': [6, 6], 'pool_op_kernel_sizes': [[1, 1], [2, 2], [2, 2], [2, 2], [2, 2], [2, 2], [2, 2]], 'conv_kernel_sizes': [[3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3]], 'unet_max_num_features': 512, 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'batch_dice': True} 

These are the global plan.json settings:
 {'dataset_name': 'Dataset122_ISIC2017', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [999.0, 1.0, 1.0], 'original_median_shape_after_transp': [1, 256, 256], 'image_reader_writer': 'NaturalImage2DIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 255.0, 'mean': 160.1475372314453, 'median': 164.0, 'min': 0.0, 'percentile_00_5': 34.0, 'percentile_99_5': 252.0, 'std': 41.12111282348633}, '1': {'max': 255.0, 'mean': 111.18875122070312, 'median': 113.0, 'min': 0.0, 'percentile_00_5': 10.0, 'percentile_99_5': 222.0, 'std': 42.475669860839844}, '2': {'max': 255.0, 'mean': 91.16386413574219, 'median': 90.0, 'min': 0.0, 'percentile_00_5': 5.0, 'percentile_99_5': 207.0, 'std': 42.03706359863281}}} 

2023-09-05 23:42:35.438144: unpacking dataset...
2023-09-05 23:42:55.588702: unpacking done...
2023-09-05 23:42:55.590164: do_dummy_2d_data_aug: False
2023-09-05 23:42:55.607551: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset122_ISIC2017/splits_final.json
2023-09-05 23:42:55.608449: The split file contains 1 splits.
2023-09-05 23:42:55.608958: Desired fold for training: 0
2023-09-05 23:42:55.609305: This split has 1500 training and 650 validation cases.
==================batch size: 49==================
2023-09-05 23:42:55.641335: Unable to plot network architecture:
2023-09-05 23:42:55.641795: No module named 'hiddenlayer'
PVTNetwork_5
===================debug: False===================
2023-09-05 23:42:57.590352: 
2023-09-05 23:42:57.591097: Epoch 110
2023-09-05 23:42:57.591800: Current learning rate: backbone 0.00066293, others 0.00066293
2023-09-05 23:42:57.592335: start training, 250
==========num_iterations_per_epoch: 250===========
using pin_memory on device 0
2023-09-05 23:44:07.877165: finished training epoch 110
2023-09-05 23:44:07.902679: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset122_ISIC2017/splits_final.json
2023-09-05 23:44:07.904093: The split file contains 1 splits.
2023-09-05 23:44:07.904682: Desired fold for training: 0
2023-09-05 23:44:07.905192: This split has 1500 training and 650 validation cases.
start computing score....
2023-09-05 23:48:01.310041: dsc: 90.14%
2023-09-05 23:48:01.311069: miou: 82.04%
2023-09-05 23:48:01.311880: acc: 96.73%, sen: 89.32%, spe: 98.22%
2023-09-05 23:48:01.312855: current best miou: 0.8204230950507166 at epoch: 110, (110, 0.8204230950507166, 0.901354303053225)
2023-09-05 23:48:01.313481: current best dsc: 0.901354303053225 at epoch: 110, (110, 0.8204230950507166, 0.901354303053225)
2023-09-05 23:48:02.903807: finished real validation
using pin_memory on device 0
2023-09-05 23:48:07.813148: train_loss -1.4368
2023-09-05 23:48:07.814440: val_loss -1.1206
2023-09-05 23:48:07.815926: Pseudo dice [0.9006]
2023-09-05 23:48:07.816648: Epoch time: 310.22 s
2023-09-05 23:48:12.496476: 
2023-09-05 23:48:12.497467: Epoch 111
2023-09-05 23:48:12.498211: Current learning rate: backbone 0.00065979, others 0.00065979
2023-09-05 23:48:12.499446: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-05 23:49:11.132486: finished training epoch 111
2023-09-05 23:49:11.156963: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset122_ISIC2017/splits_final.json
2023-09-05 23:49:11.158538: The split file contains 1 splits.
2023-09-05 23:49:11.159186: Desired fold for training: 0
2023-09-05 23:49:11.159775: This split has 1500 training and 650 validation cases.
start computing score....
2023-09-05 23:53:34.599400: dsc: 89.99%
2023-09-05 23:53:34.600678: miou: 81.79%
2023-09-05 23:53:34.601723: acc: 96.66%, sen: 89.51%, spe: 98.10%
2023-09-05 23:53:34.603880: current best miou: 0.8204230950507166 at epoch: 110, (110, 0.8204230950507166, 0.901354303053225)
2023-09-05 23:53:34.604857: current best dsc: 0.901354303053225 at epoch: 110, (110, 0.8204230950507166, 0.901354303053225)
2023-09-05 23:53:34.605668: finished real validation
2023-09-05 23:53:38.750496: train_loss -1.4365
2023-09-05 23:53:38.751717: val_loss -1.1156
2023-09-05 23:53:38.752594: Pseudo dice [0.9002]
2023-09-05 23:53:38.753254: Epoch time: 326.26 s
2023-09-05 23:53:39.875609: 
2023-09-05 23:53:39.876560: Epoch 112
2023-09-05 23:53:39.877436: Current learning rate: backbone 0.00065665, others 0.00065665
2023-09-05 23:53:39.878676: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-05 23:54:39.428146: finished training epoch 112
2023-09-05 23:54:39.465590: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset122_ISIC2017/splits_final.json
2023-09-05 23:54:39.467166: The split file contains 1 splits.
2023-09-05 23:54:39.468044: Desired fold for training: 0
2023-09-05 23:54:39.468603: This split has 1500 training and 650 validation cases.
start computing score....
2023-09-05 23:59:11.870725: dsc: 90.00%
2023-09-05 23:59:11.871931: miou: 81.82%
2023-09-05 23:59:11.872596: acc: 96.66%, sen: 89.74%, spe: 98.05%
2023-09-05 23:59:11.873533: current best miou: 0.8204230950507166 at epoch: 110, (110, 0.8204230950507166, 0.901354303053225)
2023-09-05 23:59:11.874099: current best dsc: 0.901354303053225 at epoch: 110, (110, 0.8204230950507166, 0.901354303053225)
2023-09-05 23:59:11.874608: finished real validation
2023-09-05 23:59:16.032254: train_loss -1.4371
2023-09-05 23:59:16.033341: val_loss -1.0776
2023-09-05 23:59:16.034399: Pseudo dice [0.8963]
2023-09-05 23:59:16.035176: Epoch time: 336.16 s
2023-09-05 23:59:17.139220: 
2023-09-05 23:59:17.140188: Epoch 113
2023-09-05 23:59:17.140870: Current learning rate: backbone 0.0006535, others 0.0006535
2023-09-05 23:59:17.142090: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-06 00:00:16.113558: finished training epoch 113
2023-09-06 00:00:16.145407: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset122_ISIC2017/splits_final.json
2023-09-06 00:00:16.147129: The split file contains 1 splits.
2023-09-06 00:00:16.147759: Desired fold for training: 0
2023-09-06 00:00:16.148326: This split has 1500 training and 650 validation cases.
start computing score....
2023-09-06 00:04:35.326963: dsc: 90.02%
2023-09-06 00:04:35.328383: miou: 81.85%
2023-09-06 00:04:35.329043: acc: 96.68%, sen: 89.38%, spe: 98.15%
2023-09-06 00:04:35.330163: current best miou: 0.8204230950507166 at epoch: 110, (110, 0.8204230950507166, 0.901354303053225)
2023-09-06 00:04:35.330932: current best dsc: 0.901354303053225 at epoch: 110, (110, 0.8204230950507166, 0.901354303053225)
2023-09-06 00:04:35.331525: finished real validation
2023-09-06 00:04:39.523183: train_loss -1.437
2023-09-06 00:04:39.524824: val_loss -1.1396
2023-09-06 00:04:39.526160: Pseudo dice [0.9059]
2023-09-06 00:04:39.527029: Epoch time: 322.39 s
2023-09-06 00:04:40.641689: 
2023-09-06 00:04:40.642623: Epoch 114
2023-09-06 00:04:40.643286: Current learning rate: backbone 0.00065036, others 0.00065036
2023-09-06 00:04:40.644597: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-06 00:05:39.651342: finished training epoch 114
2023-09-06 00:05:39.686694: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset122_ISIC2017/splits_final.json
2023-09-06 00:05:39.689032: The split file contains 1 splits.
2023-09-06 00:05:39.690116: Desired fold for training: 0
2023-09-06 00:05:39.690961: This split has 1500 training and 650 validation cases.
start computing score....
2023-09-06 00:09:41.357889: dsc: 89.97%
2023-09-06 00:09:41.359009: miou: 81.76%
2023-09-06 00:09:41.359595: acc: 96.66%, sen: 89.49%, spe: 98.10%
2023-09-06 00:09:41.360518: current best miou: 0.8204230950507166 at epoch: 110, (110, 0.8204230950507166, 0.901354303053225)
2023-09-06 00:09:41.361113: current best dsc: 0.901354303053225 at epoch: 110, (110, 0.8204230950507166, 0.901354303053225)
2023-09-06 00:09:41.361636: finished real validation
2023-09-06 00:09:45.560468: train_loss -1.4372
2023-09-06 00:09:45.561558: val_loss -1.1048
2023-09-06 00:09:45.562443: Pseudo dice [0.9018]
2023-09-06 00:09:45.563065: Epoch time: 304.92 s
2023-09-06 00:09:46.645123: 
2023-09-06 00:09:46.646464: Epoch 115
2023-09-06 00:09:46.647344: Current learning rate: backbone 0.00064721, others 0.00064721
2023-09-06 00:09:46.648952: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-06 00:10:45.309219: finished training epoch 115
2023-09-06 00:10:45.334007: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset122_ISIC2017/splits_final.json
2023-09-06 00:10:45.335421: The split file contains 1 splits.
2023-09-06 00:10:45.336049: Desired fold for training: 0
2023-09-06 00:10:45.336581: This split has 1500 training and 650 validation cases.
start computing score....
2023-09-06 00:14:58.616127: dsc: 90.07%
2023-09-06 00:14:58.617271: miou: 81.93%
2023-09-06 00:14:58.617926: acc: 96.70%, sen: 89.29%, spe: 98.19%
2023-09-06 00:14:58.618870: current best miou: 0.8204230950507166 at epoch: 110, (110, 0.8204230950507166, 0.901354303053225)
2023-09-06 00:14:58.619546: current best dsc: 0.901354303053225 at epoch: 110, (110, 0.8204230950507166, 0.901354303053225)
2023-09-06 00:14:58.620123: finished real validation
2023-09-06 00:15:02.810424: train_loss -1.438
2023-09-06 00:15:02.811553: val_loss -1.1032
2023-09-06 00:15:02.812403: Pseudo dice [0.8995]
2023-09-06 00:15:02.813107: Epoch time: 316.17 s
2023-09-06 00:15:03.958541: 
2023-09-06 00:15:03.959697: Epoch 116
2023-09-06 00:15:03.960477: Current learning rate: backbone 0.00064406, others 0.00064406
2023-09-06 00:15:03.961535: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-06 00:16:02.645226: finished training epoch 116
2023-09-06 00:16:02.668710: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset122_ISIC2017/splits_final.json
2023-09-06 00:16:02.670125: The split file contains 1 splits.
2023-09-06 00:16:02.670815: Desired fold for training: 0
2023-09-06 00:16:02.671429: This split has 1500 training and 650 validation cases.
start computing score....
2023-09-06 00:20:21.406890: dsc: 89.91%
2023-09-06 00:20:21.407875: miou: 81.67%
2023-09-06 00:20:21.408895: acc: 96.66%, sen: 88.86%, spe: 98.23%
2023-09-06 00:20:21.409757: current best miou: 0.8204230950507166 at epoch: 110, (110, 0.8204230950507166, 0.901354303053225)
2023-09-06 00:20:21.410438: current best dsc: 0.901354303053225 at epoch: 110, (110, 0.8204230950507166, 0.901354303053225)
2023-09-06 00:20:21.411023: finished real validation
2023-09-06 00:20:25.595105: train_loss -1.4372
2023-09-06 00:20:25.596451: val_loss -1.084
2023-09-06 00:20:25.597637: Pseudo dice [0.8957]
2023-09-06 00:20:25.598391: Epoch time: 321.64 s
2023-09-06 00:20:26.726685: 
2023-09-06 00:20:26.727881: Epoch 117
2023-09-06 00:20:26.728669: Current learning rate: backbone 0.00064091, others 0.00064091
2023-09-06 00:20:26.729974: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-06 00:21:25.473435: finished training epoch 117
2023-09-06 00:21:25.499024: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset122_ISIC2017/splits_final.json
2023-09-06 00:21:25.500515: The split file contains 1 splits.
2023-09-06 00:21:25.501304: Desired fold for training: 0
2023-09-06 00:21:25.501907: This split has 1500 training and 650 validation cases.
start computing score....
2023-09-06 00:26:04.011259: dsc: 90.07%
2023-09-06 00:26:04.012442: miou: 81.94%
2023-09-06 00:26:04.013174: acc: 96.73%, sen: 88.53%, spe: 98.38%
2023-09-06 00:26:04.014173: current best miou: 0.8204230950507166 at epoch: 110, (110, 0.8204230950507166, 0.901354303053225)
2023-09-06 00:26:04.014878: current best dsc: 0.901354303053225 at epoch: 110, (110, 0.8204230950507166, 0.901354303053225)
2023-09-06 00:26:04.015472: finished real validation
2023-09-06 00:26:08.224040: train_loss -1.4375
2023-09-06 00:26:08.225318: val_loss -1.1085
2023-09-06 00:26:08.226311: Pseudo dice [0.904]
2023-09-06 00:26:08.227082: Epoch time: 341.5 s
2023-09-06 00:26:09.349596: 
2023-09-06 00:26:09.350586: Epoch 118
2023-09-06 00:26:09.351347: Current learning rate: backbone 0.00063776, others 0.00063776
2023-09-06 00:26:09.352556: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-06 00:27:08.110200: finished training epoch 118
2023-09-06 00:27:08.135082: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset122_ISIC2017/splits_final.json
2023-09-06 00:27:08.136673: The split file contains 1 splits.
2023-09-06 00:27:08.137438: Desired fold for training: 0
2023-09-06 00:27:08.138653: This split has 1500 training and 650 validation cases.
start computing score....
2023-09-06 00:31:26.977217: dsc: 89.76%
2023-09-06 00:31:26.978551: miou: 81.42%
2023-09-06 00:31:26.979342: acc: 96.60%, sen: 88.90%, spe: 98.15%
2023-09-06 00:31:26.980576: current best miou: 0.8204230950507166 at epoch: 110, (110, 0.8204230950507166, 0.901354303053225)
2023-09-06 00:31:26.981261: current best dsc: 0.901354303053225 at epoch: 110, (110, 0.8204230950507166, 0.901354303053225)
2023-09-06 00:31:26.981902: finished real validation
2023-09-06 00:31:31.137027: train_loss -1.4379
2023-09-06 00:31:31.139130: val_loss -1.0972
2023-09-06 00:31:31.140565: Pseudo dice [0.898]
2023-09-06 00:31:31.141403: Epoch time: 321.79 s
2023-09-06 00:31:32.275188: 
2023-09-06 00:31:32.276484: Epoch 119
2023-09-06 00:31:32.277312: Current learning rate: backbone 0.0006346, others 0.0006346
2023-09-06 00:31:32.278569: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-06 00:32:30.951355: finished training epoch 119
2023-09-06 00:32:30.979169: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset122_ISIC2017/splits_final.json
2023-09-06 00:32:30.980589: The split file contains 1 splits.
2023-09-06 00:32:30.981437: Desired fold for training: 0
2023-09-06 00:32:30.982042: This split has 1500 training and 650 validation cases.
start computing score....
2023-09-06 00:37:18.214120: dsc: 89.95%
2023-09-06 00:37:18.215403: miou: 81.74%
2023-09-06 00:37:18.216314: acc: 96.66%, sen: 89.34%, spe: 98.13%
2023-09-06 00:37:18.217387: current best miou: 0.8204230950507166 at epoch: 110, (110, 0.8204230950507166, 0.901354303053225)
2023-09-06 00:37:18.218192: current best dsc: 0.901354303053225 at epoch: 110, (110, 0.8204230950507166, 0.901354303053225)
2023-09-06 00:37:18.218835: finished real validation
2023-09-06 00:37:22.439688: train_loss -1.4379
2023-09-06 00:37:22.441088: val_loss -1.1221
2023-09-06 00:37:22.442040: Pseudo dice [0.9035]
2023-09-06 00:37:22.442840: Epoch time: 350.17 s
2023-09-06 00:37:25.419853: 
2023-09-06 00:37:25.421082: Epoch 120
2023-09-06 00:37:25.421882: Current learning rate: backbone 0.00063145, others 0.00063145
2023-09-06 00:37:25.423042: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-06 00:38:24.225229: finished training epoch 120
2023-09-06 00:38:24.289217: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset122_ISIC2017/splits_final.json
2023-09-06 00:38:24.290946: The split file contains 1 splits.
2023-09-06 00:38:24.291658: Desired fold for training: 0
2023-09-06 00:38:24.292337: This split has 1500 training and 650 validation cases.
start computing score....
2023-09-06 00:42:49.299506: dsc: 90.07%
2023-09-06 00:42:49.300882: miou: 81.93%
2023-09-06 00:42:49.301574: acc: 96.72%, sen: 88.92%, spe: 98.28%
2023-09-06 00:42:49.302644: current best miou: 0.8204230950507166 at epoch: 110, (110, 0.8204230950507166, 0.901354303053225)
2023-09-06 00:42:49.303344: current best dsc: 0.901354303053225 at epoch: 110, (110, 0.8204230950507166, 0.901354303053225)
2023-09-06 00:42:49.303998: finished real validation
2023-09-06 00:42:53.523001: train_loss -1.4379
2023-09-06 00:42:53.524406: val_loss -1.1016
2023-09-06 00:42:53.525415: Pseudo dice [0.8983]
2023-09-06 00:42:53.526198: Epoch time: 328.1 s
2023-09-06 00:42:54.638512: 
2023-09-06 00:42:54.639513: Epoch 121
2023-09-06 00:42:54.640318: Current learning rate: backbone 0.00062829, others 0.00062829
2023-09-06 00:42:54.641866: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-06 00:43:53.804528: finished training epoch 121
2023-09-06 00:43:53.830968: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset122_ISIC2017/splits_final.json
2023-09-06 00:43:53.832643: The split file contains 1 splits.
2023-09-06 00:43:53.833429: Desired fold for training: 0
2023-09-06 00:43:53.834157: This split has 1500 training and 650 validation cases.
start computing score....
2023-09-06 00:48:21.792298: dsc: 90.07%
2023-09-06 00:48:21.793469: miou: 81.94%
2023-09-06 00:48:21.794149: acc: 96.70%, sen: 89.44%, spe: 98.16%
2023-09-06 00:48:21.795155: current best miou: 0.8204230950507166 at epoch: 110, (110, 0.8204230950507166, 0.901354303053225)
2023-09-06 00:48:21.795789: current best dsc: 0.901354303053225 at epoch: 110, (110, 0.8204230950507166, 0.901354303053225)
2023-09-06 00:48:21.796371: finished real validation
2023-09-06 00:48:25.922282: train_loss -1.4379
2023-09-06 00:48:25.923577: val_loss -1.1108
2023-09-06 00:48:25.925194: Pseudo dice [0.9021]
2023-09-06 00:48:25.926582: Epoch time: 331.29 s
2023-09-06 00:48:25.927646: Yayy! New best EMA pseudo Dice: 0.8999
2023-09-06 00:48:28.702970: 
2023-09-06 00:48:28.703988: Epoch 122
2023-09-06 00:48:28.704823: Current learning rate: backbone 0.00062513, others 0.00062513
2023-09-06 00:48:28.705984: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-06 00:49:28.094208: finished training epoch 122
2023-09-06 00:49:28.121504: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset122_ISIC2017/splits_final.json
2023-09-06 00:49:28.123812: The split file contains 1 splits.
2023-09-06 00:49:28.124844: Desired fold for training: 0
2023-09-06 00:49:28.125874: This split has 1500 training and 650 validation cases.
start computing score....
2023-09-06 00:53:59.642569: dsc: 90.01%
2023-09-06 00:53:59.644031: miou: 81.83%
2023-09-06 00:53:59.644832: acc: 96.70%, sen: 88.75%, spe: 98.30%
2023-09-06 00:53:59.645928: current best miou: 0.8204230950507166 at epoch: 110, (110, 0.8204230950507166, 0.901354303053225)
2023-09-06 00:53:59.646693: current best dsc: 0.901354303053225 at epoch: 110, (110, 0.8204230950507166, 0.901354303053225)
2023-09-06 00:53:59.647305: finished real validation
2023-09-06 00:54:03.819911: train_loss -1.4381
2023-09-06 00:54:03.821824: val_loss -1.1421
2023-09-06 00:54:03.823229: Pseudo dice [0.9063]
2023-09-06 00:54:03.824135: Epoch time: 335.12 s
2023-09-06 00:54:03.824838: Yayy! New best EMA pseudo Dice: 0.9006
2023-09-06 00:54:06.633297: 
2023-09-06 00:54:06.634505: Epoch 123
2023-09-06 00:54:06.635343: Current learning rate: backbone 0.00062197, others 0.00062197
2023-09-06 00:54:06.636693: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-06 00:55:06.104273: finished training epoch 123
2023-09-06 00:55:06.142182: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset122_ISIC2017/splits_final.json
2023-09-06 00:55:06.144018: The split file contains 1 splits.
2023-09-06 00:55:06.144923: Desired fold for training: 0
2023-09-06 00:55:06.145636: This split has 1500 training and 650 validation cases.
start computing score....
2023-09-06 00:59:33.938196: dsc: 89.96%
2023-09-06 00:59:33.939407: miou: 81.75%
2023-09-06 00:59:33.940101: acc: 96.68%, sen: 88.90%, spe: 98.24%
2023-09-06 00:59:33.941080: current best miou: 0.8204230950507166 at epoch: 110, (110, 0.8204230950507166, 0.901354303053225)
2023-09-06 00:59:33.941741: current best dsc: 0.901354303053225 at epoch: 110, (110, 0.8204230950507166, 0.901354303053225)
2023-09-06 00:59:33.942326: finished real validation
2023-09-06 00:59:38.066982: train_loss -1.4376
2023-09-06 00:59:38.068611: val_loss -1.1144
2023-09-06 00:59:38.070200: Pseudo dice [0.9007]
2023-09-06 00:59:38.071447: Epoch time: 331.44 s
2023-09-06 00:59:38.072446: Yayy! New best EMA pseudo Dice: 0.9006
2023-09-06 00:59:40.793738: 
2023-09-06 00:59:40.794919: Epoch 124
2023-09-06 00:59:40.795756: Current learning rate: backbone 0.0006188, others 0.0006188
2023-09-06 00:59:40.797018: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-06 01:00:40.064897: finished training epoch 124
2023-09-06 01:00:40.096260: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset122_ISIC2017/splits_final.json
2023-09-06 01:00:40.098042: The split file contains 1 splits.
2023-09-06 01:00:40.098742: Desired fold for training: 0
2023-09-06 01:00:40.099374: This split has 1500 training and 650 validation cases.
start computing score....
2023-09-06 01:05:02.936378: dsc: 89.95%
2023-09-06 01:05:02.937913: miou: 81.73%
2023-09-06 01:05:02.938706: acc: 96.67%, sen: 88.92%, spe: 98.23%
2023-09-06 01:05:02.939852: current best miou: 0.8204230950507166 at epoch: 110, (110, 0.8204230950507166, 0.901354303053225)
2023-09-06 01:05:02.940564: current best dsc: 0.901354303053225 at epoch: 110, (110, 0.8204230950507166, 0.901354303053225)
2023-09-06 01:05:02.941185: finished real validation
2023-09-06 01:05:07.057878: train_loss -1.438
2023-09-06 01:05:07.059238: val_loss -1.1069
2023-09-06 01:05:07.060297: Pseudo dice [0.8997]
2023-09-06 01:05:07.061085: Epoch time: 326.27 s
2023-09-06 01:05:08.188654: 
2023-09-06 01:05:08.189852: Epoch 125
2023-09-06 01:05:08.190712: Current learning rate: backbone 0.00061564, others 0.00061564
2023-09-06 01:05:08.192081: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-06 01:06:07.236576: finished training epoch 125
2023-09-06 01:06:07.268474: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset122_ISIC2017/splits_final.json
2023-09-06 01:06:07.270509: The split file contains 1 splits.
2023-09-06 01:06:07.271332: Desired fold for training: 0
2023-09-06 01:06:07.272091: This split has 1500 training and 650 validation cases.
start computing score....
2023-09-06 01:10:24.194775: dsc: 90.05%
2023-09-06 01:10:24.195911: miou: 81.91%
2023-09-06 01:10:24.196620: acc: 96.68%, sen: 89.79%, spe: 98.06%
2023-09-06 01:10:24.197578: current best miou: 0.8204230950507166 at epoch: 110, (110, 0.8204230950507166, 0.901354303053225)
2023-09-06 01:10:24.198287: current best dsc: 0.901354303053225 at epoch: 110, (110, 0.8204230950507166, 0.901354303053225)
2023-09-06 01:10:24.198911: finished real validation
2023-09-06 01:10:28.325126: train_loss -1.4383
2023-09-06 01:10:28.326425: val_loss -1.0837
2023-09-06 01:10:28.327448: Pseudo dice [0.8979]
2023-09-06 01:10:28.328279: Epoch time: 320.14 s
2023-09-06 01:10:29.451374: 
2023-09-06 01:10:29.452537: Epoch 126
2023-09-06 01:10:29.453428: Current learning rate: backbone 0.00061247, others 0.00061247
2023-09-06 01:10:29.454896: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-06 01:11:28.822179: finished training epoch 126
2023-09-06 01:11:28.852652: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset122_ISIC2017/splits_final.json
2023-09-06 01:11:28.854318: The split file contains 1 splits.
2023-09-06 01:11:28.855138: Desired fold for training: 0
2023-09-06 01:11:28.855836: This split has 1500 training and 650 validation cases.
start computing score....
2023-09-06 01:16:10.410809: dsc: 90.21%
2023-09-06 01:16:10.412353: miou: 82.17%
2023-09-06 01:16:10.413474: acc: 96.75%, sen: 89.51%, spe: 98.20%
2023-09-06 01:16:10.415451: current best miou: 0.821732634787054 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 01:16:10.416440: current best dsc: 0.9021440568122753 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 01:16:12.118562: finished real validation
2023-09-06 01:16:16.249687: train_loss -1.4393
2023-09-06 01:16:16.251092: val_loss -1.1038
2023-09-06 01:16:16.252142: Pseudo dice [0.9018]
2023-09-06 01:16:16.252942: Epoch time: 346.8 s
2023-09-06 01:16:17.387562: 
2023-09-06 01:16:17.388786: Epoch 127
2023-09-06 01:16:17.389639: Current learning rate: backbone 0.0006093, others 0.0006093
2023-09-06 01:16:17.390833: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-06 01:17:16.947068: finished training epoch 127
2023-09-06 01:17:16.973797: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset122_ISIC2017/splits_final.json
2023-09-06 01:17:16.975508: The split file contains 1 splits.
2023-09-06 01:17:16.976255: Desired fold for training: 0
2023-09-06 01:17:16.976914: This split has 1500 training and 650 validation cases.
start computing score....
2023-09-06 01:21:45.284367: dsc: 90.09%
2023-09-06 01:21:45.285734: miou: 81.96%
2023-09-06 01:21:45.286583: acc: 96.72%, sen: 88.97%, spe: 98.28%
2023-09-06 01:21:45.287661: current best miou: 0.821732634787054 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 01:21:45.288453: current best dsc: 0.9021440568122753 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 01:21:45.289089: finished real validation
2023-09-06 01:21:49.449851: train_loss -1.4391
2023-09-06 01:21:49.451315: val_loss -1.1092
2023-09-06 01:21:49.452369: Pseudo dice [0.902]
2023-09-06 01:21:49.453249: Epoch time: 332.06 s
2023-09-06 01:21:50.588020: 
2023-09-06 01:21:50.589407: Epoch 128
2023-09-06 01:21:50.590413: Current learning rate: backbone 0.00060613, others 0.00060613
2023-09-06 01:21:50.592339: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-06 01:22:49.946551: finished training epoch 128
2023-09-06 01:22:49.973908: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset122_ISIC2017/splits_final.json
2023-09-06 01:22:49.975453: The split file contains 1 splits.
2023-09-06 01:22:49.976242: Desired fold for training: 0
2023-09-06 01:22:49.977501: This split has 1500 training and 650 validation cases.
start computing score....
2023-09-06 01:27:15.931432: dsc: 90.12%
2023-09-06 01:27:15.933041: miou: 82.02%
2023-09-06 01:27:15.933839: acc: 96.72%, sen: 89.38%, spe: 98.20%
2023-09-06 01:27:15.935189: current best miou: 0.821732634787054 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 01:27:15.935905: current best dsc: 0.9021440568122753 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 01:27:15.936591: finished real validation
2023-09-06 01:27:20.158186: train_loss -1.4395
2023-09-06 01:27:20.159834: val_loss -1.1067
2023-09-06 01:27:20.161102: Pseudo dice [0.899]
2023-09-06 01:27:20.162017: Epoch time: 329.57 s
2023-09-06 01:27:21.333822: 
2023-09-06 01:27:21.335111: Epoch 129
2023-09-06 01:27:21.335993: Current learning rate: backbone 0.00060296, others 0.00060296
2023-09-06 01:27:21.337500: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-06 01:28:20.639887: finished training epoch 129
2023-09-06 01:28:20.694393: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset122_ISIC2017/splits_final.json
2023-09-06 01:28:20.696218: The split file contains 1 splits.
2023-09-06 01:28:20.697050: Desired fold for training: 0
2023-09-06 01:28:20.697846: This split has 1500 training and 650 validation cases.
start computing score....
2023-09-06 01:32:55.719358: dsc: 90.06%
2023-09-06 01:32:55.720779: miou: 81.91%
2023-09-06 01:32:55.721620: acc: 96.70%, sen: 89.26%, spe: 98.20%
2023-09-06 01:32:55.722737: current best miou: 0.821732634787054 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 01:32:55.723487: current best dsc: 0.9021440568122753 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 01:32:55.724167: finished real validation
2023-09-06 01:32:59.854266: train_loss -1.4397
2023-09-06 01:32:59.855665: val_loss -1.0988
2023-09-06 01:32:59.856739: Pseudo dice [0.8984]
2023-09-06 01:32:59.857610: Epoch time: 338.52 s
2023-09-06 01:33:02.512260: 
2023-09-06 01:33:02.513355: Epoch 130
2023-09-06 01:33:02.514193: Current learning rate: backbone 0.00059978, others 0.00059978
2023-09-06 01:33:02.515412: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-06 01:34:01.758234: finished training epoch 130
2023-09-06 01:34:01.784887: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset122_ISIC2017/splits_final.json
2023-09-06 01:34:01.786630: The split file contains 1 splits.
2023-09-06 01:34:01.787446: Desired fold for training: 0
2023-09-06 01:34:01.788238: This split has 1500 training and 650 validation cases.
start computing score....
2023-09-06 01:38:10.968712: dsc: 90.01%
2023-09-06 01:38:10.970762: miou: 81.83%
2023-09-06 01:38:10.971826: acc: 96.68%, sen: 89.14%, spe: 98.20%
2023-09-06 01:38:10.973987: current best miou: 0.821732634787054 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 01:38:10.975106: current best dsc: 0.9021440568122753 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 01:38:10.976127: finished real validation
2023-09-06 01:38:15.207218: train_loss -1.4394
2023-09-06 01:38:15.209147: val_loss -1.0849
2023-09-06 01:38:15.210965: Pseudo dice [0.8989]
2023-09-06 01:38:15.212221: Epoch time: 312.7 s
2023-09-06 01:38:16.335493: 
2023-09-06 01:38:16.336921: Epoch 131
2023-09-06 01:38:16.337801: Current learning rate: backbone 0.00059661, others 0.00059661
2023-09-06 01:38:16.339210: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-06 01:39:15.998420: finished training epoch 131
2023-09-06 01:39:16.032691: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset122_ISIC2017/splits_final.json
2023-09-06 01:39:16.035499: The split file contains 1 splits.
2023-09-06 01:39:16.036565: Desired fold for training: 0
2023-09-06 01:39:16.037399: This split has 1500 training and 650 validation cases.
start computing score....
2023-09-06 01:43:53.519071: dsc: 89.91%
2023-09-06 01:43:53.520563: miou: 81.68%
2023-09-06 01:43:53.521429: acc: 96.65%, sen: 89.09%, spe: 98.17%
2023-09-06 01:43:53.522800: current best miou: 0.821732634787054 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 01:43:53.523599: current best dsc: 0.9021440568122753 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 01:43:53.524403: finished real validation
2023-09-06 01:43:57.695637: train_loss -1.4398
2023-09-06 01:43:57.697072: val_loss -1.0572
2023-09-06 01:43:57.698265: Pseudo dice [0.8922]
2023-09-06 01:43:57.699136: Epoch time: 341.36 s
2023-09-06 01:43:58.854764: 
2023-09-06 01:43:58.856197: Epoch 132
2023-09-06 01:43:58.857087: Current learning rate: backbone 0.00059343, others 0.00059343
2023-09-06 01:43:58.858603: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-06 01:44:58.206888: finished training epoch 132
2023-09-06 01:44:58.241062: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset122_ISIC2017/splits_final.json
2023-09-06 01:44:58.243184: The split file contains 1 splits.
2023-09-06 01:44:58.244039: Desired fold for training: 0
2023-09-06 01:44:58.244828: This split has 1500 training and 650 validation cases.
start computing score....
2023-09-06 01:49:45.339710: dsc: 89.96%
2023-09-06 01:49:45.341053: miou: 81.75%
2023-09-06 01:49:45.341933: acc: 96.67%, sen: 89.07%, spe: 98.20%
2023-09-06 01:49:45.343092: current best miou: 0.821732634787054 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 01:49:45.344013: current best dsc: 0.9021440568122753 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 01:49:45.344739: finished real validation
2023-09-06 01:49:49.509766: train_loss -1.4403
2023-09-06 01:49:49.511120: val_loss -1.1051
2023-09-06 01:49:49.512229: Pseudo dice [0.8977]
2023-09-06 01:49:49.513213: Epoch time: 350.66 s
2023-09-06 01:49:50.641002: 
2023-09-06 01:49:50.642290: Epoch 133
2023-09-06 01:49:50.643095: Current learning rate: backbone 0.00059025, others 0.00059025
2023-09-06 01:49:50.644422: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-06 01:50:49.961023: finished training epoch 133
2023-09-06 01:50:49.989440: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset122_ISIC2017/splits_final.json
2023-09-06 01:50:49.990883: The split file contains 1 splits.
2023-09-06 01:50:49.991567: Desired fold for training: 0
2023-09-06 01:50:49.992231: This split has 1500 training and 650 validation cases.
start computing score....
2023-09-06 01:55:07.646207: dsc: 89.86%
2023-09-06 01:55:07.647904: miou: 81.59%
2023-09-06 01:55:07.648885: acc: 96.63%, sen: 89.16%, spe: 98.13%
2023-09-06 01:55:07.650441: current best miou: 0.821732634787054 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 01:55:07.651635: current best dsc: 0.9021440568122753 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 01:55:07.652691: finished real validation
2023-09-06 01:55:11.853708: train_loss -1.4408
2023-09-06 01:55:11.855284: val_loss -1.0921
2023-09-06 01:55:11.856393: Pseudo dice [0.9009]
2023-09-06 01:55:11.857306: Epoch time: 321.21 s
2023-09-06 01:55:13.006080: 
2023-09-06 01:55:13.007408: Epoch 134
2023-09-06 01:55:13.008327: Current learning rate: backbone 0.00058707, others 0.00058707
2023-09-06 01:55:13.009783: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-06 01:56:12.583442: finished training epoch 134
2023-09-06 01:56:12.610833: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset122_ISIC2017/splits_final.json
2023-09-06 01:56:12.612394: The split file contains 1 splits.
2023-09-06 01:56:12.613201: Desired fold for training: 0
2023-09-06 01:56:12.613863: This split has 1500 training and 650 validation cases.
start computing score....
2023-09-06 02:00:24.688195: dsc: 90.15%
2023-09-06 02:00:24.689393: miou: 82.07%
2023-09-06 02:00:24.690257: acc: 96.74%, sen: 89.01%, spe: 98.30%
2023-09-06 02:00:24.691318: current best miou: 0.821732634787054 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 02:00:24.692078: current best dsc: 0.9021440568122753 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 02:00:24.692767: finished real validation
2023-09-06 02:00:28.824162: train_loss -1.4402
2023-09-06 02:00:28.825385: val_loss -1.0722
2023-09-06 02:00:28.826464: Pseudo dice [0.8988]
2023-09-06 02:00:28.827296: Epoch time: 315.82 s
2023-09-06 02:00:29.951879: 
2023-09-06 02:00:29.952983: Epoch 135
2023-09-06 02:00:29.954256: Current learning rate: backbone 0.00058388, others 0.00058388
2023-09-06 02:00:29.955999: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-06 02:01:29.306552: finished training epoch 135
2023-09-06 02:01:29.339229: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset122_ISIC2017/splits_final.json
2023-09-06 02:01:29.341181: The split file contains 1 splits.
2023-09-06 02:01:29.342038: Desired fold for training: 0
2023-09-06 02:01:29.342915: This split has 1500 training and 650 validation cases.
start computing score....
2023-09-06 02:06:04.759685: dsc: 90.00%
2023-09-06 02:06:04.760832: miou: 81.82%
2023-09-06 02:06:04.761593: acc: 96.69%, sen: 88.88%, spe: 98.26%
2023-09-06 02:06:04.762693: current best miou: 0.821732634787054 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 02:06:04.763474: current best dsc: 0.9021440568122753 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 02:06:04.764139: finished real validation
2023-09-06 02:06:08.878808: train_loss -1.4402
2023-09-06 02:06:08.880157: val_loss -1.0869
2023-09-06 02:06:08.881198: Pseudo dice [0.8997]
2023-09-06 02:06:08.882124: Epoch time: 338.93 s
2023-09-06 02:06:10.003525: 
2023-09-06 02:06:10.004575: Epoch 136
2023-09-06 02:06:10.005438: Current learning rate: backbone 0.0005807, others 0.0005807
2023-09-06 02:06:10.006711: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-06 02:07:09.558447: finished training epoch 136
2023-09-06 02:07:09.587841: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset122_ISIC2017/splits_final.json
2023-09-06 02:07:09.589370: The split file contains 1 splits.
2023-09-06 02:07:09.590427: Desired fold for training: 0
2023-09-06 02:07:09.591481: This split has 1500 training and 650 validation cases.
start computing score....
2023-09-06 02:11:19.316298: dsc: 89.94%
2023-09-06 02:11:19.317965: miou: 81.72%
2023-09-06 02:11:19.318783: acc: 96.67%, sen: 88.90%, spe: 98.23%
2023-09-06 02:11:19.320050: current best miou: 0.821732634787054 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 02:11:19.320845: current best dsc: 0.9021440568122753 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 02:11:19.321556: finished real validation
2023-09-06 02:11:23.471145: train_loss -1.4403
2023-09-06 02:11:23.472504: val_loss -1.0944
2023-09-06 02:11:23.474276: Pseudo dice [0.8995]
2023-09-06 02:11:23.475605: Epoch time: 313.47 s
2023-09-06 02:11:24.606939: 
2023-09-06 02:11:24.608096: Epoch 137
2023-09-06 02:11:24.608987: Current learning rate: backbone 0.00057751, others 0.00057751
2023-09-06 02:11:24.610361: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-06 02:12:23.870376: finished training epoch 137
2023-09-06 02:12:23.898657: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset122_ISIC2017/splits_final.json
2023-09-06 02:12:23.900343: The split file contains 1 splits.
2023-09-06 02:12:23.901243: Desired fold for training: 0
2023-09-06 02:12:23.902113: This split has 1500 training and 650 validation cases.
start computing score....
2023-09-06 02:16:36.066216: dsc: 90.00%
2023-09-06 02:16:36.067613: miou: 81.82%
2023-09-06 02:16:36.068470: acc: 96.67%, sen: 89.40%, spe: 98.14%
2023-09-06 02:16:36.069685: current best miou: 0.821732634787054 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 02:16:36.070533: current best dsc: 0.9021440568122753 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 02:16:36.071262: finished real validation
2023-09-06 02:16:40.280034: train_loss -1.4404
2023-09-06 02:16:40.281322: val_loss -1.0987
2023-09-06 02:16:40.282377: Pseudo dice [0.9025]
2023-09-06 02:16:40.283233: Epoch time: 315.67 s
2023-09-06 02:16:41.407578: 
2023-09-06 02:16:41.408874: Epoch 138
2023-09-06 02:16:41.409775: Current learning rate: backbone 0.00057432, others 0.00057432
2023-09-06 02:16:41.411180: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-06 02:17:40.482316: finished training epoch 138
2023-09-06 02:17:40.512505: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset122_ISIC2017/splits_final.json
2023-09-06 02:17:40.514359: The split file contains 1 splits.
2023-09-06 02:17:40.515224: Desired fold for training: 0
2023-09-06 02:17:40.516156: This split has 1500 training and 650 validation cases.
start computing score....
2023-09-06 02:21:54.673628: dsc: 90.00%
2023-09-06 02:21:54.675050: miou: 81.81%
2023-09-06 02:21:54.675937: acc: 96.68%, sen: 89.24%, spe: 98.17%
2023-09-06 02:21:54.677095: current best miou: 0.821732634787054 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 02:21:54.677882: current best dsc: 0.9021440568122753 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 02:21:54.678636: finished real validation
2023-09-06 02:21:58.821640: train_loss -1.4407
2023-09-06 02:21:58.823241: val_loss -1.1035
2023-09-06 02:21:58.824419: Pseudo dice [0.903]
2023-09-06 02:21:58.825277: Epoch time: 317.42 s
2023-09-06 02:21:59.954377: 
2023-09-06 02:21:59.955699: Epoch 139
2023-09-06 02:21:59.956599: Current learning rate: backbone 0.00057113, others 0.00057113
2023-09-06 02:21:59.958014: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-06 02:22:59.277622: finished training epoch 139
2023-09-06 02:22:59.314729: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset122_ISIC2017/splits_final.json
2023-09-06 02:22:59.316521: The split file contains 1 splits.
2023-09-06 02:22:59.317362: Desired fold for training: 0
2023-09-06 02:22:59.318113: This split has 1500 training and 650 validation cases.
start computing score....
2023-09-06 02:27:30.871795: dsc: 90.08%
2023-09-06 02:27:30.873359: miou: 81.95%
2023-09-06 02:27:30.874325: acc: 96.70%, sen: 89.36%, spe: 98.18%
2023-09-06 02:27:30.875568: current best miou: 0.821732634787054 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 02:27:30.876507: current best dsc: 0.9021440568122753 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 02:27:30.877739: finished real validation
2023-09-06 02:27:35.060055: train_loss -1.4407
2023-09-06 02:27:35.061441: val_loss -1.0857
2023-09-06 02:27:35.062644: Pseudo dice [0.9]
2023-09-06 02:27:35.063544: Epoch time: 335.11 s
2023-09-06 02:27:38.055063: 
2023-09-06 02:27:38.056449: Epoch 140
2023-09-06 02:27:38.057357: Current learning rate: backbone 0.00056794, others 0.00056794
2023-09-06 02:27:38.058821: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-06 02:28:37.300599: finished training epoch 140
2023-09-06 02:28:37.327752: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset122_ISIC2017/splits_final.json
2023-09-06 02:28:37.329457: The split file contains 1 splits.
2023-09-06 02:28:37.330313: Desired fold for training: 0
2023-09-06 02:28:37.331135: This split has 1500 training and 650 validation cases.
start computing score....
2023-09-06 02:33:09.724109: dsc: 89.89%
2023-09-06 02:33:09.725564: miou: 81.64%
2023-09-06 02:33:09.726382: acc: 96.64%, sen: 89.13%, spe: 98.15%
2023-09-06 02:33:09.727456: current best miou: 0.821732634787054 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 02:33:09.728284: current best dsc: 0.9021440568122753 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 02:33:09.729036: finished real validation
2023-09-06 02:33:13.855802: train_loss -1.4407
2023-09-06 02:33:13.857143: val_loss -1.0634
2023-09-06 02:33:13.858285: Pseudo dice [0.8972]
2023-09-06 02:33:13.859173: Epoch time: 335.8 s
2023-09-06 02:33:14.992962: 
2023-09-06 02:33:14.994210: Epoch 141
2023-09-06 02:33:14.995122: Current learning rate: backbone 0.00056474, others 0.00056474
2023-09-06 02:33:14.996947: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-06 02:34:13.900694: finished training epoch 141
2023-09-06 02:34:13.928339: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset122_ISIC2017/splits_final.json
2023-09-06 02:34:13.930001: The split file contains 1 splits.
2023-09-06 02:34:13.930851: Desired fold for training: 0
2023-09-06 02:34:13.931603: This split has 1500 training and 650 validation cases.
start computing score....
2023-09-06 02:38:36.703415: dsc: 89.99%
2023-09-06 02:38:36.704978: miou: 81.80%
2023-09-06 02:38:36.705891: acc: 96.67%, sen: 89.37%, spe: 98.14%
2023-09-06 02:38:36.707153: current best miou: 0.821732634787054 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 02:38:36.707965: current best dsc: 0.9021440568122753 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 02:38:36.708705: finished real validation
2023-09-06 02:38:40.950510: train_loss -1.4411
2023-09-06 02:38:40.952187: val_loss -1.0836
2023-09-06 02:38:40.953432: Pseudo dice [0.8967]
2023-09-06 02:38:40.954356: Epoch time: 325.96 s
2023-09-06 02:38:42.127766: 
2023-09-06 02:38:42.129470: Epoch 142
2023-09-06 02:38:42.130582: Current learning rate: backbone 0.00056154, others 0.00056154
2023-09-06 02:38:42.132240: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-06 02:39:41.195722: finished training epoch 142
2023-09-06 02:39:41.227548: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset122_ISIC2017/splits_final.json
2023-09-06 02:39:41.229442: The split file contains 1 splits.
2023-09-06 02:39:41.230319: Desired fold for training: 0
2023-09-06 02:39:41.231081: This split has 1500 training and 650 validation cases.
start computing score....
2023-09-06 02:43:52.841177: dsc: 90.00%
2023-09-06 02:43:52.842507: miou: 81.81%
2023-09-06 02:43:52.843330: acc: 96.69%, sen: 88.99%, spe: 98.23%
2023-09-06 02:43:52.844520: current best miou: 0.821732634787054 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 02:43:52.845325: current best dsc: 0.9021440568122753 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 02:43:52.846073: finished real validation
2023-09-06 02:43:57.067091: train_loss -1.4418
2023-09-06 02:43:57.068729: val_loss -1.1128
2023-09-06 02:43:57.070024: Pseudo dice [0.9039]
2023-09-06 02:43:57.070949: Epoch time: 314.94 s
2023-09-06 02:43:58.215429: 
2023-09-06 02:43:58.216872: Epoch 143
2023-09-06 02:43:58.217831: Current learning rate: backbone 0.00055834, others 0.00055834
2023-09-06 02:43:58.219382: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-06 02:44:57.071576: finished training epoch 143
2023-09-06 02:44:57.116760: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset122_ISIC2017/splits_final.json
2023-09-06 02:44:57.118527: The split file contains 1 splits.
2023-09-06 02:44:57.119436: Desired fold for training: 0
2023-09-06 02:44:57.120245: This split has 1500 training and 650 validation cases.
start computing score....
2023-09-06 02:49:23.593915: dsc: 90.03%
2023-09-06 02:49:23.595203: miou: 81.87%
2023-09-06 02:49:23.596022: acc: 96.69%, sen: 89.15%, spe: 98.21%
2023-09-06 02:49:23.597134: current best miou: 0.821732634787054 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 02:49:23.597980: current best dsc: 0.9021440568122753 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 02:49:23.598752: finished real validation
2023-09-06 02:49:27.810993: train_loss -1.4409
2023-09-06 02:49:27.812423: val_loss -1.1146
2023-09-06 02:49:27.813541: Pseudo dice [0.9054]
2023-09-06 02:49:27.814438: Epoch time: 329.6 s
2023-09-06 02:49:28.943456: 
2023-09-06 02:49:28.944655: Epoch 144
2023-09-06 02:49:28.945599: Current learning rate: backbone 0.00055514, others 0.00055514
2023-09-06 02:49:28.946928: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-06 02:50:27.743529: finished training epoch 144
2023-09-06 02:50:27.801145: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset122_ISIC2017/splits_final.json
2023-09-06 02:50:27.804047: The split file contains 1 splits.
2023-09-06 02:50:27.805578: Desired fold for training: 0
2023-09-06 02:50:27.807990: This split has 1500 training and 650 validation cases.
start computing score....
2023-09-06 02:54:51.811969: dsc: 89.94%
2023-09-06 02:54:51.813400: miou: 81.71%
2023-09-06 02:54:51.814238: acc: 96.66%, sen: 89.05%, spe: 98.19%
2023-09-06 02:54:51.815423: current best miou: 0.821732634787054 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 02:54:51.816219: current best dsc: 0.9021440568122753 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 02:54:51.816967: finished real validation
2023-09-06 02:54:55.966252: train_loss -1.4411
2023-09-06 02:54:55.967949: val_loss -1.0753
2023-09-06 02:54:55.969362: Pseudo dice [0.8953]
2023-09-06 02:54:55.970328: Epoch time: 327.02 s
2023-09-06 02:54:57.129754: 
2023-09-06 02:54:57.131038: Epoch 145
2023-09-06 02:54:57.132075: Current learning rate: backbone 0.00055194, others 0.00055194
2023-09-06 02:54:57.134088: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-06 02:55:56.461150: finished training epoch 145
2023-09-06 02:55:56.491205: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset122_ISIC2017/splits_final.json
2023-09-06 02:55:56.493072: The split file contains 1 splits.
2023-09-06 02:55:56.494045: Desired fold for training: 0
2023-09-06 02:55:56.495078: This split has 1500 training and 650 validation cases.
start computing score....
2023-09-06 03:00:10.183698: dsc: 90.01%
2023-09-06 03:00:10.185080: miou: 81.84%
2023-09-06 03:00:10.186002: acc: 96.68%, sen: 89.28%, spe: 98.17%
2023-09-06 03:00:10.187200: current best miou: 0.821732634787054 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 03:00:10.188077: current best dsc: 0.9021440568122753 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 03:00:10.188823: finished real validation
2023-09-06 03:00:14.405089: train_loss -1.4408
2023-09-06 03:00:14.406499: val_loss -1.0912
2023-09-06 03:00:14.407602: Pseudo dice [0.8995]
2023-09-06 03:00:14.408466: Epoch time: 317.28 s
2023-09-06 03:00:15.551225: 
2023-09-06 03:00:15.552855: Epoch 146
2023-09-06 03:00:15.553777: Current learning rate: backbone 0.00054873, others 0.00054873
2023-09-06 03:00:15.555285: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-06 03:01:14.888450: finished training epoch 146
2023-09-06 03:01:14.916491: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset122_ISIC2017/splits_final.json
2023-09-06 03:01:14.918321: The split file contains 1 splits.
2023-09-06 03:01:14.919323: Desired fold for training: 0
2023-09-06 03:01:14.920731: This split has 1500 training and 650 validation cases.
start computing score....
2023-09-06 03:05:24.732984: dsc: 89.94%
2023-09-06 03:05:24.734390: miou: 81.71%
2023-09-06 03:05:24.735240: acc: 96.67%, sen: 88.84%, spe: 98.24%
2023-09-06 03:05:24.736370: current best miou: 0.821732634787054 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 03:05:24.737221: current best dsc: 0.9021440568122753 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 03:05:24.737971: finished real validation
2023-09-06 03:05:28.961447: train_loss -1.4416
2023-09-06 03:05:28.962959: val_loss -1.0837
2023-09-06 03:05:28.964395: Pseudo dice [0.8994]
2023-09-06 03:05:28.965365: Epoch time: 313.41 s
2023-09-06 03:05:30.085924: 
2023-09-06 03:05:30.087428: Epoch 147
2023-09-06 03:05:30.088376: Current learning rate: backbone 0.00054552, others 0.00054552
2023-09-06 03:05:30.089920: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-06 03:06:29.187036: finished training epoch 147
2023-09-06 03:06:29.216876: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset122_ISIC2017/splits_final.json
2023-09-06 03:06:29.218785: The split file contains 1 splits.
2023-09-06 03:06:29.219729: Desired fold for training: 0
2023-09-06 03:06:29.220661: This split has 1500 training and 650 validation cases.
start computing score....
2023-09-06 03:10:52.631465: dsc: 90.06%
2023-09-06 03:10:52.633085: miou: 81.92%
2023-09-06 03:10:52.633976: acc: 96.70%, sen: 89.27%, spe: 98.20%
2023-09-06 03:10:52.635249: current best miou: 0.821732634787054 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 03:10:52.636080: current best dsc: 0.9021440568122753 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 03:10:52.636830: finished real validation
2023-09-06 03:10:56.767941: train_loss -1.4416
2023-09-06 03:10:56.769460: val_loss -1.0811
2023-09-06 03:10:56.770702: Pseudo dice [0.8997]
2023-09-06 03:10:56.771605: Epoch time: 326.68 s
2023-09-06 03:10:57.897262: 
2023-09-06 03:10:57.898699: Epoch 148
2023-09-06 03:10:57.899670: Current learning rate: backbone 0.00054231, others 0.00054231
2023-09-06 03:10:57.901109: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-06 03:11:56.976496: finished training epoch 148
2023-09-06 03:11:57.006149: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset122_ISIC2017/splits_final.json
2023-09-06 03:11:57.007862: The split file contains 1 splits.
2023-09-06 03:11:57.008707: Desired fold for training: 0
2023-09-06 03:11:57.009474: This split has 1500 training and 650 validation cases.
start computing score....
2023-09-06 03:16:20.025244: dsc: 89.97%
2023-09-06 03:16:20.026817: miou: 81.76%
2023-09-06 03:16:20.027786: acc: 96.68%, sen: 88.93%, spe: 98.24%
2023-09-06 03:16:20.029046: current best miou: 0.821732634787054 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 03:16:20.030008: current best dsc: 0.9021440568122753 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 03:16:20.030814: finished real validation
2023-09-06 03:16:24.207826: train_loss -1.4413
2023-09-06 03:16:24.209738: val_loss -1.0877
2023-09-06 03:16:24.211266: Pseudo dice [0.9006]
2023-09-06 03:16:24.212334: Epoch time: 326.31 s
2023-09-06 03:16:25.378995: 
2023-09-06 03:16:25.380852: Epoch 149
2023-09-06 03:16:25.381934: Current learning rate: backbone 0.0005391, others 0.0005391
2023-09-06 03:16:25.383627: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-06 03:17:24.441511: finished training epoch 149
2023-09-06 03:17:24.472282: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset122_ISIC2017/splits_final.json
2023-09-06 03:17:24.474613: The split file contains 1 splits.
2023-09-06 03:17:24.475674: Desired fold for training: 0
2023-09-06 03:17:24.477023: This split has 1500 training and 650 validation cases.
start computing score....
2023-09-06 03:21:44.983699: dsc: 90.02%
2023-09-06 03:21:44.985128: miou: 81.86%
2023-09-06 03:21:44.985997: acc: 96.71%, sen: 88.53%, spe: 98.36%
2023-09-06 03:21:44.988298: current best miou: 0.821732634787054 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 03:21:44.989582: current best dsc: 0.9021440568122753 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 03:21:44.990705: finished real validation
2023-09-06 03:21:49.114878: train_loss -1.4416
2023-09-06 03:21:49.116179: val_loss -1.0942
2023-09-06 03:21:49.117927: Pseudo dice [0.9019]
2023-09-06 03:21:49.119329: Epoch time: 323.74 s
2023-09-06 03:21:51.981405: 
2023-09-06 03:21:51.982910: Epoch 150
2023-09-06 03:21:51.983872: Current learning rate: backbone 0.00053589, others 0.00053589
2023-09-06 03:21:51.985429: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-06 03:22:51.538230: finished training epoch 150
2023-09-06 03:22:51.567945: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset122_ISIC2017/splits_final.json
2023-09-06 03:22:51.570015: The split file contains 1 splits.
2023-09-06 03:22:51.571119: Desired fold for training: 0
2023-09-06 03:22:51.572190: This split has 1500 training and 650 validation cases.
start computing score....
2023-09-06 03:27:41.133399: dsc: 89.95%
2023-09-06 03:27:41.135057: miou: 81.74%
2023-09-06 03:27:41.135987: acc: 96.66%, sen: 89.31%, spe: 98.14%
2023-09-06 03:27:41.137290: current best miou: 0.821732634787054 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 03:27:41.138206: current best dsc: 0.9021440568122753 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 03:27:41.139019: finished real validation
2023-09-06 03:27:45.275367: train_loss -1.4416
2023-09-06 03:27:45.276823: val_loss -1.0894
2023-09-06 03:27:45.278050: Pseudo dice [0.9022]
2023-09-06 03:27:45.278927: Epoch time: 353.3 s
2023-09-06 03:27:46.437649: 
2023-09-06 03:27:46.439602: Epoch 151
2023-09-06 03:27:46.440681: Current learning rate: backbone 0.00053267, others 0.00053267
2023-09-06 03:27:46.442851: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-06 03:28:45.995201: finished training epoch 151
2023-09-06 03:28:46.025608: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset122_ISIC2017/splits_final.json
2023-09-06 03:28:46.027400: The split file contains 1 splits.
2023-09-06 03:28:46.028251: Desired fold for training: 0
2023-09-06 03:28:46.029008: This split has 1500 training and 650 validation cases.
start computing score....
2023-09-06 03:33:01.622309: dsc: 90.00%
2023-09-06 03:33:01.623972: miou: 81.82%
2023-09-06 03:33:01.624915: acc: 96.68%, sen: 89.05%, spe: 98.22%
2023-09-06 03:33:01.626278: current best miou: 0.821732634787054 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 03:33:01.627240: current best dsc: 0.9021440568122753 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 03:33:01.628109: finished real validation
2023-09-06 03:33:05.860791: train_loss -1.442
2023-09-06 03:33:05.862366: val_loss -1.0908
2023-09-06 03:33:05.863529: Pseudo dice [0.9006]
2023-09-06 03:33:05.864483: Epoch time: 319.43 s
2023-09-06 03:33:07.010245: 
2023-09-06 03:33:07.011744: Epoch 152
2023-09-06 03:33:07.012776: Current learning rate: backbone 0.00052945, others 0.00052945
2023-09-06 03:33:07.014313: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-06 03:34:06.460960: finished training epoch 152
2023-09-06 03:34:06.490025: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset122_ISIC2017/splits_final.json
2023-09-06 03:34:06.491901: The split file contains 1 splits.
2023-09-06 03:34:06.492759: Desired fold for training: 0
2023-09-06 03:34:06.493510: This split has 1500 training and 650 validation cases.
start computing score....
2023-09-06 03:38:13.025471: dsc: 89.95%
2023-09-06 03:38:13.041042: miou: 81.74%
2023-09-06 03:38:13.042237: acc: 96.66%, sen: 89.29%, spe: 98.14%
2023-09-06 03:38:13.043621: current best miou: 0.821732634787054 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 03:38:13.044648: current best dsc: 0.9021440568122753 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 03:38:13.045609: finished real validation
2023-09-06 03:38:17.242239: train_loss -1.4422
2023-09-06 03:38:17.243970: val_loss -1.079
2023-09-06 03:38:17.245532: Pseudo dice [0.9024]
2023-09-06 03:38:17.246689: Epoch time: 310.23 s
2023-09-06 03:38:18.407368: 
2023-09-06 03:38:18.409000: Epoch 153
2023-09-06 03:38:18.410021: Current learning rate: backbone 0.00052623, others 0.00052623
2023-09-06 03:38:18.411549: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-06 03:39:17.839190: finished training epoch 153
2023-09-06 03:39:17.876814: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset122_ISIC2017/splits_final.json
2023-09-06 03:39:17.878591: The split file contains 1 splits.
2023-09-06 03:39:17.879543: Desired fold for training: 0
2023-09-06 03:39:17.880532: This split has 1500 training and 650 validation cases.
start computing score....
2023-09-06 03:43:32.731894: dsc: 90.07%
2023-09-06 03:43:32.733407: miou: 81.93%
2023-09-06 03:43:32.734344: acc: 96.70%, sen: 89.32%, spe: 98.19%
2023-09-06 03:43:32.735584: current best miou: 0.821732634787054 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 03:43:32.736496: current best dsc: 0.9021440568122753 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 03:43:32.737339: finished real validation
2023-09-06 03:43:36.939713: train_loss -1.4417
2023-09-06 03:43:36.941471: val_loss -1.075
2023-09-06 03:43:36.942843: Pseudo dice [0.8978]
2023-09-06 03:43:36.943863: Epoch time: 318.53 s
2023-09-06 03:43:38.098883: 
2023-09-06 03:43:38.100369: Epoch 154
2023-09-06 03:43:38.101357: Current learning rate: backbone 0.00052301, others 0.00052301
2023-09-06 03:43:38.102994: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-06 03:44:37.211091: finished training epoch 154
2023-09-06 03:44:37.251456: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset122_ISIC2017/splits_final.json
2023-09-06 03:44:37.254021: The split file contains 1 splits.
2023-09-06 03:44:37.255420: Desired fold for training: 0
2023-09-06 03:44:37.256489: This split has 1500 training and 650 validation cases.
start computing score....
2023-09-06 03:49:02.010702: dsc: 90.02%
2023-09-06 03:49:02.012154: miou: 81.86%
2023-09-06 03:49:02.013095: acc: 96.69%, sen: 89.12%, spe: 98.22%
2023-09-06 03:49:02.014375: current best miou: 0.821732634787054 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 03:49:02.015282: current best dsc: 0.9021440568122753 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 03:49:02.016097: finished real validation
2023-09-06 03:49:06.230674: train_loss -1.4424
2023-09-06 03:49:06.232066: val_loss -1.0676
2023-09-06 03:49:06.233334: Pseudo dice [0.8942]
2023-09-06 03:49:06.234324: Epoch time: 328.13 s
2023-09-06 03:49:07.422982: 
2023-09-06 03:49:07.424414: Epoch 155
2023-09-06 03:49:07.425432: Current learning rate: backbone 0.00051978, others 0.00051978
2023-09-06 03:49:07.426966: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-06 03:50:06.741676: finished training epoch 155
2023-09-06 03:50:06.769384: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset122_ISIC2017/splits_final.json
2023-09-06 03:50:06.771298: The split file contains 1 splits.
2023-09-06 03:50:06.773092: Desired fold for training: 0
2023-09-06 03:50:06.774350: This split has 1500 training and 650 validation cases.
start computing score....
2023-09-06 03:54:28.395354: dsc: 90.10%
2023-09-06 03:54:28.396693: miou: 81.99%
2023-09-06 03:54:28.397600: acc: 96.71%, sen: 89.31%, spe: 98.20%
2023-09-06 03:54:28.398740: current best miou: 0.821732634787054 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 03:54:28.399649: current best dsc: 0.9021440568122753 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 03:54:28.400442: finished real validation
2023-09-06 03:54:32.499981: train_loss -1.4422
2023-09-06 03:54:32.501353: val_loss -1.1143
2023-09-06 03:54:32.502715: Pseudo dice [0.9038]
2023-09-06 03:54:32.503839: Epoch time: 325.08 s
2023-09-06 03:54:33.654075: 
2023-09-06 03:54:33.655621: Epoch 156
2023-09-06 03:54:33.656659: Current learning rate: backbone 0.00051656, others 0.00051656
2023-09-06 03:54:33.658084: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-06 03:55:32.905033: finished training epoch 156
2023-09-06 03:55:32.934637: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset122_ISIC2017/splits_final.json
2023-09-06 03:55:32.939902: The split file contains 1 splits.
2023-09-06 03:55:32.941517: Desired fold for training: 0
2023-09-06 03:55:32.942779: This split has 1500 training and 650 validation cases.
start computing score....
2023-09-06 03:59:43.845516: dsc: 90.04%
2023-09-06 03:59:43.847230: miou: 81.89%
2023-09-06 03:59:43.848157: acc: 96.70%, sen: 88.99%, spe: 98.25%
2023-09-06 03:59:43.849428: current best miou: 0.821732634787054 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 03:59:43.850367: current best dsc: 0.9021440568122753 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 03:59:43.851176: finished real validation
2023-09-06 03:59:48.036515: train_loss -1.4425
2023-09-06 03:59:48.038007: val_loss -1.085
2023-09-06 03:59:48.039268: Pseudo dice [0.9]
2023-09-06 03:59:48.040226: Epoch time: 314.38 s
2023-09-06 03:59:49.197390: 
2023-09-06 03:59:49.198794: Epoch 157
2023-09-06 03:59:49.199837: Current learning rate: backbone 0.00051333, others 0.00051333
2023-09-06 03:59:49.201557: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-06 04:00:48.684729: finished training epoch 157
2023-09-06 04:00:48.712966: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset122_ISIC2017/splits_final.json
2023-09-06 04:00:48.714707: The split file contains 1 splits.
2023-09-06 04:00:48.715760: Desired fold for training: 0
2023-09-06 04:00:48.716670: This split has 1500 training and 650 validation cases.
start computing score....
2023-09-06 04:05:14.899656: dsc: 89.98%
2023-09-06 04:05:14.901256: miou: 81.78%
2023-09-06 04:05:14.902210: acc: 96.69%, sen: 88.74%, spe: 98.29%
2023-09-06 04:05:14.903458: current best miou: 0.821732634787054 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 04:05:14.904408: current best dsc: 0.9021440568122753 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 04:05:14.905268: finished real validation
2023-09-06 04:05:19.146891: train_loss -1.4423
2023-09-06 04:05:19.148928: val_loss -1.0823
2023-09-06 04:05:19.150491: Pseudo dice [0.9022]
2023-09-06 04:05:19.151533: Epoch time: 329.95 s
2023-09-06 04:05:20.310283: 
2023-09-06 04:05:20.311857: Epoch 158
2023-09-06 04:05:20.312918: Current learning rate: backbone 0.00051009, others 0.00051009
2023-09-06 04:05:20.314656: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-06 04:06:19.281657: finished training epoch 158
2023-09-06 04:06:19.311234: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset122_ISIC2017/splits_final.json
2023-09-06 04:06:19.313246: The split file contains 1 splits.
2023-09-06 04:06:19.314670: Desired fold for training: 0
2023-09-06 04:06:19.315824: This split has 1500 training and 650 validation cases.
start computing score....
2023-09-06 04:10:45.185724: dsc: 90.04%
2023-09-06 04:10:45.187212: miou: 81.88%
2023-09-06 04:10:45.188166: acc: 96.69%, sen: 89.37%, spe: 98.16%
2023-09-06 04:10:45.189432: current best miou: 0.821732634787054 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 04:10:45.190351: current best dsc: 0.9021440568122753 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 04:10:45.191198: finished real validation
2023-09-06 04:10:49.304924: train_loss -1.4425
2023-09-06 04:10:49.306353: val_loss -1.0869
2023-09-06 04:10:49.307569: Pseudo dice [0.8997]
2023-09-06 04:10:49.308552: Epoch time: 329.0 s
2023-09-06 04:10:50.466037: 
2023-09-06 04:10:50.467493: Epoch 159
2023-09-06 04:10:50.468523: Current learning rate: backbone 0.00050686, others 0.00050686
2023-09-06 04:10:50.469947: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-06 04:11:49.782056: finished training epoch 159
2023-09-06 04:11:49.813699: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset122_ISIC2017/splits_final.json
2023-09-06 04:11:49.815712: The split file contains 1 splits.
2023-09-06 04:11:49.816648: Desired fold for training: 0
2023-09-06 04:11:49.817495: This split has 1500 training and 650 validation cases.
start computing score....
2023-09-06 04:16:03.908011: dsc: 90.05%
2023-09-06 04:16:03.909687: miou: 81.90%
2023-09-06 04:16:03.910588: acc: 96.68%, sen: 89.68%, spe: 98.09%
2023-09-06 04:16:03.911847: current best miou: 0.821732634787054 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 04:16:03.912872: current best dsc: 0.9021440568122753 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 04:16:03.913687: finished real validation
2023-09-06 04:16:08.150197: train_loss -1.4431
2023-09-06 04:16:08.151873: val_loss -1.1023
2023-09-06 04:16:08.153516: Pseudo dice [0.9027]
2023-09-06 04:16:08.154655: Epoch time: 317.69 s
2023-09-06 04:16:10.866604: 
2023-09-06 04:16:10.868001: Epoch 160
2023-09-06 04:16:10.869075: Current learning rate: backbone 0.00050362, others 0.00050362
2023-09-06 04:16:10.870722: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-06 04:17:10.117023: finished training epoch 160
2023-09-06 04:17:10.156372: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset122_ISIC2017/splits_final.json
2023-09-06 04:17:10.158607: The split file contains 1 splits.
2023-09-06 04:17:10.159630: Desired fold for training: 0
2023-09-06 04:17:10.160531: This split has 1500 training and 650 validation cases.
start computing score....
2023-09-06 04:21:48.008256: dsc: 89.94%
2023-09-06 04:21:48.009798: miou: 81.72%
2023-09-06 04:21:48.010793: acc: 96.67%, sen: 88.98%, spe: 98.21%
2023-09-06 04:21:48.012100: current best miou: 0.821732634787054 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 04:21:48.013012: current best dsc: 0.9021440568122753 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 04:21:48.013861: finished real validation
2023-09-06 04:21:52.252027: train_loss -1.4429
2023-09-06 04:21:52.253575: val_loss -1.1022
2023-09-06 04:21:52.255058: Pseudo dice [0.9025]
2023-09-06 04:21:52.256042: Epoch time: 341.39 s
2023-09-06 04:21:52.256959: Yayy! New best EMA pseudo Dice: 0.9007
2023-09-06 04:21:55.124233: 
2023-09-06 04:21:55.125547: Epoch 161
2023-09-06 04:21:55.126519: Current learning rate: backbone 0.00050038, others 0.00050038
2023-09-06 04:21:55.127956: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-06 04:22:54.180192: finished training epoch 161
2023-09-06 04:22:54.217099: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset122_ISIC2017/splits_final.json
2023-09-06 04:22:54.219170: The split file contains 1 splits.
2023-09-06 04:22:54.220186: Desired fold for training: 0
2023-09-06 04:22:54.221115: This split has 1500 training and 650 validation cases.
start computing score....
2023-09-06 04:27:14.946112: dsc: 89.92%
2023-09-06 04:27:14.947622: miou: 81.68%
2023-09-06 04:27:14.948654: acc: 96.66%, sen: 89.02%, spe: 98.19%
2023-09-06 04:27:14.949885: current best miou: 0.821732634787054 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 04:27:14.950917: current best dsc: 0.9021440568122753 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 04:27:14.952151: finished real validation
2023-09-06 04:27:19.133934: train_loss -1.4425
2023-09-06 04:27:19.135567: val_loss -1.0916
2023-09-06 04:27:19.136893: Pseudo dice [0.8986]
2023-09-06 04:27:19.137922: Epoch time: 324.01 s
2023-09-06 04:27:20.287843: 
2023-09-06 04:27:20.289546: Epoch 162
2023-09-06 04:27:20.290589: Current learning rate: backbone 0.00049714, others 0.00049714
2023-09-06 04:27:20.292203: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-06 04:28:19.442984: finished training epoch 162
2023-09-06 04:28:19.473826: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset122_ISIC2017/splits_final.json
2023-09-06 04:28:19.476192: The split file contains 1 splits.
2023-09-06 04:28:19.477299: Desired fold for training: 0
2023-09-06 04:28:19.478307: This split has 1500 training and 650 validation cases.
start computing score....
2023-09-06 04:32:39.936824: dsc: 89.99%
2023-09-06 04:32:39.938536: miou: 81.80%
2023-09-06 04:32:39.939518: acc: 96.69%, sen: 88.72%, spe: 98.30%
2023-09-06 04:32:39.941058: current best miou: 0.821732634787054 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 04:32:39.942009: current best dsc: 0.9021440568122753 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 04:32:39.943110: finished real validation
2023-09-06 04:32:44.177734: train_loss -1.4426
2023-09-06 04:32:44.179220: val_loss -1.0586
2023-09-06 04:32:44.180498: Pseudo dice [0.8946]
2023-09-06 04:32:44.181776: Epoch time: 323.89 s
2023-09-06 04:32:45.363694: 
2023-09-06 04:32:45.365545: Epoch 163
2023-09-06 04:32:45.366696: Current learning rate: backbone 0.0004939, others 0.0004939
2023-09-06 04:32:45.368948: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-06 04:33:44.211272: finished training epoch 163
2023-09-06 04:33:44.242370: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset122_ISIC2017/splits_final.json
2023-09-06 04:33:44.244557: The split file contains 1 splits.
2023-09-06 04:33:44.245701: Desired fold for training: 0
2023-09-06 04:33:44.246774: This split has 1500 training and 650 validation cases.
start computing score....
2023-09-06 04:38:12.669667: dsc: 89.99%
2023-09-06 04:38:12.671319: miou: 81.80%
2023-09-06 04:38:12.672320: acc: 96.70%, sen: 88.57%, spe: 98.33%
2023-09-06 04:38:12.673588: current best miou: 0.821732634787054 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 04:38:12.674533: current best dsc: 0.9021440568122753 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 04:38:12.675408: finished real validation
2023-09-06 04:38:16.887955: train_loss -1.4427
2023-09-06 04:38:16.890057: val_loss -1.0709
2023-09-06 04:38:16.891592: Pseudo dice [0.8965]
2023-09-06 04:38:16.892718: Epoch time: 331.53 s
2023-09-06 04:38:18.079887: 
2023-09-06 04:38:18.081361: Epoch 164
2023-09-06 04:38:18.082524: Current learning rate: backbone 0.00049065, others 0.00049065
2023-09-06 04:38:18.084737: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-06 04:39:17.253051: finished training epoch 164
2023-09-06 04:39:17.283510: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset122_ISIC2017/splits_final.json
2023-09-06 04:39:17.286222: The split file contains 1 splits.
2023-09-06 04:39:17.287509: Desired fold for training: 0
2023-09-06 04:39:17.288644: This split has 1500 training and 650 validation cases.
start computing score....
2023-09-06 04:44:19.688960: dsc: 90.00%
2023-09-06 04:44:19.690856: miou: 81.82%
2023-09-06 04:44:19.691881: acc: 96.69%, sen: 88.83%, spe: 98.28%
2023-09-06 04:44:19.693313: current best miou: 0.821732634787054 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 04:44:19.694325: current best dsc: 0.9021440568122753 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 04:44:19.695190: finished real validation
2023-09-06 04:44:23.809263: train_loss -1.443
2023-09-06 04:44:23.811056: val_loss -1.1141
2023-09-06 04:44:23.812299: Pseudo dice [0.9059]
2023-09-06 04:44:23.813293: Epoch time: 365.73 s
2023-09-06 04:44:24.933962: 
2023-09-06 04:44:24.935408: Epoch 165
2023-09-06 04:44:24.936470: Current learning rate: backbone 0.00048741, others 0.00048741
2023-09-06 04:44:24.937965: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-06 04:45:24.331159: finished training epoch 165
2023-09-06 04:45:24.360772: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset122_ISIC2017/splits_final.json
2023-09-06 04:45:24.362767: The split file contains 1 splits.
2023-09-06 04:45:24.364184: Desired fold for training: 0
2023-09-06 04:45:24.365317: This split has 1500 training and 650 validation cases.
start computing score....
2023-09-06 04:49:53.962661: dsc: 90.07%
2023-09-06 04:49:53.964344: miou: 81.93%
2023-09-06 04:49:53.965356: acc: 96.69%, sen: 89.66%, spe: 98.10%
2023-09-06 04:49:53.966665: current best miou: 0.821732634787054 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 04:49:53.967801: current best dsc: 0.9021440568122753 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 04:49:53.968707: finished real validation
2023-09-06 04:49:58.194527: train_loss -1.4436
2023-09-06 04:49:58.196008: val_loss -1.0723
2023-09-06 04:49:58.197320: Pseudo dice [0.8968]
2023-09-06 04:49:58.198316: Epoch time: 333.26 s
2023-09-06 04:49:59.324089: 
2023-09-06 04:49:59.325536: Epoch 166
2023-09-06 04:49:59.326670: Current learning rate: backbone 0.00048416, others 0.00048416
2023-09-06 04:49:59.328425: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-06 04:50:58.585824: finished training epoch 166
2023-09-06 04:50:58.615126: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset122_ISIC2017/splits_final.json
2023-09-06 04:50:58.617189: The split file contains 1 splits.
2023-09-06 04:50:58.618211: Desired fold for training: 0
2023-09-06 04:50:58.619141: This split has 1500 training and 650 validation cases.
start computing score....
2023-09-06 04:55:34.809901: dsc: 90.04%
2023-09-06 04:55:34.811440: miou: 81.88%
2023-09-06 04:55:34.812404: acc: 96.66%, sen: 90.20%, spe: 97.96%
2023-09-06 04:55:34.813694: current best miou: 0.821732634787054 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 04:55:34.814665: current best dsc: 0.9021440568122753 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 04:55:34.815528: finished real validation
2023-09-06 04:55:39.033497: train_loss -1.4431
2023-09-06 04:55:39.035164: val_loss -1.0654
2023-09-06 04:55:39.036458: Pseudo dice [0.899]
2023-09-06 04:55:39.037547: Epoch time: 339.71 s
2023-09-06 04:55:40.156567: 
2023-09-06 04:55:40.157993: Epoch 167
2023-09-06 04:55:40.159164: Current learning rate: backbone 0.0004809, others 0.0004809
2023-09-06 04:55:40.160861: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-06 04:56:39.253132: finished training epoch 167
2023-09-06 04:56:39.280833: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset122_ISIC2017/splits_final.json
2023-09-06 04:56:39.282726: The split file contains 1 splits.
2023-09-06 04:56:39.283818: Desired fold for training: 0
2023-09-06 04:56:39.284819: This split has 1500 training and 650 validation cases.
start computing score....
2023-09-06 05:01:04.082696: dsc: 89.99%
2023-09-06 05:01:04.084204: miou: 81.80%
2023-09-06 05:01:04.085266: acc: 96.68%, sen: 89.09%, spe: 98.21%
2023-09-06 05:01:04.086815: current best miou: 0.821732634787054 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 05:01:04.087760: current best dsc: 0.9021440568122753 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 05:01:04.088737: finished real validation
2023-09-06 05:01:08.311658: train_loss -1.4432
2023-09-06 05:01:08.313209: val_loss -1.0507
2023-09-06 05:01:08.314442: Pseudo dice [0.8954]
2023-09-06 05:01:08.315422: Epoch time: 328.16 s
2023-09-06 05:01:09.445541: 
2023-09-06 05:01:09.446925: Epoch 168
2023-09-06 05:01:09.447935: Current learning rate: backbone 0.00047765, others 0.00047765
2023-09-06 05:01:09.449454: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-06 05:02:08.402300: finished training epoch 168
2023-09-06 05:02:08.431620: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset122_ISIC2017/splits_final.json
2023-09-06 05:02:08.433749: The split file contains 1 splits.
2023-09-06 05:02:08.434839: Desired fold for training: 0
2023-09-06 05:02:08.435879: This split has 1500 training and 650 validation cases.
start computing score....
2023-09-06 05:06:51.327773: dsc: 90.01%
2023-09-06 05:06:51.329559: miou: 81.83%
2023-09-06 05:06:51.330511: acc: 96.66%, sen: 89.83%, spe: 98.03%
2023-09-06 05:06:51.331831: current best miou: 0.821732634787054 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 05:06:51.332856: current best dsc: 0.9021440568122753 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 05:06:51.333745: finished real validation
2023-09-06 05:06:55.559226: train_loss -1.443
2023-09-06 05:06:55.561302: val_loss -1.0504
2023-09-06 05:06:55.562920: Pseudo dice [0.8958]
2023-09-06 05:06:55.563991: Epoch time: 346.12 s
2023-09-06 05:06:56.729300: 
2023-09-06 05:06:56.730884: Epoch 169
2023-09-06 05:06:56.731985: Current learning rate: backbone 0.00047439, others 0.00047439
2023-09-06 05:06:56.733696: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-06 05:07:56.001114: finished training epoch 169
2023-09-06 05:07:56.038266: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset122_ISIC2017/splits_final.json
2023-09-06 05:07:56.040147: The split file contains 1 splits.
2023-09-06 05:07:56.041214: Desired fold for training: 0
2023-09-06 05:07:56.042246: This split has 1500 training and 650 validation cases.
start computing score....
2023-09-06 05:13:19.999305: dsc: 90.05%
2023-09-06 05:13:20.000913: miou: 81.90%
2023-09-06 05:13:20.001994: acc: 96.71%, sen: 88.92%, spe: 98.28%
2023-09-06 05:13:20.003475: current best miou: 0.821732634787054 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 05:13:20.004452: current best dsc: 0.9021440568122753 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 05:13:20.005528: finished real validation
2023-09-06 05:13:24.755026: train_loss -1.4442
2023-09-06 05:13:24.756569: val_loss -1.0579
2023-09-06 05:13:24.757802: Pseudo dice [0.8955]
2023-09-06 05:13:24.758801: Epoch time: 388.03 s
2023-09-06 05:13:27.765392: 
2023-09-06 05:13:27.767208: Epoch 170
2023-09-06 05:13:27.768676: Current learning rate: backbone 0.00047113, others 0.00047113
2023-09-06 05:13:27.770357: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-06 05:14:26.860393: finished training epoch 170
2023-09-06 05:14:26.896053: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset122_ISIC2017/splits_final.json
2023-09-06 05:14:26.898353: The split file contains 1 splits.
2023-09-06 05:14:26.899357: Desired fold for training: 0
2023-09-06 05:14:26.900289: This split has 1500 training and 650 validation cases.
start computing score....
2023-09-06 05:18:43.297223: dsc: 90.12%
2023-09-06 05:18:43.298732: miou: 82.02%
2023-09-06 05:18:43.299839: acc: 96.72%, sen: 89.24%, spe: 98.23%
2023-09-06 05:18:43.301106: current best miou: 0.821732634787054 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 05:18:43.302133: current best dsc: 0.9021440568122753 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 05:18:43.303193: finished real validation
2023-09-06 05:18:47.536041: train_loss -1.4432
2023-09-06 05:18:47.537583: val_loss -1.0478
2023-09-06 05:18:47.538883: Pseudo dice [0.8968]
2023-09-06 05:18:47.539937: Epoch time: 319.77 s
2023-09-06 05:18:48.647172: 
2023-09-06 05:18:48.648651: Epoch 171
2023-09-06 05:18:48.649709: Current learning rate: backbone 0.00046787, others 0.00046787
2023-09-06 05:18:48.651515: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-06 05:19:47.566878: finished training epoch 171
2023-09-06 05:19:47.595988: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset122_ISIC2017/splits_final.json
2023-09-06 05:19:47.597986: The split file contains 1 splits.
2023-09-06 05:19:47.599307: Desired fold for training: 0
2023-09-06 05:19:47.600259: This split has 1500 training and 650 validation cases.
start computing score....
2023-09-06 05:24:34.750891: dsc: 90.11%
2023-09-06 05:24:34.752550: miou: 82.00%
2023-09-06 05:24:34.753668: acc: 96.72%, sen: 89.15%, spe: 98.25%
2023-09-06 05:24:34.755556: current best miou: 0.821732634787054 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 05:24:34.756783: current best dsc: 0.9021440568122753 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 05:24:34.758052: finished real validation
2023-09-06 05:24:38.981472: train_loss -1.4434
2023-09-06 05:24:38.983056: val_loss -1.0995
2023-09-06 05:24:38.984383: Pseudo dice [0.9043]
2023-09-06 05:24:38.985467: Epoch time: 350.34 s
2023-09-06 05:24:40.090876: 
2023-09-06 05:24:40.092378: Epoch 172
2023-09-06 05:24:40.093451: Current learning rate: backbone 0.0004646, others 0.0004646
2023-09-06 05:24:40.095396: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-06 05:25:38.959229: finished training epoch 172
2023-09-06 05:25:38.992789: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset122_ISIC2017/splits_final.json
2023-09-06 05:25:38.994979: The split file contains 1 splits.
2023-09-06 05:25:38.996007: Desired fold for training: 0
2023-09-06 05:25:38.996975: This split has 1500 training and 650 validation cases.
start computing score....
2023-09-06 05:30:05.584233: dsc: 90.17%
2023-09-06 05:30:05.585759: miou: 82.09%
2023-09-06 05:30:05.587098: acc: 96.75%, sen: 89.07%, spe: 98.29%
2023-09-06 05:30:05.589334: current best miou: 0.821732634787054 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 05:30:05.590519: current best dsc: 0.9021440568122753 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 05:30:05.591679: finished real validation
2023-09-06 05:30:09.824540: train_loss -1.4439
2023-09-06 05:30:09.826210: val_loss -1.0579
2023-09-06 05:30:09.827566: Pseudo dice [0.8966]
2023-09-06 05:30:09.828685: Epoch time: 329.74 s
2023-09-06 05:30:10.943239: 
2023-09-06 05:30:10.961873: Epoch 173
2023-09-06 05:30:10.963606: Current learning rate: backbone 0.00046133, others 0.00046133
2023-09-06 05:30:10.965942: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-06 05:31:09.922712: finished training epoch 173
2023-09-06 05:31:09.950450: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset122_ISIC2017/splits_final.json
2023-09-06 05:31:09.952491: The split file contains 1 splits.
2023-09-06 05:31:09.953599: Desired fold for training: 0
2023-09-06 05:31:09.954659: This split has 1500 training and 650 validation cases.
start computing score....
2023-09-06 05:35:29.124403: dsc: 90.11%
2023-09-06 05:35:29.125951: miou: 82.00%
2023-09-06 05:35:29.127105: acc: 96.71%, sen: 89.36%, spe: 98.19%
2023-09-06 05:35:29.129039: current best miou: 0.821732634787054 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 05:35:29.130028: current best dsc: 0.9021440568122753 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 05:35:29.131104: finished real validation
2023-09-06 05:35:33.352898: train_loss -1.4434
2023-09-06 05:35:33.354596: val_loss -1.078
2023-09-06 05:35:33.356148: Pseudo dice [0.902]
2023-09-06 05:35:33.357307: Epoch time: 322.41 s
2023-09-06 05:35:34.455199: 
2023-09-06 05:35:34.456679: Epoch 174
2023-09-06 05:35:34.458171: Current learning rate: backbone 0.00045806, others 0.00045806
2023-09-06 05:35:34.459868: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-06 05:36:33.085041: finished training epoch 174
2023-09-06 05:36:33.112190: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset122_ISIC2017/splits_final.json
2023-09-06 05:36:33.114118: The split file contains 1 splits.
2023-09-06 05:36:33.115179: Desired fold for training: 0
2023-09-06 05:36:33.116175: This split has 1500 training and 650 validation cases.
start computing score....
2023-09-06 05:40:41.011993: dsc: 90.18%
2023-09-06 05:40:41.013554: miou: 82.12%
2023-09-06 05:40:41.014845: acc: 96.74%, sen: 89.39%, spe: 98.22%
2023-09-06 05:40:41.016562: current best miou: 0.821732634787054 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 05:40:41.017894: current best dsc: 0.9021440568122753 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 05:40:41.019159: finished real validation
2023-09-06 05:40:45.238178: train_loss -1.4443
2023-09-06 05:40:45.239803: val_loss -1.0711
2023-09-06 05:40:45.241147: Pseudo dice [0.8991]
2023-09-06 05:40:45.242223: Epoch time: 310.78 s
2023-09-06 05:40:46.335745: 
2023-09-06 05:40:46.337615: Epoch 175
2023-09-06 05:40:46.338941: Current learning rate: backbone 0.00045479, others 0.00045479
2023-09-06 05:40:46.340955: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-06 05:41:44.893454: finished training epoch 175
2023-09-06 05:41:44.918606: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset122_ISIC2017/splits_final.json
2023-09-06 05:41:44.920547: The split file contains 1 splits.
2023-09-06 05:41:44.921779: Desired fold for training: 0
2023-09-06 05:41:44.922756: This split has 1500 training and 650 validation cases.
start computing score....
2023-09-06 05:45:48.518046: dsc: 89.97%
2023-09-06 05:45:48.519636: miou: 81.77%
2023-09-06 05:45:48.520962: acc: 96.67%, sen: 89.13%, spe: 98.19%
2023-09-06 05:45:48.522525: current best miou: 0.821732634787054 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 05:45:48.523583: current best dsc: 0.9021440568122753 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 05:45:48.524561: finished real validation
2023-09-06 05:45:52.744523: train_loss -1.4446
2023-09-06 05:45:52.746191: val_loss -1.0709
2023-09-06 05:45:52.747459: Pseudo dice [0.8988]
2023-09-06 05:45:52.748554: Epoch time: 306.41 s
2023-09-06 05:45:53.844634: 
2023-09-06 05:45:53.846048: Epoch 176
2023-09-06 05:45:53.847138: Current learning rate: backbone 0.00045151, others 0.00045151
2023-09-06 05:45:53.849109: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-06 05:46:52.534710: finished training epoch 176
2023-09-06 05:46:52.560776: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset122_ISIC2017/splits_final.json
2023-09-06 05:46:52.562677: The split file contains 1 splits.
2023-09-06 05:46:52.563716: Desired fold for training: 0
2023-09-06 05:46:52.564655: This split has 1500 training and 650 validation cases.
start computing score....
2023-09-06 05:50:56.319235: dsc: 90.07%
2023-09-06 05:50:56.320931: miou: 81.94%
2023-09-06 05:50:56.322202: acc: 96.70%, sen: 89.25%, spe: 98.20%
2023-09-06 05:50:56.324215: current best miou: 0.821732634787054 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 05:50:56.325446: current best dsc: 0.9021440568122753 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 05:50:56.326492: finished real validation
2023-09-06 05:51:00.539557: train_loss -1.4441
2023-09-06 05:51:00.541283: val_loss -1.0755
2023-09-06 05:51:00.542563: Pseudo dice [0.8994]
2023-09-06 05:51:00.543945: Epoch time: 306.7 s
2023-09-06 05:51:01.632936: 
2023-09-06 05:51:01.634331: Epoch 177
2023-09-06 05:51:01.635797: Current learning rate: backbone 0.00044823, others 0.00044823
2023-09-06 05:51:01.637612: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-06 05:52:00.233767: finished training epoch 177
2023-09-06 05:52:00.259122: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset122_ISIC2017/splits_final.json
2023-09-06 05:52:00.260936: The split file contains 1 splits.
2023-09-06 05:52:00.261881: Desired fold for training: 0
2023-09-06 05:52:00.262794: This split has 1500 training and 650 validation cases.
start computing score....
2023-09-06 05:56:06.008404: dsc: 90.15%
2023-09-06 05:56:06.010043: miou: 82.07%
2023-09-06 05:56:06.011133: acc: 96.72%, sen: 89.69%, spe: 98.13%
2023-09-06 05:56:06.012549: current best miou: 0.821732634787054 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 05:56:06.013987: current best dsc: 0.9021440568122753 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 05:56:06.015170: finished real validation
2023-09-06 05:56:10.236769: train_loss -1.4445
2023-09-06 05:56:10.238445: val_loss -1.0681
2023-09-06 05:56:10.239807: Pseudo dice [0.8979]
2023-09-06 05:56:10.240880: Epoch time: 308.61 s
2023-09-06 05:56:11.330989: 
2023-09-06 05:56:11.332550: Epoch 178
2023-09-06 05:56:11.334085: Current learning rate: backbone 0.00044495, others 0.00044495
2023-09-06 05:56:11.335977: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-06 05:57:09.898895: finished training epoch 178
2023-09-06 05:57:09.924902: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset122_ISIC2017/splits_final.json
2023-09-06 05:57:09.926771: The split file contains 1 splits.
2023-09-06 05:57:09.927861: Desired fold for training: 0
2023-09-06 05:57:09.928879: This split has 1500 training and 650 validation cases.
start computing score....
2023-09-06 06:01:13.723396: dsc: 89.99%
2023-09-06 06:01:13.724964: miou: 81.81%
2023-09-06 06:01:13.726027: acc: 96.68%, sen: 89.16%, spe: 98.19%
2023-09-06 06:01:13.727398: current best miou: 0.821732634787054 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 06:01:13.728688: current best dsc: 0.9021440568122753 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 06:01:13.729818: finished real validation
2023-09-06 06:01:17.941525: train_loss -1.4443
2023-09-06 06:01:17.943082: val_loss -1.0732
2023-09-06 06:01:17.944380: Pseudo dice [0.899]
2023-09-06 06:01:17.945562: Epoch time: 306.61 s
2023-09-06 06:01:19.042120: 
2023-09-06 06:01:19.043651: Epoch 179
2023-09-06 06:01:19.045087: Current learning rate: backbone 0.00044167, others 0.00044167
2023-09-06 06:01:19.046794: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-06 06:02:17.673681: finished training epoch 179
2023-09-06 06:02:17.699615: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset122_ISIC2017/splits_final.json
2023-09-06 06:02:17.701394: The split file contains 1 splits.
2023-09-06 06:02:17.702542: Desired fold for training: 0
2023-09-06 06:02:17.703568: This split has 1500 training and 650 validation cases.
start computing score....
2023-09-06 06:06:20.926538: dsc: 90.10%
2023-09-06 06:06:20.928230: miou: 81.99%
2023-09-06 06:06:20.929216: acc: 96.72%, sen: 89.21%, spe: 98.23%
2023-09-06 06:06:20.930515: current best miou: 0.821732634787054 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 06:06:20.931530: current best dsc: 0.9021440568122753 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 06:06:20.932437: finished real validation
2023-09-06 06:06:25.144074: train_loss -1.4442
2023-09-06 06:06:25.145884: val_loss -1.0776
2023-09-06 06:06:25.147503: Pseudo dice [0.8995]
2023-09-06 06:06:25.148776: Epoch time: 306.1 s
2023-09-06 06:06:27.788444: 
2023-09-06 06:06:27.789897: Epoch 180
2023-09-06 06:06:27.791312: Current learning rate: backbone 0.00043838, others 0.00043838
2023-09-06 06:06:27.793066: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-06 06:07:26.500816: finished training epoch 180
2023-09-06 06:07:26.527367: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset122_ISIC2017/splits_final.json
2023-09-06 06:07:26.529467: The split file contains 1 splits.
2023-09-06 06:07:26.530786: Desired fold for training: 0
2023-09-06 06:07:26.532046: This split has 1500 training and 650 validation cases.
start computing score....
2023-09-06 06:11:38.345040: dsc: 90.06%
2023-09-06 06:11:38.346641: miou: 81.92%
2023-09-06 06:11:38.347849: acc: 96.71%, sen: 88.90%, spe: 98.29%
2023-09-06 06:11:38.349522: current best miou: 0.821732634787054 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 06:11:38.350623: current best dsc: 0.9021440568122753 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 06:11:38.351800: finished real validation
2023-09-06 06:11:42.569406: train_loss -1.444
2023-09-06 06:11:42.571331: val_loss -1.0717
2023-09-06 06:11:42.573212: Pseudo dice [0.8995]
2023-09-06 06:11:42.574772: Epoch time: 314.78 s
2023-09-06 06:11:43.672302: 
2023-09-06 06:11:43.673946: Epoch 181
2023-09-06 06:11:43.675076: Current learning rate: backbone 0.00043509, others 0.00043509
2023-09-06 06:11:43.677030: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-06 06:12:42.215959: finished training epoch 181
2023-09-06 06:12:42.242035: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset122_ISIC2017/splits_final.json
2023-09-06 06:12:42.243955: The split file contains 1 splits.
2023-09-06 06:12:42.245053: Desired fold for training: 0
2023-09-06 06:12:42.246081: This split has 1500 training and 650 validation cases.
start computing score....
2023-09-06 06:16:46.385418: dsc: 90.13%
2023-09-06 06:16:46.386960: miou: 82.03%
2023-09-06 06:16:46.388348: acc: 96.73%, sen: 89.21%, spe: 98.24%
2023-09-06 06:16:46.390046: current best miou: 0.821732634787054 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 06:16:46.391395: current best dsc: 0.9021440568122753 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 06:16:46.392788: finished real validation
2023-09-06 06:16:50.620915: train_loss -1.4447
2023-09-06 06:16:50.622596: val_loss -1.0835
2023-09-06 06:16:50.623942: Pseudo dice [0.9029]
2023-09-06 06:16:50.625075: Epoch time: 306.95 s
2023-09-06 06:16:51.758375: 
2023-09-06 06:16:51.760193: Epoch 182
2023-09-06 06:16:51.761679: Current learning rate: backbone 0.0004318, others 0.0004318
2023-09-06 06:16:51.763568: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-06 06:17:50.370164: finished training epoch 182
2023-09-06 06:17:50.417122: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset122_ISIC2017/splits_final.json
2023-09-06 06:17:50.419245: The split file contains 1 splits.
2023-09-06 06:17:50.420298: Desired fold for training: 0
2023-09-06 06:17:50.421291: This split has 1500 training and 650 validation cases.
start computing score....
2023-09-06 06:22:19.109444: dsc: 90.03%
2023-09-06 06:22:19.111278: miou: 81.86%
2023-09-06 06:22:19.112487: acc: 96.69%, sen: 89.06%, spe: 98.23%
2023-09-06 06:22:19.113944: current best miou: 0.821732634787054 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 06:22:19.115337: current best dsc: 0.9021440568122753 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 06:22:19.116479: finished real validation
2023-09-06 06:22:23.335057: train_loss -1.4448
2023-09-06 06:22:23.336684: val_loss -1.0904
2023-09-06 06:22:23.337947: Pseudo dice [0.9025]
2023-09-06 06:22:23.339042: Epoch time: 331.58 s
2023-09-06 06:22:24.440405: 
2023-09-06 06:22:24.441826: Epoch 183
2023-09-06 06:22:24.443351: Current learning rate: backbone 0.00042851, others 0.00042851
2023-09-06 06:22:24.444813: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-06 06:23:23.114054: finished training epoch 183
2023-09-06 06:23:23.247298: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset122_ISIC2017/splits_final.json
2023-09-06 06:23:23.260159: The split file contains 1 splits.
2023-09-06 06:23:23.269395: Desired fold for training: 0
2023-09-06 06:23:23.282412: This split has 1500 training and 650 validation cases.
start computing score....
2023-09-06 06:28:09.363313: dsc: 90.07%
2023-09-06 06:28:09.364935: miou: 81.94%
2023-09-06 06:28:09.366086: acc: 96.70%, sen: 89.48%, spe: 98.15%
2023-09-06 06:28:09.368019: current best miou: 0.821732634787054 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 06:28:09.369353: current best dsc: 0.9021440568122753 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 06:28:09.370613: finished real validation
2023-09-06 06:28:13.595560: train_loss -1.4449
2023-09-06 06:28:13.597329: val_loss -1.0823
2023-09-06 06:28:13.598658: Pseudo dice [0.9022]
2023-09-06 06:28:13.599800: Epoch time: 349.16 s
2023-09-06 06:28:14.730999: 
2023-09-06 06:28:14.732347: Epoch 184
2023-09-06 06:28:14.733479: Current learning rate: backbone 0.00042521, others 0.00042521
2023-09-06 06:28:14.734919: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-06 06:29:13.497534: finished training epoch 184
2023-09-06 06:29:13.535198: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset122_ISIC2017/splits_final.json
2023-09-06 06:29:13.537506: The split file contains 1 splits.
2023-09-06 06:29:13.538561: Desired fold for training: 0
2023-09-06 06:29:13.539570: This split has 1500 training and 650 validation cases.
start computing score....
2023-09-06 06:33:28.656131: dsc: 90.08%
2023-09-06 06:33:28.821414: miou: 81.96%
2023-09-06 06:33:28.822805: acc: 96.71%, sen: 89.33%, spe: 98.19%
2023-09-06 06:33:28.825154: current best miou: 0.821732634787054 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 06:33:28.826373: current best dsc: 0.9021440568122753 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 06:33:28.827583: finished real validation
2023-09-06 06:33:33.036818: train_loss -1.4447
2023-09-06 06:33:33.038277: val_loss -1.0896
2023-09-06 06:33:33.039580: Pseudo dice [0.9014]
2023-09-06 06:33:33.040696: Epoch time: 318.31 s
2023-09-06 06:33:34.246683: 
2023-09-06 06:33:34.247952: Epoch 185
2023-09-06 06:33:34.249180: Current learning rate: backbone 0.00042191, others 0.00042191
2023-09-06 06:33:34.250604: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-06 06:34:33.027877: finished training epoch 185
2023-09-06 06:34:33.068747: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset122_ISIC2017/splits_final.json
2023-09-06 06:34:33.070644: The split file contains 1 splits.
2023-09-06 06:34:33.071741: Desired fold for training: 0
2023-09-06 06:34:33.072779: This split has 1500 training and 650 validation cases.
start computing score....
2023-09-06 06:38:47.196955: dsc: 89.94%
2023-09-06 06:38:47.198681: miou: 81.72%
2023-09-06 06:38:47.200013: acc: 96.65%, sen: 89.36%, spe: 98.12%
2023-09-06 06:38:47.201530: current best miou: 0.821732634787054 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 06:38:47.202606: current best dsc: 0.9021440568122753 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 06:38:47.203708: finished real validation
2023-09-06 06:38:51.405455: train_loss -1.4449
2023-09-06 06:38:51.407029: val_loss -1.0923
2023-09-06 06:38:51.408440: Pseudo dice [0.904]
2023-09-06 06:38:51.409603: Epoch time: 317.16 s
2023-09-06 06:38:52.536677: 
2023-09-06 06:38:52.538088: Epoch 186
2023-09-06 06:38:52.539340: Current learning rate: backbone 0.00041861, others 0.00041861
2023-09-06 06:38:52.540894: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-06 06:39:51.364457: finished training epoch 186
2023-09-06 06:39:51.401860: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset122_ISIC2017/splits_final.json
2023-09-06 06:39:51.404001: The split file contains 1 splits.
2023-09-06 06:39:51.405378: Desired fold for training: 0
2023-09-06 06:39:51.406876: This split has 1500 training and 650 validation cases.
start computing score....
2023-09-06 06:44:01.250722: dsc: 90.07%
2023-09-06 06:44:01.252574: miou: 81.93%
2023-09-06 06:44:01.253634: acc: 96.69%, sen: 89.69%, spe: 98.09%
2023-09-06 06:44:01.255142: current best miou: 0.821732634787054 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 06:44:01.256420: current best dsc: 0.9021440568122753 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 06:44:01.257674: finished real validation
2023-09-06 06:44:05.458696: train_loss -1.4452
2023-09-06 06:44:05.460341: val_loss -1.0658
2023-09-06 06:44:05.461709: Pseudo dice [0.9002]
2023-09-06 06:44:05.463071: Epoch time: 312.92 s
2023-09-06 06:44:06.602650: 
2023-09-06 06:44:06.604303: Epoch 187
2023-09-06 06:44:06.605461: Current learning rate: backbone 0.0004153, others 0.0004153
2023-09-06 06:44:06.606966: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-06 06:45:05.409283: finished training epoch 187
2023-09-06 06:45:05.444021: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset122_ISIC2017/splits_final.json
2023-09-06 06:45:05.447294: The split file contains 1 splits.
2023-09-06 06:45:05.450203: Desired fold for training: 0
2023-09-06 06:45:05.452976: This split has 1500 training and 650 validation cases.
start computing score....
2023-09-06 06:49:12.108550: dsc: 90.12%
2023-09-06 06:49:12.111506: miou: 82.01%
2023-09-06 06:49:12.114430: acc: 96.72%, sen: 89.33%, spe: 98.20%
2023-09-06 06:49:12.117913: current best miou: 0.821732634787054 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 06:49:12.120522: current best dsc: 0.9021440568122753 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 06:49:12.123157: finished real validation
2023-09-06 06:49:16.323262: train_loss -1.4447
2023-09-06 06:49:16.326230: val_loss -1.0908
2023-09-06 06:49:16.329053: Pseudo dice [0.9017]
2023-09-06 06:49:16.331547: Epoch time: 309.72 s
2023-09-06 06:49:17.449523: 
2023-09-06 06:49:17.452607: Epoch 188
2023-09-06 06:49:17.455359: Current learning rate: backbone 0.00041199, others 0.00041199
2023-09-06 06:49:17.458744: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-06 06:50:16.176882: finished training epoch 188
2023-09-06 06:50:16.203886: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset122_ISIC2017/splits_final.json
2023-09-06 06:50:16.206628: The split file contains 1 splits.
2023-09-06 06:50:16.208702: Desired fold for training: 0
2023-09-06 06:50:16.210484: This split has 1500 training and 650 validation cases.
start computing score....
2023-09-06 06:54:29.357667: dsc: 90.13%
2023-09-06 06:54:29.359489: miou: 82.04%
2023-09-06 06:54:29.360576: acc: 96.72%, sen: 89.30%, spe: 98.22%
2023-09-06 06:54:29.362812: current best miou: 0.821732634787054 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 06:54:29.364003: current best dsc: 0.9021440568122753 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 06:54:29.365279: finished real validation
2023-09-06 06:54:33.557296: train_loss -1.4455
2023-09-06 06:54:33.558962: val_loss -1.0926
2023-09-06 06:54:33.560517: Pseudo dice [0.9047]
2023-09-06 06:54:33.561890: Epoch time: 316.11 s
2023-09-06 06:54:33.563221: Yayy! New best EMA pseudo Dice: 0.901
2023-09-06 06:54:36.442006: 
2023-09-06 06:54:36.444020: Epoch 189
2023-09-06 06:54:36.445677: Current learning rate: backbone 0.00040868, others 0.00040868
2023-09-06 06:54:36.447814: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-06 06:55:35.415323: finished training epoch 189
2023-09-06 06:55:35.441204: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset122_ISIC2017/splits_final.json
2023-09-06 06:55:35.443106: The split file contains 1 splits.
2023-09-06 06:55:35.444424: Desired fold for training: 0
2023-09-06 06:55:35.445749: This split has 1500 training and 650 validation cases.
start computing score....
2023-09-06 07:00:43.170996: dsc: 90.16%
2023-09-06 07:00:43.173065: miou: 82.09%
2023-09-06 07:00:43.174633: acc: 96.73%, sen: 89.55%, spe: 98.17%
2023-09-06 07:00:43.177096: current best miou: 0.821732634787054 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 07:00:43.179625: current best dsc: 0.9021440568122753 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 07:00:43.182400: finished real validation
2023-09-06 07:00:47.393581: train_loss -1.4451
2023-09-06 07:00:47.395310: val_loss -1.0741
2023-09-06 07:00:47.396892: Pseudo dice [0.9005]
2023-09-06 07:00:47.398173: Epoch time: 370.95 s
2023-09-06 07:00:50.288105: 
2023-09-06 07:00:50.289819: Epoch 190
2023-09-06 07:00:50.291553: Current learning rate: backbone 0.00040536, others 0.00040536
2023-09-06 07:00:50.293813: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-06 07:01:49.196054: finished training epoch 190
2023-09-06 07:01:49.237665: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset122_ISIC2017/splits_final.json
2023-09-06 07:01:49.240199: The split file contains 1 splits.
2023-09-06 07:01:49.241713: Desired fold for training: 0
2023-09-06 07:01:49.243412: This split has 1500 training and 650 validation cases.
start computing score....
2023-09-06 07:06:03.174191: dsc: 90.02%
2023-09-06 07:06:03.177701: miou: 81.86%
2023-09-06 07:06:03.180967: acc: 96.68%, sen: 89.43%, spe: 98.14%
2023-09-06 07:06:03.185081: current best miou: 0.821732634787054 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 07:06:03.188308: current best dsc: 0.9021440568122753 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 07:06:03.191472: finished real validation
2023-09-06 07:06:07.412209: train_loss -1.4447
2023-09-06 07:06:07.414851: val_loss -1.0976
2023-09-06 07:06:07.417539: Pseudo dice [0.9027]
2023-09-06 07:06:07.420028: Epoch time: 317.13 s
2023-09-06 07:06:07.422505: Yayy! New best EMA pseudo Dice: 0.9012
2023-09-06 07:06:10.471966: 
2023-09-06 07:06:10.473569: Epoch 191
2023-09-06 07:06:10.474770: Current learning rate: backbone 0.00040205, others 0.00040205
2023-09-06 07:06:10.476840: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-06 07:07:09.220337: finished training epoch 191
2023-09-06 07:07:09.260827: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset122_ISIC2017/splits_final.json
2023-09-06 07:07:09.263994: The split file contains 1 splits.
2023-09-06 07:07:09.265921: Desired fold for training: 0
2023-09-06 07:07:09.267163: This split has 1500 training and 650 validation cases.
start computing score....
2023-09-06 07:11:23.442649: dsc: 90.04%
2023-09-06 07:11:23.445142: miou: 81.89%
2023-09-06 07:11:23.446610: acc: 96.71%, sen: 88.96%, spe: 98.26%
2023-09-06 07:11:23.449072: current best miou: 0.821732634787054 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 07:11:23.451077: current best dsc: 0.9021440568122753 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 07:11:23.452887: finished real validation
2023-09-06 07:11:27.668924: train_loss -1.4452
2023-09-06 07:11:27.671081: val_loss -1.0688
2023-09-06 07:11:27.673083: Pseudo dice [0.8976]
2023-09-06 07:11:27.674563: Epoch time: 317.2 s
2023-09-06 07:11:28.808079: 
2023-09-06 07:11:28.811743: Epoch 192
2023-09-06 07:11:28.813614: Current learning rate: backbone 0.00039872, others 0.00039872
2023-09-06 07:11:28.815896: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-06 07:12:27.656567: finished training epoch 192
2023-09-06 07:12:27.695675: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset122_ISIC2017/splits_final.json
2023-09-06 07:12:27.697917: The split file contains 1 splits.
2023-09-06 07:12:27.699352: Desired fold for training: 0
2023-09-06 07:12:27.700709: This split has 1500 training and 650 validation cases.
start computing score....
2023-09-06 07:16:33.121370: dsc: 90.12%
2023-09-06 07:16:33.124290: miou: 82.02%
2023-09-06 07:16:33.126574: acc: 96.73%, sen: 89.10%, spe: 98.26%
2023-09-06 07:16:33.129512: current best miou: 0.821732634787054 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 07:16:33.131268: current best dsc: 0.9021440568122753 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 07:16:33.132688: finished real validation
2023-09-06 07:16:37.344515: train_loss -1.4453
2023-09-06 07:16:37.346499: val_loss -1.1131
2023-09-06 07:16:37.347986: Pseudo dice [0.9089]
2023-09-06 07:16:37.349246: Epoch time: 308.54 s
2023-09-06 07:16:37.350403: Yayy! New best EMA pseudo Dice: 0.9016
2023-09-06 07:16:40.166450: 
2023-09-06 07:16:40.168584: Epoch 193
2023-09-06 07:16:40.170848: Current learning rate: backbone 0.0003954, others 0.0003954
2023-09-06 07:16:40.172761: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-06 07:17:38.874906: finished training epoch 193
2023-09-06 07:17:38.900330: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset122_ISIC2017/splits_final.json
2023-09-06 07:17:38.902404: The split file contains 1 splits.
2023-09-06 07:17:38.903587: Desired fold for training: 0
2023-09-06 07:17:38.904668: This split has 1500 training and 650 validation cases.
start computing score....
2023-09-06 07:21:47.899466: dsc: 90.20%
2023-09-06 07:21:47.901411: miou: 82.15%
2023-09-06 07:21:47.902972: acc: 96.75%, sen: 89.39%, spe: 98.23%
2023-09-06 07:21:47.904701: current best miou: 0.821732634787054 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 07:21:47.905925: current best dsc: 0.9021440568122753 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 07:21:47.907245: finished real validation
2023-09-06 07:21:52.114791: train_loss -1.4452
2023-09-06 07:21:52.116717: val_loss -1.0842
2023-09-06 07:21:52.118277: Pseudo dice [0.9027]
2023-09-06 07:21:52.119839: Epoch time: 311.95 s
2023-09-06 07:21:52.121225: Yayy! New best EMA pseudo Dice: 0.9017
2023-09-06 07:21:54.947095: 
2023-09-06 07:21:54.949013: Epoch 194
2023-09-06 07:21:54.950485: Current learning rate: backbone 0.00039207, others 0.00039207
2023-09-06 07:21:54.952612: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-06 07:22:54.315445: finished training epoch 194
2023-09-06 07:22:54.356663: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset122_ISIC2017/splits_final.json
2023-09-06 07:22:54.359387: The split file contains 1 splits.
2023-09-06 07:22:54.361212: Desired fold for training: 0
2023-09-06 07:22:54.362512: This split has 1500 training and 650 validation cases.
start computing score....
2023-09-06 07:27:03.242546: dsc: 90.14%
2023-09-06 07:27:03.245338: miou: 82.05%
2023-09-06 07:27:03.248248: acc: 96.72%, sen: 89.60%, spe: 98.15%
2023-09-06 07:27:03.251299: current best miou: 0.821732634787054 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 07:27:03.254191: current best dsc: 0.9021440568122753 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 07:27:03.256361: finished real validation
2023-09-06 07:27:07.473775: train_loss -1.4447
2023-09-06 07:27:07.475709: val_loss -1.0935
2023-09-06 07:27:07.478004: Pseudo dice [0.903]
2023-09-06 07:27:07.480344: Epoch time: 312.53 s
2023-09-06 07:27:07.482523: Yayy! New best EMA pseudo Dice: 0.9018
2023-09-06 07:27:10.626513: 
2023-09-06 07:27:10.628407: Epoch 195
2023-09-06 07:27:10.630381: Current learning rate: backbone 0.00038874, others 0.00038874
2023-09-06 07:27:10.632769: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-06 07:28:09.388190: finished training epoch 195
2023-09-06 07:28:09.415118: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset122_ISIC2017/splits_final.json
2023-09-06 07:28:09.418198: The split file contains 1 splits.
2023-09-06 07:28:09.420302: Desired fold for training: 0
2023-09-06 07:28:09.422382: This split has 1500 training and 650 validation cases.
start computing score....
2023-09-06 07:32:23.662915: dsc: 90.02%
2023-09-06 07:32:23.664578: miou: 81.85%
2023-09-06 07:32:23.665690: acc: 96.68%, sen: 89.46%, spe: 98.13%
2023-09-06 07:32:23.667159: current best miou: 0.821732634787054 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 07:32:23.668340: current best dsc: 0.9021440568122753 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 07:32:23.669396: finished real validation
2023-09-06 07:32:27.863487: train_loss -1.4457
2023-09-06 07:32:27.865748: val_loss -1.0619
2023-09-06 07:32:27.867852: Pseudo dice [0.8978]
2023-09-06 07:32:27.869781: Epoch time: 317.24 s
2023-09-06 07:32:29.041880: 
2023-09-06 07:32:29.044351: Epoch 196
2023-09-06 07:32:29.046960: Current learning rate: backbone 0.00038541, others 0.00038541
2023-09-06 07:32:29.049160: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-06 07:33:27.780094: finished training epoch 196
2023-09-06 07:33:27.848969: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset122_ISIC2017/splits_final.json
2023-09-06 07:33:27.857904: The split file contains 1 splits.
2023-09-06 07:33:27.865863: Desired fold for training: 0
2023-09-06 07:33:27.867208: This split has 1500 training and 650 validation cases.
start computing score....
2023-09-06 07:38:32.381608: dsc: 90.11%
2023-09-06 07:38:32.383382: miou: 82.00%
2023-09-06 07:38:32.384830: acc: 96.72%, sen: 89.24%, spe: 98.22%
2023-09-06 07:38:32.387012: current best miou: 0.821732634787054 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 07:38:32.388542: current best dsc: 0.9021440568122753 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 07:38:32.389917: finished real validation
2023-09-06 07:38:36.600960: train_loss -1.446
2023-09-06 07:38:36.602632: val_loss -1.0749
2023-09-06 07:38:36.604040: Pseudo dice [0.9005]
2023-09-06 07:38:36.606124: Epoch time: 367.56 s
2023-09-06 07:38:37.748064: 
2023-09-06 07:38:37.750458: Epoch 197
2023-09-06 07:38:37.753590: Current learning rate: backbone 0.00038207, others 0.00038207
2023-09-06 07:38:37.756779: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-06 07:39:36.592860: finished training epoch 197
2023-09-06 07:39:36.618866: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset122_ISIC2017/splits_final.json
2023-09-06 07:39:36.620764: The split file contains 1 splits.
2023-09-06 07:39:36.621929: Desired fold for training: 0
2023-09-06 07:39:36.623032: This split has 1500 training and 650 validation cases.
start computing score....
2023-09-06 07:43:53.352968: dsc: 90.04%
2023-09-06 07:43:53.354865: miou: 81.88%
2023-09-06 07:43:53.356177: acc: 96.71%, sen: 88.71%, spe: 98.32%
2023-09-06 07:43:53.357787: current best miou: 0.821732634787054 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 07:43:53.359040: current best dsc: 0.9021440568122753 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 07:43:53.360205: finished real validation
2023-09-06 07:43:57.558456: train_loss -1.4458
2023-09-06 07:43:57.560402: val_loss -1.0861
2023-09-06 07:43:57.562874: Pseudo dice [0.9045]
2023-09-06 07:43:57.565090: Epoch time: 319.81 s
2023-09-06 07:43:58.736977: 
2023-09-06 07:43:58.738705: Epoch 198
2023-09-06 07:43:58.740016: Current learning rate: backbone 0.00037873, others 0.00037873
2023-09-06 07:43:58.741832: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-06 07:44:57.606022: finished training epoch 198
2023-09-06 07:44:57.640792: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset122_ISIC2017/splits_final.json
2023-09-06 07:44:57.643437: The split file contains 1 splits.
2023-09-06 07:44:57.644680: Desired fold for training: 0
2023-09-06 07:44:57.646036: This split has 1500 training and 650 validation cases.
start computing score....
2023-09-06 07:49:16.538424: dsc: 90.09%
2023-09-06 07:49:16.542038: miou: 81.96%
2023-09-06 07:49:16.543834: acc: 96.70%, sen: 89.61%, spe: 98.12%
2023-09-06 07:49:16.546432: current best miou: 0.821732634787054 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 07:49:16.548099: current best dsc: 0.9021440568122753 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 07:49:16.549808: finished real validation
2023-09-06 07:49:20.765909: train_loss -1.4462
2023-09-06 07:49:20.767781: val_loss -1.0659
2023-09-06 07:49:20.769262: Pseudo dice [0.9014]
2023-09-06 07:49:20.770599: Epoch time: 322.03 s
2023-09-06 07:49:21.932691: 
2023-09-06 07:49:21.934638: Epoch 199
2023-09-06 07:49:21.936033: Current learning rate: backbone 0.00037539, others 0.00037539
2023-09-06 07:49:21.937942: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-06 07:50:20.829687: finished training epoch 199
2023-09-06 07:50:20.867636: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset122_ISIC2017/splits_final.json
2023-09-06 07:50:20.869407: The split file contains 1 splits.
2023-09-06 07:50:20.870854: Desired fold for training: 0
2023-09-06 07:50:20.872535: This split has 1500 training and 650 validation cases.
start computing score....
2023-09-06 07:55:02.090486: dsc: 89.98%
2023-09-06 07:55:02.092762: miou: 81.78%
2023-09-06 07:55:02.094111: acc: 96.67%, sen: 89.30%, spe: 98.15%
2023-09-06 07:55:02.096040: current best miou: 0.821732634787054 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 07:55:02.097566: current best dsc: 0.9021440568122753 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 07:55:02.099047: finished real validation
2023-09-06 07:55:06.295999: train_loss -1.4463
2023-09-06 07:55:06.297832: val_loss -1.0763
2023-09-06 07:55:06.299327: Pseudo dice [0.9019]
2023-09-06 07:55:06.300597: Epoch time: 344.36 s
2023-09-06 07:55:09.033557: 
2023-09-06 07:55:09.035251: Epoch 200
2023-09-06 07:55:09.036831: Current learning rate: backbone 0.00037204, others 0.00037204
2023-09-06 07:55:09.038785: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-06 07:56:07.872726: finished training epoch 200
2023-09-06 07:56:07.906173: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset122_ISIC2017/splits_final.json
2023-09-06 07:56:07.909020: The split file contains 1 splits.
2023-09-06 07:56:07.911071: Desired fold for training: 0
2023-09-06 07:56:07.912539: This split has 1500 training and 650 validation cases.
start computing score....
2023-09-06 08:00:18.108432: dsc: 90.10%
2023-09-06 08:00:18.112797: miou: 81.98%
2023-09-06 08:00:18.115164: acc: 96.71%, sen: 89.45%, spe: 98.17%
2023-09-06 08:00:18.117873: current best miou: 0.821732634787054 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 08:00:18.120402: current best dsc: 0.9021440568122753 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 08:00:18.123375: finished real validation
2023-09-06 08:00:22.312104: train_loss -1.4455
2023-09-06 08:00:22.314493: val_loss -1.0793
2023-09-06 08:00:22.316787: Pseudo dice [0.9032]
2023-09-06 08:00:22.318247: Epoch time: 313.28 s
2023-09-06 08:00:23.451222: 
2023-09-06 08:00:23.452969: Epoch 201
2023-09-06 08:00:23.454430: Current learning rate: backbone 0.00036869, others 0.00036869
2023-09-06 08:00:23.456342: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-06 08:01:22.194795: finished training epoch 201
2023-09-06 08:01:22.222414: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset122_ISIC2017/splits_final.json
2023-09-06 08:01:22.227451: The split file contains 1 splits.
2023-09-06 08:01:22.231374: Desired fold for training: 0
2023-09-06 08:01:22.234547: This split has 1500 training and 650 validation cases.
start computing score....
2023-09-06 08:05:39.535641: dsc: 89.94%
2023-09-06 08:05:39.538301: miou: 81.71%
2023-09-06 08:05:39.540077: acc: 96.65%, sen: 89.28%, spe: 98.14%
2023-09-06 08:05:39.541876: current best miou: 0.821732634787054 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 08:05:39.543270: current best dsc: 0.9021440568122753 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 08:05:39.544795: finished real validation
2023-09-06 08:05:43.738206: train_loss -1.4459
2023-09-06 08:05:43.740138: val_loss -1.0526
2023-09-06 08:05:43.741688: Pseudo dice [0.897]
2023-09-06 08:05:43.743014: Epoch time: 320.29 s
2023-09-06 08:05:44.882508: 
2023-09-06 08:05:44.884464: Epoch 202
2023-09-06 08:05:44.886387: Current learning rate: backbone 0.00036534, others 0.00036534
2023-09-06 08:05:44.888169: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-06 08:06:43.620661: finished training epoch 202
2023-09-06 08:06:43.659037: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset122_ISIC2017/splits_final.json
2023-09-06 08:06:43.661151: The split file contains 1 splits.
2023-09-06 08:06:43.662338: Desired fold for training: 0
2023-09-06 08:06:43.663528: This split has 1500 training and 650 validation cases.
start computing score....
2023-09-06 08:11:08.038279: dsc: 90.08%
2023-09-06 08:11:08.040005: miou: 81.95%
2023-09-06 08:11:08.041281: acc: 96.71%, sen: 89.14%, spe: 98.23%
2023-09-06 08:11:08.042746: current best miou: 0.821732634787054 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 08:11:08.043956: current best dsc: 0.9021440568122753 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 08:11:08.045237: finished real validation
2023-09-06 08:11:12.244270: train_loss -1.4458
2023-09-06 08:11:12.246042: val_loss -1.0824
2023-09-06 08:11:12.247720: Pseudo dice [0.9035]
2023-09-06 08:11:12.248957: Epoch time: 327.36 s
2023-09-06 08:11:13.473873: 
2023-09-06 08:11:13.475587: Epoch 203
2023-09-06 08:11:13.476846: Current learning rate: backbone 0.00036198, others 0.00036198
2023-09-06 08:11:13.478456: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-06 08:12:12.586450: finished training epoch 203
2023-09-06 08:12:12.615092: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset122_ISIC2017/splits_final.json
2023-09-06 08:12:12.617087: The split file contains 1 splits.
2023-09-06 08:12:12.618325: Desired fold for training: 0
2023-09-06 08:12:12.619420: This split has 1500 training and 650 validation cases.
start computing score....
2023-09-06 08:16:27.584849: dsc: 90.03%
2023-09-06 08:16:27.586648: miou: 81.87%
2023-09-06 08:16:27.588123: acc: 96.68%, sen: 89.61%, spe: 98.10%
2023-09-06 08:16:27.590657: current best miou: 0.821732634787054 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 08:16:27.592185: current best dsc: 0.9021440568122753 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 08:16:27.593523: finished real validation
2023-09-06 08:16:31.785568: train_loss -1.4461
2023-09-06 08:16:31.787567: val_loss -1.074
2023-09-06 08:16:31.789208: Pseudo dice [0.9007]
2023-09-06 08:16:31.790555: Epoch time: 318.31 s
2023-09-06 08:16:32.938132: 
2023-09-06 08:16:32.939829: Epoch 204
2023-09-06 08:16:32.941441: Current learning rate: backbone 0.00035862, others 0.00035862
2023-09-06 08:16:32.943429: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-06 08:17:31.922076: finished training epoch 204
2023-09-06 08:17:31.956155: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset122_ISIC2017/splits_final.json
2023-09-06 08:17:31.958620: The split file contains 1 splits.
2023-09-06 08:17:31.960047: Desired fold for training: 0
2023-09-06 08:17:31.961395: This split has 1500 training and 650 validation cases.
start computing score....
2023-09-06 08:21:47.956680: dsc: 90.07%
2023-09-06 08:21:47.958608: miou: 81.93%
2023-09-06 08:21:47.959900: acc: 96.70%, sen: 89.27%, spe: 98.20%
2023-09-06 08:21:47.961760: current best miou: 0.821732634787054 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 08:21:47.962976: current best dsc: 0.9021440568122753 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 08:21:47.964120: finished real validation
2023-09-06 08:21:52.148914: train_loss -1.446
2023-09-06 08:21:52.150838: val_loss -1.0415
2023-09-06 08:21:52.152508: Pseudo dice [0.8955]
2023-09-06 08:21:52.153819: Epoch time: 319.21 s
2023-09-06 08:21:53.285471: 
2023-09-06 08:21:53.287499: Epoch 205
2023-09-06 08:21:53.289214: Current learning rate: backbone 0.00035526, others 0.00035526
2023-09-06 08:21:53.291359: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-06 08:22:52.135286: finished training epoch 205
2023-09-06 08:22:52.175213: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset122_ISIC2017/splits_final.json
2023-09-06 08:22:52.177636: The split file contains 1 splits.
2023-09-06 08:22:52.179355: Desired fold for training: 0
2023-09-06 08:22:52.180883: This split has 1500 training and 650 validation cases.
start computing score....
2023-09-06 08:26:58.867104: dsc: 90.09%
2023-09-06 08:26:58.869504: miou: 81.97%
2023-09-06 08:26:58.870733: acc: 96.70%, sen: 89.46%, spe: 98.16%
2023-09-06 08:26:58.872377: current best miou: 0.821732634787054 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 08:26:58.873586: current best dsc: 0.9021440568122753 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 08:26:58.874899: finished real validation
2023-09-06 08:27:03.081460: train_loss -1.4465
2023-09-06 08:27:03.083302: val_loss -1.0758
2023-09-06 08:27:03.084825: Pseudo dice [0.8993]
2023-09-06 08:27:03.086129: Epoch time: 309.8 s
2023-09-06 08:27:04.204243: 
2023-09-06 08:27:04.205955: Epoch 206
2023-09-06 08:27:04.207259: Current learning rate: backbone 0.00035189, others 0.00035189
2023-09-06 08:27:04.208959: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-06 08:28:03.109199: finished training epoch 206
2023-09-06 08:28:03.135733: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset122_ISIC2017/splits_final.json
2023-09-06 08:28:03.137733: The split file contains 1 splits.
2023-09-06 08:28:03.138935: Desired fold for training: 0
2023-09-06 08:28:03.140024: This split has 1500 training and 650 validation cases.
start computing score....
2023-09-06 08:32:11.231329: dsc: 90.09%
2023-09-06 08:32:11.233154: miou: 81.97%
2023-09-06 08:32:11.234643: acc: 96.71%, sen: 89.30%, spe: 98.20%
2023-09-06 08:32:11.236439: current best miou: 0.821732634787054 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 08:32:11.237651: current best dsc: 0.9021440568122753 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 08:32:11.238796: finished real validation
2023-09-06 08:32:15.444371: train_loss -1.4468
2023-09-06 08:32:15.446161: val_loss -1.0734
2023-09-06 08:32:15.447678: Pseudo dice [0.9021]
2023-09-06 08:32:15.448997: Epoch time: 311.24 s
2023-09-06 08:32:16.547491: 
2023-09-06 08:32:16.549744: Epoch 207
2023-09-06 08:32:16.551029: Current learning rate: backbone 0.00034852, others 0.00034852
2023-09-06 08:32:16.552692: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-06 08:33:15.310497: finished training epoch 207
2023-09-06 08:33:15.341151: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset122_ISIC2017/splits_final.json
2023-09-06 08:33:15.344118: The split file contains 1 splits.
2023-09-06 08:33:15.346449: Desired fold for training: 0
2023-09-06 08:33:15.348548: This split has 1500 training and 650 validation cases.
start computing score....
2023-09-06 08:37:25.559719: dsc: 90.00%
2023-09-06 08:37:25.561700: miou: 81.82%
2023-09-06 08:37:25.563388: acc: 96.68%, sen: 89.13%, spe: 98.20%
2023-09-06 08:37:25.567716: current best miou: 0.821732634787054 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 08:37:25.570844: current best dsc: 0.9021440568122753 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 08:37:25.572762: finished real validation
2023-09-06 08:37:29.776267: train_loss -1.4468
2023-09-06 08:37:29.778494: val_loss -1.0645
2023-09-06 08:37:29.780295: Pseudo dice [0.8996]
2023-09-06 08:37:29.781586: Epoch time: 313.23 s
2023-09-06 08:37:30.879593: 
2023-09-06 08:37:30.881366: Epoch 208
2023-09-06 08:37:30.882746: Current learning rate: backbone 0.00034514, others 0.00034514
2023-09-06 08:37:30.884573: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-06 08:38:29.774081: finished training epoch 208
2023-09-06 08:38:29.801213: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset122_ISIC2017/splits_final.json
2023-09-06 08:38:29.803325: The split file contains 1 splits.
2023-09-06 08:38:29.805084: Desired fold for training: 0
2023-09-06 08:38:29.806727: This split has 1500 training and 650 validation cases.
start computing score....
2023-09-06 08:42:40.160050: dsc: 90.01%
2023-09-06 08:42:40.162265: miou: 81.83%
2023-09-06 08:42:40.164162: acc: 96.69%, sen: 89.06%, spe: 98.22%
2023-09-06 08:42:40.166619: current best miou: 0.821732634787054 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 08:42:40.168131: current best dsc: 0.9021440568122753 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 08:42:40.169766: finished real validation
2023-09-06 08:42:44.368278: train_loss -1.4467
2023-09-06 08:42:44.370097: val_loss -1.0809
2023-09-06 08:42:44.371635: Pseudo dice [0.9021]
2023-09-06 08:42:44.372917: Epoch time: 313.49 s
2023-09-06 08:42:45.466110: 
2023-09-06 08:42:45.467730: Epoch 209
2023-09-06 08:42:45.469021: Current learning rate: backbone 0.00034177, others 0.00034177
2023-09-06 08:42:45.471009: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-06 08:43:44.439818: finished training epoch 209
2023-09-06 08:43:44.477233: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset122_ISIC2017/splits_final.json
2023-09-06 08:43:44.479377: The split file contains 1 splits.
2023-09-06 08:43:44.480625: Desired fold for training: 0
2023-09-06 08:43:44.482294: This split has 1500 training and 650 validation cases.
start computing score....
2023-09-06 08:47:54.795193: dsc: 90.05%
2023-09-06 08:47:54.798264: miou: 81.90%
2023-09-06 08:47:54.800349: acc: 96.71%, sen: 88.98%, spe: 98.26%
2023-09-06 08:47:54.802753: current best miou: 0.821732634787054 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 08:47:54.804266: current best dsc: 0.9021440568122753 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 08:47:54.805567: finished real validation
2023-09-06 08:47:58.983343: train_loss -1.4464
2023-09-06 08:47:58.985394: val_loss -1.0563
2023-09-06 08:47:58.986942: Pseudo dice [0.8996]
2023-09-06 08:47:58.988304: Epoch time: 313.52 s
2023-09-06 08:48:01.668000: 
2023-09-06 08:48:01.669749: Epoch 210
2023-09-06 08:48:01.671161: Current learning rate: backbone 0.00033838, others 0.00033838
2023-09-06 08:48:01.672863: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-06 08:49:00.525495: finished training epoch 210
2023-09-06 08:49:00.552317: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset122_ISIC2017/splits_final.json
2023-09-06 08:49:00.554686: The split file contains 1 splits.
2023-09-06 08:49:00.556186: Desired fold for training: 0
2023-09-06 08:49:00.557559: This split has 1500 training and 650 validation cases.
start computing score....
2023-09-06 08:53:11.697009: dsc: 90.04%
2023-09-06 08:53:11.699232: miou: 81.89%
2023-09-06 08:53:11.700657: acc: 96.70%, sen: 89.19%, spe: 98.21%
2023-09-06 08:53:11.702548: current best miou: 0.821732634787054 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 08:53:11.704131: current best dsc: 0.9021440568122753 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 08:53:11.705478: finished real validation
2023-09-06 08:53:15.889820: train_loss -1.4459
2023-09-06 08:53:15.892015: val_loss -1.0922
2023-09-06 08:53:15.893804: Pseudo dice [0.904]
2023-09-06 08:53:15.895361: Epoch time: 314.22 s
2023-09-06 08:53:17.018570: 
2023-09-06 08:53:17.020905: Epoch 211
2023-09-06 08:53:17.023020: Current learning rate: backbone 0.000335, others 0.000335
2023-09-06 08:53:17.025589: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-06 08:54:15.849852: finished training epoch 211
2023-09-06 08:54:15.886872: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset122_ISIC2017/splits_final.json
2023-09-06 08:54:15.889291: The split file contains 1 splits.
2023-09-06 08:54:15.890523: Desired fold for training: 0
2023-09-06 08:54:15.891664: This split has 1500 training and 650 validation cases.
start computing score....
2023-09-06 08:58:32.968604: dsc: 90.04%
2023-09-06 08:58:32.971239: miou: 81.88%
2023-09-06 08:58:32.972754: acc: 96.70%, sen: 88.94%, spe: 98.27%
2023-09-06 08:58:32.974315: current best miou: 0.821732634787054 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 08:58:32.975701: current best dsc: 0.9021440568122753 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 08:58:32.977097: finished real validation
2023-09-06 08:58:37.161019: train_loss -1.4456
2023-09-06 08:58:37.162894: val_loss -1.0845
2023-09-06 08:58:37.164330: Pseudo dice [0.9023]
2023-09-06 08:58:37.165589: Epoch time: 320.14 s
2023-09-06 08:58:38.244934: 
2023-09-06 08:58:38.246933: Epoch 212
2023-09-06 08:58:38.248252: Current learning rate: backbone 0.00033161, others 0.00033161
2023-09-06 08:58:38.249860: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-06 08:59:37.059678: finished training epoch 212
2023-09-06 08:59:37.098503: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset122_ISIC2017/splits_final.json
2023-09-06 08:59:37.101068: The split file contains 1 splits.
2023-09-06 08:59:37.102427: Desired fold for training: 0
2023-09-06 08:59:37.104569: This split has 1500 training and 650 validation cases.
start computing score....
2023-09-06 09:03:47.355724: dsc: 90.11%
2023-09-06 09:03:47.357557: miou: 82.00%
2023-09-06 09:03:47.358811: acc: 96.71%, sen: 89.47%, spe: 98.17%
2023-09-06 09:03:47.360676: current best miou: 0.821732634787054 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 09:03:47.362257: current best dsc: 0.9021440568122753 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 09:03:47.363633: finished real validation
2023-09-06 09:03:51.550238: train_loss -1.446
2023-09-06 09:03:51.552014: val_loss -1.0673
2023-09-06 09:03:51.553578: Pseudo dice [0.9004]
2023-09-06 09:03:51.555017: Epoch time: 313.31 s
2023-09-06 09:03:52.650268: 
2023-09-06 09:03:52.651956: Epoch 213
2023-09-06 09:03:52.655147: Current learning rate: backbone 0.00032821, others 0.00032821
2023-09-06 09:03:52.657310: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-06 09:04:51.462021: finished training epoch 213
2023-09-06 09:04:51.489526: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset122_ISIC2017/splits_final.json
2023-09-06 09:04:51.491635: The split file contains 1 splits.
2023-09-06 09:04:51.493075: Desired fold for training: 0
2023-09-06 09:04:51.494680: This split has 1500 training and 650 validation cases.
start computing score....
2023-09-06 09:09:05.925073: dsc: 90.02%
2023-09-06 09:09:05.927175: miou: 81.86%
2023-09-06 09:09:05.928736: acc: 96.69%, sen: 89.06%, spe: 98.23%
2023-09-06 09:09:05.930588: current best miou: 0.821732634787054 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 09:09:05.932373: current best dsc: 0.9021440568122753 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 09:09:05.933937: finished real validation
2023-09-06 09:09:10.127909: train_loss -1.4462
2023-09-06 09:09:10.129685: val_loss -1.1011
2023-09-06 09:09:10.131264: Pseudo dice [0.9045]
2023-09-06 09:09:10.132636: Epoch time: 317.48 s
2023-09-06 09:09:11.271702: 
2023-09-06 09:09:11.273313: Epoch 214
2023-09-06 09:09:11.274805: Current learning rate: backbone 0.00032482, others 0.00032482
2023-09-06 09:09:11.276751: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-06 09:10:10.366308: finished training epoch 214
2023-09-06 09:10:10.393141: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset122_ISIC2017/splits_final.json
2023-09-06 09:10:10.397679: The split file contains 1 splits.
2023-09-06 09:10:10.399590: Desired fold for training: 0
2023-09-06 09:10:10.401137: This split has 1500 training and 650 validation cases.
start computing score....
2023-09-06 09:14:25.189537: dsc: 90.10%
2023-09-06 09:14:25.191263: miou: 81.99%
2023-09-06 09:14:25.192402: acc: 96.71%, sen: 89.34%, spe: 98.19%
2023-09-06 09:14:25.193897: current best miou: 0.821732634787054 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 09:14:25.195040: current best dsc: 0.9021440568122753 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 09:14:25.196168: finished real validation
2023-09-06 09:14:29.396951: train_loss -1.4465
2023-09-06 09:14:29.399107: val_loss -1.0854
2023-09-06 09:14:29.403122: Pseudo dice [0.9034]
2023-09-06 09:14:29.404436: Epoch time: 318.13 s
2023-09-06 09:14:30.488977: 
2023-09-06 09:14:30.490643: Epoch 215
2023-09-06 09:14:30.492155: Current learning rate: backbone 0.00032142, others 0.00032142
2023-09-06 09:14:30.494079: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-06 09:15:29.360238: finished training epoch 215
2023-09-06 09:15:29.392537: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset122_ISIC2017/splits_final.json
2023-09-06 09:15:29.394950: The split file contains 1 splits.
2023-09-06 09:15:29.396246: Desired fold for training: 0
2023-09-06 09:15:29.397508: This split has 1500 training and 650 validation cases.
start computing score....
2023-09-06 09:20:49.216678: dsc: 89.98%
2023-09-06 09:20:49.218596: miou: 81.79%
2023-09-06 09:20:49.219957: acc: 96.69%, sen: 88.88%, spe: 98.26%
2023-09-06 09:20:49.222252: current best miou: 0.821732634787054 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 09:20:49.223925: current best dsc: 0.9021440568122753 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 09:20:49.225263: finished real validation
2023-09-06 09:20:53.417137: train_loss -1.4466
2023-09-06 09:20:53.420113: val_loss -1.0996
2023-09-06 09:20:53.421939: Pseudo dice [0.9039]
2023-09-06 09:20:53.426111: Epoch time: 382.93 s
2023-09-06 09:20:53.428030: Yayy! New best EMA pseudo Dice: 0.9019
2023-09-06 09:20:56.097384: 
2023-09-06 09:20:56.099489: Epoch 216
2023-09-06 09:20:56.102287: Current learning rate: backbone 0.00031801, others 0.00031801
2023-09-06 09:20:56.104368: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-06 09:21:54.935926: finished training epoch 216
2023-09-06 09:21:54.970067: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset122_ISIC2017/splits_final.json
2023-09-06 09:21:54.973254: The split file contains 1 splits.
2023-09-06 09:21:54.974673: Desired fold for training: 0
2023-09-06 09:21:54.976032: This split has 1500 training and 650 validation cases.
start computing score....
2023-09-06 09:27:07.529993: dsc: 90.09%
2023-09-06 09:27:07.536601: miou: 81.97%
2023-09-06 09:27:07.538979: acc: 96.71%, sen: 89.19%, spe: 98.23%
2023-09-06 09:27:07.541086: current best miou: 0.821732634787054 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 09:27:07.542946: current best dsc: 0.9021440568122753 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 09:27:07.544776: finished real validation
2023-09-06 09:27:11.739900: train_loss -1.4465
2023-09-06 09:27:11.741580: val_loss -1.0747
2023-09-06 09:27:11.743114: Pseudo dice [0.9026]
2023-09-06 09:27:11.744420: Epoch time: 375.64 s
2023-09-06 09:27:11.745621: Yayy! New best EMA pseudo Dice: 0.9019
2023-09-06 09:27:14.528689: 
2023-09-06 09:27:14.530671: Epoch 217
2023-09-06 09:27:14.532470: Current learning rate: backbone 0.0003146, others 0.0003146
2023-09-06 09:27:14.534930: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-06 09:28:13.322556: finished training epoch 217
2023-09-06 09:28:13.374509: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset122_ISIC2017/splits_final.json
2023-09-06 09:28:13.376790: The split file contains 1 splits.
2023-09-06 09:28:13.378021: Desired fold for training: 0
2023-09-06 09:28:13.379164: This split has 1500 training and 650 validation cases.
start computing score....
2023-09-06 09:32:37.423786: dsc: 90.06%
2023-09-06 09:32:37.425761: miou: 81.91%
2023-09-06 09:32:37.427971: acc: 96.70%, sen: 89.16%, spe: 98.22%
2023-09-06 09:32:37.430421: current best miou: 0.821732634787054 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 09:32:37.431937: current best dsc: 0.9021440568122753 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 09:32:37.433223: finished real validation
2023-09-06 09:32:41.649205: train_loss -1.4465
2023-09-06 09:32:41.651212: val_loss -1.0459
2023-09-06 09:32:41.652975: Pseudo dice [0.8983]
2023-09-06 09:32:41.654307: Epoch time: 327.12 s
2023-09-06 09:32:42.766118: 
2023-09-06 09:32:42.767923: Epoch 218
2023-09-06 09:32:42.769164: Current learning rate: backbone 0.00031119, others 0.00031119
2023-09-06 09:32:42.770719: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-06 09:33:41.457711: finished training epoch 218
2023-09-06 09:33:41.483849: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset122_ISIC2017/splits_final.json
2023-09-06 09:33:41.486129: The split file contains 1 splits.
2023-09-06 09:33:41.487441: Desired fold for training: 0
2023-09-06 09:33:41.488679: This split has 1500 training and 650 validation cases.
start computing score....
2023-09-06 09:38:10.895293: dsc: 90.12%
2023-09-06 09:38:10.897150: miou: 82.01%
2023-09-06 09:38:10.898402: acc: 96.72%, sen: 89.40%, spe: 98.19%
2023-09-06 09:38:10.899961: current best miou: 0.821732634787054 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 09:38:10.901192: current best dsc: 0.9021440568122753 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 09:38:10.902307: finished real validation
2023-09-06 09:38:15.108782: train_loss -1.4469
2023-09-06 09:38:15.110420: val_loss -1.0587
2023-09-06 09:38:15.111969: Pseudo dice [0.9002]
2023-09-06 09:38:15.113252: Epoch time: 332.34 s
2023-09-06 09:38:16.210811: 
2023-09-06 09:38:16.212984: Epoch 219
2023-09-06 09:38:16.214480: Current learning rate: backbone 0.00030777, others 0.00030777
2023-09-06 09:38:16.216493: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-06 09:39:14.959112: finished training epoch 219
2023-09-06 09:39:14.998937: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset122_ISIC2017/splits_final.json
2023-09-06 09:39:15.002117: The split file contains 1 splits.
2023-09-06 09:39:15.004014: Desired fold for training: 0
2023-09-06 09:39:15.005466: This split has 1500 training and 650 validation cases.
start computing score....
2023-09-06 09:43:23.884506: dsc: 90.05%
2023-09-06 09:43:23.886463: miou: 81.91%
2023-09-06 09:43:23.888042: acc: 96.71%, sen: 88.99%, spe: 98.26%
2023-09-06 09:43:23.890185: current best miou: 0.821732634787054 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 09:43:23.891857: current best dsc: 0.9021440568122753 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 09:43:23.893487: finished real validation
2023-09-06 09:43:28.095450: train_loss -1.4471
2023-09-06 09:43:28.097281: val_loss -1.0608
2023-09-06 09:43:28.098811: Pseudo dice [0.8998]
2023-09-06 09:43:28.100135: Epoch time: 311.89 s
2023-09-06 09:43:30.727113: 
2023-09-06 09:43:30.728776: Epoch 220
2023-09-06 09:43:30.730239: Current learning rate: backbone 0.00030435, others 0.00030435
2023-09-06 09:43:30.732104: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-06 09:44:29.540280: finished training epoch 220
2023-09-06 09:44:29.599692: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset122_ISIC2017/splits_final.json
2023-09-06 09:44:29.602571: The split file contains 1 splits.
2023-09-06 09:44:29.603974: Desired fold for training: 0
2023-09-06 09:44:29.605302: This split has 1500 training and 650 validation cases.
start computing score....
2023-09-06 09:48:44.559388: dsc: 90.02%
2023-09-06 09:48:44.561273: miou: 81.85%
2023-09-06 09:48:44.563005: acc: 96.70%, sen: 88.77%, spe: 98.30%
2023-09-06 09:48:44.564873: current best miou: 0.821732634787054 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 09:48:44.566467: current best dsc: 0.9021440568122753 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 09:48:44.568053: finished real validation
2023-09-06 09:48:48.770430: train_loss -1.4468
2023-09-06 09:48:48.772290: val_loss -1.0849
2023-09-06 09:48:48.773833: Pseudo dice [0.9066]
2023-09-06 09:48:48.775162: Epoch time: 318.04 s
2023-09-06 09:48:49.897065: 
2023-09-06 09:48:49.898942: Epoch 221
2023-09-06 09:48:49.900330: Current learning rate: backbone 0.00030092, others 0.00030092
2023-09-06 09:48:49.902455: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-06 09:49:48.990498: finished training epoch 221
2023-09-06 09:49:49.031364: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset122_ISIC2017/splits_final.json
2023-09-06 09:49:49.033407: The split file contains 1 splits.
2023-09-06 09:49:49.034890: Desired fold for training: 0
2023-09-06 09:49:49.036148: This split has 1500 training and 650 validation cases.
start computing score....
2023-09-06 09:53:59.076403: dsc: 90.00%
2023-09-06 09:53:59.077715: miou: 81.82%
2023-09-06 09:53:59.078809: acc: 96.70%, sen: 88.79%, spe: 98.29%
2023-09-06 09:53:59.080232: current best miou: 0.821732634787054 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 09:53:59.081360: current best dsc: 0.9021440568122753 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 09:53:59.082404: finished real validation
2023-09-06 09:54:03.296483: train_loss -1.4472
2023-09-06 09:54:03.298214: val_loss -1.0502
2023-09-06 09:54:03.299829: Pseudo dice [0.8952]
2023-09-06 09:54:03.301189: Epoch time: 313.4 s
2023-09-06 09:54:04.407670: 
2023-09-06 09:54:04.409301: Epoch 222
2023-09-06 09:54:04.410578: Current learning rate: backbone 0.00029749, others 0.00029749
2023-09-06 09:54:04.412265: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-06 09:55:03.075088: finished training epoch 222
2023-09-06 09:55:03.102229: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset122_ISIC2017/splits_final.json
2023-09-06 09:55:03.104334: The split file contains 1 splits.
2023-09-06 09:55:03.105620: Desired fold for training: 0
2023-09-06 09:55:03.106906: This split has 1500 training and 650 validation cases.
start computing score....
2023-09-06 09:59:12.172466: dsc: 90.01%
2023-09-06 09:59:12.174740: miou: 81.83%
2023-09-06 09:59:12.176283: acc: 96.70%, sen: 88.72%, spe: 98.31%
2023-09-06 09:59:12.178262: current best miou: 0.821732634787054 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 09:59:12.179722: current best dsc: 0.9021440568122753 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 09:59:12.181035: finished real validation
2023-09-06 09:59:16.400575: train_loss -1.4473
2023-09-06 09:59:16.402300: val_loss -1.0582
2023-09-06 09:59:16.403744: Pseudo dice [0.8968]
2023-09-06 09:59:16.404998: Epoch time: 311.99 s
2023-09-06 09:59:17.512314: 
2023-09-06 09:59:17.514161: Epoch 223
2023-09-06 09:59:17.515484: Current learning rate: backbone 0.00029406, others 0.00029406
2023-09-06 09:59:17.517249: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-06 10:00:16.312785: finished training epoch 223
2023-09-06 10:00:16.384737: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset122_ISIC2017/splits_final.json
2023-09-06 10:00:16.386890: The split file contains 1 splits.
2023-09-06 10:00:16.388758: Desired fold for training: 0
2023-09-06 10:00:16.390848: This split has 1500 training and 650 validation cases.
start computing score....
2023-09-06 10:04:32.058499: dsc: 89.87%
2023-09-06 10:04:32.060423: miou: 81.60%
2023-09-06 10:04:32.061785: acc: 96.66%, sen: 88.43%, spe: 98.32%
2023-09-06 10:04:32.063613: current best miou: 0.821732634787054 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 10:04:32.064937: current best dsc: 0.9021440568122753 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 10:04:32.066156: finished real validation
2023-09-06 10:04:36.277889: train_loss -1.4476
2023-09-06 10:04:36.279678: val_loss -1.0368
2023-09-06 10:04:36.281172: Pseudo dice [0.8967]
2023-09-06 10:04:36.282468: Epoch time: 318.77 s
2023-09-06 10:04:37.388817: 
2023-09-06 10:04:37.390680: Epoch 224
2023-09-06 10:04:37.392000: Current learning rate: backbone 0.00029062, others 0.00029062
2023-09-06 10:04:37.394121: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-06 10:05:36.709620: finished training epoch 224
2023-09-06 10:05:36.738093: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset122_ISIC2017/splits_final.json
2023-09-06 10:05:36.743250: The split file contains 1 splits.
2023-09-06 10:05:36.744849: Desired fold for training: 0
2023-09-06 10:05:36.746169: This split has 1500 training and 650 validation cases.
start computing score....
2023-09-06 10:09:40.181669: dsc: 89.96%
2023-09-06 10:09:40.183644: miou: 81.75%
2023-09-06 10:09:40.185170: acc: 96.68%, sen: 88.68%, spe: 98.29%
2023-09-06 10:09:40.186963: current best miou: 0.821732634787054 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 10:09:40.188399: current best dsc: 0.9021440568122753 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 10:09:40.189882: finished real validation
2023-09-06 10:09:44.396680: train_loss -1.4472
2023-09-06 10:09:44.398548: val_loss -1.0261
2023-09-06 10:09:44.400113: Pseudo dice [0.8923]
2023-09-06 10:09:44.401418: Epoch time: 307.01 s
2023-09-06 10:09:45.483421: 
2023-09-06 10:09:45.485158: Epoch 225
2023-09-06 10:09:45.486445: Current learning rate: backbone 0.00028717, others 0.00028717
2023-09-06 10:09:45.488198: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-06 10:10:44.222078: finished training epoch 225
2023-09-06 10:10:44.255564: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset122_ISIC2017/splits_final.json
2023-09-06 10:10:44.258230: The split file contains 1 splits.
2023-09-06 10:10:44.259555: Desired fold for training: 0
2023-09-06 10:10:44.260798: This split has 1500 training and 650 validation cases.
start computing score....
2023-09-06 10:14:57.103302: dsc: 89.98%
2023-09-06 10:14:57.105669: miou: 81.79%
2023-09-06 10:14:57.107136: acc: 96.69%, sen: 88.68%, spe: 98.30%
2023-09-06 10:14:57.109188: current best miou: 0.821732634787054 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 10:14:57.110642: current best dsc: 0.9021440568122753 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 10:14:57.111864: finished real validation
2023-09-06 10:15:01.330739: train_loss -1.4474
2023-09-06 10:15:01.332651: val_loss -1.0584
2023-09-06 10:15:01.334383: Pseudo dice [0.9001]
2023-09-06 10:15:01.335899: Epoch time: 315.85 s
2023-09-06 10:15:02.425314: 
2023-09-06 10:15:02.427169: Epoch 226
2023-09-06 10:15:02.428965: Current learning rate: backbone 0.00028373, others 0.00028373
2023-09-06 10:15:02.431064: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-06 10:16:01.076754: finished training epoch 226
2023-09-06 10:16:01.114943: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset122_ISIC2017/splits_final.json
2023-09-06 10:16:01.117442: The split file contains 1 splits.
2023-09-06 10:16:01.118774: Desired fold for training: 0
2023-09-06 10:16:01.120048: This split has 1500 training and 650 validation cases.
start computing score....
2023-09-06 10:20:11.768467: dsc: 90.08%
2023-09-06 10:20:11.770027: miou: 81.96%
2023-09-06 10:20:11.771226: acc: 96.72%, sen: 88.96%, spe: 98.28%
2023-09-06 10:20:11.772724: current best miou: 0.821732634787054 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 10:20:11.774073: current best dsc: 0.9021440568122753 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 10:20:11.775374: finished real validation
2023-09-06 10:20:15.991489: train_loss -1.4471
2023-09-06 10:20:15.993392: val_loss -1.0683
2023-09-06 10:20:15.995008: Pseudo dice [0.9002]
2023-09-06 10:20:15.996312: Epoch time: 313.57 s
2023-09-06 10:20:17.100917: 
2023-09-06 10:20:17.103227: Epoch 227
2023-09-06 10:20:17.104991: Current learning rate: backbone 0.00028027, others 0.00028027
2023-09-06 10:20:17.106844: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-06 10:21:15.823179: finished training epoch 227
2023-09-06 10:21:15.868740: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset122_ISIC2017/splits_final.json
2023-09-06 10:21:15.871003: The split file contains 1 splits.
2023-09-06 10:21:15.872374: Desired fold for training: 0
2023-09-06 10:21:15.873701: This split has 1500 training and 650 validation cases.
start computing score....
2023-09-06 10:25:22.722296: dsc: 89.98%
2023-09-06 10:25:22.724195: miou: 81.78%
2023-09-06 10:25:22.725505: acc: 96.69%, sen: 88.75%, spe: 98.28%
2023-09-06 10:25:22.727878: current best miou: 0.821732634787054 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 10:25:22.729438: current best dsc: 0.9021440568122753 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 10:25:22.730717: finished real validation
2023-09-06 10:25:26.931385: train_loss -1.4477
2023-09-06 10:25:26.933288: val_loss -1.0605
2023-09-06 10:25:26.935000: Pseudo dice [0.8992]
2023-09-06 10:25:26.936459: Epoch time: 309.83 s
2023-09-06 10:25:28.047279: 
2023-09-06 10:25:28.049223: Epoch 228
2023-09-06 10:25:28.050737: Current learning rate: backbone 0.00027682, others 0.00027682
2023-09-06 10:25:28.052759: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-06 10:26:26.641409: finished training epoch 228
2023-09-06 10:26:26.678806: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset122_ISIC2017/splits_final.json
2023-09-06 10:26:26.680838: The split file contains 1 splits.
2023-09-06 10:26:26.682367: Desired fold for training: 0
2023-09-06 10:26:26.683961: This split has 1500 training and 650 validation cases.
start computing score....
2023-09-06 10:30:57.279721: dsc: 89.89%
2023-09-06 10:30:57.281738: miou: 81.64%
2023-09-06 10:30:57.283163: acc: 96.66%, sen: 88.63%, spe: 98.28%
2023-09-06 10:30:57.285168: current best miou: 0.821732634787054 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 10:30:57.286772: current best dsc: 0.9021440568122753 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 10:30:57.288152: finished real validation
2023-09-06 10:31:01.553608: train_loss -1.447
2023-09-06 10:31:01.555660: val_loss -1.0595
2023-09-06 10:31:01.557484: Pseudo dice [0.8998]
2023-09-06 10:31:01.558937: Epoch time: 333.51 s
2023-09-06 10:31:02.698095: 
2023-09-06 10:31:02.699852: Epoch 229
2023-09-06 10:31:02.701343: Current learning rate: backbone 0.00027335, others 0.00027335
2023-09-06 10:31:02.703202: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-06 10:32:01.720937: finished training epoch 229
2023-09-06 10:32:01.769795: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset122_ISIC2017/splits_final.json
2023-09-06 10:32:01.772102: The split file contains 1 splits.
2023-09-06 10:32:01.773459: Desired fold for training: 0
2023-09-06 10:32:01.775294: This split has 1500 training and 650 validation cases.
start computing score....
2023-09-06 10:36:38.443136: dsc: 90.06%
2023-09-06 10:36:38.445557: miou: 81.91%
2023-09-06 10:36:38.447103: acc: 96.71%, sen: 89.05%, spe: 98.25%
2023-09-06 10:36:38.448823: current best miou: 0.821732634787054 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 10:36:38.450449: current best dsc: 0.9021440568122753 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 10:36:38.451989: finished real validation
2023-09-06 10:36:42.657026: train_loss -1.447
2023-09-06 10:36:42.659093: val_loss -1.0677
2023-09-06 10:36:42.661278: Pseudo dice [0.8977]
2023-09-06 10:36:42.663684: Epoch time: 339.96 s
2023-09-06 10:36:45.517426: 
2023-09-06 10:36:45.523318: Epoch 230
2023-09-06 10:36:45.526282: Current learning rate: backbone 0.00026989, others 0.00026989
2023-09-06 10:36:45.532655: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-06 10:37:44.330502: finished training epoch 230
2023-09-06 10:37:44.371806: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset122_ISIC2017/splits_final.json
2023-09-06 10:37:44.374907: The split file contains 1 splits.
2023-09-06 10:37:44.376648: Desired fold for training: 0
2023-09-06 10:37:44.378244: This split has 1500 training and 650 validation cases.
start computing score....
2023-09-06 10:41:48.336753: dsc: 89.91%
2023-09-06 10:41:48.338678: miou: 81.66%
2023-09-06 10:41:48.340479: acc: 96.66%, sen: 88.92%, spe: 98.21%
2023-09-06 10:41:48.342601: current best miou: 0.821732634787054 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 10:41:48.344323: current best dsc: 0.9021440568122753 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 10:41:48.345767: finished real validation
2023-09-06 10:41:52.549554: train_loss -1.4477
2023-09-06 10:41:52.551535: val_loss -1.0726
2023-09-06 10:41:52.553149: Pseudo dice [0.8999]
2023-09-06 10:41:52.554562: Epoch time: 307.03 s
2023-09-06 10:41:53.636075: 
2023-09-06 10:41:53.638180: Epoch 231
2023-09-06 10:41:53.640019: Current learning rate: backbone 0.00026641, others 0.00026641
2023-09-06 10:41:53.641768: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-06 10:42:52.257285: finished training epoch 231
2023-09-06 10:42:52.327495: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset122_ISIC2017/splits_final.json
2023-09-06 10:42:52.330087: The split file contains 1 splits.
2023-09-06 10:42:52.331412: Desired fold for training: 0
2023-09-06 10:42:52.332715: This split has 1500 training and 650 validation cases.
start computing score....
2023-09-06 10:47:01.316696: dsc: 90.03%
2023-09-06 10:47:01.323085: miou: 81.86%
2023-09-06 10:47:01.327863: acc: 96.70%, sen: 89.05%, spe: 98.23%
2023-09-06 10:47:01.334807: current best miou: 0.821732634787054 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 10:47:01.340781: current best dsc: 0.9021440568122753 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 10:47:01.346888: finished real validation
2023-09-06 10:47:05.559311: train_loss -1.4472
2023-09-06 10:47:05.566106: val_loss -1.0709
2023-09-06 10:47:05.571427: Pseudo dice [0.9035]
2023-09-06 10:47:05.577405: Epoch time: 311.92 s
2023-09-06 10:47:06.676774: 
2023-09-06 10:47:06.678562: Epoch 232
2023-09-06 10:47:06.680872: Current learning rate: backbone 0.00026294, others 0.00026294
2023-09-06 10:47:06.683222: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-06 10:48:05.275070: finished training epoch 232
2023-09-06 10:48:05.311799: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset122_ISIC2017/splits_final.json
2023-09-06 10:48:05.314917: The split file contains 1 splits.
2023-09-06 10:48:05.316591: Desired fold for training: 0
2023-09-06 10:48:05.318233: This split has 1500 training and 650 validation cases.
start computing score....
2023-09-06 10:52:17.933131: dsc: 90.07%
2023-09-06 10:52:17.934679: miou: 81.93%
2023-09-06 10:52:17.937408: acc: 96.71%, sen: 89.02%, spe: 98.26%
2023-09-06 10:52:17.939036: current best miou: 0.821732634787054 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 10:52:17.940267: current best dsc: 0.9021440568122753 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 10:52:17.941477: finished real validation
2023-09-06 10:52:22.128833: train_loss -1.448
2023-09-06 10:52:22.130534: val_loss -1.062
2023-09-06 10:52:22.132465: Pseudo dice [0.9019]
2023-09-06 10:52:22.133736: Epoch time: 315.45 s
2023-09-06 10:52:23.290154: 
2023-09-06 10:52:23.294173: Epoch 233
2023-09-06 10:52:23.296762: Current learning rate: backbone 0.00025945, others 0.00025945
2023-09-06 10:52:23.298719: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-06 10:53:22.007411: finished training epoch 233
2023-09-06 10:53:22.055656: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset122_ISIC2017/splits_final.json
2023-09-06 10:53:22.057859: The split file contains 1 splits.
2023-09-06 10:53:22.059280: Desired fold for training: 0
2023-09-06 10:53:22.060789: This split has 1500 training and 650 validation cases.
start computing score....
2023-09-06 10:57:39.743852: dsc: 89.98%
2023-09-06 10:57:39.745615: miou: 81.78%
2023-09-06 10:57:39.747185: acc: 96.68%, sen: 89.07%, spe: 98.21%
2023-09-06 10:57:39.749160: current best miou: 0.821732634787054 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 10:57:39.750845: current best dsc: 0.9021440568122753 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 10:57:39.752334: finished real validation
2023-09-06 10:57:43.949485: train_loss -1.4477
2023-09-06 10:57:43.951267: val_loss -1.0764
2023-09-06 10:57:43.952934: Pseudo dice [0.9028]
2023-09-06 10:57:43.954460: Epoch time: 320.66 s
2023-09-06 10:57:45.050478: 
2023-09-06 10:57:45.052292: Epoch 234
2023-09-06 10:57:45.053649: Current learning rate: backbone 0.00025596, others 0.00025596
2023-09-06 10:57:45.055468: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-06 10:58:43.789126: finished training epoch 234
2023-09-06 10:58:43.904087: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset122_ISIC2017/splits_final.json
2023-09-06 10:58:43.911205: The split file contains 1 splits.
2023-09-06 10:58:43.916795: Desired fold for training: 0
2023-09-06 10:58:43.918032: This split has 1500 training and 650 validation cases.
start computing score....
2023-09-06 11:02:54.211513: dsc: 89.97%
2023-09-06 11:02:54.213760: miou: 81.77%
2023-09-06 11:02:54.215875: acc: 96.68%, sen: 88.80%, spe: 98.27%
2023-09-06 11:02:54.219182: current best miou: 0.821732634787054 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 11:02:54.221295: current best dsc: 0.9021440568122753 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 11:02:54.223219: finished real validation
2023-09-06 11:02:58.417721: train_loss -1.4474
2023-09-06 11:02:58.419544: val_loss -1.0662
2023-09-06 11:02:58.421073: Pseudo dice [0.902]
2023-09-06 11:02:58.422409: Epoch time: 313.37 s
2023-09-06 11:02:59.535457: 
2023-09-06 11:02:59.537386: Epoch 235
2023-09-06 11:02:59.539031: Current learning rate: backbone 0.00025247, others 0.00025247
2023-09-06 11:02:59.540924: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-06 11:03:58.213770: finished training epoch 235
2023-09-06 11:03:58.249338: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset122_ISIC2017/splits_final.json
2023-09-06 11:03:58.251747: The split file contains 1 splits.
2023-09-06 11:03:58.253278: Desired fold for training: 0
2023-09-06 11:03:58.254751: This split has 1500 training and 650 validation cases.
start computing score....
2023-09-06 11:08:10.173095: dsc: 90.07%
2023-09-06 11:08:10.175082: miou: 81.93%
2023-09-06 11:08:10.176349: acc: 96.71%, sen: 89.21%, spe: 98.21%
2023-09-06 11:08:10.177966: current best miou: 0.821732634787054 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 11:08:10.179227: current best dsc: 0.9021440568122753 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 11:08:10.180445: finished real validation
2023-09-06 11:08:14.388830: train_loss -1.4473
2023-09-06 11:08:14.390688: val_loss -1.0413
2023-09-06 11:08:14.392362: Pseudo dice [0.897]
2023-09-06 11:08:14.393734: Epoch time: 314.85 s
2023-09-06 11:08:15.498819: 
2023-09-06 11:08:15.500688: Epoch 236
2023-09-06 11:08:15.502049: Current learning rate: backbone 0.00024897, others 0.00024897
2023-09-06 11:08:15.504100: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-06 11:09:14.179557: finished training epoch 236
2023-09-06 11:09:14.217386: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset122_ISIC2017/splits_final.json
2023-09-06 11:09:14.220767: The split file contains 1 splits.
2023-09-06 11:09:14.222643: Desired fold for training: 0
2023-09-06 11:09:14.224410: This split has 1500 training and 650 validation cases.
start computing score....
2023-09-06 11:13:19.983662: dsc: 90.06%
2023-09-06 11:13:19.985683: miou: 81.92%
2023-09-06 11:13:19.987225: acc: 96.71%, sen: 88.95%, spe: 98.27%
2023-09-06 11:13:19.989053: current best miou: 0.821732634787054 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 11:13:19.990819: current best dsc: 0.9021440568122753 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 11:13:19.992626: finished real validation
2023-09-06 11:13:24.195524: train_loss -1.4476
2023-09-06 11:13:24.197980: val_loss -1.0959
2023-09-06 11:13:24.200985: Pseudo dice [0.9064]
2023-09-06 11:13:24.203822: Epoch time: 308.7 s
2023-09-06 11:13:25.300758: 
2023-09-06 11:13:25.302813: Epoch 237
2023-09-06 11:13:25.304259: Current learning rate: backbone 0.00024547, others 0.00024547
2023-09-06 11:13:25.306329: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-06 11:14:24.015577: finished training epoch 237
2023-09-06 11:14:24.043265: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset122_ISIC2017/splits_final.json
2023-09-06 11:14:24.045484: The split file contains 1 splits.
2023-09-06 11:14:24.046921: Desired fold for training: 0
2023-09-06 11:14:24.048217: This split has 1500 training and 650 validation cases.
start computing score....
2023-09-06 11:18:30.828030: dsc: 90.06%
2023-09-06 11:18:30.831243: miou: 81.91%
2023-09-06 11:18:30.834768: acc: 96.71%, sen: 89.07%, spe: 98.24%
2023-09-06 11:18:30.840710: current best miou: 0.821732634787054 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 11:18:30.843889: current best dsc: 0.9021440568122753 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 11:18:30.845952: finished real validation
2023-09-06 11:18:35.050313: train_loss -1.448
2023-09-06 11:18:35.052304: val_loss -1.0635
2023-09-06 11:18:35.054011: Pseudo dice [0.8987]
2023-09-06 11:18:35.055479: Epoch time: 309.75 s
2023-09-06 11:18:36.130666: 
2023-09-06 11:18:36.132407: Epoch 238
2023-09-06 11:18:36.134209: Current learning rate: backbone 0.00024196, others 0.00024196
2023-09-06 11:18:36.136603: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-06 11:19:34.732471: finished training epoch 238
2023-09-06 11:19:34.758189: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset122_ISIC2017/splits_final.json
2023-09-06 11:19:34.761309: The split file contains 1 splits.
2023-09-06 11:19:34.762826: Desired fold for training: 0
2023-09-06 11:19:34.764682: This split has 1500 training and 650 validation cases.
start computing score....
2023-09-06 11:23:43.026600: dsc: 89.93%
2023-09-06 11:23:43.029006: miou: 81.70%
2023-09-06 11:23:43.030307: acc: 96.64%, sen: 89.43%, spe: 98.09%
2023-09-06 11:23:43.031868: current best miou: 0.821732634787054 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 11:23:43.033132: current best dsc: 0.9021440568122753 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 11:23:43.037700: finished real validation
2023-09-06 11:23:47.242341: train_loss -1.4475
2023-09-06 11:23:47.245811: val_loss -1.0542
2023-09-06 11:23:47.247473: Pseudo dice [0.899]
2023-09-06 11:23:47.249522: Epoch time: 311.11 s
2023-09-06 11:23:48.412704: 
2023-09-06 11:23:48.414241: Epoch 239
2023-09-06 11:23:48.415630: Current learning rate: backbone 0.00023844, others 0.00023844
2023-09-06 11:23:48.417287: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-06 11:24:47.173484: finished training epoch 239
2023-09-06 11:24:47.201806: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset122_ISIC2017/splits_final.json
2023-09-06 11:24:47.204230: The split file contains 1 splits.
2023-09-06 11:24:47.205688: Desired fold for training: 0
2023-09-06 11:24:47.207000: This split has 1500 training and 650 validation cases.
start computing score....
2023-09-06 11:29:06.327230: dsc: 90.07%
2023-09-06 11:29:06.329219: miou: 81.93%
2023-09-06 11:29:06.330576: acc: 96.70%, sen: 89.25%, spe: 98.20%
2023-09-06 11:29:06.333443: current best miou: 0.821732634787054 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 11:29:06.336460: current best dsc: 0.9021440568122753 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 11:29:06.338739: finished real validation
2023-09-06 11:29:10.535992: train_loss -1.4481
2023-09-06 11:29:10.538015: val_loss -1.0451
2023-09-06 11:29:10.540057: Pseudo dice [0.8998]
2023-09-06 11:29:10.542334: Epoch time: 322.12 s
2023-09-06 11:29:13.374362: 
2023-09-06 11:29:13.376240: Epoch 240
2023-09-06 11:29:13.377707: Current learning rate: backbone 0.00023492, others 0.00023492
2023-09-06 11:29:13.379520: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-06 11:30:12.306022: finished training epoch 240
2023-09-06 11:30:12.373011: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset122_ISIC2017/splits_final.json
2023-09-06 11:30:12.389864: The split file contains 1 splits.
2023-09-06 11:30:12.400600: Desired fold for training: 0
2023-09-06 11:30:12.408812: This split has 1500 training and 650 validation cases.
start computing score....
2023-09-06 11:34:58.056871: dsc: 90.00%
2023-09-06 11:34:58.058946: miou: 81.81%
2023-09-06 11:34:58.060516: acc: 96.68%, sen: 89.19%, spe: 98.19%
2023-09-06 11:34:58.062680: current best miou: 0.821732634787054 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 11:34:58.064292: current best dsc: 0.9021440568122753 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 11:34:58.065917: finished real validation
2023-09-06 11:35:02.261451: train_loss -1.4478
2023-09-06 11:35:02.263406: val_loss -1.0237
2023-09-06 11:35:02.265331: Pseudo dice [0.8942]
2023-09-06 11:35:02.266856: Epoch time: 348.89 s
2023-09-06 11:35:03.375238: 
2023-09-06 11:35:03.377848: Epoch 241
2023-09-06 11:35:03.379411: Current learning rate: backbone 0.0002314, others 0.0002314
2023-09-06 11:35:03.381522: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-06 11:36:02.216650: finished training epoch 241
2023-09-06 11:36:02.274390: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset122_ISIC2017/splits_final.json
2023-09-06 11:36:02.278700: The split file contains 1 splits.
2023-09-06 11:36:02.280237: Desired fold for training: 0
2023-09-06 11:36:02.282030: This split has 1500 training and 650 validation cases.
start computing score....
2023-09-06 11:41:25.064026: dsc: 90.02%
2023-09-06 11:41:25.065942: miou: 81.84%
2023-09-06 11:41:25.067458: acc: 96.69%, sen: 89.03%, spe: 98.23%
2023-09-06 11:41:25.069463: current best miou: 0.821732634787054 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 11:41:25.071012: current best dsc: 0.9021440568122753 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 11:41:25.072664: finished real validation
2023-09-06 11:41:29.258120: train_loss -1.4482
2023-09-06 11:41:29.260216: val_loss -1.0643
2023-09-06 11:41:29.261892: Pseudo dice [0.9006]
2023-09-06 11:41:29.263339: Epoch time: 385.88 s
2023-09-06 11:41:30.378825: 
2023-09-06 11:41:30.380562: Epoch 242
2023-09-06 11:41:30.382011: Current learning rate: backbone 0.00022786, others 0.00022786
2023-09-06 11:41:30.383768: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-06 11:42:29.167767: finished training epoch 242
2023-09-06 11:42:29.210490: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset122_ISIC2017/splits_final.json
2023-09-06 11:42:29.212827: The split file contains 1 splits.
2023-09-06 11:42:29.214234: Desired fold for training: 0
2023-09-06 11:42:29.215563: This split has 1500 training and 650 validation cases.
start computing score....
2023-09-06 11:47:54.587085: dsc: 90.01%
2023-09-06 11:47:54.592069: miou: 81.84%
2023-09-06 11:47:54.596010: acc: 96.71%, sen: 88.66%, spe: 98.33%
2023-09-06 11:47:54.601387: current best miou: 0.821732634787054 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 11:47:54.604554: current best dsc: 0.9021440568122753 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 11:47:54.608081: finished real validation
2023-09-06 11:47:58.808462: train_loss -1.4478
2023-09-06 11:47:58.812429: val_loss -1.0599
2023-09-06 11:47:58.814797: Pseudo dice [0.8981]
2023-09-06 11:47:58.817028: Epoch time: 388.43 s
2023-09-06 11:47:59.960686: 
2023-09-06 11:47:59.962563: Epoch 243
2023-09-06 11:47:59.964127: Current learning rate: backbone 0.00022433, others 0.00022433
2023-09-06 11:47:59.966252: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-06 11:48:58.800334: finished training epoch 243
2023-09-06 11:48:58.870213: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset122_ISIC2017/splits_final.json
2023-09-06 11:48:58.872857: The split file contains 1 splits.
2023-09-06 11:48:58.874892: Desired fold for training: 0
2023-09-06 11:48:58.877221: This split has 1500 training and 650 validation cases.
start computing score....
2023-09-06 11:53:54.362886: dsc: 89.95%
2023-09-06 11:53:54.365244: miou: 81.73%
2023-09-06 11:53:54.366735: acc: 96.68%, sen: 88.62%, spe: 98.30%
2023-09-06 11:53:54.368825: current best miou: 0.821732634787054 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 11:53:54.370982: current best dsc: 0.9021440568122753 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 11:53:54.373191: finished real validation
2023-09-06 11:53:58.572222: train_loss -1.4486
2023-09-06 11:53:58.574381: val_loss -1.0323
2023-09-06 11:53:58.576174: Pseudo dice [0.8957]
2023-09-06 11:53:58.577753: Epoch time: 358.61 s
2023-09-06 11:53:59.682195: 
2023-09-06 11:53:59.684225: Epoch 244
2023-09-06 11:53:59.685866: Current learning rate: backbone 0.00022078, others 0.00022078
2023-09-06 11:53:59.687853: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-06 11:54:58.487967: finished training epoch 244
2023-09-06 11:54:58.529163: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset122_ISIC2017/splits_final.json
2023-09-06 11:54:58.532752: The split file contains 1 splits.
2023-09-06 11:54:58.534708: Desired fold for training: 0
2023-09-06 11:54:58.536522: This split has 1500 training and 650 validation cases.
start computing score....
2023-09-06 11:59:05.658450: dsc: 90.02%
2023-09-06 11:59:05.660426: miou: 81.85%
2023-09-06 11:59:05.661840: acc: 96.69%, sen: 89.12%, spe: 98.21%
2023-09-06 11:59:05.663567: current best miou: 0.821732634787054 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 11:59:05.665130: current best dsc: 0.9021440568122753 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 11:59:05.666916: finished real validation
2023-09-06 11:59:09.872971: train_loss -1.4478
2023-09-06 11:59:09.874916: val_loss -1.0779
2023-09-06 11:59:09.876559: Pseudo dice [0.9004]
2023-09-06 11:59:09.878067: Epoch time: 310.19 s
2023-09-06 11:59:10.983808: 
2023-09-06 11:59:10.985673: Epoch 245
2023-09-06 11:59:10.987639: Current learning rate: backbone 0.00021723, others 0.00021723
2023-09-06 11:59:10.990402: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-06 12:00:09.861675: finished training epoch 245
2023-09-06 12:00:09.891129: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset122_ISIC2017/splits_final.json
2023-09-06 12:00:09.893443: The split file contains 1 splits.
2023-09-06 12:00:09.894870: Desired fold for training: 0
2023-09-06 12:00:09.896259: This split has 1500 training and 650 validation cases.
start computing score....
2023-09-06 12:04:22.135007: dsc: 89.99%
2023-09-06 12:04:22.137244: miou: 81.80%
2023-09-06 12:04:22.138773: acc: 96.69%, sen: 88.85%, spe: 98.26%
2023-09-06 12:04:22.140510: current best miou: 0.821732634787054 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 12:04:22.142200: current best dsc: 0.9021440568122753 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 12:04:22.143831: finished real validation
2023-09-06 12:04:26.341786: train_loss -1.4478
2023-09-06 12:04:26.343868: val_loss -1.0515
2023-09-06 12:04:26.345790: Pseudo dice [0.8993]
2023-09-06 12:04:26.347405: Epoch time: 315.36 s
2023-09-06 12:04:27.447221: 
2023-09-06 12:04:27.449888: Epoch 246
2023-09-06 12:04:27.451742: Current learning rate: backbone 0.00021367, others 0.00021367
2023-09-06 12:04:27.453884: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-06 12:05:26.164442: finished training epoch 246
2023-09-06 12:05:26.193905: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset122_ISIC2017/splits_final.json
2023-09-06 12:05:26.196256: The split file contains 1 splits.
2023-09-06 12:05:26.197819: Desired fold for training: 0
2023-09-06 12:05:26.199496: This split has 1500 training and 650 validation cases.
start computing score....
2023-09-06 12:09:49.446823: dsc: 90.04%
2023-09-06 12:09:49.449121: miou: 81.89%
2023-09-06 12:09:49.450884: acc: 96.70%, sen: 88.94%, spe: 98.27%
2023-09-06 12:09:49.453047: current best miou: 0.821732634787054 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 12:09:49.454482: current best dsc: 0.9021440568122753 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 12:09:49.455865: finished real validation
2023-09-06 12:09:53.657113: train_loss -1.4479
2023-09-06 12:09:53.660345: val_loss -1.0971
2023-09-06 12:09:53.662719: Pseudo dice [0.9062]
2023-09-06 12:09:53.664333: Epoch time: 326.21 s
2023-09-06 12:09:54.773627: 
2023-09-06 12:09:54.775868: Epoch 247
2023-09-06 12:09:54.777922: Current learning rate: backbone 0.00021011, others 0.00021011
2023-09-06 12:09:54.779972: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-06 12:10:53.615875: finished training epoch 247
2023-09-06 12:10:53.643242: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset122_ISIC2017/splits_final.json
2023-09-06 12:10:53.645916: The split file contains 1 splits.
2023-09-06 12:10:53.649517: Desired fold for training: 0
2023-09-06 12:10:53.650995: This split has 1500 training and 650 validation cases.
start computing score....
2023-09-06 12:15:15.514219: dsc: 90.01%
2023-09-06 12:15:15.517459: miou: 81.83%
2023-09-06 12:15:15.520270: acc: 96.71%, sen: 88.57%, spe: 98.34%
2023-09-06 12:15:15.522916: current best miou: 0.821732634787054 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 12:15:15.526263: current best dsc: 0.9021440568122753 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 12:15:15.528380: finished real validation
2023-09-06 12:15:19.736892: train_loss -1.4484
2023-09-06 12:15:19.739069: val_loss -1.047
2023-09-06 12:15:19.740730: Pseudo dice [0.8958]
2023-09-06 12:15:19.742315: Epoch time: 324.96 s
2023-09-06 12:15:20.862646: 
2023-09-06 12:15:20.864710: Epoch 248
2023-09-06 12:15:20.866153: Current learning rate: backbone 0.00020654, others 0.00020654
2023-09-06 12:15:20.867944: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-06 12:16:19.768967: finished training epoch 248
2023-09-06 12:16:19.798531: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset122_ISIC2017/splits_final.json
2023-09-06 12:16:19.801021: The split file contains 1 splits.
2023-09-06 12:16:19.802540: Desired fold for training: 0
2023-09-06 12:16:19.803957: This split has 1500 training and 650 validation cases.
start computing score....
2023-09-06 12:20:37.482926: dsc: 90.04%
2023-09-06 12:20:37.485017: miou: 81.88%
2023-09-06 12:20:37.486644: acc: 96.70%, sen: 89.14%, spe: 98.22%
2023-09-06 12:20:37.488619: current best miou: 0.821732634787054 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 12:20:37.490282: current best dsc: 0.9021440568122753 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 12:20:37.491729: finished real validation
2023-09-06 12:20:41.693225: train_loss -1.4483
2023-09-06 12:20:41.695341: val_loss -1.0602
2023-09-06 12:20:41.697234: Pseudo dice [0.9]
2023-09-06 12:20:41.699081: Epoch time: 320.83 s
2023-09-06 12:20:42.832601: 
2023-09-06 12:20:42.834656: Epoch 249
2023-09-06 12:20:42.836155: Current learning rate: backbone 0.00020296, others 0.00020296
2023-09-06 12:20:42.837988: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-06 12:21:41.716349: finished training epoch 249
2023-09-06 12:21:41.745600: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset122_ISIC2017/splits_final.json
2023-09-06 12:21:41.748347: The split file contains 1 splits.
2023-09-06 12:21:41.750284: Desired fold for training: 0
2023-09-06 12:21:41.751787: This split has 1500 training and 650 validation cases.
start computing score....
2023-09-06 12:25:56.182138: dsc: 90.01%
2023-09-06 12:25:56.184190: miou: 81.84%
2023-09-06 12:25:56.185557: acc: 96.69%, sen: 88.98%, spe: 98.25%
2023-09-06 12:25:56.187227: current best miou: 0.821732634787054 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 12:25:56.188624: current best dsc: 0.9021440568122753 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 12:25:56.189920: finished real validation
2023-09-06 12:26:00.392620: train_loss -1.4483
2023-09-06 12:26:00.394819: val_loss -1.0734
2023-09-06 12:26:00.397236: Pseudo dice [0.9019]
2023-09-06 12:26:00.399243: Epoch time: 317.56 s
2023-09-06 12:26:03.064597: 
2023-09-06 12:26:03.066856: Epoch 250
2023-09-06 12:26:03.068389: Current learning rate: backbone 0.00019937, others 0.00019937
2023-09-06 12:26:03.070537: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-06 12:27:01.905907: finished training epoch 250
2023-09-06 12:27:01.934530: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset122_ISIC2017/splits_final.json
2023-09-06 12:27:01.936799: The split file contains 1 splits.
2023-09-06 12:27:01.938268: Desired fold for training: 0
2023-09-06 12:27:01.939672: This split has 1500 training and 650 validation cases.
start computing score....
2023-09-06 12:31:14.909379: dsc: 89.94%
2023-09-06 12:31:14.911298: miou: 81.73%
2023-09-06 12:31:14.912822: acc: 96.67%, sen: 88.90%, spe: 98.23%
2023-09-06 12:31:14.914617: current best miou: 0.821732634787054 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 12:31:14.916168: current best dsc: 0.9021440568122753 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 12:31:14.917622: finished real validation
2023-09-06 12:31:19.116972: train_loss -1.4484
2023-09-06 12:31:19.119242: val_loss -1.056
2023-09-06 12:31:19.121131: Pseudo dice [0.8994]
2023-09-06 12:31:19.122823: Epoch time: 316.05 s
2023-09-06 12:31:20.269344: 
2023-09-06 12:31:20.271455: Epoch 251
2023-09-06 12:31:20.273132: Current learning rate: backbone 0.00019578, others 0.00019578
2023-09-06 12:31:20.275221: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-06 12:32:19.082481: finished training epoch 251
2023-09-06 12:32:19.114484: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset122_ISIC2017/splits_final.json
2023-09-06 12:32:19.117191: The split file contains 1 splits.
2023-09-06 12:32:19.118881: Desired fold for training: 0
2023-09-06 12:32:19.120498: This split has 1500 training and 650 validation cases.
start computing score....
2023-09-06 12:36:47.101698: dsc: 90.01%
2023-09-06 12:36:47.104823: miou: 81.84%
2023-09-06 12:36:47.107495: acc: 96.70%, sen: 88.78%, spe: 98.30%
2023-09-06 12:36:47.110372: current best miou: 0.821732634787054 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 12:36:47.112818: current best dsc: 0.9021440568122753 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 12:36:47.115274: finished real validation
2023-09-06 12:36:51.318580: train_loss -1.4485
2023-09-06 12:36:51.320782: val_loss -1.044
2023-09-06 12:36:51.322673: Pseudo dice [0.898]
2023-09-06 12:36:51.324859: Epoch time: 331.05 s
2023-09-06 12:36:52.451646: 
2023-09-06 12:36:52.453689: Epoch 252
2023-09-06 12:36:52.455324: Current learning rate: backbone 0.00019218, others 0.00019218
2023-09-06 12:36:52.457221: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-06 12:37:51.212141: finished training epoch 252
2023-09-06 12:37:51.248634: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset122_ISIC2017/splits_final.json
2023-09-06 12:37:51.251244: The split file contains 1 splits.
2023-09-06 12:37:51.252926: Desired fold for training: 0
2023-09-06 12:37:51.255848: This split has 1500 training and 650 validation cases.
start computing score....
2023-09-06 12:42:05.970707: dsc: 90.02%
2023-09-06 12:42:05.972714: miou: 81.85%
2023-09-06 12:42:05.974344: acc: 96.70%, sen: 88.90%, spe: 98.27%
2023-09-06 12:42:05.976314: current best miou: 0.821732634787054 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 12:42:05.977908: current best dsc: 0.9021440568122753 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 12:42:05.979533: finished real validation
2023-09-06 12:42:10.183193: train_loss -1.4481
2023-09-06 12:42:10.185450: val_loss -1.0757
2023-09-06 12:42:10.187401: Pseudo dice [0.903]
2023-09-06 12:42:10.188927: Epoch time: 317.73 s
2023-09-06 12:42:11.311660: 
2023-09-06 12:42:11.313885: Epoch 253
2023-09-06 12:42:11.315361: Current learning rate: backbone 0.00018857, others 0.00018857
2023-09-06 12:42:11.317296: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-06 12:43:10.108618: finished training epoch 253
2023-09-06 12:43:10.158566: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset122_ISIC2017/splits_final.json
2023-09-06 12:43:10.160861: The split file contains 1 splits.
2023-09-06 12:43:10.162539: Desired fold for training: 0
2023-09-06 12:43:10.163966: This split has 1500 training and 650 validation cases.
start computing score....
2023-09-06 12:47:28.673290: dsc: 89.92%
2023-09-06 12:47:28.675472: miou: 81.69%
2023-09-06 12:47:28.677277: acc: 96.67%, sen: 88.73%, spe: 98.27%
2023-09-06 12:47:28.678974: current best miou: 0.821732634787054 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 12:47:28.680368: current best dsc: 0.9021440568122753 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 12:47:28.681758: finished real validation
2023-09-06 12:47:32.893370: train_loss -1.4481
2023-09-06 12:47:32.895332: val_loss -1.0397
2023-09-06 12:47:32.897197: Pseudo dice [0.8984]
2023-09-06 12:47:32.898699: Epoch time: 321.58 s
2023-09-06 12:47:34.034323: 
2023-09-06 12:47:34.036241: Epoch 254
2023-09-06 12:47:34.037733: Current learning rate: backbone 0.00018496, others 0.00018496
2023-09-06 12:47:34.039594: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-06 12:48:33.037976: finished training epoch 254
2023-09-06 12:48:33.066263: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset122_ISIC2017/splits_final.json
2023-09-06 12:48:33.068676: The split file contains 1 splits.
2023-09-06 12:48:33.071285: Desired fold for training: 0
2023-09-06 12:48:33.072997: This split has 1500 training and 650 validation cases.
start computing score....
2023-09-06 12:52:49.987159: dsc: 89.95%
2023-09-06 12:52:49.989909: miou: 81.73%
2023-09-06 12:52:49.991425: acc: 96.69%, sen: 88.51%, spe: 98.33%
2023-09-06 12:52:49.993545: current best miou: 0.821732634787054 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 12:52:49.995203: current best dsc: 0.9021440568122753 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 12:52:49.996851: finished real validation
2023-09-06 12:52:54.211716: train_loss -1.4482
2023-09-06 12:52:54.213887: val_loss -1.0505
2023-09-06 12:52:54.215735: Pseudo dice [0.899]
2023-09-06 12:52:54.217304: Epoch time: 320.18 s
2023-09-06 12:52:55.338550: 
2023-09-06 12:52:55.340621: Epoch 255
2023-09-06 12:52:55.342592: Current learning rate: backbone 0.00018134, others 0.00018134
2023-09-06 12:52:55.344640: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-06 12:53:54.136669: finished training epoch 255
2023-09-06 12:53:54.165641: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset122_ISIC2017/splits_final.json
2023-09-06 12:53:54.168043: The split file contains 1 splits.
2023-09-06 12:53:54.169523: Desired fold for training: 0
2023-09-06 12:53:54.170926: This split has 1500 training and 650 validation cases.
start computing score....
2023-09-06 12:58:01.039691: dsc: 89.99%
2023-09-06 12:58:01.041760: miou: 81.81%
2023-09-06 12:58:01.043352: acc: 96.68%, sen: 89.07%, spe: 98.22%
2023-09-06 12:58:01.045307: current best miou: 0.821732634787054 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 12:58:01.046751: current best dsc: 0.9021440568122753 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 12:58:01.048279: finished real validation
2023-09-06 12:58:05.249403: train_loss -1.4487
2023-09-06 12:58:05.251544: val_loss -1.064
2023-09-06 12:58:05.253354: Pseudo dice [0.9035]
2023-09-06 12:58:05.255008: Epoch time: 309.91 s
2023-09-06 12:58:06.347824: 
2023-09-06 12:58:06.350008: Epoch 256
2023-09-06 12:58:06.351666: Current learning rate: backbone 0.0001777, others 0.0001777
2023-09-06 12:58:06.353971: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-06 12:59:05.184361: finished training epoch 256
2023-09-06 12:59:05.253088: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset122_ISIC2017/splits_final.json
2023-09-06 12:59:05.255616: The split file contains 1 splits.
2023-09-06 12:59:05.257313: Desired fold for training: 0
2023-09-06 12:59:05.258910: This split has 1500 training and 650 validation cases.
start computing score....
2023-09-06 13:03:20.589966: dsc: 90.01%
2023-09-06 13:03:20.592294: miou: 81.84%
2023-09-06 13:03:20.594338: acc: 96.69%, sen: 89.08%, spe: 98.22%
2023-09-06 13:03:20.596652: current best miou: 0.821732634787054 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 13:03:20.598269: current best dsc: 0.9021440568122753 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 13:03:20.599771: finished real validation
2023-09-06 13:03:24.798739: train_loss -1.4479
2023-09-06 13:03:24.801021: val_loss -1.0635
2023-09-06 13:03:24.802986: Pseudo dice [0.8997]
2023-09-06 13:03:24.804765: Epoch time: 318.45 s
2023-09-06 13:03:25.907737: 
2023-09-06 13:03:25.909660: Epoch 257
2023-09-06 13:03:25.911358: Current learning rate: backbone 0.00017407, others 0.00017407
2023-09-06 13:03:25.913592: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-06 13:04:24.605688: finished training epoch 257
2023-09-06 13:04:24.632394: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset122_ISIC2017/splits_final.json
2023-09-06 13:04:24.634940: The split file contains 1 splits.
2023-09-06 13:04:24.636569: Desired fold for training: 0
2023-09-06 13:04:24.638204: This split has 1500 training and 650 validation cases.
start computing score....
2023-09-06 13:08:35.521297: dsc: 90.04%
2023-09-06 13:08:35.523362: miou: 81.88%
2023-09-06 13:08:35.524878: acc: 96.70%, sen: 89.12%, spe: 98.22%
2023-09-06 13:08:35.526579: current best miou: 0.821732634787054 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 13:08:35.528065: current best dsc: 0.9021440568122753 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 13:08:35.529776: finished real validation
2023-09-06 13:08:39.723627: train_loss -1.4489
2023-09-06 13:08:39.725903: val_loss -1.0721
2023-09-06 13:08:39.728102: Pseudo dice [0.9026]
2023-09-06 13:08:39.729953: Epoch time: 313.82 s
2023-09-06 13:08:40.845968: 
2023-09-06 13:08:40.848087: Epoch 258
2023-09-06 13:08:40.849968: Current learning rate: backbone 0.00017042, others 0.00017042
2023-09-06 13:08:40.852260: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-06 13:09:40.387282: finished training epoch 258
2023-09-06 13:09:40.414942: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset122_ISIC2017/splits_final.json
2023-09-06 13:09:40.417317: The split file contains 1 splits.
2023-09-06 13:09:40.418921: Desired fold for training: 0
2023-09-06 13:09:40.420611: This split has 1500 training and 650 validation cases.
start computing score....
2023-09-06 13:13:55.298563: dsc: 90.03%
2023-09-06 13:13:55.300780: miou: 81.87%
2023-09-06 13:13:55.302502: acc: 96.71%, sen: 88.81%, spe: 98.29%
2023-09-06 13:13:55.304616: current best miou: 0.821732634787054 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 13:13:55.306269: current best dsc: 0.9021440568122753 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 13:13:55.307957: finished real validation
2023-09-06 13:13:59.494141: train_loss -1.4485
2023-09-06 13:13:59.496263: val_loss -1.0404
2023-09-06 13:13:59.497953: Pseudo dice [0.8952]
2023-09-06 13:13:59.499446: Epoch time: 318.65 s
2023-09-06 13:14:00.611813: 
2023-09-06 13:14:00.613807: Epoch 259
2023-09-06 13:14:00.615330: Current learning rate: backbone 0.00016676, others 0.00016676
2023-09-06 13:14:00.617286: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-06 13:14:59.542974: finished training epoch 259
2023-09-06 13:14:59.593237: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset122_ISIC2017/splits_final.json
2023-09-06 13:14:59.595369: The split file contains 1 splits.
2023-09-06 13:14:59.596955: Desired fold for training: 0
2023-09-06 13:14:59.598302: This split has 1500 training and 650 validation cases.
start computing score....
2023-09-06 13:20:12.992000: dsc: 89.96%
2023-09-06 13:20:12.994131: miou: 81.76%
2023-09-06 13:20:12.995776: acc: 96.67%, sen: 89.10%, spe: 98.19%
2023-09-06 13:20:12.998055: current best miou: 0.821732634787054 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 13:20:12.999557: current best dsc: 0.9021440568122753 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 13:20:13.001036: finished real validation
2023-09-06 13:20:17.195982: train_loss -1.4487
2023-09-06 13:20:17.197860: val_loss -1.0644
2023-09-06 13:20:17.199599: Pseudo dice [0.9014]
2023-09-06 13:20:17.201095: Epoch time: 376.59 s
2023-09-06 13:20:19.859941: 
2023-09-06 13:20:19.862120: Epoch 260
2023-09-06 13:20:19.864050: Current learning rate: backbone 0.0001631, others 0.0001631
2023-09-06 13:20:19.866012: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-06 13:21:18.593324: finished training epoch 260
2023-09-06 13:21:18.616824: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset122_ISIC2017/splits_final.json
2023-09-06 13:21:18.618914: The split file contains 1 splits.
2023-09-06 13:21:18.620360: Desired fold for training: 0
2023-09-06 13:21:18.621739: This split has 1500 training and 650 validation cases.
start computing score....
2023-09-06 13:26:45.130939: dsc: 89.93%
2023-09-06 13:26:45.133188: miou: 81.71%
2023-09-06 13:26:45.134863: acc: 96.67%, sen: 88.92%, spe: 98.22%
2023-09-06 13:26:45.136858: current best miou: 0.821732634787054 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 13:26:45.138595: current best dsc: 0.9021440568122753 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 13:26:45.140525: finished real validation
2023-09-06 13:26:49.327892: train_loss -1.4484
2023-09-06 13:26:49.329916: val_loss -1.0344
2023-09-06 13:26:49.331804: Pseudo dice [0.8949]
2023-09-06 13:26:49.333637: Epoch time: 389.47 s
2023-09-06 13:26:50.433717: 
2023-09-06 13:26:50.435807: Epoch 261
2023-09-06 13:26:50.437557: Current learning rate: backbone 0.00015942, others 0.00015942
2023-09-06 13:26:50.439581: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-06 13:27:49.197281: finished training epoch 261
2023-09-06 13:27:49.238215: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset122_ISIC2017/splits_final.json
2023-09-06 13:27:49.241671: The split file contains 1 splits.
2023-09-06 13:27:49.243613: Desired fold for training: 0
2023-09-06 13:27:49.245428: This split has 1500 training and 650 validation cases.
start computing score....
2023-09-06 13:31:59.608566: dsc: 89.97%
2023-09-06 13:31:59.611001: miou: 81.77%
2023-09-06 13:31:59.612673: acc: 96.67%, sen: 89.12%, spe: 98.19%
2023-09-06 13:31:59.614677: current best miou: 0.821732634787054 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 13:31:59.616280: current best dsc: 0.9021440568122753 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 13:31:59.617928: finished real validation
2023-09-06 13:32:03.796404: train_loss -1.4484
2023-09-06 13:32:03.798732: val_loss -1.064
2023-09-06 13:32:03.800800: Pseudo dice [0.8981]
2023-09-06 13:32:03.802564: Epoch time: 313.36 s
2023-09-06 13:32:04.904329: 
2023-09-06 13:32:04.906449: Epoch 262
2023-09-06 13:32:04.908190: Current learning rate: backbone 0.00015574, others 0.00015574
2023-09-06 13:32:04.910629: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-06 13:33:03.736910: finished training epoch 262
2023-09-06 13:33:03.767279: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset122_ISIC2017/splits_final.json
2023-09-06 13:33:03.769645: The split file contains 1 splits.
2023-09-06 13:33:03.771140: Desired fold for training: 0
2023-09-06 13:33:03.772604: This split has 1500 training and 650 validation cases.
start computing score....
2023-09-06 13:37:21.874568: dsc: 90.03%
2023-09-06 13:37:21.876598: miou: 81.87%
2023-09-06 13:37:21.878204: acc: 96.70%, sen: 89.02%, spe: 98.24%
2023-09-06 13:37:21.880260: current best miou: 0.821732634787054 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 13:37:21.881946: current best dsc: 0.9021440568122753 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 13:37:21.883422: finished real validation
2023-09-06 13:37:26.070417: train_loss -1.4488
2023-09-06 13:37:26.072572: val_loss -1.0507
2023-09-06 13:37:26.074358: Pseudo dice [0.899]
2023-09-06 13:37:26.075925: Epoch time: 321.17 s
2023-09-06 13:37:27.195609: 
2023-09-06 13:37:27.197720: Epoch 263
2023-09-06 13:37:27.199261: Current learning rate: backbone 0.00015205, others 0.00015205
2023-09-06 13:37:27.201169: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-06 13:38:26.021609: finished training epoch 263
2023-09-06 13:38:26.046932: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset122_ISIC2017/splits_final.json
2023-09-06 13:38:26.049169: The split file contains 1 splits.
2023-09-06 13:38:26.050737: Desired fold for training: 0
2023-09-06 13:38:26.052193: This split has 1500 training and 650 validation cases.
start computing score....
2023-09-06 13:43:17.744896: dsc: 90.01%
2023-09-06 13:43:17.746977: miou: 81.83%
2023-09-06 13:43:17.748523: acc: 96.69%, sen: 89.06%, spe: 98.22%
2023-09-06 13:43:17.750370: current best miou: 0.821732634787054 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 13:43:17.751978: current best dsc: 0.9021440568122753 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 13:43:17.753431: finished real validation
2023-09-06 13:43:21.944322: train_loss -1.4486
2023-09-06 13:43:21.946226: val_loss -1.0544
2023-09-06 13:43:21.948005: Pseudo dice [0.8992]
2023-09-06 13:43:21.949531: Epoch time: 354.75 s
2023-09-06 13:43:23.063244: 
2023-09-06 13:43:23.065329: Epoch 264
2023-09-06 13:43:23.066886: Current learning rate: backbone 0.00014834, others 0.00014834
2023-09-06 13:43:23.068911: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-06 13:44:22.043557: finished training epoch 264
2023-09-06 13:44:22.082504: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset122_ISIC2017/splits_final.json
2023-09-06 13:44:22.085204: The split file contains 1 splits.
2023-09-06 13:44:22.086670: Desired fold for training: 0
2023-09-06 13:44:22.088035: This split has 1500 training and 650 validation cases.
start computing score....
2023-09-06 13:48:35.067548: dsc: 90.02%
2023-09-06 13:48:35.069705: miou: 81.85%
2023-09-06 13:48:35.071340: acc: 96.71%, sen: 88.67%, spe: 98.32%
2023-09-06 13:48:35.073344: current best miou: 0.821732634787054 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 13:48:35.075053: current best dsc: 0.9021440568122753 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 13:48:35.076488: finished real validation
2023-09-06 13:48:39.257297: train_loss -1.4487
2023-09-06 13:48:39.259279: val_loss -1.04
2023-09-06 13:48:39.261252: Pseudo dice [0.8964]
2023-09-06 13:48:39.262830: Epoch time: 316.2 s
2023-09-06 13:48:40.375827: 
2023-09-06 13:48:40.377750: Epoch 265
2023-09-06 13:48:40.379291: Current learning rate: backbone 0.00014463, others 0.00014463
2023-09-06 13:48:40.381276: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-06 13:49:39.575862: finished training epoch 265
2023-09-06 13:49:39.664364: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset122_ISIC2017/splits_final.json
2023-09-06 13:49:39.675154: The split file contains 1 splits.
2023-09-06 13:49:39.687458: Desired fold for training: 0
2023-09-06 13:49:39.699380: This split has 1500 training and 650 validation cases.
start computing score....
2023-09-06 13:54:10.402870: dsc: 90.06%
2023-09-06 13:54:10.405355: miou: 81.92%
2023-09-06 13:54:10.407160: acc: 96.70%, sen: 89.27%, spe: 98.19%
2023-09-06 13:54:10.409236: current best miou: 0.821732634787054 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 13:54:10.410885: current best dsc: 0.9021440568122753 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 13:54:10.412540: finished real validation
2023-09-06 13:54:14.603542: train_loss -1.4488
2023-09-06 13:54:14.605799: val_loss -1.0697
2023-09-06 13:54:14.607809: Pseudo dice [0.9046]
2023-09-06 13:54:14.609745: Epoch time: 334.23 s
2023-09-06 13:54:15.744111: 
2023-09-06 13:54:15.746280: Epoch 266
2023-09-06 13:54:15.748560: Current learning rate: backbone 0.0001409, others 0.0001409
2023-09-06 13:54:15.751036: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-06 13:55:14.813276: finished training epoch 266
2023-09-06 13:55:14.842881: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset122_ISIC2017/splits_final.json
2023-09-06 13:55:14.847180: The split file contains 1 splits.
2023-09-06 13:55:14.849032: Desired fold for training: 0
2023-09-06 13:55:14.850513: This split has 1500 training and 650 validation cases.
start computing score....
2023-09-06 13:59:26.225956: dsc: 89.99%
2023-09-06 13:59:26.228134: miou: 81.80%
2023-09-06 13:59:26.229640: acc: 96.68%, sen: 89.06%, spe: 98.21%
2023-09-06 13:59:26.231482: current best miou: 0.821732634787054 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 13:59:26.233026: current best dsc: 0.9021440568122753 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 13:59:26.234473: finished real validation
2023-09-06 13:59:30.413943: train_loss -1.4488
2023-09-06 13:59:30.415918: val_loss -1.0717
2023-09-06 13:59:30.417655: Pseudo dice [0.9025]
2023-09-06 13:59:30.419180: Epoch time: 314.67 s
2023-09-06 13:59:31.539819: 
2023-09-06 13:59:31.542009: Epoch 267
2023-09-06 13:59:31.543567: Current learning rate: backbone 0.00013717, others 0.00013717
2023-09-06 13:59:31.545447: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-06 14:00:30.342698: finished training epoch 267
2023-09-06 14:00:30.379632: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset122_ISIC2017/splits_final.json
2023-09-06 14:00:30.382313: The split file contains 1 splits.
2023-09-06 14:00:30.383839: Desired fold for training: 0
2023-09-06 14:00:30.385296: This split has 1500 training and 650 validation cases.
start computing score....
2023-09-06 14:04:41.018277: dsc: 90.03%
2023-09-06 14:04:41.020428: miou: 81.88%
2023-09-06 14:04:41.022245: acc: 96.69%, sen: 89.25%, spe: 98.19%
2023-09-06 14:04:41.024365: current best miou: 0.821732634787054 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 14:04:41.026042: current best dsc: 0.9021440568122753 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 14:04:41.027700: finished real validation
2023-09-06 14:04:45.217892: train_loss -1.449
2023-09-06 14:04:45.220173: val_loss -1.0435
2023-09-06 14:04:45.222203: Pseudo dice [0.9011]
2023-09-06 14:04:45.223995: Epoch time: 313.68 s
2023-09-06 14:04:46.322019: 
2023-09-06 14:04:46.324246: Epoch 268
2023-09-06 14:04:46.326179: Current learning rate: backbone 0.00013342, others 0.00013342
2023-09-06 14:04:46.328330: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-06 14:05:45.113215: finished training epoch 268
2023-09-06 14:05:45.151565: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset122_ISIC2017/splits_final.json
2023-09-06 14:05:45.154332: The split file contains 1 splits.
2023-09-06 14:05:45.156026: Desired fold for training: 0
2023-09-06 14:05:45.157508: This split has 1500 training and 650 validation cases.
start computing score....
2023-09-06 14:09:53.366433: dsc: 90.01%
2023-09-06 14:09:53.369188: miou: 81.83%
2023-09-06 14:09:53.370959: acc: 96.70%, sen: 88.76%, spe: 98.30%
2023-09-06 14:09:53.373173: current best miou: 0.821732634787054 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 14:09:53.375035: current best dsc: 0.9021440568122753 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 14:09:53.376644: finished real validation
2023-09-06 14:09:57.570271: train_loss -1.4485
2023-09-06 14:09:57.572510: val_loss -1.0686
2023-09-06 14:09:57.574358: Pseudo dice [0.9012]
2023-09-06 14:09:57.575921: Epoch time: 311.25 s
2023-09-06 14:09:58.672302: 
2023-09-06 14:09:58.674234: Epoch 269
2023-09-06 14:09:58.675816: Current learning rate: backbone 0.00012966, others 0.00012966
2023-09-06 14:09:58.678342: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-06 14:10:57.421799: finished training epoch 269
2023-09-06 14:10:57.450040: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset122_ISIC2017/splits_final.json
2023-09-06 14:10:57.452382: The split file contains 1 splits.
2023-09-06 14:10:57.453964: Desired fold for training: 0
2023-09-06 14:10:57.455449: This split has 1500 training and 650 validation cases.
start computing score....
2023-09-06 14:15:08.771167: dsc: 90.00%
2023-09-06 14:15:08.773892: miou: 81.81%
2023-09-06 14:15:08.775388: acc: 96.67%, sen: 89.37%, spe: 98.14%
2023-09-06 14:15:08.777378: current best miou: 0.821732634787054 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 14:15:08.779412: current best dsc: 0.9021440568122753 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 14:15:08.781231: finished real validation
2023-09-06 14:15:12.994452: train_loss -1.4488
2023-09-06 14:15:12.996160: val_loss -1.0567
2023-09-06 14:15:12.997763: Pseudo dice [0.9021]
2023-09-06 14:15:12.999221: Epoch time: 314.32 s
2023-09-06 14:15:15.927419: 
2023-09-06 14:15:15.929188: Epoch 270
2023-09-06 14:15:15.930776: Current learning rate: backbone 0.00012589, others 0.00012589
2023-09-06 14:15:15.932723: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-06 14:16:14.727427: finished training epoch 270
2023-09-06 14:16:14.754541: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset122_ISIC2017/splits_final.json
2023-09-06 14:16:14.757086: The split file contains 1 splits.
2023-09-06 14:16:14.758726: Desired fold for training: 0
2023-09-06 14:16:14.760162: This split has 1500 training and 650 validation cases.
start computing score....
2023-09-06 14:20:27.354684: dsc: 90.02%
2023-09-06 14:20:27.356876: miou: 81.86%
2023-09-06 14:20:27.358626: acc: 96.70%, sen: 89.02%, spe: 98.24%
2023-09-06 14:20:27.360668: current best miou: 0.821732634787054 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 14:20:27.362239: current best dsc: 0.9021440568122753 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 14:20:27.363690: finished real validation
2023-09-06 14:20:31.564173: train_loss -1.4491
2023-09-06 14:20:31.566612: val_loss -1.0652
2023-09-06 14:20:31.568498: Pseudo dice [0.9025]
2023-09-06 14:20:31.570081: Epoch time: 315.64 s
2023-09-06 14:20:32.686026: 
2023-09-06 14:20:32.688086: Epoch 271
2023-09-06 14:20:32.689686: Current learning rate: backbone 0.00012211, others 0.00012211
2023-09-06 14:20:32.691719: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-06 14:21:31.487858: finished training epoch 271
2023-09-06 14:21:31.515558: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset122_ISIC2017/splits_final.json
2023-09-06 14:21:31.517904: The split file contains 1 splits.
2023-09-06 14:21:31.519468: Desired fold for training: 0
2023-09-06 14:21:31.521015: This split has 1500 training and 650 validation cases.
start computing score....
2023-09-06 14:26:22.189263: dsc: 89.99%
2023-09-06 14:26:22.191383: miou: 81.80%
2023-09-06 14:26:22.193212: acc: 96.69%, sen: 88.88%, spe: 98.26%
2023-09-06 14:26:22.195873: current best miou: 0.821732634787054 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 14:26:22.197909: current best dsc: 0.9021440568122753 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 14:26:22.199839: finished real validation
2023-09-06 14:26:26.396533: train_loss -1.4486
2023-09-06 14:26:26.398589: val_loss -1.0357
2023-09-06 14:26:26.400403: Pseudo dice [0.8979]
2023-09-06 14:26:26.402063: Epoch time: 353.71 s
2023-09-06 14:26:27.494918: 
2023-09-06 14:26:27.497419: Epoch 272
2023-09-06 14:26:27.499660: Current learning rate: backbone 0.00011831, others 0.00011831
2023-09-06 14:26:27.501666: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-06 14:27:26.435243: finished training epoch 272
2023-09-06 14:27:26.466569: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset122_ISIC2017/splits_final.json
2023-09-06 14:27:26.469248: The split file contains 1 splits.
2023-09-06 14:27:26.471124: Desired fold for training: 0
2023-09-06 14:27:26.472957: This split has 1500 training and 650 validation cases.
start computing score....
2023-09-06 14:31:35.478299: dsc: 89.98%
2023-09-06 14:31:35.480349: miou: 81.78%
2023-09-06 14:31:35.482002: acc: 96.68%, sen: 89.06%, spe: 98.21%
2023-09-06 14:31:35.484079: current best miou: 0.821732634787054 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 14:31:35.485718: current best dsc: 0.9021440568122753 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 14:31:35.487472: finished real validation
2023-09-06 14:31:39.677385: train_loss -1.4496
2023-09-06 14:31:39.679634: val_loss -1.0445
2023-09-06 14:31:39.681636: Pseudo dice [0.895]
2023-09-06 14:31:39.683397: Epoch time: 312.18 s
2023-09-06 14:31:40.786642: 
2023-09-06 14:31:40.789056: Epoch 273
2023-09-06 14:31:40.790849: Current learning rate: backbone 0.0001145, others 0.0001145
2023-09-06 14:31:40.793093: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-06 14:32:39.569386: finished training epoch 273
2023-09-06 14:32:39.605223: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset122_ISIC2017/splits_final.json
2023-09-06 14:32:39.607783: The split file contains 1 splits.
2023-09-06 14:32:39.609361: Desired fold for training: 0
2023-09-06 14:32:39.610880: This split has 1500 training and 650 validation cases.
start computing score....
2023-09-06 14:36:48.780895: dsc: 89.94%
2023-09-06 14:36:48.783117: miou: 81.72%
2023-09-06 14:36:48.784995: acc: 96.66%, sen: 89.07%, spe: 98.19%
2023-09-06 14:36:48.787105: current best miou: 0.821732634787054 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 14:36:48.788929: current best dsc: 0.9021440568122753 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 14:36:48.790796: finished real validation
2023-09-06 14:36:52.974864: train_loss -1.4491
2023-09-06 14:36:52.977151: val_loss -1.0574
2023-09-06 14:36:52.979188: Pseudo dice [0.9013]
2023-09-06 14:36:52.980921: Epoch time: 312.19 s
2023-09-06 14:36:54.090748: 
2023-09-06 14:36:54.092800: Epoch 274
2023-09-06 14:36:54.094992: Current learning rate: backbone 0.00011068, others 0.00011068
2023-09-06 14:36:54.097184: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-06 14:37:52.887385: finished training epoch 274
2023-09-06 14:37:52.926712: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset122_ISIC2017/splits_final.json
2023-09-06 14:37:52.930198: The split file contains 1 splits.
2023-09-06 14:37:52.932143: Desired fold for training: 0
2023-09-06 14:37:52.933893: This split has 1500 training and 650 validation cases.
start computing score....
2023-09-06 14:42:04.716286: dsc: 89.96%
2023-09-06 14:42:04.718400: miou: 81.75%
2023-09-06 14:42:04.720133: acc: 96.68%, sen: 88.89%, spe: 98.24%
2023-09-06 14:42:04.722090: current best miou: 0.821732634787054 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 14:42:04.723884: current best dsc: 0.9021440568122753 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 14:42:04.725820: finished real validation
2023-09-06 14:42:08.919690: train_loss -1.4486
2023-09-06 14:42:08.922045: val_loss -1.0602
2023-09-06 14:42:08.923935: Pseudo dice [0.8999]
2023-09-06 14:42:08.925759: Epoch time: 314.83 s
2023-09-06 14:42:10.023544: 
2023-09-06 14:42:10.025456: Epoch 275
2023-09-06 14:42:10.027132: Current learning rate: backbone 0.00010684, others 0.00010684
2023-09-06 14:42:10.029694: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-06 14:43:08.703316: finished training epoch 275
2023-09-06 14:43:08.747633: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset122_ISIC2017/splits_final.json
2023-09-06 14:43:08.750097: The split file contains 1 splits.
2023-09-06 14:43:08.751714: Desired fold for training: 0
2023-09-06 14:43:08.753192: This split has 1500 training and 650 validation cases.
start computing score....
2023-09-06 14:47:19.427457: dsc: 89.98%
2023-09-06 14:47:19.429571: miou: 81.78%
2023-09-06 14:47:19.431238: acc: 96.68%, sen: 88.93%, spe: 98.24%
2023-09-06 14:47:19.433579: current best miou: 0.821732634787054 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 14:47:19.435236: current best dsc: 0.9021440568122753 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 14:47:19.436764: finished real validation
2023-09-06 14:47:23.622192: train_loss -1.4491
2023-09-06 14:47:23.624731: val_loss -1.0365
2023-09-06 14:47:23.626803: Pseudo dice [0.8996]
2023-09-06 14:47:23.628677: Epoch time: 313.6 s
2023-09-06 14:47:24.725762: 
2023-09-06 14:47:24.727990: Epoch 276
2023-09-06 14:47:24.729818: Current learning rate: backbone 0.00010299, others 0.00010299
2023-09-06 14:47:24.732519: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-06 14:48:23.725492: finished training epoch 276
2023-09-06 14:48:23.763189: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset122_ISIC2017/splits_final.json
2023-09-06 14:48:23.765581: The split file contains 1 splits.
2023-09-06 14:48:23.767182: Desired fold for training: 0
2023-09-06 14:48:23.768788: This split has 1500 training and 650 validation cases.
start computing score....
2023-09-06 14:52:31.828245: dsc: 90.02%
2023-09-06 14:52:31.830325: miou: 81.86%
2023-09-06 14:52:31.831884: acc: 96.70%, sen: 89.02%, spe: 98.24%
2023-09-06 14:52:31.833739: current best miou: 0.821732634787054 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 14:52:31.835242: current best dsc: 0.9021440568122753 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 14:52:31.836743: finished real validation
2023-09-06 14:52:36.025378: train_loss -1.4489
2023-09-06 14:52:36.027768: val_loss -1.05
2023-09-06 14:52:36.029845: Pseudo dice [0.9008]
2023-09-06 14:52:36.031655: Epoch time: 311.3 s
2023-09-06 14:52:37.139881: 
2023-09-06 14:52:37.142253: Epoch 277
2023-09-06 14:52:37.144163: Current learning rate: backbone 9.912e-05, others 9.912e-05
2023-09-06 14:52:37.146456: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-06 14:53:35.967094: finished training epoch 277
2023-09-06 14:53:35.994053: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset122_ISIC2017/splits_final.json
2023-09-06 14:53:35.996490: The split file contains 1 splits.
2023-09-06 14:53:35.998042: Desired fold for training: 0
2023-09-06 14:53:35.999727: This split has 1500 training and 650 validation cases.
start computing score....
2023-09-06 14:57:45.103789: dsc: 89.92%
2023-09-06 14:57:45.106107: miou: 81.68%
2023-09-06 14:57:45.107715: acc: 96.67%, sen: 88.55%, spe: 98.31%
2023-09-06 14:57:45.109627: current best miou: 0.821732634787054 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 14:57:45.111174: current best dsc: 0.9021440568122753 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 14:57:45.112665: finished real validation
2023-09-06 14:57:49.302972: train_loss -1.4489
2023-09-06 14:57:49.304924: val_loss -1.0654
2023-09-06 14:57:49.307384: Pseudo dice [0.8986]
2023-09-06 14:57:49.309137: Epoch time: 312.16 s
2023-09-06 14:57:50.403053: 
2023-09-06 14:57:50.405538: Epoch 278
2023-09-06 14:57:50.407451: Current learning rate: backbone 9.523e-05, others 9.523e-05
2023-09-06 14:57:50.410009: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-06 14:58:49.352046: finished training epoch 278
2023-09-06 14:58:49.389414: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset122_ISIC2017/splits_final.json
2023-09-06 14:58:49.392112: The split file contains 1 splits.
2023-09-06 14:58:49.394035: Desired fold for training: 0
2023-09-06 14:58:49.395741: This split has 1500 training and 650 validation cases.
start computing score....
2023-09-06 15:03:01.854277: dsc: 90.03%
2023-09-06 15:03:01.856612: miou: 81.86%
2023-09-06 15:03:01.858522: acc: 96.70%, sen: 88.90%, spe: 98.27%
2023-09-06 15:03:01.860746: current best miou: 0.821732634787054 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 15:03:01.862406: current best dsc: 0.9021440568122753 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 15:03:01.864138: finished real validation
2023-09-06 15:03:06.082207: train_loss -1.4489
2023-09-06 15:03:06.084530: val_loss -1.0331
2023-09-06 15:03:06.086514: Pseudo dice [0.8948]
2023-09-06 15:03:06.088195: Epoch time: 315.68 s
2023-09-06 15:03:07.202842: 
2023-09-06 15:03:07.205091: Epoch 279
2023-09-06 15:03:07.206784: Current learning rate: backbone 9.132e-05, others 9.132e-05
2023-09-06 15:03:07.208879: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-06 15:04:06.006173: finished training epoch 279
2023-09-06 15:04:06.032876: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset122_ISIC2017/splits_final.json
2023-09-06 15:04:06.035400: The split file contains 1 splits.
2023-09-06 15:04:06.037199: Desired fold for training: 0
2023-09-06 15:04:06.038806: This split has 1500 training and 650 validation cases.
start computing score....
2023-09-06 15:08:13.937616: dsc: 90.00%
2023-09-06 15:08:13.939778: miou: 81.82%
2023-09-06 15:08:13.941625: acc: 96.69%, sen: 88.84%, spe: 98.28%
2023-09-06 15:08:13.943677: current best miou: 0.821732634787054 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 15:08:13.945761: current best dsc: 0.9021440568122753 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 15:08:13.947567: finished real validation
2023-09-06 15:08:18.139354: train_loss -1.4492
2023-09-06 15:08:18.141681: val_loss -1.0551
2023-09-06 15:08:18.143738: Pseudo dice [0.8984]
2023-09-06 15:08:18.145561: Epoch time: 310.94 s
2023-09-06 15:08:20.794821: 
2023-09-06 15:08:20.796961: Epoch 280
2023-09-06 15:08:20.798706: Current learning rate: backbone 8.74e-05, others 8.74e-05
2023-09-06 15:08:20.800847: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-06 15:09:19.681419: finished training epoch 280
2023-09-06 15:09:19.715929: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset122_ISIC2017/splits_final.json
2023-09-06 15:09:19.718715: The split file contains 1 splits.
2023-09-06 15:09:19.720425: Desired fold for training: 0
2023-09-06 15:09:19.722073: This split has 1500 training and 650 validation cases.
start computing score....
2023-09-06 15:13:27.962216: dsc: 90.00%
2023-09-06 15:13:27.964451: miou: 81.81%
2023-09-06 15:13:27.966286: acc: 96.70%, sen: 88.74%, spe: 98.30%
2023-09-06 15:13:27.968421: current best miou: 0.821732634787054 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 15:13:27.970231: current best dsc: 0.9021440568122753 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 15:13:27.972013: finished real validation
2023-09-06 15:13:32.164559: train_loss -1.4489
2023-09-06 15:13:32.166659: val_loss -1.0189
2023-09-06 15:13:32.168483: Pseudo dice [0.8918]
2023-09-06 15:13:32.170148: Epoch time: 311.37 s
2023-09-06 15:13:33.270794: 
2023-09-06 15:13:33.273189: Epoch 281
2023-09-06 15:13:33.275075: Current learning rate: backbone 8.346e-05, others 8.346e-05
2023-09-06 15:13:33.277238: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-06 15:14:32.633599: finished training epoch 281
2023-09-06 15:14:32.695711: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset122_ISIC2017/splits_final.json
2023-09-06 15:14:32.698125: The split file contains 1 splits.
2023-09-06 15:14:32.699788: Desired fold for training: 0
2023-09-06 15:14:32.701434: This split has 1500 training and 650 validation cases.
start computing score....
2023-09-06 15:18:41.867383: dsc: 90.01%
2023-09-06 15:18:41.869850: miou: 81.84%
2023-09-06 15:18:41.871829: acc: 96.69%, sen: 88.95%, spe: 98.25%
2023-09-06 15:18:41.874911: current best miou: 0.821732634787054 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 15:18:41.877161: current best dsc: 0.9021440568122753 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 15:18:41.879332: finished real validation
2023-09-06 15:18:46.082767: train_loss -1.4492
2023-09-06 15:18:46.085202: val_loss -1.0648
2023-09-06 15:18:46.087102: Pseudo dice [0.9005]
2023-09-06 15:18:46.088808: Epoch time: 312.81 s
2023-09-06 15:18:47.183352: 
2023-09-06 15:18:47.185339: Epoch 282
2023-09-06 15:18:47.187097: Current learning rate: backbone 7.949e-05, others 7.949e-05
2023-09-06 15:18:47.189258: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-06 15:19:45.986701: finished training epoch 282
2023-09-06 15:19:46.013800: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset122_ISIC2017/splits_final.json
2023-09-06 15:19:46.016191: The split file contains 1 splits.
2023-09-06 15:19:46.017921: Desired fold for training: 0
2023-09-06 15:19:46.019509: This split has 1500 training and 650 validation cases.
start computing score....
2023-09-06 15:23:56.066844: dsc: 90.00%
2023-09-06 15:23:56.068994: miou: 81.82%
2023-09-06 15:23:56.070601: acc: 96.69%, sen: 88.91%, spe: 98.26%
2023-09-06 15:23:56.072447: current best miou: 0.821732634787054 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 15:23:56.074323: current best dsc: 0.9021440568122753 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 15:23:56.075965: finished real validation
2023-09-06 15:24:00.271232: train_loss -1.4488
2023-09-06 15:24:00.273394: val_loss -1.0481
2023-09-06 15:24:00.275319: Pseudo dice [0.8974]
2023-09-06 15:24:00.277070: Epoch time: 313.09 s
2023-09-06 15:24:01.364134: 
2023-09-06 15:24:01.366315: Epoch 283
2023-09-06 15:24:01.368343: Current learning rate: backbone 7.551e-05, others 7.551e-05
2023-09-06 15:24:01.370718: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-06 15:25:00.080038: finished training epoch 283
2023-09-06 15:25:00.121389: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset122_ISIC2017/splits_final.json
2023-09-06 15:25:00.124234: The split file contains 1 splits.
2023-09-06 15:25:00.125985: Desired fold for training: 0
2023-09-06 15:25:00.127656: This split has 1500 training and 650 validation cases.
start computing score....
2023-09-06 15:29:06.487260: dsc: 89.98%
2023-09-06 15:29:06.490110: miou: 81.78%
2023-09-06 15:29:06.491850: acc: 96.69%, sen: 88.65%, spe: 98.31%
2023-09-06 15:29:06.493741: current best miou: 0.821732634787054 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 15:29:06.495331: current best dsc: 0.9021440568122753 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 15:29:06.496835: finished real validation
2023-09-06 15:29:10.697270: train_loss -1.4493
2023-09-06 15:29:10.699539: val_loss -1.0863
2023-09-06 15:29:10.701407: Pseudo dice [0.9047]
2023-09-06 15:29:10.703117: Epoch time: 309.33 s
2023-09-06 15:29:11.808182: 
2023-09-06 15:29:11.810408: Epoch 284
2023-09-06 15:29:11.812447: Current learning rate: backbone 7.15e-05, others 7.15e-05
2023-09-06 15:29:11.814897: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-06 15:30:10.769219: finished training epoch 284
2023-09-06 15:30:10.796839: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset122_ISIC2017/splits_final.json
2023-09-06 15:30:10.799676: The split file contains 1 splits.
2023-09-06 15:30:10.801633: Desired fold for training: 0
2023-09-06 15:30:10.803378: This split has 1500 training and 650 validation cases.
start computing score....
2023-09-06 15:34:20.489686: dsc: 90.02%
2023-09-06 15:34:20.492625: miou: 81.86%
2023-09-06 15:34:20.494553: acc: 96.69%, sen: 89.17%, spe: 98.20%
2023-09-06 15:34:20.496793: current best miou: 0.821732634787054 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 15:34:20.498555: current best dsc: 0.9021440568122753 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 15:34:20.500475: finished real validation
2023-09-06 15:34:24.698057: train_loss -1.4491
2023-09-06 15:34:24.701432: val_loss -1.0489
2023-09-06 15:34:24.704534: Pseudo dice [0.8987]
2023-09-06 15:34:24.707273: Epoch time: 312.89 s
2023-09-06 15:34:25.834890: 
2023-09-06 15:34:25.837136: Epoch 285
2023-09-06 15:34:25.838892: Current learning rate: backbone 6.746e-05, others 6.746e-05
2023-09-06 15:34:25.840984: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-06 15:35:24.540746: finished training epoch 285
2023-09-06 15:35:24.576521: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset122_ISIC2017/splits_final.json
2023-09-06 15:35:24.579280: The split file contains 1 splits.
2023-09-06 15:35:24.580870: Desired fold for training: 0
2023-09-06 15:35:24.582367: This split has 1500 training and 650 validation cases.
start computing score....
2023-09-06 15:39:33.467224: dsc: 90.06%
2023-09-06 15:39:33.469321: miou: 81.91%
2023-09-06 15:39:33.470887: acc: 96.71%, sen: 88.90%, spe: 98.28%
2023-09-06 15:39:33.472734: current best miou: 0.821732634787054 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 15:39:33.474368: current best dsc: 0.9021440568122753 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 15:39:33.475957: finished real validation
2023-09-06 15:39:37.699790: train_loss -1.4491
2023-09-06 15:39:37.702321: val_loss -1.0326
2023-09-06 15:39:37.705461: Pseudo dice [0.8967]
2023-09-06 15:39:37.708102: Epoch time: 311.87 s
2023-09-06 15:39:38.846381: 
2023-09-06 15:39:38.848562: Epoch 286
2023-09-06 15:39:38.850276: Current learning rate: backbone 6.34e-05, others 6.34e-05
2023-09-06 15:39:38.852371: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-06 15:40:37.945545: finished training epoch 286
2023-09-06 15:40:38.036078: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset122_ISIC2017/splits_final.json
2023-09-06 15:40:38.045871: The split file contains 1 splits.
2023-09-06 15:40:38.053355: Desired fold for training: 0
2023-09-06 15:40:38.056284: This split has 1500 training and 650 validation cases.
start computing score....
2023-09-06 15:44:48.005913: dsc: 90.05%
2023-09-06 15:44:48.008368: miou: 81.90%
2023-09-06 15:44:48.010251: acc: 96.70%, sen: 89.12%, spe: 98.23%
2023-09-06 15:44:48.012391: current best miou: 0.821732634787054 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 15:44:48.014050: current best dsc: 0.9021440568122753 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 15:44:48.015605: finished real validation
2023-09-06 15:44:52.224356: train_loss -1.4492
2023-09-06 15:44:52.226500: val_loss -1.0542
2023-09-06 15:44:52.228407: Pseudo dice [0.9008]
2023-09-06 15:44:52.230447: Epoch time: 313.38 s
2023-09-06 15:44:53.358440: 
2023-09-06 15:44:53.360781: Epoch 287
2023-09-06 15:44:53.362737: Current learning rate: backbone 5.931e-05, others 5.931e-05
2023-09-06 15:44:53.365014: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-06 15:45:52.105160: finished training epoch 287
2023-09-06 15:45:52.134263: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset122_ISIC2017/splits_final.json
2023-09-06 15:45:52.137079: The split file contains 1 splits.
2023-09-06 15:45:52.139008: Desired fold for training: 0
2023-09-06 15:45:52.140853: This split has 1500 training and 650 validation cases.
start computing score....
2023-09-06 15:50:03.329675: dsc: 89.95%
2023-09-06 15:50:03.332104: miou: 81.74%
2023-09-06 15:50:03.333768: acc: 96.68%, sen: 88.78%, spe: 98.27%
2023-09-06 15:50:03.335940: current best miou: 0.821732634787054 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 15:50:03.337592: current best dsc: 0.9021440568122753 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 15:50:03.339176: finished real validation
2023-09-06 15:50:07.557617: train_loss -1.4491
2023-09-06 15:50:07.559665: val_loss -1.0651
2023-09-06 15:50:07.561511: Pseudo dice [0.9025]
2023-09-06 15:50:07.563123: Epoch time: 314.2 s
2023-09-06 15:50:08.687399: 
2023-09-06 15:50:08.689598: Epoch 288
2023-09-06 15:50:08.691703: Current learning rate: backbone 5.519e-05, others 5.519e-05
2023-09-06 15:50:08.694026: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-06 15:51:07.426934: finished training epoch 288
2023-09-06 15:51:07.463082: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset122_ISIC2017/splits_final.json
2023-09-06 15:51:07.465760: The split file contains 1 splits.
2023-09-06 15:51:07.467299: Desired fold for training: 0
2023-09-06 15:51:07.468837: This split has 1500 training and 650 validation cases.
start computing score....
2023-09-06 15:55:15.290759: dsc: 90.01%
2023-09-06 15:55:15.293282: miou: 81.84%
2023-09-06 15:55:15.295292: acc: 96.70%, sen: 88.87%, spe: 98.27%
2023-09-06 15:55:15.297901: current best miou: 0.821732634787054 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 15:55:15.301638: current best dsc: 0.9021440568122753 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 15:55:15.303935: finished real validation
2023-09-06 15:55:19.510206: train_loss -1.4492
2023-09-06 15:55:19.512634: val_loss -1.0387
2023-09-06 15:55:19.514812: Pseudo dice [0.8996]
2023-09-06 15:55:19.516592: Epoch time: 310.82 s
2023-09-06 15:55:20.638273: 
2023-09-06 15:55:20.640881: Epoch 289
2023-09-06 15:55:20.642676: Current learning rate: backbone 5.103e-05, others 5.103e-05
2023-09-06 15:55:20.644992: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-06 15:56:19.474006: finished training epoch 289
2023-09-06 15:56:19.519738: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset122_ISIC2017/splits_final.json
2023-09-06 15:56:19.522399: The split file contains 1 splits.
2023-09-06 15:56:19.524056: Desired fold for training: 0
2023-09-06 15:56:19.525605: This split has 1500 training and 650 validation cases.
start computing score....
2023-09-06 16:01:00.352036: dsc: 89.99%
2023-09-06 16:01:00.354362: miou: 81.81%
2023-09-06 16:01:00.356232: acc: 96.69%, sen: 88.74%, spe: 98.30%
2023-09-06 16:01:00.358410: current best miou: 0.821732634787054 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 16:01:00.360290: current best dsc: 0.9021440568122753 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 16:01:00.362055: finished real validation
2023-09-06 16:01:04.547297: train_loss -1.4495
2023-09-06 16:01:04.549324: val_loss -1.0522
2023-09-06 16:01:04.551156: Pseudo dice [0.8981]
2023-09-06 16:01:04.552784: Epoch time: 343.91 s
2023-09-06 16:01:07.183331: 
2023-09-06 16:01:07.185324: Epoch 290
2023-09-06 16:01:07.187025: Current learning rate: backbone 4.684e-05, others 4.684e-05
2023-09-06 16:01:07.189139: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-06 16:02:06.332527: finished training epoch 290
2023-09-06 16:02:06.360746: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset122_ISIC2017/splits_final.json
2023-09-06 16:02:06.363429: The split file contains 1 splits.
2023-09-06 16:02:06.365434: Desired fold for training: 0
2023-09-06 16:02:06.367125: This split has 1500 training and 650 validation cases.
start computing score....
2023-09-06 16:06:22.660174: dsc: 89.94%
2023-09-06 16:06:22.662392: miou: 81.71%
2023-09-06 16:06:22.664070: acc: 96.68%, sen: 88.66%, spe: 98.29%
2023-09-06 16:06:22.666358: current best miou: 0.821732634787054 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 16:06:22.667969: current best dsc: 0.9021440568122753 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 16:06:22.669705: finished real validation
2023-09-06 16:06:26.856068: train_loss -1.4494
2023-09-06 16:06:26.858565: val_loss -1.0704
2023-09-06 16:06:26.860819: Pseudo dice [0.9026]
2023-09-06 16:06:26.862697: Epoch time: 319.67 s
2023-09-06 16:06:27.980191: 
2023-09-06 16:06:27.982637: Epoch 291
2023-09-06 16:06:27.984839: Current learning rate: backbone 4.26e-05, others 4.26e-05
2023-09-06 16:06:27.987491: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-06 16:07:26.942127: finished training epoch 291
2023-09-06 16:07:26.979848: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset122_ISIC2017/splits_final.json
2023-09-06 16:07:26.982221: The split file contains 1 splits.
2023-09-06 16:07:26.984905: Desired fold for training: 0
2023-09-06 16:07:26.986859: This split has 1500 training and 650 validation cases.
start computing score....
2023-09-06 16:11:40.120444: dsc: 89.96%
2023-09-06 16:11:40.122741: miou: 81.75%
2023-09-06 16:11:40.124847: acc: 96.68%, sen: 88.77%, spe: 98.27%
2023-09-06 16:11:40.127362: current best miou: 0.821732634787054 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 16:11:40.129276: current best dsc: 0.9021440568122753 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 16:11:40.131212: finished real validation
2023-09-06 16:11:44.316597: train_loss -1.4496
2023-09-06 16:11:44.318706: val_loss -1.0685
2023-09-06 16:11:44.320536: Pseudo dice [0.9021]
2023-09-06 16:11:44.322237: Epoch time: 316.34 s
2023-09-06 16:11:45.444539: 
2023-09-06 16:11:45.446555: Epoch 292
2023-09-06 16:11:45.448513: Current learning rate: backbone 3.832e-05, others 3.832e-05
2023-09-06 16:11:45.450734: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-06 16:12:44.127360: finished training epoch 292
2023-09-06 16:12:44.159697: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset122_ISIC2017/splits_final.json
2023-09-06 16:12:44.164814: The split file contains 1 splits.
2023-09-06 16:12:44.166550: Desired fold for training: 0
2023-09-06 16:12:44.168239: This split has 1500 training and 650 validation cases.
start computing score....
2023-09-06 16:17:02.030673: dsc: 89.99%
2023-09-06 16:17:02.032977: miou: 81.81%
2023-09-06 16:17:02.035157: acc: 96.69%, sen: 88.87%, spe: 98.26%
2023-09-06 16:17:02.037763: current best miou: 0.821732634787054 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 16:17:02.039690: current best dsc: 0.9021440568122753 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 16:17:02.041479: finished real validation
2023-09-06 16:17:06.231393: train_loss -1.4488
2023-09-06 16:17:06.234120: val_loss -1.0437
2023-09-06 16:17:06.236256: Pseudo dice [0.8976]
2023-09-06 16:17:06.238305: Epoch time: 320.79 s
2023-09-06 16:17:07.370295: 
2023-09-06 16:17:07.372662: Epoch 293
2023-09-06 16:17:07.374360: Current learning rate: backbone 3.398e-05, others 3.398e-05
2023-09-06 16:17:07.376389: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-06 16:18:06.087898: finished training epoch 293
2023-09-06 16:18:06.128649: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset122_ISIC2017/splits_final.json
2023-09-06 16:18:06.131383: The split file contains 1 splits.
2023-09-06 16:18:06.133096: Desired fold for training: 0
2023-09-06 16:18:06.134779: This split has 1500 training and 650 validation cases.
start computing score....
2023-09-06 16:22:14.494987: dsc: 89.96%
2023-09-06 16:22:14.497580: miou: 81.76%
2023-09-06 16:22:14.499506: acc: 96.68%, sen: 88.89%, spe: 98.24%
2023-09-06 16:22:14.502004: current best miou: 0.821732634787054 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 16:22:14.503946: current best dsc: 0.9021440568122753 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 16:22:14.506001: finished real validation
2023-09-06 16:22:18.695827: train_loss -1.4496
2023-09-06 16:22:18.698311: val_loss -1.0468
2023-09-06 16:22:18.700234: Pseudo dice [0.8995]
2023-09-06 16:22:18.701940: Epoch time: 311.33 s
2023-09-06 16:22:19.812846: 
2023-09-06 16:22:19.815216: Epoch 294
2023-09-06 16:22:19.817334: Current learning rate: backbone 2.958e-05, others 2.958e-05
2023-09-06 16:22:19.819985: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-06 16:23:18.482062: finished training epoch 294
2023-09-06 16:23:18.519077: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset122_ISIC2017/splits_final.json
2023-09-06 16:23:18.522427: The split file contains 1 splits.
2023-09-06 16:23:18.524449: Desired fold for training: 0
2023-09-06 16:23:18.526310: This split has 1500 training and 650 validation cases.
start computing score....
2023-09-06 16:27:27.443423: dsc: 90.00%
2023-09-06 16:27:27.445635: miou: 81.82%
2023-09-06 16:27:27.447440: acc: 96.69%, sen: 88.92%, spe: 98.25%
2023-09-06 16:27:27.449558: current best miou: 0.821732634787054 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 16:27:27.451357: current best dsc: 0.9021440568122753 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 16:27:27.453301: finished real validation
2023-09-06 16:27:31.639539: train_loss -1.4492
2023-09-06 16:27:31.641757: val_loss -1.0503
2023-09-06 16:27:31.643744: Pseudo dice [0.8991]
2023-09-06 16:27:31.645626: Epoch time: 311.83 s
2023-09-06 16:27:32.777593: 
2023-09-06 16:27:32.779718: Epoch 295
2023-09-06 16:27:32.781758: Current learning rate: backbone 2.51e-05, others 2.51e-05
2023-09-06 16:27:32.783792: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-06 16:28:31.600071: finished training epoch 295
2023-09-06 16:28:31.628197: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset122_ISIC2017/splits_final.json
2023-09-06 16:28:31.630892: The split file contains 1 splits.
2023-09-06 16:28:31.633017: Desired fold for training: 0
2023-09-06 16:28:31.634660: This split has 1500 training and 650 validation cases.
start computing score....
2023-09-06 16:32:49.545548: dsc: 89.93%
2023-09-06 16:32:49.547396: miou: 81.71%
2023-09-06 16:32:49.548890: acc: 96.69%, sen: 88.29%, spe: 98.38%
2023-09-06 16:32:49.550736: current best miou: 0.821732634787054 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 16:32:49.552210: current best dsc: 0.9021440568122753 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 16:32:49.553628: finished real validation
2023-09-06 16:32:53.758557: train_loss -1.449
2023-09-06 16:32:53.761113: val_loss -1.0485
2023-09-06 16:32:53.763154: Pseudo dice [0.8997]
2023-09-06 16:32:53.764849: Epoch time: 320.98 s
2023-09-06 16:32:54.896877: 
2023-09-06 16:32:54.899260: Epoch 296
2023-09-06 16:32:54.901321: Current learning rate: backbone 2.053e-05, others 2.053e-05
2023-09-06 16:32:54.903717: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-06 16:33:54.020139: finished training epoch 296
2023-09-06 16:33:54.050526: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset122_ISIC2017/splits_final.json
2023-09-06 16:33:54.053364: The split file contains 1 splits.
2023-09-06 16:33:54.055449: Desired fold for training: 0
2023-09-06 16:33:54.057271: This split has 1500 training and 650 validation cases.
start computing score....
2023-09-06 16:38:04.554501: dsc: 89.95%
2023-09-06 16:38:04.556800: miou: 81.73%
2023-09-06 16:38:04.558834: acc: 96.68%, sen: 88.71%, spe: 98.28%
2023-09-06 16:38:04.561936: current best miou: 0.821732634787054 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 16:38:04.563910: current best dsc: 0.9021440568122753 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 16:38:04.565696: finished real validation
2023-09-06 16:38:08.754860: train_loss -1.4492
2023-09-06 16:38:08.757142: val_loss -1.0683
2023-09-06 16:38:08.759184: Pseudo dice [0.9015]
2023-09-06 16:38:08.761083: Epoch time: 313.86 s
2023-09-06 16:38:09.890400: 
2023-09-06 16:38:09.892741: Epoch 297
2023-09-06 16:38:09.895158: Current learning rate: backbone 1.585e-05, others 1.585e-05
2023-09-06 16:38:09.897818: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-06 16:39:08.772238: finished training epoch 297
2023-09-06 16:39:08.812155: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset122_ISIC2017/splits_final.json
2023-09-06 16:39:08.814646: The split file contains 1 splits.
2023-09-06 16:39:08.816689: Desired fold for training: 0
2023-09-06 16:39:08.818459: This split has 1500 training and 650 validation cases.
start computing score....
2023-09-06 16:44:20.446760: dsc: 89.97%
2023-09-06 16:44:20.449103: miou: 81.76%
2023-09-06 16:44:20.451038: acc: 96.69%, sen: 88.71%, spe: 98.29%
2023-09-06 16:44:20.453415: current best miou: 0.821732634787054 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 16:44:20.455550: current best dsc: 0.9021440568122753 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 16:44:20.457338: finished real validation
2023-09-06 16:44:24.655293: train_loss -1.4494
2023-09-06 16:44:24.657393: val_loss -1.0443
2023-09-06 16:44:24.659165: Pseudo dice [0.8983]
2023-09-06 16:44:24.660749: Epoch time: 374.77 s
2023-09-06 16:44:25.777690: 
2023-09-06 16:44:25.780137: Epoch 298
2023-09-06 16:44:25.782029: Current learning rate: backbone 1.1e-05, others 1.1e-05
2023-09-06 16:44:25.784321: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-06 16:45:24.465241: finished training epoch 298
2023-09-06 16:45:24.503540: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset122_ISIC2017/splits_final.json
2023-09-06 16:45:24.506810: The split file contains 1 splits.
2023-09-06 16:45:24.508716: Desired fold for training: 0
2023-09-06 16:45:24.510686: This split has 1500 training and 650 validation cases.
start computing score....
2023-09-06 16:49:40.081712: dsc: 89.96%
2023-09-06 16:49:40.084401: miou: 81.75%
2023-09-06 16:49:40.086529: acc: 96.69%, sen: 88.57%, spe: 98.32%
2023-09-06 16:49:40.088997: current best miou: 0.821732634787054 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 16:49:40.091109: current best dsc: 0.9021440568122753 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 16:49:40.093018: finished real validation
2023-09-06 16:49:44.284550: train_loss -1.4495
2023-09-06 16:49:44.287074: val_loss -1.0678
2023-09-06 16:49:44.289320: Pseudo dice [0.9019]
2023-09-06 16:49:44.291960: Epoch time: 318.51 s
2023-09-06 16:49:45.431146: 
2023-09-06 16:49:45.433476: Epoch 299
2023-09-06 16:49:45.435711: Current learning rate: backbone 5.9e-06, others 5.9e-06
2023-09-06 16:49:45.438196: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-06 16:50:44.125217: finished training epoch 299
2023-09-06 16:50:44.162474: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset122_ISIC2017/splits_final.json
2023-09-06 16:50:44.165259: The split file contains 1 splits.
2023-09-06 16:50:44.167001: Desired fold for training: 0
2023-09-06 16:50:44.168806: This split has 1500 training and 650 validation cases.
start computing score....
2023-09-06 16:54:49.445734: dsc: 90.00%
2023-09-06 16:54:49.448544: miou: 81.81%
2023-09-06 16:54:49.450635: acc: 96.69%, sen: 88.76%, spe: 98.29%
2023-09-06 16:54:49.453085: current best miou: 0.821732634787054 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 16:54:49.455240: current best dsc: 0.9021440568122753 at epoch: 126, (126, 0.821732634787054, 0.9021440568122753)
2023-09-06 16:54:49.457353: finished real validation
2023-09-06 16:54:53.643200: train_loss -1.4496
2023-09-06 16:54:53.645840: val_loss -1.0738
2023-09-06 16:54:53.648028: Pseudo dice [0.9028]
2023-09-06 16:54:53.649858: Epoch time: 308.21 s
2023-09-06 16:54:56.397460: Training done.
2023-09-06 16:54:56.481871: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset122_ISIC2017/splits_final.json
2023-09-06 16:54:56.484584: The split file contains 1 splits.
2023-09-06 16:54:56.486309: Desired fold for training: 0
2023-09-06 16:54:56.487906: This split has 1500 training and 650 validation cases.
2023-09-06 16:54:56.509362: predicting ISIC_0001769
2023-09-06 16:54:56.677117: predicting ISIC_0001852
2023-09-06 16:54:56.824220: predicting ISIC_0001871
2023-09-06 16:54:56.976965: predicting ISIC_0003462
2023-09-06 16:54:57.144977: predicting ISIC_0003539
2023-09-06 16:54:57.296573: predicting ISIC_0003582
2023-09-06 16:54:57.447513: predicting ISIC_0003657
2023-09-06 16:54:57.592691: predicting ISIC_0003805
2023-09-06 16:54:57.743594: predicting ISIC_0004337
2023-09-06 16:54:57.891642: predicting ISIC_0006651
2023-09-06 16:54:58.039624: predicting ISIC_0006671
2023-09-06 16:54:58.199413: predicting ISIC_0006815
2023-09-06 16:54:58.345720: predicting ISIC_0006914
2023-09-06 16:54:58.502209: predicting ISIC_0007141
2023-09-06 16:54:58.703662: predicting ISIC_0007156
2023-09-06 16:54:58.850949: predicting ISIC_0007235
2023-09-06 16:54:59.005837: predicting ISIC_0007241
2023-09-06 16:54:59.160160: predicting ISIC_0007332
2023-09-06 16:54:59.309333: predicting ISIC_0007344
2023-09-06 16:54:59.455855: predicting ISIC_0007528
2023-09-06 16:54:59.601325: predicting ISIC_0007796
2023-09-06 16:54:59.742665: predicting ISIC_0008025
2023-09-06 16:54:59.886549: predicting ISIC_0008524
2023-09-06 16:55:00.045606: predicting ISIC_0009995
2023-09-06 16:55:24.949776: predicting ISIC_0010459
2023-09-06 16:55:25.120967: predicting ISIC_0012099
2023-09-06 16:55:25.289464: predicting ISIC_0012109
2023-09-06 16:55:25.456586: predicting ISIC_0012126
2023-09-06 16:55:25.614436: predicting ISIC_0012127
2023-09-06 16:55:25.768829: predicting ISIC_0012143
2023-09-06 16:55:25.920931: predicting ISIC_0012151
2023-09-06 16:55:26.077352: predicting ISIC_0012159
2023-09-06 16:55:26.230127: predicting ISIC_0012160
2023-09-06 16:55:26.380954: predicting ISIC_0012191
2023-09-06 16:55:26.530318: predicting ISIC_0012201
2023-09-06 16:55:26.689600: predicting ISIC_0012204
2023-09-06 16:55:26.841957: predicting ISIC_0012206
2023-09-06 16:55:26.990328: predicting ISIC_0012210
2023-09-06 16:55:27.135353: predicting ISIC_0012221
2023-09-06 16:55:27.280552: predicting ISIC_0012222
2023-09-06 16:55:27.435960: predicting ISIC_0012254
2023-09-06 16:55:27.590776: predicting ISIC_0012256
2023-09-06 16:55:27.752865: predicting ISIC_0012288
2023-09-06 16:55:27.901887: predicting ISIC_0012306
2023-09-06 16:55:28.048341: predicting ISIC_0012313
2023-09-06 16:55:28.196042: predicting ISIC_0012316
2023-09-06 16:55:28.341455: predicting ISIC_0012335
2023-09-06 16:55:28.487357: predicting ISIC_0012380
2023-09-06 16:55:28.634153: predicting ISIC_0012383
2023-09-06 16:55:28.780068: predicting ISIC_0012400
2023-09-06 16:55:28.926026: predicting ISIC_0012417
2023-09-06 16:55:29.074371: predicting ISIC_0012434
2023-09-06 16:55:29.220401: predicting ISIC_0012492
2023-09-06 16:55:29.366703: predicting ISIC_0012513
2023-09-06 16:55:29.513070: predicting ISIC_0012538
2023-09-06 16:55:29.660630: predicting ISIC_0012547
2023-09-06 16:55:29.802694: predicting ISIC_0012660
2023-09-06 16:55:29.936402: predicting ISIC_0012684
2023-09-06 16:55:30.068588: predicting ISIC_0012720
2023-09-06 16:55:30.202168: predicting ISIC_0012746
2023-09-06 16:55:30.337236: predicting ISIC_0012876
2023-09-06 16:55:30.474552: predicting ISIC_0012927
2023-09-06 16:55:30.607792: predicting ISIC_0012956
2023-09-06 16:55:30.761753: predicting ISIC_0012959
2023-09-06 16:55:30.908725: predicting ISIC_0012965
2023-09-06 16:55:31.055417: predicting ISIC_0013010
2023-09-06 16:55:31.207253: predicting ISIC_0013082
2023-09-06 16:55:31.354525: predicting ISIC_0013104
2023-09-06 16:55:31.502182: predicting ISIC_0013127
2023-09-06 16:55:31.649452: predicting ISIC_0013128
2023-09-06 16:55:31.795621: predicting ISIC_0013132
2023-09-06 16:55:31.943369: predicting ISIC_0013188
2023-09-06 16:55:32.090367: predicting ISIC_0013215
2023-09-06 16:55:32.235590: predicting ISIC_0013232
2023-09-06 16:55:32.382656: predicting ISIC_0013421
2023-09-06 16:55:32.527843: predicting ISIC_0013474
2023-09-06 16:55:32.674384: predicting ISIC_0013480
2023-09-06 16:55:32.830613: predicting ISIC_0013486
2023-09-06 16:55:32.983421: predicting ISIC_0013487
2023-09-06 16:55:33.134438: predicting ISIC_0013488
2023-09-06 16:55:33.283196: predicting ISIC_0013489
2023-09-06 16:55:33.431464: predicting ISIC_0013490
2023-09-06 16:55:33.590487: predicting ISIC_0013491
2023-09-06 16:55:33.745516: predicting ISIC_0013492
2023-09-06 16:55:33.896954: predicting ISIC_0013493
2023-09-06 16:55:34.046771: predicting ISIC_0013494
2023-09-06 16:55:34.195210: predicting ISIC_0013495
2023-09-06 16:55:34.349620: predicting ISIC_0013497
2023-09-06 16:55:34.499362: predicting ISIC_0013498
2023-09-06 16:55:34.647122: predicting ISIC_0013499
2023-09-06 16:55:34.797320: predicting ISIC_0013500
2023-09-06 16:55:34.952505: predicting ISIC_0013501
2023-09-06 16:55:35.102849: predicting ISIC_0013516
2023-09-06 16:55:35.248895: predicting ISIC_0013517
2023-09-06 16:55:35.396732: predicting ISIC_0013518
2023-09-06 16:55:35.546342: predicting ISIC_0013523
2023-09-06 16:55:35.696898: predicting ISIC_0013525
2023-09-06 16:55:35.855082: predicting ISIC_0013526
2023-09-06 16:55:36.012547: predicting ISIC_0013527
2023-09-06 16:55:36.164067: predicting ISIC_0013530
2023-09-06 16:55:36.312806: predicting ISIC_0013549
2023-09-06 16:55:36.462469: predicting ISIC_0013552
2023-09-06 16:55:36.611369: predicting ISIC_0013553
2023-09-06 16:55:36.759680: predicting ISIC_0013554
2023-09-06 16:55:36.905596: predicting ISIC_0013558
2023-09-06 16:55:37.051099: predicting ISIC_0013559
2023-09-06 16:55:37.196563: predicting ISIC_0013561
2023-09-06 16:55:37.341669: predicting ISIC_0013562
2023-09-06 16:55:37.487211: predicting ISIC_0013567
2023-09-06 16:55:37.633849: predicting ISIC_0013568
2023-09-06 16:55:37.781787: predicting ISIC_0013572
2023-09-06 16:55:37.930013: predicting ISIC_0013573
2023-09-06 16:55:38.086618: predicting ISIC_0013578
2023-09-06 16:55:38.240390: predicting ISIC_0013579
2023-09-06 16:55:38.391537: predicting ISIC_0013580
2023-09-06 16:55:38.542096: predicting ISIC_0013581
2023-09-06 16:55:38.691865: predicting ISIC_0013584
2023-09-06 16:55:38.840164: predicting ISIC_0013585
2023-09-06 16:55:38.977444: predicting ISIC_0013592
2023-09-06 16:55:39.113404: predicting ISIC_0013594
2023-09-06 16:55:39.246054: predicting ISIC_0013595
2023-09-06 16:55:39.376828: predicting ISIC_0013596
2023-09-06 16:55:39.506852: predicting ISIC_0013597
2023-09-06 16:55:39.637617: predicting ISIC_0013599
2023-09-06 16:55:39.767710: predicting ISIC_0013601
2023-09-06 16:55:39.896967: predicting ISIC_0013603
2023-09-06 16:55:40.025564: predicting ISIC_0013606
2023-09-06 16:55:40.159490: predicting ISIC_0013610
2023-09-06 16:55:40.292609: predicting ISIC_0013618
2023-09-06 16:55:40.423671: predicting ISIC_0013621
2023-09-06 16:55:40.552713: predicting ISIC_0013625
2023-09-06 16:55:40.682764: predicting ISIC_0013626
2023-09-06 16:55:40.811804: predicting ISIC_0013632
2023-09-06 16:55:40.941070: predicting ISIC_0013634
2023-09-06 16:55:41.073279: predicting ISIC_0013635
2023-09-06 16:55:41.206639: predicting ISIC_0013637
2023-09-06 16:55:41.336991: predicting ISIC_0013639
2023-09-06 16:55:41.466117: predicting ISIC_0013643
2023-09-06 16:55:41.596499: predicting ISIC_0013644
2023-09-06 16:55:41.733047: predicting ISIC_0013651
2023-09-06 16:55:41.867650: predicting ISIC_0013652
2023-09-06 16:55:42.000228: predicting ISIC_0013656
2023-09-06 16:55:42.130923: predicting ISIC_0013663
2023-09-06 16:55:42.263139: predicting ISIC_0013664
2023-09-06 16:55:42.393413: predicting ISIC_0013667
2023-09-06 16:55:42.524601: predicting ISIC_0013670
2023-09-06 16:55:42.655802: predicting ISIC_0013671
2023-09-06 16:55:42.787897: predicting ISIC_0013672
2023-09-06 16:55:42.918072: predicting ISIC_0013674
2023-09-06 16:55:43.048971: predicting ISIC_0013675
2023-09-06 16:55:43.181864: predicting ISIC_0013676
2023-09-06 16:55:43.316523: predicting ISIC_0013680
2023-09-06 16:55:43.456999: predicting ISIC_0013682
2023-09-06 16:55:43.595671: predicting ISIC_0013684
2023-09-06 16:55:43.732679: predicting ISIC_0013685
2023-09-06 16:55:43.875721: predicting ISIC_0013687
2023-09-06 16:55:44.008327: predicting ISIC_0013688
2023-09-06 16:55:44.145288: predicting ISIC_0013689
2023-09-06 16:55:44.290780: predicting ISIC_0013690
2023-09-06 16:55:44.436799: predicting ISIC_0013691
2023-09-06 16:55:44.573301: predicting ISIC_0013695
2023-09-06 16:55:44.706682: predicting ISIC_0013702
2023-09-06 16:55:44.839004: predicting ISIC_0013706
2023-09-06 16:55:44.976592: predicting ISIC_0013707
2023-09-06 16:55:45.113832: predicting ISIC_0013709
2023-09-06 16:55:45.244979: predicting ISIC_0013712
2023-09-06 16:55:45.376628: predicting ISIC_0013713
2023-09-06 16:55:45.507883: predicting ISIC_0013719
2023-09-06 16:55:45.644389: predicting ISIC_0013721
2023-09-06 16:55:45.780346: predicting ISIC_0013725
2023-09-06 16:55:45.914293: predicting ISIC_0013731
2023-09-06 16:55:46.049743: predicting ISIC_0013736
2023-09-06 16:55:46.183028: predicting ISIC_0013737
2023-09-06 16:55:46.315511: predicting ISIC_0013740
2023-09-06 16:55:46.456606: predicting ISIC_0013742
2023-09-06 16:55:46.600420: predicting ISIC_0013747
2023-09-06 16:55:46.741176: predicting ISIC_0013748
2023-09-06 16:55:46.876822: predicting ISIC_0013749
2023-09-06 16:55:47.011131: predicting ISIC_0013758
2023-09-06 16:55:47.150330: predicting ISIC_0013762
2023-09-06 16:55:47.285215: predicting ISIC_0013765
2023-09-06 16:55:47.421571: predicting ISIC_0013772
2023-09-06 16:55:47.556048: predicting ISIC_0013775
2023-09-06 16:55:47.691269: predicting ISIC_0013777
2023-09-06 16:55:47.826371: predicting ISIC_0013778
2023-09-06 16:55:47.971827: predicting ISIC_0013782
2023-09-06 16:55:48.117788: predicting ISIC_0013783
2023-09-06 16:55:48.256738: predicting ISIC_0013789
2023-09-06 16:55:48.393627: predicting ISIC_0013792
2023-09-06 16:55:48.528266: predicting ISIC_0013793
2023-09-06 16:55:48.680179: predicting ISIC_0013795
2023-09-06 16:55:48.830394: predicting ISIC_0013796
2023-09-06 16:55:48.972300: predicting ISIC_0013797
2023-09-06 16:55:49.114676: predicting ISIC_0013798
2023-09-06 16:55:49.259048: predicting ISIC_0013799
2023-09-06 16:55:49.396248: predicting ISIC_0013800
2023-09-06 16:55:49.545115: predicting ISIC_0013801
2023-09-06 16:55:49.686294: predicting ISIC_0013802
2023-09-06 16:55:49.824247: predicting ISIC_0013803
2023-09-06 16:55:49.962207: predicting ISIC_0013804
2023-09-06 16:55:50.099055: predicting ISIC_0013805
2023-09-06 16:55:50.237502: predicting ISIC_0013806
2023-09-06 16:55:50.376639: predicting ISIC_0013807
2023-09-06 16:55:50.514441: predicting ISIC_0013808
2023-09-06 16:55:50.651527: predicting ISIC_0013815
2023-09-06 16:55:50.788719: predicting ISIC_0013816
2023-09-06 16:55:50.926916: predicting ISIC_0013817
2023-09-06 16:55:51.073303: predicting ISIC_0013819
2023-09-06 16:55:51.216539: predicting ISIC_0013828
2023-09-06 16:55:51.357768: predicting ISIC_0013830
2023-09-06 16:55:51.495903: predicting ISIC_0013831
2023-09-06 16:55:51.635389: predicting ISIC_0013832
2023-09-06 16:55:51.785610: predicting ISIC_0013835
2023-09-06 16:55:51.930894: predicting ISIC_0013836
2023-09-06 16:55:52.087952: predicting ISIC_0013837
2023-09-06 16:55:52.223156: predicting ISIC_0013839
2023-09-06 16:55:52.362778: predicting ISIC_0013840
2023-09-06 16:55:52.498395: predicting ISIC_0013841
2023-09-06 16:55:52.633187: predicting ISIC_0013843
2023-09-06 16:55:52.764961: predicting ISIC_0013844
2023-09-06 16:55:52.896789: predicting ISIC_0013845
2023-09-06 16:55:53.029478: predicting ISIC_0013861
2023-09-06 16:55:53.160839: predicting ISIC_0013862
2023-09-06 16:55:53.295816: predicting ISIC_0013863
2023-09-06 16:55:53.429065: predicting ISIC_0013864
2023-09-06 16:55:53.559935: predicting ISIC_0013865
2023-09-06 16:55:53.691714: predicting ISIC_0013874
2023-09-06 16:55:53.823069: predicting ISIC_0013876
2023-09-06 16:55:53.955008: predicting ISIC_0013879
2023-09-06 16:55:54.094653: predicting ISIC_0013886
2023-09-06 16:55:54.230772: predicting ISIC_0013888
2023-09-06 16:55:54.366993: predicting ISIC_0013890
2023-09-06 16:55:54.501317: predicting ISIC_0013896
2023-09-06 16:55:54.640942: predicting ISIC_0013898
2023-09-06 16:55:54.798173: predicting ISIC_0013910
2023-09-06 16:55:54.936960: predicting ISIC_0013918
2023-09-06 16:55:55.070220: predicting ISIC_0013921
2023-09-06 16:55:55.203802: predicting ISIC_0013922
2023-09-06 16:55:55.339929: predicting ISIC_0013927
2023-09-06 16:55:55.478196: predicting ISIC_0013929
2023-09-06 16:55:55.616174: predicting ISIC_0013933
2023-09-06 16:55:55.752226: predicting ISIC_0013935
2023-09-06 16:55:55.888428: predicting ISIC_0013936
2023-09-06 16:55:56.023053: predicting ISIC_0013942
2023-09-06 16:55:56.159256: predicting ISIC_0013945
2023-09-06 16:55:56.295190: predicting ISIC_0013946
2023-09-06 16:55:56.430871: predicting ISIC_0013958
2023-09-06 16:55:56.566660: predicting ISIC_0013961
2023-09-06 16:55:56.699970: predicting ISIC_0013962
2023-09-06 16:55:56.831808: predicting ISIC_0013965
2023-09-06 16:55:56.965350: predicting ISIC_0013967
2023-09-06 16:55:57.099071: predicting ISIC_0013969
2023-09-06 16:55:57.234796: predicting ISIC_0013970
2023-09-06 16:55:57.371257: predicting ISIC_0013971
2023-09-06 16:55:57.503630: predicting ISIC_0013972
2023-09-06 16:55:57.635554: predicting ISIC_0013975
2023-09-06 16:55:57.768606: predicting ISIC_0013980
2023-09-06 16:55:57.903320: predicting ISIC_0013981
2023-09-06 16:55:58.035025: predicting ISIC_0013982
2023-09-06 16:55:58.169406: predicting ISIC_0013983
2023-09-06 16:55:58.300468: predicting ISIC_0013984
2023-09-06 16:55:58.432095: predicting ISIC_0013986
2023-09-06 16:55:58.567276: predicting ISIC_0013995
2023-09-06 16:55:58.702031: predicting ISIC_0013996
2023-09-06 16:55:58.833512: predicting ISIC_0013997
2023-09-06 16:55:58.965649: predicting ISIC_0014001
2023-09-06 16:55:59.097376: predicting ISIC_0014004
2023-09-06 16:55:59.228975: predicting ISIC_0014013
2023-09-06 16:55:59.369081: predicting ISIC_0014026
2023-09-06 16:55:59.511803: predicting ISIC_0014028
2023-09-06 16:55:59.647008: predicting ISIC_0014029
2023-09-06 16:55:59.784103: predicting ISIC_0014031
2023-09-06 16:55:59.919227: predicting ISIC_0014032
2023-09-06 16:56:00.053862: predicting ISIC_0014037
2023-09-06 16:56:00.192940: predicting ISIC_0014038
2023-09-06 16:56:00.327441: predicting ISIC_0014044
2023-09-06 16:56:00.464113: predicting ISIC_0014045
2023-09-06 16:56:00.598506: predicting ISIC_0014046
2023-09-06 16:56:00.735397: predicting ISIC_0014049
2023-09-06 16:56:00.876585: predicting ISIC_0014055
2023-09-06 16:56:01.018456: predicting ISIC_0014061
2023-09-06 16:56:01.159453: predicting ISIC_0014062
2023-09-06 16:56:01.304989: predicting ISIC_0014066
2023-09-06 16:56:01.446346: predicting ISIC_0014069
2023-09-06 16:56:01.609993: predicting ISIC_0014072
2023-09-06 16:56:01.763871: predicting ISIC_0014073
2023-09-06 16:56:01.911855: predicting ISIC_0014074
2023-09-06 16:56:02.056182: predicting ISIC_0014076
2023-09-06 16:56:02.202499: predicting ISIC_0014079
2023-09-06 16:56:02.340410: predicting ISIC_0014080
2023-09-06 16:56:02.481835: predicting ISIC_0014081
2023-09-06 16:56:02.617752: predicting ISIC_0014082
2023-09-06 16:56:02.753323: predicting ISIC_0014083
2023-09-06 16:56:02.887864: predicting ISIC_0014088
2023-09-06 16:56:03.019252: predicting ISIC_0014089
2023-09-06 16:56:03.157252: predicting ISIC_0014092
2023-09-06 16:56:03.291029: predicting ISIC_0014093
2023-09-06 16:56:03.423609: predicting ISIC_0014094
2023-09-06 16:56:03.556024: predicting ISIC_0014099
2023-09-06 16:56:03.696970: predicting ISIC_0014108
2023-09-06 16:56:03.837857: predicting ISIC_0014114
2023-09-06 16:56:03.980290: predicting ISIC_0014120
2023-09-06 16:56:04.120429: predicting ISIC_0014127
2023-09-06 16:56:04.264121: predicting ISIC_0014131
2023-09-06 16:56:04.403988: predicting ISIC_0014132
2023-09-06 16:56:04.539231: predicting ISIC_0014133
2023-09-06 16:56:04.683196: predicting ISIC_0014136
2023-09-06 16:56:04.817694: predicting ISIC_0014139
2023-09-06 16:56:04.952515: predicting ISIC_0014144
2023-09-06 16:56:05.084691: predicting ISIC_0014149
2023-09-06 16:56:05.214768: predicting ISIC_0014150
2023-09-06 16:56:05.346032: predicting ISIC_0014151
2023-09-06 16:56:05.476561: predicting ISIC_0014156
2023-09-06 16:56:05.606817: predicting ISIC_0014157
2023-09-06 16:56:05.738821: predicting ISIC_0014158
2023-09-06 16:56:05.868749: predicting ISIC_0014162
2023-09-06 16:56:05.998025: predicting ISIC_0014163
2023-09-06 16:56:06.129337: predicting ISIC_0014164
2023-09-06 16:56:06.266192: predicting ISIC_0014166
2023-09-06 16:56:06.401844: predicting ISIC_0014169
2023-09-06 16:56:06.533403: predicting ISIC_0014171
2023-09-06 16:56:06.663430: predicting ISIC_0014173
2023-09-06 16:56:06.791211: predicting ISIC_0014174
2023-09-06 16:56:06.923324: predicting ISIC_0014178
2023-09-06 16:56:07.060769: predicting ISIC_0014179
2023-09-06 16:56:07.196133: predicting ISIC_0014183
2023-09-06 16:56:07.342359: predicting ISIC_0014185
2023-09-06 16:56:07.483622: predicting ISIC_0014187
2023-09-06 16:56:07.618467: predicting ISIC_0014189
2023-09-06 16:56:07.777278: predicting ISIC_0014190
2023-09-06 16:56:07.925806: predicting ISIC_0014191
2023-09-06 16:56:08.064427: predicting ISIC_0014195
2023-09-06 16:56:08.200232: predicting ISIC_0014197
2023-09-06 16:56:08.337303: predicting ISIC_0014211
2023-09-06 16:56:08.487810: predicting ISIC_0014212
2023-09-06 16:56:08.628056: predicting ISIC_0014216
2023-09-06 16:56:08.765600: predicting ISIC_0014217
2023-09-06 16:56:08.901947: predicting ISIC_0014222
2023-09-06 16:56:09.038673: predicting ISIC_0014225
2023-09-06 16:56:09.175138: predicting ISIC_0014229
2023-09-06 16:56:09.318149: predicting ISIC_0014238
2023-09-06 16:56:09.455192: predicting ISIC_0014248
2023-09-06 16:56:09.592546: predicting ISIC_0014249
2023-09-06 16:56:09.727722: predicting ISIC_0014253
2023-09-06 16:56:09.860758: predicting ISIC_0014263
2023-09-06 16:56:09.993958: predicting ISIC_0014264
2023-09-06 16:56:10.128006: predicting ISIC_0014272
2023-09-06 16:56:10.265570: predicting ISIC_0014273
2023-09-06 16:56:10.398217: predicting ISIC_0014274
2023-09-06 16:56:10.531431: predicting ISIC_0014286
2023-09-06 16:56:10.664333: predicting ISIC_0014289
2023-09-06 16:56:10.796082: predicting ISIC_0014290
2023-09-06 16:56:10.928049: predicting ISIC_0014291
2023-09-06 16:56:11.059685: predicting ISIC_0014299
2023-09-06 16:56:11.190957: predicting ISIC_0014302
2023-09-06 16:56:11.320412: predicting ISIC_0014308
2023-09-06 16:56:11.447486: predicting ISIC_0014310
2023-09-06 16:56:11.578737: predicting ISIC_0014311
2023-09-06 16:56:11.717818: predicting ISIC_0014316
2023-09-06 16:56:11.849127: predicting ISIC_0014317
2023-09-06 16:56:11.980708: predicting ISIC_0014324
2023-09-06 16:56:12.116121: predicting ISIC_0014325
2023-09-06 16:56:12.247899: predicting ISIC_0014327
2023-09-06 16:56:12.390054: predicting ISIC_0014328
2023-09-06 16:56:12.526669: predicting ISIC_0014331
2023-09-06 16:56:12.677181: predicting ISIC_0014337
2023-09-06 16:56:12.822967: predicting ISIC_0014341
2023-09-06 16:56:12.958111: predicting ISIC_0014346
2023-09-06 16:56:13.093642: predicting ISIC_0014347
2023-09-06 16:56:13.230130: predicting ISIC_0014353
2023-09-06 16:56:13.362731: predicting ISIC_0014357
2023-09-06 16:56:13.497891: predicting ISIC_0014360
2023-09-06 16:56:13.631005: predicting ISIC_0014361
2023-09-06 16:56:13.763967: predicting ISIC_0014365
2023-09-06 16:56:13.911840: predicting ISIC_0014366
2023-09-06 16:56:14.050215: predicting ISIC_0014372
2023-09-06 16:56:14.187427: predicting ISIC_0014382
2023-09-06 16:56:14.322298: predicting ISIC_0014385
2023-09-06 16:56:14.458514: predicting ISIC_0014393
2023-09-06 16:56:14.595423: predicting ISIC_0014394
2023-09-06 16:56:14.730484: predicting ISIC_0014395
2023-09-06 16:56:14.868401: predicting ISIC_0014397
2023-09-06 16:56:15.000844: predicting ISIC_0014410
2023-09-06 16:56:15.132174: predicting ISIC_0014422
2023-09-06 16:56:15.264730: predicting ISIC_0014428
2023-09-06 16:56:15.399040: predicting ISIC_0014430
2023-09-06 16:56:15.531754: predicting ISIC_0014431
2023-09-06 16:56:15.663633: predicting ISIC_0014432
2023-09-06 16:56:15.798504: predicting ISIC_0014433
2023-09-06 16:56:15.927461: predicting ISIC_0014438
2023-09-06 16:56:16.056378: predicting ISIC_0014440
2023-09-06 16:56:16.186410: predicting ISIC_0014441
2023-09-06 16:56:16.316654: predicting ISIC_0014453
2023-09-06 16:56:16.448615: predicting ISIC_0014458
2023-09-06 16:56:16.580033: predicting ISIC_0014469
2023-09-06 16:56:16.714768: predicting ISIC_0014473
2023-09-06 16:56:16.849547: predicting ISIC_0014475
2023-09-06 16:56:16.987840: predicting ISIC_0014476
2023-09-06 16:56:17.122992: predicting ISIC_0014480
2023-09-06 16:56:17.258759: predicting ISIC_0014486
2023-09-06 16:56:17.394112: predicting ISIC_0014490
2023-09-06 16:56:17.531481: predicting ISIC_0014498
2023-09-06 16:56:17.672561: predicting ISIC_0014501
2023-09-06 16:56:17.812100: predicting ISIC_0014502
2023-09-06 16:56:17.945498: predicting ISIC_0014504
2023-09-06 16:56:18.076921: predicting ISIC_0014507
2023-09-06 16:56:18.206639: predicting ISIC_0014511
2023-09-06 16:56:18.337269: predicting ISIC_0014515
2023-09-06 16:56:18.476821: predicting ISIC_0014516
2023-09-06 16:56:18.613816: predicting ISIC_0014518
2023-09-06 16:56:18.753108: predicting ISIC_0014522
2023-09-06 16:56:18.889954: predicting ISIC_0014525
2023-09-06 16:56:19.024154: predicting ISIC_0014526
2023-09-06 16:56:19.164365: predicting ISIC_0014527
2023-09-06 16:56:19.305552: predicting ISIC_0014529
2023-09-06 16:56:19.445945: predicting ISIC_0014535
2023-09-06 16:56:19.581401: predicting ISIC_0014537
2023-09-06 16:56:19.715344: predicting ISIC_0014543
2023-09-06 16:56:19.854003: predicting ISIC_0014545
2023-09-06 16:56:19.988363: predicting ISIC_0014547
2023-09-06 16:56:20.117680: predicting ISIC_0014554
2023-09-06 16:56:20.249081: predicting ISIC_0014557
2023-09-06 16:56:20.381644: predicting ISIC_0014558
2023-09-06 16:56:20.514578: predicting ISIC_0014568
2023-09-06 16:56:20.647954: predicting ISIC_0014569
2023-09-06 16:56:20.790947: predicting ISIC_0014570
2023-09-06 16:56:20.927605: predicting ISIC_0014571
2023-09-06 16:56:21.065834: predicting ISIC_0014572
2023-09-06 16:56:21.200962: predicting ISIC_0014573
2023-09-06 16:56:21.338732: predicting ISIC_0014576
2023-09-06 16:56:21.483670: predicting ISIC_0014577
2023-09-06 16:56:21.625429: predicting ISIC_0014578
2023-09-06 16:56:21.765294: predicting ISIC_0014579
2023-09-06 16:56:21.901834: predicting ISIC_0014580
2023-09-06 16:56:22.034777: predicting ISIC_0014581
2023-09-06 16:56:22.170437: predicting ISIC_0014582
2023-09-06 16:56:22.309522: predicting ISIC_0014583
2023-09-06 16:56:22.451301: predicting ISIC_0014585
2023-09-06 16:56:22.586673: predicting ISIC_0014589
2023-09-06 16:56:22.723229: predicting ISIC_0014591
2023-09-06 16:56:22.854551: predicting ISIC_0014592
2023-09-06 16:56:22.994693: predicting ISIC_0014593
2023-09-06 16:56:23.131715: predicting ISIC_0014594
2023-09-06 16:56:23.269504: predicting ISIC_0014595
2023-09-06 16:56:23.405969: predicting ISIC_0014596
2023-09-06 16:56:23.542398: predicting ISIC_0014597
2023-09-06 16:56:23.676690: predicting ISIC_0014598
2023-09-06 16:56:23.811285: predicting ISIC_0014599
2023-09-06 16:56:23.948514: predicting ISIC_0014601
2023-09-06 16:56:24.082585: predicting ISIC_0014602
2023-09-06 16:56:24.213117: predicting ISIC_0014603
2023-09-06 16:56:24.344696: predicting ISIC_0014605
2023-09-06 16:56:24.474220: predicting ISIC_0014606
2023-09-06 16:56:24.605141: predicting ISIC_0014607
2023-09-06 16:56:24.736181: predicting ISIC_0014608
2023-09-06 16:56:24.867674: predicting ISIC_0014609
2023-09-06 16:56:25.000133: predicting ISIC_0014610
2023-09-06 16:56:25.130749: predicting ISIC_0014611
2023-09-06 16:56:25.261091: predicting ISIC_0014612
2023-09-06 16:56:25.392435: predicting ISIC_0014613
2023-09-06 16:56:25.523983: predicting ISIC_0014615
2023-09-06 16:56:25.654822: predicting ISIC_0014616
2023-09-06 16:56:25.783518: predicting ISIC_0014617
2023-09-06 16:56:25.913253: predicting ISIC_0014618
2023-09-06 16:56:26.051346: predicting ISIC_0014620
2023-09-06 16:56:26.188603: predicting ISIC_0014621
2023-09-06 16:56:26.325015: predicting ISIC_0014622
2023-09-06 16:56:26.461624: predicting ISIC_0014623
2023-09-06 16:56:26.595413: predicting ISIC_0014624
2023-09-06 16:56:26.734003: predicting ISIC_0014625
2023-09-06 16:56:26.874092: predicting ISIC_0014628
2023-09-06 16:56:27.008110: predicting ISIC_0014630
2023-09-06 16:56:27.140260: predicting ISIC_0014632
2023-09-06 16:56:27.270908: predicting ISIC_0014633
2023-09-06 16:56:27.401555: predicting ISIC_0014635
2023-09-06 16:56:27.536928: predicting ISIC_0014636
2023-09-06 16:56:27.668231: predicting ISIC_0014637
2023-09-06 16:56:27.799546: predicting ISIC_0014638
2023-09-06 16:56:27.931804: predicting ISIC_0014639
2023-09-06 16:56:28.072947: predicting ISIC_0014640
2023-09-06 16:56:28.204764: predicting ISIC_0014641
2023-09-06 16:56:28.343799: predicting ISIC_0014642
2023-09-06 16:56:28.479514: predicting ISIC_0014646
2023-09-06 16:56:28.613437: predicting ISIC_0014650
2023-09-06 16:56:28.747437: predicting ISIC_0014651
2023-09-06 16:56:28.883111: predicting ISIC_0014654
2023-09-06 16:56:29.015708: predicting ISIC_0014657
2023-09-06 16:56:29.152817: predicting ISIC_0014658
2023-09-06 16:56:29.287106: predicting ISIC_0014661
2023-09-06 16:56:29.418089: predicting ISIC_0014664
2023-09-06 16:56:29.548505: predicting ISIC_0014665
2023-09-06 16:56:29.681204: predicting ISIC_0014667
2023-09-06 16:56:29.814018: predicting ISIC_0014680
2023-09-06 16:56:29.947140: predicting ISIC_0014682
2023-09-06 16:56:30.083278: predicting ISIC_0014683
2023-09-06 16:56:30.218394: predicting ISIC_0014684
2023-09-06 16:56:30.350954: predicting ISIC_0014685
2023-09-06 16:56:30.483593: predicting ISIC_0014688
2023-09-06 16:56:30.619652: predicting ISIC_0014692
2023-09-06 16:56:30.752300: predicting ISIC_0014694
2023-09-06 16:56:30.883290: predicting ISIC_0014696
2023-09-06 16:56:31.021343: predicting ISIC_0014699
2023-09-06 16:56:31.155586: predicting ISIC_0014702
2023-09-06 16:56:31.294466: predicting ISIC_0014707
2023-09-06 16:56:31.430805: predicting ISIC_0014708
2023-09-06 16:56:31.564049: predicting ISIC_0014711
2023-09-06 16:56:31.695799: predicting ISIC_0014712
2023-09-06 16:56:31.828098: predicting ISIC_0014713
2023-09-06 16:56:31.960870: predicting ISIC_0014714
2023-09-06 16:56:32.099692: predicting ISIC_0014715
2023-09-06 16:56:32.239993: predicting ISIC_0014716
2023-09-06 16:56:32.378357: predicting ISIC_0014722
2023-09-06 16:56:32.514663: predicting ISIC_0014723
2023-09-06 16:56:32.650552: predicting ISIC_0014724
2023-09-06 16:56:32.785053: predicting ISIC_0014726
2023-09-06 16:56:32.922260: predicting ISIC_0014730
2023-09-06 16:56:33.054249: predicting ISIC_0014731
2023-09-06 16:56:33.187613: predicting ISIC_0014735
2023-09-06 16:56:33.318599: predicting ISIC_0014739
2023-09-06 16:56:33.451190: predicting ISIC_0014742
2023-09-06 16:56:33.584728: predicting ISIC_0014745
2023-09-06 16:56:33.718031: predicting ISIC_0014748
2023-09-06 16:56:33.849318: predicting ISIC_0014754
2023-09-06 16:56:33.980798: predicting ISIC_0014760
2023-09-06 16:56:34.111585: predicting ISIC_0014762
2023-09-06 16:56:34.244608: predicting ISIC_0014763
2023-09-06 16:56:34.385759: predicting ISIC_0014769
2023-09-06 16:56:34.524014: predicting ISIC_0014770
2023-09-06 16:56:34.660536: predicting ISIC_0014771
2023-09-06 16:56:34.796668: predicting ISIC_0014775
2023-09-06 16:56:34.933733: predicting ISIC_0014778
2023-09-06 16:56:35.068946: predicting ISIC_0014779
2023-09-06 16:56:35.210638: predicting ISIC_0014782
2023-09-06 16:56:35.346589: predicting ISIC_0014783
2023-09-06 16:56:35.479407: predicting ISIC_0014785
2023-09-06 16:56:35.613771: predicting ISIC_0014788
2023-09-06 16:56:35.748130: predicting ISIC_0014791
2023-09-06 16:56:35.882577: predicting ISIC_0014793
2023-09-06 16:56:36.017118: predicting ISIC_0014794
2023-09-06 16:56:36.149265: predicting ISIC_0014795
2023-09-06 16:56:36.287339: predicting ISIC_0014797
2023-09-06 16:56:36.419107: predicting ISIC_0014802
2023-09-06 16:56:36.549033: predicting ISIC_0014803
2023-09-06 16:56:36.688462: predicting ISIC_0014804
2023-09-06 16:56:36.825788: predicting ISIC_0014805
2023-09-06 16:56:36.968562: predicting ISIC_0014806
2023-09-06 16:56:37.104206: predicting ISIC_0014808
2023-09-06 16:56:37.238558: predicting ISIC_0014809
2023-09-06 16:56:37.372752: predicting ISIC_0014811
2023-09-06 16:56:37.505546: predicting ISIC_0014812
2023-09-06 16:56:37.638185: predicting ISIC_0014818
2023-09-06 16:56:37.774137: predicting ISIC_0014819
2023-09-06 16:56:37.905918: predicting ISIC_0014821
2023-09-06 16:56:38.038501: predicting ISIC_0014823
2023-09-06 16:56:38.171622: predicting ISIC_0014825
2023-09-06 16:56:38.303432: predicting ISIC_0014829
2023-09-06 16:56:38.436877: predicting ISIC_0014830
2023-09-06 16:56:38.569968: predicting ISIC_0014831
2023-09-06 16:56:38.701963: predicting ISIC_0014832
2023-09-06 16:56:38.834555: predicting ISIC_0014834
2023-09-06 16:56:38.969503: predicting ISIC_0014836
2023-09-06 16:56:39.103308: predicting ISIC_0014838
2023-09-06 16:56:39.234299: predicting ISIC_0014839
2023-09-06 16:56:39.367075: predicting ISIC_0014843
2023-09-06 16:56:39.497111: predicting ISIC_0014845
2023-09-06 16:56:39.630898: predicting ISIC_0014846
2023-09-06 16:56:39.763413: predicting ISIC_0014848
2023-09-06 16:56:39.897936: predicting ISIC_0014849
2023-09-06 16:56:40.030809: predicting ISIC_0014850
2023-09-06 16:56:40.162280: predicting ISIC_0014851
2023-09-06 16:56:40.292990: predicting ISIC_0014855
2023-09-06 16:56:40.425471: predicting ISIC_0014857
2023-09-06 16:56:40.564246: predicting ISIC_0014860
2023-09-06 16:56:40.697521: predicting ISIC_0014866
2023-09-06 16:56:40.830100: predicting ISIC_0014869
2023-09-06 16:56:40.964742: predicting ISIC_0014890
2023-09-06 16:56:41.102379: predicting ISIC_0014891
2023-09-06 16:56:41.245469: predicting ISIC_0014897
2023-09-06 16:56:41.385812: predicting ISIC_0014898
2023-09-06 16:56:41.520667: predicting ISIC_0014903
2023-09-06 16:56:41.654318: predicting ISIC_0014904
2023-09-06 16:56:41.790219: predicting ISIC_0014908
2023-09-06 16:56:41.923542: predicting ISIC_0014911
2023-09-06 16:56:42.065099: predicting ISIC_0014913
2023-09-06 16:56:42.203362: predicting ISIC_0014915
2023-09-06 16:56:42.339979: predicting ISIC_0014919
2023-09-06 16:56:42.480046: predicting ISIC_0014920
2023-09-06 16:56:42.616961: predicting ISIC_0014922
2023-09-06 16:56:42.750307: predicting ISIC_0014923
2023-09-06 16:56:42.885099: predicting ISIC_0014925
2023-09-06 16:56:43.017523: predicting ISIC_0014926
2023-09-06 16:56:43.150722: predicting ISIC_0014929
2023-09-06 16:56:43.282491: predicting ISIC_0014930
2023-09-06 16:56:43.411815: predicting ISIC_0014931
2023-09-06 16:56:43.543154: predicting ISIC_0014933
2023-09-06 16:56:43.675902: predicting ISIC_0014937
2023-09-06 16:56:43.805764: predicting ISIC_0014945
2023-09-06 16:56:43.936856: predicting ISIC_0014946
2023-09-06 16:56:44.070295: predicting ISIC_0014951
2023-09-06 16:56:44.200626: predicting ISIC_0014975
2023-09-06 16:56:44.332211: predicting ISIC_0014979
2023-09-06 16:56:44.464488: predicting ISIC_0014983
2023-09-06 16:56:44.594993: predicting ISIC_0014985
2023-09-06 16:56:44.726219: predicting ISIC_0014987
2023-09-06 16:56:44.858438: predicting ISIC_0014989
2023-09-06 16:56:44.989887: predicting ISIC_0015005
2023-09-06 16:56:45.131781: predicting ISIC_0015006
2023-09-06 16:56:45.267947: predicting ISIC_0015032
2023-09-06 16:56:45.402771: predicting ISIC_0015038
2023-09-06 16:56:45.536348: predicting ISIC_0015043
2023-09-06 16:56:45.670511: predicting ISIC_0015044
2023-09-06 16:56:45.807222: predicting ISIC_0015045
2023-09-06 16:56:45.942714: predicting ISIC_0015062
2023-09-06 16:56:46.077479: predicting ISIC_0015079
2023-09-06 16:56:46.210003: predicting ISIC_0015082
2023-09-06 16:56:46.340328: predicting ISIC_0015108
2023-09-06 16:56:46.475479: predicting ISIC_0015109
2023-09-06 16:56:46.607998: predicting ISIC_0015110
2023-09-06 16:56:46.739174: predicting ISIC_0015112
2023-09-06 16:56:46.871580: predicting ISIC_0015113
2023-09-06 16:56:47.003051: predicting ISIC_0015124
2023-09-06 16:56:47.132096: predicting ISIC_0015144
2023-09-06 16:56:47.264951: predicting ISIC_0015153
2023-09-06 16:56:47.398134: predicting ISIC_0015158
2023-09-06 16:56:47.529324: predicting ISIC_0015166
2023-09-06 16:56:47.660449: predicting ISIC_0015168
2023-09-06 16:56:47.795627: predicting ISIC_0015170
2023-09-06 16:56:47.927085: predicting ISIC_0015181
2023-09-06 16:56:48.058659: predicting ISIC_0015182
2023-09-06 16:56:48.189772: predicting ISIC_0015189
2023-09-06 16:56:48.320349: predicting ISIC_0015190
2023-09-06 16:56:48.449933: predicting ISIC_0015200
2023-09-06 16:56:48.581742: predicting ISIC_0015204
2023-09-06 16:56:48.712020: predicting ISIC_0015211
2023-09-06 16:56:48.840433: predicting ISIC_0015219
2023-09-06 16:56:48.972130: predicting ISIC_0015220
2023-09-06 16:56:49.103224: predicting ISIC_0015233
2023-09-06 16:56:49.234350: predicting ISIC_0015243
2023-09-06 16:56:49.363931: predicting ISIC_0015256
2023-09-06 16:56:49.492564: predicting ISIC_0015260
2023-09-06 16:56:49.625927: predicting ISIC_0015284
2023-09-06 16:56:49.756434: predicting ISIC_0015295
2023-09-06 16:56:49.890041: predicting ISIC_0015313
2023-09-06 16:56:50.019604: predicting ISIC_0015372
2023-09-06 16:56:50.150135: predicting ISIC_0015401
2023-09-06 16:56:50.281124: predicting ISIC_0015443
2023-09-06 16:56:50.419248: predicting ISIC_0015445
2023-09-06 16:56:50.554538: predicting ISIC_0015483
2023-09-06 16:56:50.687689: predicting ISIC_0015496
2023-09-06 16:56:50.822226: predicting ISIC_0015627
2023-09-06 16:57:01.377406: Validation complete
2023-09-06 16:57:01.379351: Mean Validation Dice:  0.8824869209428544
