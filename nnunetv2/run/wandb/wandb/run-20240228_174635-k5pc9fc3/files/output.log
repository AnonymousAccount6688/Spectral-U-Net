<class 'nnunetv2.training.network.model.waveunet.brain_wave_unet.WaveUNet'>
============<class 'nnunetv2.training.network.model.waveunet.brain_wave_unet.WaveUNet'>=============
lr: 0.01
ds wegihts: [0.50793651 0.25396825 0.12698413 0.06349206 0.03174603 0.01587302]
This is the configuration used by this training:
Configuration name: 2d
 {'data_identifier': 'nnUNetPlans_2d', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 105, 'patch_size': [192, 160], 'median_image_size_in_voxels': [169.0, 138.0], 'spacing': [1.0, 1.0], 'normalization_schemes': ['ZScoreNormalization', 'ZScoreNormalization', 'ZScoreNormalization', 'ZScoreNormalization'], 'use_mask_for_norm': [True, True, True, True], 'UNet_class_name': 'PlainConvUNet', 'UNet_base_num_features': 32, 'n_conv_per_stage_encoder': [2, 2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2, 2], 'num_pool_per_axis': [5, 5], 'pool_op_kernel_sizes': [[1, 1], [2, 2], [2, 2], [2, 2], [2, 2], [2, 2]], 'conv_kernel_sizes': [[3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3]], 'unet_max_num_features': 512, 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'batch_dice': True}
These are the global plan.json settings:
 {'dataset_name': 'Dataset201_BrainTumour', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [1.0, 1.0, 1.0], 'original_median_shape_after_transp': [138, 169, 138], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 5721.0, 'mean': 728.8666381835938, 'median': 779.0, 'min': 0.0, 'percentile_00_5': 104.0, 'percentile_99_5': 1733.0, 'std': 354.5618896484375}, '1': {'max': 8761.0, 'mean': 621.560791015625, 'median': 644.0, 'min': 0.0, 'percentile_00_5': 56.0, 'percentile_99_5': 2421.0, 'std': 335.946044921875}, '2': {'max': 9012.0, 'mean': 662.5552368164062, 'median': 639.0, 'min': 0.0, 'percentile_00_5': 44.0, 'percentile_99_5': 2963.0, 'std': 420.2735595703125}, '3': {'max': 3346.0, 'mean': 664.2885131835938, 'median': 647.0, 'min': 0.0, 'percentile_00_5': 103.0, 'percentile_99_5': 1997.0, 'std': 318.48980712890625}}}
2024-02-28 17:46:39.021120: unpacking dataset...
2024-02-28 17:46:51.836218: unpacking done...
2024-02-28 17:46:51.838852: do_dummy_2d_data_aug: False
2024-02-28 17:46:51.849249: Using splits from existing split file: /scratch365/ypeng4/data/preprocessed_data/Dataset201_BrainTumour/splits_final.json
2024-02-28 17:46:51.851713: The split file contains 5 splits.
2024-02-28 17:46:51.852708: Desired fold for training: 0
2024-02-28 17:46:51.853729: This split has 387 training and 97 validation cases.
==================batch size: 2===================
2024-02-28 17:46:51.949401: Unable to plot network architecture:
2024-02-28 17:46:51.950868: No module named 'hiddenlayer'
lr: 0.01
2024-02-28 17:46:52.005574:
2024-02-28 17:46:52.006775: Epoch 0
2024-02-28 17:46:52.007855: start training, 250
2024-02-28 17:46:52.009058: learning rate: 0.01
using pin_memory on device 0
2024-02-28 17:46:55.112876: finished training
2024-02-28 17:46:55.333038: Using splits from existing split file: /scratch365/ypeng4/data/preprocessed_data/Dataset201_BrainTumour/splits_final.json
2024-02-28 17:46:55.336566: The split file contains 5 splits.
2024-02-28 17:46:55.337930: Desired fold for training: 0
2024-02-28 17:46:55.339180: This split has 387 training and 97 validation cases.
